<html><head><title>CUDA Runtime API :: CUDA Toolkit Documentation</title></head><body><body>
 <span id="company">
  NVIDIA
 </span>
 <span id="site-title">
  CUDA Toolkit Documentation
 </span>
 Search In:
 Entire Site
 Just This Document
 clear search
 search
 <a href="https://docs.nvidia.com/cuda/index.html" title="The root of the site.">
  CUDA Toolkit 
                  
                  
                  v12.5.1
 </a>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html" title="CUDA Runtime API">
  CUDA Runtime API
 </a>
 <ul>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/driver-vs-runtime-api.html#driver-vs-runtime-api">
    1.Â Difference between the driver and runtime APIs
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior">
    2.Â API synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior">
    3.Â Stream synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/graphs-thread-safety.html#graphs-thread-safety">
    4.Â Graph object thread safety
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/version-mixing-rules.html#version-mixing-rules">
    5.Â Rules for version mixing
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/modules.html#modules">
    6.Â Modules
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE">
      6.1.Â Device Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE__DEPRECATED.html#group__CUDART__DEVICE__DEPRECATED">
      6.2.Â Device Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__THREAD__DEPRECATED.html#group__CUDART__THREAD__DEPRECATED">
      6.3.Â Thread Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html#group__CUDART__ERROR">
      6.4.Â Error Handling
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM">
      6.5.Â Stream Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT">
      6.6.Â Event Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP">
      6.7.Â External Resource Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION">
      6.8.Â Execution Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html#group__CUDART__EXECUTION__DEPRECATED">
      6.9.Â Execution Control [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY">
      6.10.Â Occupancy
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY">
      6.11.Â Memory Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__DEPRECATED.html#group__CUDART__MEMORY__DEPRECATED">
      6.12.Â Memory Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS">
      6.13.Â Stream Ordered Memory Allocator
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__UNIFIED.html#group__CUDART__UNIFIED">
      6.14.Â Unified Addressing
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER">
      6.15.Â Peer Device Memory Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL.html#group__CUDART__OPENGL">
      6.16.Â OpenGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL__DEPRECATED.html#group__CUDART__OPENGL__DEPRECATED">
      6.17.Â OpenGL Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9.html#group__CUDART__D3D9">
      6.18.Â Direct3D 9 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9__DEPRECATED.html#group__CUDART__D3D9__DEPRECATED">
      6.19.Â Direct3D 9 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10.html#group__CUDART__D3D10">
      6.20.Â Direct3D 10 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10__DEPRECATED.html#group__CUDART__D3D10__DEPRECATED">
      6.21.Â Direct3D 10 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11.html#group__CUDART__D3D11">
      6.22.Â Direct3D 11 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11__DEPRECATED.html#group__CUDART__D3D11__DEPRECATED">
      6.23.Â Direct3D 11 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__VDPAU.html#group__CUDART__VDPAU">
      6.24.Â VDPAU Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EGL.html#group__CUDART__EGL">
      6.25.Â EGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__INTEROP.html#group__CUDART__INTEROP">
      6.26.Â Graphics Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TEXTURE__OBJECT.html#group__CUDART__TEXTURE__OBJECT">
      6.27.Â Texture Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__SURFACE__OBJECT.html#group__CUDART__SURFACE__OBJECT">
      6.28.Â Surface Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART____VERSION.html#group__CUDART____VERSION">
      6.29.Â Version Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">
      6.30.Â Graph Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER__ENTRY__POINT.html#group__CUDART__DRIVER__ENTRY__POINT">
      6.31.Â Driver Entry Point Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL">
      6.32.Â C++ API Routines
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER.html#group__CUDART__DRIVER">
      6.33.Â Interactions with the CUDA Driver API
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER">
      6.34.Â Profiler Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES">
      6.35.Â Data types used by CUDA Runtime
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/annotated.html#annotated">
    7.Â Data Structures
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/class____cudaOccupancyB2DHelper.html#class____cudaOccupancyB2DHelper">
      7.1.Â __cudaOccupancyB2DHelper
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html#structcudaAccessPolicyWindow">
      7.2.Â cudaAccessPolicyWindow
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements">
      7.3.Â cudaArrayMemoryRequirements
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties">
      7.4.Â cudaArraySparseProperties
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAsyncNotificationInfo__t.html#structcudaAsyncNotificationInfo__t">
      7.5.Â cudaAsyncNotificationInfo_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc">
      7.6.Â cudaChannelFormatDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChildGraphNodeParams.html#structcudaChildGraphNodeParams">
      7.7.Â cudaChildGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaConditionalNodeParams.html#structcudaConditionalNodeParams">
      7.8.Â cudaConditionalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp">
      7.9.Â cudaDeviceProp
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglFrame.html#structcudaEglFrame">
      7.10.Â cudaEglFrame
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglPlaneDesc.html#structcudaEglPlaneDesc">
      7.11.Â cudaEglPlaneDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventRecordNodeParams.html#structcudaEventRecordNodeParams">
      7.12.Â cudaEventRecordNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventWaitNodeParams.html#structcudaEventWaitNodeParams">
      7.13.Â cudaEventWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent">
      7.14.Â cudaExtent
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryBufferDesc.html#structcudaExternalMemoryBufferDesc">
      7.15.Â cudaExternalMemoryBufferDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryHandleDesc.html#structcudaExternalMemoryHandleDesc">
      7.16.Â cudaExternalMemoryHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryMipmappedArrayDesc.html#structcudaExternalMemoryMipmappedArrayDesc">
      7.17.Â cudaExternalMemoryMipmappedArrayDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreHandleDesc.html#structcudaExternalSemaphoreHandleDesc">
      7.18.Â cudaExternalSemaphoreHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParams.html#structcudaExternalSemaphoreSignalNodeParams">
      7.19.Â cudaExternalSemaphoreSignalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParamsV2.html#structcudaExternalSemaphoreSignalNodeParamsV2">
      7.20.Â cudaExternalSemaphoreSignalNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams.html#structcudaExternalSemaphoreSignalParams">
      7.21.Â cudaExternalSemaphoreSignalParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams__v1.html#structcudaExternalSemaphoreSignalParams__v1">
      7.22.Â cudaExternalSemaphoreSignalParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParams.html#structcudaExternalSemaphoreWaitNodeParams">
      7.23.Â cudaExternalSemaphoreWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParamsV2.html#structcudaExternalSemaphoreWaitNodeParamsV2">
      7.24.Â cudaExternalSemaphoreWaitNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams.html#structcudaExternalSemaphoreWaitParams">
      7.25.Â cudaExternalSemaphoreWaitParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams__v1.html#structcudaExternalSemaphoreWaitParams__v1">
      7.26.Â cudaExternalSemaphoreWaitParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaFuncAttributes.html#structcudaFuncAttributes">
      7.27.Â cudaFuncAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphEdgeData.html#structcudaGraphEdgeData">
      7.28.Â cudaGraphEdgeData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphExecUpdateResultInfo.html#structcudaGraphExecUpdateResultInfo">
      7.29.Â cudaGraphExecUpdateResultInfo
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphInstantiateParams.html#structcudaGraphInstantiateParams">
      7.30.Â cudaGraphInstantiateParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphKernelNodeUpdate.html#structcudaGraphKernelNodeUpdate">
      7.31.Â cudaGraphKernelNodeUpdate
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphNodeParams.html#structcudaGraphNodeParams">
      7.32.Â cudaGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParams.html#structcudaHostNodeParams">
      7.33.Â cudaHostNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParamsV2.html#structcudaHostNodeParamsV2">
      7.34.Â cudaHostNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t">
      7.35.Â cudaIpcEventHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t">
      7.36.Â cudaIpcMemHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParams.html#structcudaKernelNodeParams">
      7.37.Â cudaKernelNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParamsV2.html#structcudaKernelNodeParamsV2">
      7.38.Â cudaKernelNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchAttribute.html#structcudaLaunchAttribute">
      7.39.Â cudaLaunchAttribute
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/unioncudaLaunchAttributeValue.html#unioncudaLaunchAttributeValue">
      7.40.Â cudaLaunchAttributeValue
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t">
      7.41.Â cudaLaunchConfig_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchMemSyncDomainMap.html#structcudaLaunchMemSyncDomainMap">
      7.42.Â cudaLaunchMemSyncDomainMap
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchParams.html#structcudaLaunchParams">
      7.43.Â cudaLaunchParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAccessDesc.html#structcudaMemAccessDesc">
      7.44.Â cudaMemAccessDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParams.html#structcudaMemAllocNodeParams">
      7.45.Â cudaMemAllocNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParamsV2.html#structcudaMemAllocNodeParamsV2">
      7.46.Â cudaMemAllocNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms">
      7.47.Â cudaMemcpy3DParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms">
      7.48.Â cudaMemcpy3DPeerParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpyNodeParams.html#structcudaMemcpyNodeParams">
      7.49.Â cudaMemcpyNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemFreeNodeParams.html#structcudaMemFreeNodeParams">
      7.50.Â cudaMemFreeNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation">
      7.51.Â cudaMemLocation
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps">
      7.52.Â cudaMemPoolProps
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData">
      7.53.Â cudaMemPoolPtrExportData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParams.html#structcudaMemsetParams">
      7.54.Â cudaMemsetParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParamsV2.html#structcudaMemsetParamsV2">
      7.55.Â cudaMemsetParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr">
      7.56.Â cudaPitchedPtr
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPointerAttributes.html#structcudaPointerAttributes">
      7.57.Â cudaPointerAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos">
      7.58.Â cudaPos
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceDesc.html#structcudaResourceDesc">
      7.59.Â cudaResourceDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceViewDesc.html#structcudaResourceViewDesc">
      7.60.Â cudaResourceViewDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaTextureDesc.html#structcudaTextureDesc">
      7.61.Â cudaTextureDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structCUuuid__st.html#structCUuuid__st">
      7.62.Â CUuuid_st
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/functions.html#functions">
    8.Â Data Fields
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated">
    9.Â Deprecated List
   </a>
  </li>
 </ul>
 <h2>
  Search Results
 </h2>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/modules.html" shape="rect">
  &lt; Previous
 </a>
 |
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE__DEPRECATED.html" shape="rect">
  Next &gt;
 </a>
 CUDA Runtime API
                  (
 <a href="https://docs.nvidia.com/cuda/pdf/CUDA_Runtime_API.pdf">
  PDF
 </a>
 )
                  -
                   
                  
                  
                  v12.5.1
                  (
 <a href="https://developer.nvidia.com/cuda-toolkit-archive">
  older
 </a>
 )
                  -
                  Last updated July 1, 2024
                  -
 <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA%20Toolkit%20Documentation%20Feedback:%20CUDA%20Runtime%20API">
  Send Feedback
 </a>
 <a name="group__CUDART__DEVICE" shape="rect">
  <!-- -->
 </a>
 <h2 class="topictitle2 cppModule">
  6.1.Â Device Management
 </h2>
 <p>
  This section describes the device management functions of the CUDA runtime application programming interface.
 </p>
 <h3 class="fake_sectiontitle member_header">
  Functions
 </h3>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect">
   cudaChooseDevice
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp" shape="rect" title="">
   cudaDeviceProp
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   prop
  </span>
  )
 </span>
 <span class="desc">
  Select compute-device which best matches criteria.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g3fc2853f4f30ce29019a8db822354d12" shape="rect">
   cudaDeviceFlushGPUDirectRDMAWrites
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g79b83831173a16801d2fb885b02e54a4" shape="rect" title="">
   cudaFlushGPUDirectRDMAWritesTarget
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   target
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1ed1a981bc94ef42e16f73c91faf8f1a" shape="rect" title="">
   cudaFlushGPUDirectRDMAWritesScope
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   scope
  </span>
  )
 </span>
 <span class="desc">
  Blocks until remote writes are visible to the specified scope.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect">
   cudaDeviceGetAttribute
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g49e2f8c2c0bd6fe264f2fc970912e5cd" shape="rect" title="">
   cudaDeviceAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns information about the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g65f57fb8d0981ca03f6f9b20031c3e5d" shape="rect">
   cudaDeviceGetByPCIBusId
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , const char*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pciBusId
  </span>
  )
 </span>
 <span class="desc">
  Returns a handle to a compute device.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gd9bf5eae6d464de05aa3840df9f5deeb" shape="rect">
   cudaDeviceGetCacheConfig
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gb980f35ed69ee7991704de29a13de49b" shape="rect" title="">
   cudaFuncCache
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pCacheConfig
  </span>
  )
 </span>
 <span class="desc">
  Returns the preferred cache configuration for the current device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect">
   cudaDeviceGetDefaultMemPool
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns the default mempool of a device.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g720e159aeb125910c22aa20fe9611ec2" shape="rect">
   cudaDeviceGetLimit
  </a>
  (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pValue
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4c4b34c054d383b0e9a63ab0ffc93651" shape="rect" title="">
   cudaLimit
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   limit
  </span>
  )
 </span>
 <span class="desc">
  Return resource limits.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect">
   cudaDeviceGetMemPool
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Gets the current mempool for a device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf70468b1bb3a7483d1cc393eb7301f2f" shape="rect">
   cudaDeviceGetNvSciSyncAttributes
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   nvSciSyncAttrList
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Return NvSciSync attributes that this device can support.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gc63e5bf168e53b2daf71904eab048fa9" shape="rect">
   cudaDeviceGetP2PAttribute
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2f597e2acceab33f60bd61c41fea0c1b" shape="rect" title="">
   cudaDeviceP2PAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   srcDevice
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  )
 </span>
 <span class="desc">
  Queries attributes of the link between two devices.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gea264dad3d8c4898e0b82213c0253def" shape="rect">
   cudaDeviceGetPCIBusId
  </a>
  (  char*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pciBusId
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   len
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns a PCI Bus Id string for the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gfdb79818f7c0ee7bc585648c91770275" shape="rect">
   cudaDeviceGetStreamPriorityRange
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   leastPriority
  </span>
  , int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   greatestPriority
  </span>
  )
 </span>
 <span class="desc">
  Returns numerical values that correspond to the least and greatest stream priorities.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g45f0345fd7a3697d0766596593920f61" shape="rect">
   cudaDeviceGetTexture1DLinearMaxWidth
  </a>
  (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   maxWidthInElements
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   fmtDesc
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns the maximum number of elements allocatable in a 1D linear texture for a given element size.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gcff9794f21aa34d3b5ccc5b6b245da4a" shape="rect">
   cudaDeviceRegisterAsyncNotification
  </a>
  (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , cudaAsyncCallback
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   callbackFunc
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   userData
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf5d1b31c73cce10a9ae82d3cc11157d2" shape="rect" title="">
   cudaAsyncCallbackHandle_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   callback
  </span>
  )
 </span>
 <span class="desc">
  Registers a callback function to receive async notifications.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" shape="rect">
   cudaDeviceReset
  </a>
  (  void )
 </span>
 <span class="desc">
  Destroy all allocations and reset all state on the current device in the current process.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g6c9cc78ca80490386cf593b4baa35a15" shape="rect">
   cudaDeviceSetCacheConfig
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gb980f35ed69ee7991704de29a13de49b" shape="rect" title="">
   cudaFuncCache
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   cacheConfig
  </span>
  )
 </span>
 <span class="desc">
  Sets the preferred cache configuration for the current device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d" shape="rect">
   cudaDeviceSetLimit
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4c4b34c054d383b0e9a63ab0ffc93651" shape="rect" title="">
   cudaLimit
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   limit
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  )
 </span>
 <span class="desc">
  Set resource limits.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect">
   cudaDeviceSetMemPool
  </a>
  (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  )
 </span>
 <span class="desc">
  Sets the current memory pool of a device.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect">
   cudaDeviceSynchronize
  </a>
  (  void )
 </span>
 <span class="desc">
  Wait for compute device to finish.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1geeeae22bfbfc38915ed9b7b58376e64d" shape="rect">
   cudaDeviceUnregisterAsyncNotification
  </a>
  (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf5d1b31c73cce10a9ae82d3cc11157d2" shape="rect" title="">
   cudaAsyncCallbackHandle_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   callback
  </span>
  )
 </span>
 <span class="desc">
  Unregisters an async notification callback.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect">
   cudaGetDevice
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns which device is currently being used.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect">
   cudaGetDeviceCount
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 <span class="desc">
  Returns the number of compute-capable devices.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" shape="rect">
   cudaGetDeviceFlags
  </a>
  (  unsigned int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Gets the flags for the current device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect">
   cudaGetDeviceProperties
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp" shape="rect" title="">
   cudaDeviceProp
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   prop
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns information about the compute-device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect">
   cudaInitDevice
  </a>
  (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   deviceFlags
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Initialize device to be used for GPU executions.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect">
   cudaIpcCloseMemHandle
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  )
 </span>
 <span class="desc">
  Attempts to close memory mapped with cudaIpcOpenMemHandle.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect">
   cudaIpcGetEventHandle
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t" shape="rect" title="">
   cudaIpcEventHandle_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gea2f543a9fc0e52fe4ae712920fd1247" shape="rect" title="">
   cudaEvent_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   event
  </span>
  )
 </span>
 <span class="desc">
  Gets an interprocess handle for a previously allocated event.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect">
   cudaIpcGetMemHandle
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t" shape="rect" title="">
   cudaIpcMemHandle_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  )
 </span>
 <span class="desc">
  Gets an interprocess memory handle for an existing device memory allocation.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect">
   cudaIpcOpenEventHandle
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gea2f543a9fc0e52fe4ae712920fd1247" shape="rect" title="">
   cudaEvent_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   event
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t" shape="rect" title="">
   cudaIpcEventHandle_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  )
 </span>
 <span class="desc">
  Opens an interprocess event handle for use in the current process.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect">
   cudaIpcOpenMemHandle
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t" shape="rect" title="">
   cudaIpcMemHandle_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect">
   cudaSetDevice
  </a>
  (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Set device to be used for GPU executions.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect">
   cudaSetDeviceFlags
  </a>
  (  unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Sets flags to be used for device executions.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1b9336c70f2299405f67a4f8496d7cfe" shape="rect">
   cudaSetValidDevices
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device_arr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   len
  </span>
  )
 </span>
 <span class="desc">
  Set a list of devices that can be used for CUDA.
 </span>
 <h3 class="sectiontitle">
  Functions
 </h3>
 <a id="group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" name="group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaChooseDevice (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp" shape="rect" title="">
   cudaDeviceProp
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   prop
  </span>
  )
 </span>
 Select compute-device which best matches criteria.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device with best match
 <span class="keyword keyword apiItemName">
  prop
 </span>
 - Desired device properties
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *device
  the device which has properties that best match
  *prop
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g3fc2853f4f30ce29019a8db822354d12" name="group__CUDART__DEVICE_1g3fc2853f4f30ce29019a8db822354d12" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceFlushGPUDirectRDMAWrites (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g79b83831173a16801d2fb885b02e54a4" shape="rect" title="">
   cudaFlushGPUDirectRDMAWritesTarget
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   target
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1ed1a981bc94ef42e16f73c91faf8f1a" shape="rect" title="">
   cudaFlushGPUDirectRDMAWritesScope
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   scope
  </span>
  )
 </span>
 Blocks until remote writes are visible to the specified scope.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  target
 </span>
 - The target of the operation, see cudaFlushGPUDirectRDMAWritesTarget
 <span class="keyword keyword apiItemName">
  scope
 </span>
 - The scope of the operation, see cudaFlushGPUDirectRDMAWritesScope
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Blocks until remote writes to the target context via mappings created through GPUDirect RDMA APIs, like nvidia_p2p_get_pages
                                 (see
  <a class="xref" href="https://docs.nvidia.com/cuda/gpudirect-rdma" shape="rect" target="_blank">
   https://docs.nvidia.com/cuda/gpudirect-rdma
  </a>
  for more information), are visible to the specified scope.
 </p>
 <p class="p">
  If the scope equals or lies within the scope indicated by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd881d5b0c5bf7777e382920af4d743bde" shape="rect">
   cudaDevAttrGPUDirectRDMAWritesOrdering
  </a>
  , the call will be a no-op and can be safely omitted for performance. This can be determined by comparing the numerical values
                                 between the two enums, with smaller scopes having smaller values.
 </p>
 <p class="p">
  Users may query support for this API via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd7b3462e13705248606f39fb5381446ee" shape="rect">
   cudaDevAttrGPUDirectRDMAFlushWritesOptions
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g265e3c82ef0f0fe035f85c4c45a8fbdf" shape="rect" target="_blank">
   cuFlushGPUDirectRDMAWrites
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" name="group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetAttribute (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g49e2f8c2c0bd6fe264f2fc970912e5cd" shape="rect" title="">
   cudaDeviceAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns information about the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Returned device attribute value
 <span class="keyword keyword apiItemName">
  attr
 </span>
 - Device attribute to query
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device number to query
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *value
  the integer value of the attribute
  attr
  on device
  device
  . The supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd08fbcb2d50dbfad988a6203170b10156" shape="rect">
     cudaDevAttrMaxThreadsPerBlock
    </a>
    : Maximum number of threads per block
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdf6d8420cf810d454284e7f6a702597f8" shape="rect">
     cudaDevAttrMaxBlockDimX
    </a>
    : Maximum x-dimension of a block
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0fdadc81fcef7969fc4c24260a582601" shape="rect">
     cudaDevAttrMaxBlockDimY
    </a>
    : Maximum y-dimension of a block
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde4a6ca644302689dbc6dd8a7a5fca03d" shape="rect">
     cudaDevAttrMaxBlockDimZ
    </a>
    : Maximum z-dimension of a block
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd744bfd226d491b299cf70ebabcab3757" shape="rect">
     cudaDevAttrMaxGridDimX
    </a>
    : Maximum x-dimension of a grid
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd28faa2a117810186bb90f3d5432bb70d" shape="rect">
     cudaDevAttrMaxGridDimY
    </a>
    : Maximum y-dimension of a grid
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd5bd31420dbad853642a42e69958c7cbc" shape="rect">
     cudaDevAttrMaxGridDimZ
    </a>
    : Maximum z-dimension of a grid
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdcf1490f9974e877131048b1b3eb8bdcc" shape="rect">
     cudaDevAttrMaxSharedMemoryPerBlock
    </a>
    : Maximum amount of shared memory available to a thread block in bytes
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdca216ef679ac7324567d35fb947f3e64" shape="rect">
     cudaDevAttrTotalConstantMemory
    </a>
    : Memory available on device for __constant__ variables in a CUDA C kernel in bytes
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd6bc392b398b9209d8a3431debec990fd" shape="rect">
     cudaDevAttrWarpSize
    </a>
    : Warp size in threads
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd7e7a9cf0ed2a239199d499ae5091f281" shape="rect">
     cudaDevAttrMaxPitch
    </a>
    : Maximum pitch in bytes allowed by the memory copy functions that involve memory regions allocated through
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
     cudaMallocPitch()
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd7bd81d5b47f5890da85f352862a8d33e" shape="rect">
     cudaDevAttrMaxTexture1DWidth
    </a>
    : Maximum 1D texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd1de34e923feff0673f3fce9131f42051" shape="rect">
     cudaDevAttrMaxTexture1DLinearWidth
    </a>
    : Maximum width for a 1D texture bound to linear memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdeda31a42f6e0adbffa52f0b1d352b4fa" shape="rect">
     cudaDevAttrMaxTexture1DMipmappedWidth
    </a>
    : Maximum mipmapped 1D texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb5d795b3f581056805544ef28511075d" shape="rect">
     cudaDevAttrMaxTexture2DWidth
    </a>
    : Maximum 2D texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdcf28c321f66908dc1ec9cb46d9ec59a5" shape="rect">
     cudaDevAttrMaxTexture2DHeight
    </a>
    : Maximum 2D texture height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd2fa1932b63870857f540b28e4444a02f" shape="rect">
     cudaDevAttrMaxTexture2DLinearWidth
    </a>
    : Maximum width for a 2D texture bound to linear memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd9e6b26ed4fa978295a706d536b6fd2d4" shape="rect">
     cudaDevAttrMaxTexture2DLinearHeight
    </a>
    : Maximum height for a 2D texture bound to linear memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdbd3b15e8d7f58f04c31873bef0cf117c" shape="rect">
     cudaDevAttrMaxTexture2DLinearPitch
    </a>
    : Maximum pitch in bytes for a 2D texture bound to linear memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde05045d1eba85ad27f416222c2d03ace" shape="rect">
     cudaDevAttrMaxTexture2DMipmappedWidth
    </a>
    : Maximum mipmapped 2D texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd3b6d9586385e9d6b86e0c6859fe570cd" shape="rect">
     cudaDevAttrMaxTexture2DMipmappedHeight
    </a>
    : Maximum mipmapped 2D texture height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cda0017a2ead91b03d1075c306aced933c" shape="rect">
     cudaDevAttrMaxTexture3DWidth
    </a>
    : Maximum 3D texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd14bced4c8e08e4ca35d1324a22476a5c" shape="rect">
     cudaDevAttrMaxTexture3DHeight
    </a>
    : Maximum 3D texture height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc2a1bce21302fee6da652e0afd92dfc0" shape="rect">
     cudaDevAttrMaxTexture3DDepth
    </a>
    : Maximum 3D texture depth
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdd1bffdc561f20553849b54e7ebbbde11" shape="rect">
     cudaDevAttrMaxTexture3DWidthAlt
    </a>
    : Alternate maximum 3D texture width, 0 if no alternate maximum 3D texture size is supported
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd289c6eb12fb79d51b9ad3bb2b8bc7357" shape="rect">
     cudaDevAttrMaxTexture3DHeightAlt
    </a>
    : Alternate maximum 3D texture height, 0 if no alternate maximum 3D texture size is supported
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdf30a2551356d44cee876398067aae25a" shape="rect">
     cudaDevAttrMaxTexture3DDepthAlt
    </a>
    : Alternate maximum 3D texture depth, 0 if no alternate maximum 3D texture size is supported
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd849f60b9f26213c8f2c17716e0884228" shape="rect">
     cudaDevAttrMaxTextureCubemapWidth
    </a>
    : Maximum cubemap texture width or height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd8a09b5ae0d4ea648878fcb6c1d6302c2" shape="rect">
     cudaDevAttrMaxTexture1DLayeredWidth
    </a>
    : Maximum 1D layered texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd68019a4c962a0967b80f9553657976ae" shape="rect">
     cudaDevAttrMaxTexture1DLayeredLayers
    </a>
    : Maximum layers in a 1D layered texture
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd9493ee965d9c35d2a2d6cc19b9af393c" shape="rect">
     cudaDevAttrMaxTexture2DLayeredWidth
    </a>
    : Maximum 2D layered texture width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd6a86483d8f56dc1796c29c0dfdcff85e" shape="rect">
     cudaDevAttrMaxTexture2DLayeredHeight
    </a>
    : Maximum 2D layered texture height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb64a8c3b8857209d411dcdd18d6566cd" shape="rect">
     cudaDevAttrMaxTexture2DLayeredLayers
    </a>
    : Maximum layers in a 2D layered texture
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd69c79fb543330218be45f046361d9c6c" shape="rect">
     cudaDevAttrMaxTextureCubemapLayeredWidth
    </a>
    : Maximum cubemap layered texture width or height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cda22e3d29bc779b832338003a58c11771" shape="rect">
     cudaDevAttrMaxTextureCubemapLayeredLayers
    </a>
    : Maximum layers in a cubemap layered texture
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde982243eeba0012a8309719bbdf8e787" shape="rect">
     cudaDevAttrMaxSurface1DWidth
    </a>
    : Maximum 1D surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd9c847f23d3ac641e49273fa7e7aadad4" shape="rect">
     cudaDevAttrMaxSurface2DWidth
    </a>
    : Maximum 2D surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd6d65871ae86777965f63375924e5d4b6" shape="rect">
     cudaDevAttrMaxSurface2DHeight
    </a>
    : Maximum 2D surface height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd95fdef60393108768816b49a69412fea" shape="rect">
     cudaDevAttrMaxSurface3DWidth
    </a>
    : Maximum 3D surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdcd29057dfab0acc9c1b4bae62b31a6fc" shape="rect">
     cudaDevAttrMaxSurface3DHeight
    </a>
    : Maximum 3D surface height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc65f6e09e306453928e504124f0400d2" shape="rect">
     cudaDevAttrMaxSurface3DDepth
    </a>
    : Maximum 3D surface depth
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0bb5be7291722c024db914e67b16bb0f" shape="rect">
     cudaDevAttrMaxSurface1DLayeredWidth
    </a>
    : Maximum 1D layered surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cda11787cba44bfcdab50a565546718fde" shape="rect">
     cudaDevAttrMaxSurface1DLayeredLayers
    </a>
    : Maximum layers in a 1D layered surface
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd5f8341be4c264cec2ddd9c153e74b2a2" shape="rect">
     cudaDevAttrMaxSurface2DLayeredWidth
    </a>
    : Maximum 2D layered surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd349a016c64a83540a16efcd6c7f48002" shape="rect">
     cudaDevAttrMaxSurface2DLayeredHeight
    </a>
    : Maximum 2D layered surface height
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdaaa31c1f16c4cc6c4934964045417d42" shape="rect">
     cudaDevAttrMaxSurface2DLayeredLayers
    </a>
    : Maximum layers in a 2D layered surface
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd330ae617b2503e5a7ec2c74cd65d73e0" shape="rect">
     cudaDevAttrMaxSurfaceCubemapWidth
    </a>
    : Maximum cubemap surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd3287281e5a089843d5a8eb140187126d" shape="rect">
     cudaDevAttrMaxSurfaceCubemapLayeredWidth
    </a>
    : Maximum cubemap layered surface width
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdbe8696b02b34231e6cc0058553d7ad7d" shape="rect">
     cudaDevAttrMaxSurfaceCubemapLayeredLayers
    </a>
    : Maximum layers in a cubemap layered surface
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddfbbe8d1cb269bf4824f5465b71f2e1f" shape="rect">
     cudaDevAttrMaxRegistersPerBlock
    </a>
    : Maximum number of 32-bit registers available to a thread block
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0bc2bd833cdf0f092a43f4fab7221a9e" shape="rect">
     cudaDevAttrClockRate
    </a>
    : Peak clock frequency in kilohertz
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdea4010e77cea234af52cb9b6ba53faf3" shape="rect">
     cudaDevAttrTextureAlignment
    </a>
    : Alignment requirement; texture base addresses aligned to textureAlign bytes do not need an offset applied to texture fetches
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd57e9e5b8b5911a542b3d3c338cdc936a" shape="rect">
     cudaDevAttrTexturePitchAlignment
    </a>
    : Pitch alignment requirement for 2D texture references bound to pitched memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc73c5b37c6e88c0ea32829b4dfea20e9" shape="rect">
     cudaDevAttrGpuOverlap
    </a>
    : 1 if the device can concurrently copy memory between host and device while executing a kernel, or 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd74de9ed281f917c8e4ef272da09f338a" shape="rect">
     cudaDevAttrMultiProcessorCount
    </a>
    : Number of multiprocessors on the device
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd94c4716a60420f8e7ff2464f6381faea" shape="rect">
     cudaDevAttrKernelExecTimeout
    </a>
    : 1 if there is a run time limit for kernels executed on the device, or 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd5e2efe8fc55f0602896a582f915e8ade" shape="rect">
     cudaDevAttrIntegrated
    </a>
    : 1 if the device is integrated with the memory subsystem, or 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdab8d5fcf5498b163c2a342487b0799c6" shape="rect">
     cudaDevAttrCanMapHostMemory
    </a>
    : 1 if the device can map host memory into the CUDA address space, or 0 if not
   </p>
  </li>
  <li class="li">
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd60b1eb0c9d9c5d10cc15f8d22bd635b1" shape="rect">
    cudaDevAttrComputeMode
   </a>
   : Compute mode is the compute mode that the device is currently in. Available modes are as follows:
   <ul class="ul">
    <li class="li">
     <p class="p">
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d04f74579a1612e99d5a3170813897b34f" shape="rect">
       cudaComputeModeDefault
      </a>
      : Default mode - Device is not restricted and multiple threads can use
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice()
      </a>
      with this device.
     </p>
    </li>
    <li class="li">
     <p class="p">
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d0fc71b88518e4501544d6e65b5f3671b6" shape="rect">
       cudaComputeModeProhibited
      </a>
      : Compute-prohibited mode - No threads can use
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice()
      </a>
      with this device.
     </p>
    </li>
    <li class="li">
     <p class="p">
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d02cd032834fecbec513ea1018145b111d" shape="rect">
       cudaComputeModeExclusiveProcess
      </a>
      : Compute-exclusive-process mode - Many threads in one process will be able to use
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice()
      </a>
      with this device.
     </p>
    </li>
   </ul>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdca44ee69956aa3575ae528453c92145b" shape="rect">
     cudaDevAttrConcurrentKernels
    </a>
    : 1 if the device supports executing multiple kernels within the same context simultaneously, or 0 if not. It is not guaranteed
                                          that multiple kernels will be resident on the device concurrently so this feature should not be relied upon for correctness.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd4eda3f8cee267406e6a5bae59e0e9355" shape="rect">
     cudaDevAttrEccEnabled
    </a>
    : 1 if error correction is enabled on the device, 0 if error correction is disabled or not supported by the device
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd43510a3c7deb77547365592346efea2e" shape="rect">
     cudaDevAttrPciBusId
    </a>
    : PCI bus identifier of the device
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb4dbdca8eaaf0da8c10f7625811923d6" shape="rect">
     cudaDevAttrPciDeviceId
    </a>
    : PCI device (also known as slot) identifier of the device
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc56e7ca3cfe198f40ec5af569f509594" shape="rect">
     cudaDevAttrTccDriver
    </a>
    : 1 if the device is using a TCC driver. TCC is only available on Tesla hardware running Windows Vista or later.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb496a68470a711a91b1decaf3722b876" shape="rect">
     cudaDevAttrMemoryClockRate
    </a>
    : Peak memory clock frequency in kilohertz
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd3b05daa4e76a34af2183f31143bb9a92" shape="rect">
     cudaDevAttrGlobalMemoryBusWidth
    </a>
    : Global memory bus width in bits
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd1b0342682d15910022ba3f383a851ad7" shape="rect">
     cudaDevAttrL2CacheSize
    </a>
    : Size of L2 cache in bytes. 0 if the device doesn't have L2 cache.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd7134e378583c080549742fae9e9ab2c1" shape="rect">
     cudaDevAttrMaxThreadsPerMultiProcessor
    </a>
    : Maximum resident threads per multiprocessor
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd00bbd7151c3af0c95253182a82a9ad37" shape="rect">
     cudaDevAttrUnifiedAddressing
    </a>
    : 1 if the device shares a unified address space with the host, or 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd220ff111a6616ab512e229d8f2f8bf87" shape="rect">
     cudaDevAttrComputeCapabilityMajor
    </a>
    : Major compute capability version number
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd2c981c76c9de58d39502e483a7b484c7" shape="rect">
     cudaDevAttrComputeCapabilityMinor
    </a>
    : Minor compute capability version number
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd98c866015b622979af1ffd155867561b" shape="rect">
     cudaDevAttrStreamPrioritiesSupported
    </a>
    : 1 if the device supports stream priorities, or 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb604005d7e05a02d8456ea88a98df71a" shape="rect">
     cudaDevAttrGlobalL1CacheSupported
    </a>
    : 1 if device supports caching globals in L1 cache, 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdf7b1a72971ff5b5e4f7b8aed3c2402f6" shape="rect">
     cudaDevAttrLocalL1CacheSupported
    </a>
    : 1 if device supports caching locals in L1 cache, 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc478150b5ec1689a2944aaf7e25a5685" shape="rect">
     cudaDevAttrMaxSharedMemoryPerMultiprocessor
    </a>
    : Maximum amount of shared memory available to a multiprocessor in bytes; this amount is shared by all thread blocks simultaneously
                                          resident on a multiprocessor
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdbfd53fc7581bed23d0f68860e5aa7519" shape="rect">
     cudaDevAttrMaxRegistersPerMultiprocessor
    </a>
    : Maximum number of 32-bit registers available to a multiprocessor; this number is shared by all thread blocks simultaneously
                                          resident on a multiprocessor
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd5467985f87821a03625ab62e72195ff8" shape="rect">
     cudaDevAttrManagedMemory
    </a>
    : 1 if device supports allocating managed memory, 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0b9ed60aade2b0822cce3333c7328ac0" shape="rect">
     cudaDevAttrIsMultiGpuBoard
    </a>
    : 1 if device is on a multi-GPU board, 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cda1a1451c4d46071acf2b0d5a1b266b62" shape="rect">
     cudaDevAttrMultiGpuBoardGroupID
    </a>
    : Unique identifier for a group of devices on the same multi-GPU board
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdbe97c871f26473bdede939ce116e1230" shape="rect">
     cudaDevAttrHostNativeAtomicSupported
    </a>
    : 1 if the link between the device and the host supports native atomic operations
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd4ac89cbfc8aa6328b51942f5db4d312e" shape="rect">
     cudaDevAttrSingleToDoublePrecisionPerfRatio
    </a>
    : Ratio of single precision performance (in floating-point operations per second) to double precision performance
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    : 1 if the device supports coherently accessing pageable memory without calling cudaHostRegister on it, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    : 1 if the device can coherently access managed memory concurrently with the CPU, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde023ca14ea2a9aa5b829f0a63baa2001" shape="rect">
     cudaDevAttrComputePreemptionSupported
    </a>
    : 1 if the device supports Compute Preemption, 0 if not
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb08e379a7a038dc8134914702c223f69" shape="rect">
     cudaDevAttrCanUseHostPointerForRegisteredMem
    </a>
    : 1 if the device can access host registered memory at the same virtual address as the CPU, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd108260813c2eb395a60d4acf08c97595" shape="rect">
     cudaDevAttrCooperativeLaunch
    </a>
    : 1 if the device supports launching cooperative kernels via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gc0210b928f9bf4e212af07d35ac11d67" shape="rect" title="Launches a device function.">
     cudaLaunchCooperativeKernel
    </a>
    , and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdd23f91b7405936dcbdb32cccf4598ea3" shape="rect">
     cudaDevAttrCooperativeMultiDeviceLaunch
    </a>
    : 1 if the device supports launching cooperative kernels via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g63685d849da7565b5774f5321a342f05" shape="rect" title="Launches device functions on multiple devices where thread blocks can cooperate and synchronize as they execute.">
     cudaLaunchCooperativeKernelMultiDevice
    </a>
    , and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd7028b9e7fccc21045febe4ee96a33e0e" shape="rect">
     cudaDevAttrCanFlushRemoteWrites
    </a>
    : 1 if the device supports flushing of outstanding remote writes, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd6ea4a004a336c3c95b6ff06ec6269e29" shape="rect">
     cudaDevAttrHostRegisterSupported
    </a>
    : 1 if the device supports host memory registration via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
     cudaHostRegister
    </a>
    , and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    : 1 if the device accesses pageable memory via the host's page tables, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde3b8c9e94a896324793a79584a23266f" shape="rect">
     cudaDevAttrDirectManagedMemAccessFromHost
    </a>
    : 1 if the host can directly access managed memory on the device without migration, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd024f669ca60d8ff7b3126dbfc61fd925" shape="rect">
     cudaDevAttrMaxSharedMemoryPerBlockOptin
    </a>
    : Maximum per block shared memory size on the device. This value can be opted into when using
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g422642bfa0c035a590e4c43ff7c11f8d" shape="rect" title="[C++ API] Set attributes for a given function">
     cudaFuncSetAttribute
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd604e92a71cd70a2c98cd2e7ba0b75fe2" shape="rect">
     cudaDevAttrMaxBlocksPerMultiprocessor
    </a>
    : Maximum number of thread blocks that can reside on a multiprocessor
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdbc47e76096ac988700e36e558f13bdde" shape="rect">
     cudaDevAttrMaxPersistingL2CacheSize
    </a>
    : Maximum L2 persisting lines capacity setting in bytes
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb703bd10410d3c3965e126f240ba5a9f" shape="rect">
     cudaDevAttrMaxAccessPolicyWindowSize
    </a>
    : Maximum value of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html#structcudaAccessPolicyWindow_1bbd68021cb5c3cb1928bee0a2941eb24" shape="rect">
     cudaAccessPolicyWindow::num_bytes
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdca7531b1f24df46a77a30f6f958d38f5" shape="rect">
     cudaDevAttrReservedSharedMemoryPerBlock
    </a>
    : Shared memory reserved by CUDA driver per block in bytes
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0bd3faa93fb551ff4ec32bea432ddb94" shape="rect">
     cudaDevAttrSparseCudaArraySupported
    </a>
    : 1 if the device supports sparse CUDA arrays and sparse CUDA mipmapped arrays.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde8ea38ec2872f63a74170354e375edb3" shape="rect">
     cudaDevAttrHostRegisterReadOnlySupported
    </a>
    : Device supports using the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
     cudaHostRegister
    </a>
    flag cudaHostRegisterReadOnly to register memory that must be mapped as read-only to the GPU
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0876515d3b274cb0b40f8a7d913fb1aa" shape="rect">
     cudaDevAttrMemoryPoolsSupported
    </a>
    : 1 if the device supports using the cudaMallocAsync and cudaMemPool family of APIs, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd4c3d612ec82ddaacc50f698c39f8a939" shape="rect">
     cudaDevAttrGPUDirectRDMASupported
    </a>
    : 1 if the device supports GPUDirect RDMA APIs, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd7b3462e13705248606f39fb5381446ee" shape="rect">
     cudaDevAttrGPUDirectRDMAFlushWritesOptions
    </a>
    : bitmask to be interpreted according to the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g08213e5a1b0dfdeeb88ed0146ca86f63" shape="rect">
     cudaFlushGPUDirectRDMAWritesOptions
    </a>
    enum
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd881d5b0c5bf7777e382920af4d743bde" shape="rect">
     cudaDevAttrGPUDirectRDMAWritesOrdering
    </a>
    : see the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd945c8e3f04e38760c1dac290519eb19" shape="rect">
     cudaGPUDirectRDMAWritesOrdering
    </a>
    enum for numerical values
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde094b6ab84c5173906bb0740f7175ff5" shape="rect">
     cudaDevAttrMemoryPoolSupportedHandleTypes
    </a>
    : Bitmask of handle types supported with mempool based IPC
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cde8478f8218ee09456b2294a11d62d434" shape="rect">
     cudaDevAttrDeferredMappingCudaArraySupported
    </a>
    : 1 if the device supports deferred mapping CUDA arrays and CUDA mipmapped arrays.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0ab012a7c597ffbe86090ee2f9e1758c" shape="rect">
     cudaDevAttrIpcEventSupport
    </a>
    : 1 if the device supports IPC Events.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd1f5175daa5db89ae8edb36cb20982933" shape="rect">
     cudaDevAttrNumaConfig
    </a>
    : NUMA configuration of a device: value is of type
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf69109376a24f6493aec77f1f3e78c2" shape="rect">
     cudaDeviceNumaConfig
    </a>
    enum
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddf48bff1805be727ac72ef53807b242f" shape="rect">
     cudaDevAttrNumaId
    </a>
    : NUMA node ID of the GPU memory
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" shape="rect" target="_blank">
   cuDeviceGetAttribute
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g65f57fb8d0981ca03f6f9b20031c3e5d" name="group__CUDART__DEVICE_1g65f57fb8d0981ca03f6f9b20031c3e5d" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetByPCIBusId (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , const char*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pciBusId
  </span>
  )
 </span>
 Returns a handle to a compute device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Returned device ordinal
 <span class="keyword keyword apiItemName">
  pciBusId
 </span>
 - String in one of the following forms: [domain]:[bus]:[device].[function] [domain]:[bus]:[device] [bus]:[device].[function]
                                    where
 domain
 ,
 bus
 ,
 device
 , and
 function
 are all hexadecimal values
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *device
  a device ordinal given a PCI bus ID string.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gea264dad3d8c4898e0b82213c0253def" shape="rect" title="Returns a PCI Bus Id string for the device.">
   cudaDeviceGetPCIBusId
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ga89cd3fa06334ba7853ed1232c5ebe2a" shape="rect" target="_blank">
   cuDeviceGetByPCIBusId
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gd9bf5eae6d464de05aa3840df9f5deeb" name="group__CUDART__DEVICE_1gd9bf5eae6d464de05aa3840df9f5deeb" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetCacheConfig (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gb980f35ed69ee7991704de29a13de49b" shape="rect" title="">
   cudaFuncCache
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pCacheConfig
  </span>
  )
 </span>
 Returns the preferred cache configuration for the current device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pCacheConfig
 </span>
 - Returned cache configuration
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  On devices where the L1 cache and shared memory use the same hardware resources, this returns through
  pCacheConfig
  the preferred cache configuration for the current device. This is only a preference. The runtime will use the requested configuration
                                 if possible, but it is free to choose a different configuration if required to execute functions.
 </p>
 <p class="p">
  This will return a
  pCacheConfig
  of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b3b4b8c65376ce1ca107be413e15981bc" shape="rect">
   cudaFuncCachePreferNone
  </a>
  on devices where the size of the L1 cache and shared memory are fixed.
 </p>
 <p class="p">
  The supported cache configurations are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b3b4b8c65376ce1ca107be413e15981bc" shape="rect">
     cudaFuncCachePreferNone
    </a>
    : no preference for shared memory or L1 (default)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b84725d25c531f9bafc61ae329afe5b2b" shape="rect">
     cudaFuncCachePreferShared
    </a>
    : prefer larger shared memory and smaller L1 cache
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b8ecb48ccbc2230c81528a2c7c695100e" shape="rect">
     cudaFuncCachePreferL1
    </a>
    : prefer larger L1 cache and smaller shared memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49bd151ac8d667150c601de4b9542887a3b" shape="rect">
     cudaFuncCachePreferEqual
    </a>
    : prefer equal size L1 cache and shared memory
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g6c9cc78ca80490386cf593b4baa35a15" shape="rect" title="Sets the preferred cache configuration for the current device.">
   cudaDeviceSetCacheConfig
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g6699ca1943ac2655effa0d571b2f4f15" shape="rect" title="Sets the preferred cache configuration for a device function.">
   cudaFuncSetCacheConfig ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g7d9cc996fe45b6260ebb086caff1c685" shape="rect" title="[C++ API] Sets the preferred cache configuration for a device function">
   cudaFuncSetCacheConfig ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g40b6b141698f76744dea6e39b9a25360" shape="rect" target="_blank">
   cuCtxGetCacheConfig
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" name="group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetDefaultMemPool (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns the default mempool of a device.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  The default mempool of a device contains device memory from that device.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc8bca3c97a78816303b8aa5773b741f2" shape="rect" target="_blank">
   cuDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g0faf526bcfffd835aa95a4514fb2f7d5" shape="rect" title="Tries to release memory back to the OS.">
   cudaMemPoolTrimTo
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4ff47ef59413a4ed9d760c0841ce4a99" shape="rect" title="Gets attributes of a memory pool.">
   cudaMemPoolGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g0229135f7ef724b4f479a435ca300af5" shape="rect" title="Sets attributes of a memory pool.">
   cudaMemPoolSetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" shape="rect" title="Controls visibility of pools between devices.">
   cudaMemPoolSetAccess
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g720e159aeb125910c22aa20fe9611ec2" name="group__CUDART__DEVICE_1g720e159aeb125910c22aa20fe9611ec2" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetLimit (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pValue
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4c4b34c054d383b0e9a63ab0ffc93651" shape="rect" title="">
   cudaLimit
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   limit
  </span>
  )
 </span>
 Return resource limits.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pValue
 </span>
 - Returned size of the limit
 <span class="keyword keyword apiItemName">
  limit
 </span>
 - Limit to query
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c3b950b6f8668f7282fae25bfcefd13a" shape="rect">
   cudaErrorUnsupportedLimit
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *pValue
  the current size of
  limit
  . The following
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4c4b34c054d383b0e9a63ab0ffc93651" shape="rect">
   cudaLimit
  </a>
  values are supported.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651fc8f54e641c9b133f1b57703d22ce656" shape="rect">
     cudaLimitStackSize
    </a>
    is the stack size in bytes of each GPU thread.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123b80a6221a6853e918c2816bb76742c" shape="rect">
     cudaLimitPrintfFifoSize
    </a>
    is the size in bytes of the shared FIFO used by the printf() device system call.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651b399716bf0a592bc42055473c1273881" shape="rect">
     cudaLimitMallocHeapSize
    </a>
    is the size in bytes of the heap used by the malloc() and free() device system calls.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123c4900be4af436cb769e4c72d07be11" shape="rect">
     cudaLimitDevRuntimeSyncDepth
    </a>
    is the maximum grid depth at which a thread can isssue the device runtime call
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
     cudaDeviceSynchronize()
    </a>
    to wait on child grid launches to complete. This functionality is removed for devices of compute capability &gt;= 9.0, and hence
                                          will return error
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c3b950b6f8668f7282fae25bfcefd13a" shape="rect">
     cudaErrorUnsupportedLimit
    </a>
    on such devices.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365118712cb05d2c3efaeea73afba823d916" shape="rect">
     cudaLimitDevRuntimePendingLaunchCount
    </a>
    is the maximum number of outstanding device runtime launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365168d3522068213e4ba46c4c99ebc4ce12" shape="rect">
     cudaLimitMaxL2FetchGranularity
    </a>
    is the L2 cache fetch granularity.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651fc5135f91c07d7aa2d1072db9854b113" shape="rect">
     cudaLimitPersistingL2CacheSize
    </a>
    is the persisting L2 cache size in bytes.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d" shape="rect" title="Set resource limits.">
   cudaDeviceSetLimit
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g9f2d47d1745752aa16da7ed0d111b6a8" shape="rect" target="_blank">
   cuCtxGetLimit
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" name="group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetMemPool (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Gets the current mempool for a device.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns the last pool provided to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  for this device or the device's default memory pool if
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  has never been called. By default the current mempool is the default mempool for a device, otherwise the returned pool must
                                 have been set with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g4f2f276b84d9c2eaefdc76d6274db4a0" shape="rect" target="_blank">
   cuDeviceSetMemPool
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gdf186e9559d53a5eb18e572d48c1121b" shape="rect" target="_blank">
   cuDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gf70468b1bb3a7483d1cc393eb7301f2f" name="group__CUDART__DEVICE_1gf70468b1bb3a7483d1cc393eb7301f2f" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetNvSciSyncAttributes (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   nvSciSyncAttrList
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Return NvSciSync attributes that this device can support.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  nvSciSyncAttrList
 </span>
 - Return NvSciSync attributes supported.
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Valid Cuda Device to get NvSciSync attributes for.
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - flags describing NvSciSync usage.
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  nvSciSyncAttrList
  , the properties of NvSciSync that this CUDA device,
  dev
  can support. The returned
  nvSciSyncAttrList
  can be used to create an NvSciSync that matches this device's capabilities.
 </p>
 <p class="p">
  If NvSciSyncAttrKey_RequiredPerm field in
  nvSciSyncAttrList
  is already set this API will return
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  .
 </p>
 <p class="p">
  The applications should set
  nvSciSyncAttrList
  to a valid NvSciSyncAttrList failing which this API will return cudaErrorInvalidHandle.
 </p>
 <p class="p">
  The
  flags
  controls how applications intends to use the NvSciSync created from the
  nvSciSyncAttrList
  . The valid flags are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8157cb1b3c077ba222a56779a37d3bd1" shape="rect">
     cudaNvSciSyncAttrSignal
    </a>
    , specifies that the applications intends to signal an NvSciSync on this CUDA device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g407f1fe03a9f560b23220faa306e70cf" shape="rect">
     cudaNvSciSyncAttrWait
    </a>
    , specifies that the applications intends to wait on an NvSciSync on this CUDA device.
   </p>
  </li>
 </ul>
 <p class="p">
  At least one of these flags must be set, failing which the API returns
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  . Both the flags are orthogonal to one another: a developer may set both these flags that allows to set both wait and signal
                                 specific attributes in the same
  nvSciSyncAttrList
  .
 </p>
 <p class="p">
  Note that this API updates the input
  nvSciSyncAttrList
  with values equivalent to the following public attribute key-values: NvSciSyncAttrKey_RequiredPerm is set to
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    NvSciSyncAccessPerm_SignalOnly if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8157cb1b3c077ba222a56779a37d3bd1" shape="rect">
     cudaNvSciSyncAttrSignal
    </a>
    is set in
    flags
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    NvSciSyncAccessPerm_WaitOnly if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g407f1fe03a9f560b23220faa306e70cf" shape="rect">
     cudaNvSciSyncAttrWait
    </a>
    is set in
    flags
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    NvSciSyncAccessPerm_WaitSignal if both
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g407f1fe03a9f560b23220faa306e70cf" shape="rect">
     cudaNvSciSyncAttrWait
    </a>
    and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8157cb1b3c077ba222a56779a37d3bd1" shape="rect">
     cudaNvSciSyncAttrSignal
    </a>
    are set in
    flags
    . NvSciSyncAttrKey_PrimitiveInfo is set to
   </p>
  </li>
  <li class="li">
   <p class="p">
    NvSciSyncAttrValPrimitiveType_SysmemSemaphore on any valid
    device
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    NvSciSyncAttrValPrimitiveType_Syncpoint if
    device
    is a Tegra device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    NvSciSyncAttrValPrimitiveType_SysmemSemaphorePayload64b if
    device
    is GA10X+. NvSciSyncAttrKey_GpuId is set to the same UUID that is returned in
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1626c20637498c7be1381db55a6261308" shape="rect">
     cudaDeviceProp.uuid
    </a>
    from cudaDeviceGetProperties for this
    device
    .
   </p>
  </li>
 </ul>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00389e95927732f0d5a68151c72296581504" shape="rect">
   cudaErrorDeviceUninitialized
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  , cudaErrorInvalidHandle,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP_1g64f7155c1fc4459a746db31b4aae263b" shape="rect" title="Imports an external semaphore.">
   cudaImportExternalSemaphore
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP_1gd596384c606982e5e5a8b9a1e4dcec15" shape="rect" title="Destroys an external semaphore.">
   cudaDestroyExternalSemaphore
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP_1gb0806d36d4bc72b82afcf9315f11330c" shape="rect" title="Signals a set of external semaphore objects.">
   cudaSignalExternalSemaphoresAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP_1g52ecbdf57e75f0fde9fa44a2f9532c2d" shape="rect" title="Waits on a set of external semaphore objects.">
   cudaWaitExternalSemaphoresAsync
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gc63e5bf168e53b2daf71904eab048fa9" name="group__CUDART__DEVICE_1gc63e5bf168e53b2daf71904eab048fa9" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetP2PAttribute (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2f597e2acceab33f60bd61c41fea0c1b" shape="rect" title="">
   cudaDeviceP2PAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   srcDevice
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  )
 </span>
 Queries attributes of the link between two devices.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Returned value of the requested attribute
 <span class="keyword keyword apiItemName">
  attr
 </span>
 <span class="keyword keyword apiItemName">
  srcDevice
 </span>
 - The source device of the target link.
 <span class="keyword keyword apiItemName">
  dstDevice
 </span>
 - The destination device of the target link.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *value
  the value of the requested attribute
  attrib
  of the link between
  srcDevice
  and
  dstDevice
  . The supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2f597e2acceab33f60bd61c41fea0c1bdca8430f659738ac2ebfbfc4e0899d3b" shape="rect">
     cudaDevP2PAttrPerformanceRank
    </a>
    : A relative value indicating the performance of the link between two devices. Lower value means better performance (0 being
                                          the value used for most performant link).
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2f597e2acceab33f60bd61c41fea0c1b0fa6e51b6472b6ea6ea0cd27fea05a3c" shape="rect">
     cudaDevP2PAttrAccessSupported
    </a>
    : 1 if peer access is enabled.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2f597e2acceab33f60bd61c41fea0c1b8513982962e4439fa60f2a24348be587" shape="rect">
     cudaDevP2PAttrNativeAtomicSupported
    </a>
    : 1 if native atomic operations over the link are supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2f597e2acceab33f60bd61c41fea0c1bc11dffbfb7a6d8872dfaeca4b971c11e" shape="rect">
     cudaDevP2PAttrCudaArrayAccessSupported
    </a>
    : 1 if accessing CUDA arrays over the link is supported.
   </p>
  </li>
 </ul>
 <p class="p">
  Returns
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  if
  srcDevice
  or
  dstDevice
  are not valid or if they represent the same device.
 </p>
 <p class="p">
  Returns
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  if
  attrib
  is not valid or if
  value
  is a null pointer.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g2b0adabf90db37e5cfddc92cbb2589f3" shape="rect" title="Enables direct access to memory allocations on a peer device.">
   cudaDeviceEnablePeerAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g9663734ad02653207ad6836053bf572e" shape="rect" title="Disables direct access to memory allocations on a peer device.">
   cudaDeviceDisablePeerAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g4db0d04e44995d5c1c34be4ecc863f22" shape="rect" title="Queries if a device may directly access a peer device's memory.">
   cudaDeviceCanAccessPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PEER__ACCESS.html#group__CUDA__PEER__ACCESS_1g4c55c60508f8eba4546b51f2ee545393" shape="rect" target="_blank">
   cuDeviceGetP2PAttribute
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gea264dad3d8c4898e0b82213c0253def" name="group__CUDART__DEVICE_1gea264dad3d8c4898e0b82213c0253def" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetPCIBusId (  char*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pciBusId
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   len
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns a PCI Bus Id string for the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pciBusId
 </span>
 - Returned identifier string for the device in the following format [domain]:[bus]:[device].[function] where
 domain
 ,
 bus
 ,
 device
 , and
 function
 are all hexadecimal values. pciBusId should be large enough to store 13 characters including the NULL-terminator.
 <span class="keyword keyword apiItemName">
  len
 </span>
 - Maximum length of string to store in
 name
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device to get identifier string for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns an ASCII string identifying the device
  dev
  in the NULL-terminated string pointed to by
  pciBusId
  .
  len
  specifies the maximum length of the string that may be returned.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g65f57fb8d0981ca03f6f9b20031c3e5d" shape="rect" title="Returns a handle to a compute device.">
   cudaDeviceGetByPCIBusId
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g85295e7d9745ab8f0aa80dd1e172acfc" shape="rect" target="_blank">
   cuDeviceGetPCIBusId
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gfdb79818f7c0ee7bc585648c91770275" name="group__CUDART__DEVICE_1gfdb79818f7c0ee7bc585648c91770275" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetStreamPriorityRange (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   leastPriority
  </span>
  , int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   greatestPriority
  </span>
  )
 </span>
 Returns numerical values that correspond to the least and greatest stream priorities.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  leastPriority
 </span>
 - Pointer to an int in which the numerical value for least stream priority is returned
 <span class="keyword keyword apiItemName">
  greatestPriority
 </span>
 - Pointer to an int in which the numerical value for greatest stream priority is returned
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *leastPriority
  and
  *greatestPriority
  the numerical values that correspond to the least and greatest stream priorities respectively. Stream priorities follow a
                                 convention where lower numbers imply greater priorities. The range of meaningful stream priorities is given by [
  *greatestPriority
  ,
  *leastPriority
  ]. If the user attempts to create a stream with a priority value that is outside the the meaningful range as specified by
                                 this API, the priority is automatically clamped down or up to either
  *leastPriority
  or
  *greatestPriority
  respectively. See
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1ge2be9e9858849bf62ba4a8b66d1c3540" shape="rect" title="Create an asynchronous stream with the specified priority.">
   cudaStreamCreateWithPriority
  </a>
  for details on creating a priority stream. A NULL may be passed in for
  *leastPriority
  or
  *greatestPriority
  if the value is not desired.
 </p>
 <p class="p">
  This function will return '0' in both
  *leastPriority
  and
  *greatestPriority
  if the current context's device does not support stream priorities (see
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  ).
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1ge2be9e9858849bf62ba4a8b66d1c3540" shape="rect" title="Create an asynchronous stream with the specified priority.">
   cudaStreamCreateWithPriority
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g192bb727d15c4407c119747de7d198a6" shape="rect" title="Query the priority of a stream.">
   cudaStreamGetPriority
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g137920ab61a71be6ce67605b9f294091" shape="rect" target="_blank">
   cuCtxGetStreamPriorityRange
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g45f0345fd7a3697d0766596593920f61" name="group__CUDART__DEVICE_1g45f0345fd7a3697d0766596593920f61" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceGetTexture1DLinearMaxWidth (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   maxWidthInElements
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   fmtDesc
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns the maximum number of elements allocatable in a 1D linear texture for a given element size.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  maxWidthInElements
 </span>
 - Returns maximum number of texture elements allocatable for given
 fmtDesc
 .
 <span class="keyword keyword apiItemName">
  fmtDesc
 </span>
 - Texture format description.
 <span class="keyword keyword apiItemName">
  device
 </span>
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c3b950b6f8668f7282fae25bfcefd13a" shape="rect">
   cudaErrorUnsupportedLimit
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  maxWidthInElements
  the maximum number of elements allocatable in a 1D linear texture for given format descriptor
  fmtDesc
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gb41b3a675bae9932bffa1c0ae969b1e0" shape="rect" target="_blank">
   cuDeviceGetTexture1DLinearMaxWidth
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gcff9794f21aa34d3b5ccc5b6b245da4a" name="group__CUDART__DEVICE_1gcff9794f21aa34d3b5ccc5b6b245da4a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceRegisterAsyncNotification (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , cudaAsyncCallback
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   callbackFunc
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   userData
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf5d1b31c73cce10a9ae82d3cc11157d2" shape="rect" title="">
   cudaAsyncCallbackHandle_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   callback
  </span>
  )
 </span>
 Registers a callback function to receive async notifications.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - The device on which to register the callback
 <span class="keyword keyword apiItemName">
  callbackFunc
 </span>
 - The function to register as a callback
 <span class="keyword keyword apiItemName">
  userData
 </span>
 - A generic pointer to user data. This is passed into the callback function.
 <span class="keyword keyword apiItemName">
  callback
 </span>
 - A handle representing the registered callback instance
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Registers
  callbackFunc
  to receive async notifications.
 </p>
 <p class="p">
  The
  userData
  parameter is passed to the callback function at async notification time. Likewise,
  callback
  is also passed to the callback function to distinguish between multiple registered callbacks.
 </p>
 <p class="p">
  The callback function being registered should be designed to return quickly (~10ms). Any long running tasks should be queued
                                 for execution on an application thread.
 </p>
 <p class="p">
  Callbacks may not call cudaDeviceRegisterAsyncNotification or cudaDeviceUnregisterAsyncNotification. Doing so will result
                                 in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  . Async notification callbacks execute in an undefined order and may be serialized.
 </p>
 <p class="p">
  Returns in
  *callback
  a handle representing the registered callback instance.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Note that this function may also return error codes from previous, asynchronous launches.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1geeeae22bfbfc38915ed9b7b58376e64d" shape="rect" title="Unregisters an async notification callback.">
   cudaDeviceUnregisterAsyncNotification
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" name="group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceReset (  void )
 </span>
 Destroy all allocations and reset all state on the current device in the current process.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Explicitly destroys and cleans up all resources associated with the current device in the current process. It is the caller's
                                 responsibility to ensure that the resources are not accessed or passed in subsequent API calls and doing so will result in
                                 undefined behavior. These resources include CUDA types
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect">
   cudaStream_t
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gea2f543a9fc0e52fe4ae712920fd1247" shape="rect">
   cudaEvent_t
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect">
   cudaArray_t
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect">
   cudaMipmappedArray_t
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g83eb271ebc4cb2817e66d7c752f0c29b" shape="rect">
   cudaTextureObject_t
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gbe57cf2ccbe7f9d696f18808dd634c0a" shape="rect">
   cudaSurfaceObject_t
  </a>
  , textureReference, surfaceReference,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g79a2bf6a3a2aa9011a96dc17d476faf7" shape="rect">
   cudaExternalMemory_t
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf8bc7ab93d638c5835e5289ac7d683c4" shape="rect">
   cudaExternalSemaphore_t
  </a>
  and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf58dd8d3c7a65714ff7f5459adbf7e6f" shape="rect">
   cudaGraphicsResource_t
  </a>
  . These resources also include memory allocations by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd5c991beb38e2b8419f50285707ae87e" shape="rect" title="[C++ API] Allocates page-locked memory on the host">
   cudaMallocHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  . Any subsequent API call to this device will reinitialize the device.
 </p>
 <p class="p">
  Note that this function will reset the device immediately. It is the caller's responsibility to ensure that the device is
                                 not being accessed by any other host threads from the process when this function is called.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" shape="rect" title="Destroy all allocations and reset all state on the current device in the current process.">
     cudaDeviceReset()
    </a>
    will not destroy memory allocations by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gbbf70065888d61853c047513baa14081" shape="rect" title="Allocates memory with stream ordered semantics.">
     cudaMallocAsync()
    </a>
    and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
     cudaMallocFromPoolAsync()
    </a>
    . These memory allocations need to be destroyed explicitly.
   </p>
  </li>
  <li class="li">
   <p class="p">
    If a non-primary
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gf9f5bd81658f866613785b3a0bb7d7d9" shape="rect" target="_blank">
     CUcontext
    </a>
    is current to the thread,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" shape="rect" title="Destroy all allocations and reset all state on the current device in the current process.">
     cudaDeviceReset()
    </a>
    will destroy only the internal CUDA RT state for that
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gf9f5bd81658f866613785b3a0bb7d7d9" shape="rect" target="_blank">
     CUcontext
    </a>
    .
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
   cudaDeviceSynchronize
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g6c9cc78ca80490386cf593b4baa35a15" name="group__CUDART__DEVICE_1g6c9cc78ca80490386cf593b4baa35a15" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceSetCacheConfig (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gb980f35ed69ee7991704de29a13de49b" shape="rect" title="">
   cudaFuncCache
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   cacheConfig
  </span>
  )
 </span>
 Sets the preferred cache configuration for the current device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  cacheConfig
 </span>
 - Requested cache configuration
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  On devices where the L1 cache and shared memory use the same hardware resources, this sets through
  cacheConfig
  the preferred cache configuration for the current device. This is only a preference. The runtime will use the requested configuration
                                 if possible, but it is free to choose a different configuration if required to execute the function. Any function preference
                                 set via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g6699ca1943ac2655effa0d571b2f4f15" shape="rect" title="Sets the preferred cache configuration for a device function.">
   cudaFuncSetCacheConfig ( C API)
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g7d9cc996fe45b6260ebb086caff1c685" shape="rect" title="[C++ API] Sets the preferred cache configuration for a device function">
   cudaFuncSetCacheConfig ( C++ API)
  </a>
  will be preferred over this device-wide setting. Setting the device-wide cache configuration to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b3b4b8c65376ce1ca107be413e15981bc" shape="rect">
   cudaFuncCachePreferNone
  </a>
  will cause subsequent kernel launches to prefer to not change the cache configuration unless required to launch the kernel.
 </p>
 <p class="p">
  This setting does nothing on devices where the size of the L1 cache and shared memory are fixed.
 </p>
 <p class="p">
  Launching a kernel with a different preference than the most recent preference setting may insert a device-side synchronization
                                 point.
 </p>
 <p class="p">
  The supported cache configurations are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b3b4b8c65376ce1ca107be413e15981bc" shape="rect">
     cudaFuncCachePreferNone
    </a>
    : no preference for shared memory or L1 (default)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b84725d25c531f9bafc61ae329afe5b2b" shape="rect">
     cudaFuncCachePreferShared
    </a>
    : prefer larger shared memory and smaller L1 cache
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49b8ecb48ccbc2230c81528a2c7c695100e" shape="rect">
     cudaFuncCachePreferL1
    </a>
    : prefer larger L1 cache and smaller shared memory
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggb980f35ed69ee7991704de29a13de49bd151ac8d667150c601de4b9542887a3b" shape="rect">
     cudaFuncCachePreferEqual
    </a>
    : prefer equal size L1 cache and shared memory
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gd9bf5eae6d464de05aa3840df9f5deeb" shape="rect" title="Returns the preferred cache configuration for the current device.">
   cudaDeviceGetCacheConfig
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g6699ca1943ac2655effa0d571b2f4f15" shape="rect" title="Sets the preferred cache configuration for a device function.">
   cudaFuncSetCacheConfig ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g7d9cc996fe45b6260ebb086caff1c685" shape="rect" title="[C++ API] Sets the preferred cache configuration for a device function">
   cudaFuncSetCacheConfig ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g54699acf7e2ef27279d013ca2095f4a3" shape="rect" target="_blank">
   cuCtxSetCacheConfig
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d" name="group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceSetLimit (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4c4b34c054d383b0e9a63ab0ffc93651" shape="rect" title="">
   cudaLimit
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   limit
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  )
 </span>
 Set resource limits.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  limit
 </span>
 - Limit to set
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Size of limit
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c3b950b6f8668f7282fae25bfcefd13a" shape="rect">
   cudaErrorUnsupportedLimit
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Setting
  limit
  to
  value
  is a request by the application to update the current limit maintained by the device. The driver is free to modify the requested
                                 value to meet h/w requirements (this could be clamping to minimum or maximum values, rounding up to nearest element size,
                                 etc). The application can use
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g720e159aeb125910c22aa20fe9611ec2" shape="rect" title="Return resource limits.">
   cudaDeviceGetLimit()
  </a>
  to find out exactly what the limit has been set to.
 </p>
 <p class="p">
  Setting each
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4c4b34c054d383b0e9a63ab0ffc93651" shape="rect">
   cudaLimit
  </a>
  has its own specific restrictions, so each is discussed here.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651fc8f54e641c9b133f1b57703d22ce656" shape="rect">
     cudaLimitStackSize
    </a>
    controls the stack size in bytes of each GPU thread.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123b80a6221a6853e918c2816bb76742c" shape="rect">
     cudaLimitPrintfFifoSize
    </a>
    controls the size in bytes of the shared FIFO used by the printf() device system call. Setting
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123b80a6221a6853e918c2816bb76742c" shape="rect">
     cudaLimitPrintfFifoSize
    </a>
    must not be performed after launching any kernel that uses the printf() device system call - in such case
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
     cudaErrorInvalidValue
    </a>
    will be returned.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651b399716bf0a592bc42055473c1273881" shape="rect">
     cudaLimitMallocHeapSize
    </a>
    controls the size in bytes of the heap used by the malloc() and free() device system calls. Setting
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651b399716bf0a592bc42055473c1273881" shape="rect">
     cudaLimitMallocHeapSize
    </a>
    must not be performed after launching any kernel that uses the malloc() or free() device system calls - in such case
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
     cudaErrorInvalidValue
    </a>
    will be returned.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365123c4900be4af436cb769e4c72d07be11" shape="rect">
     cudaLimitDevRuntimeSyncDepth
    </a>
    controls the maximum nesting depth of a grid at which a thread can safely call
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
     cudaDeviceSynchronize()
    </a>
    . Setting this limit must be performed before any launch of a kernel that uses the device runtime and calls
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
     cudaDeviceSynchronize()
    </a>
    above the default sync depth, two levels of grids. Calls to
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
     cudaDeviceSynchronize()
    </a>
    will fail with error code
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038265dbf94c45903cd582cfc40f93a176a" shape="rect">
     cudaErrorSyncDepthExceeded
    </a>
    if the limitation is violated. This limit can be set smaller than the default or up the maximum launch depth of 24. When
                                          setting this limit, keep in mind that additional levels of sync depth require the runtime to reserve large amounts of device
                                          memory which can no longer be used for user allocations. If these reservations of device memory fail,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d" shape="rect" title="Set resource limits.">
     cudaDeviceSetLimit
    </a>
    will return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
     cudaErrorMemoryAllocation
    </a>
    , and the limit can be reset to a lower value. This limit is only applicable to devices of compute capability &lt; 9.0. Attempting
                                          to set this limit on devices of other compute capability will results in error
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c3b950b6f8668f7282fae25bfcefd13a" shape="rect">
     cudaErrorUnsupportedLimit
    </a>
    being returned.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365118712cb05d2c3efaeea73afba823d916" shape="rect">
     cudaLimitDevRuntimePendingLaunchCount
    </a>
    controls the maximum number of outstanding device runtime launches that can be made from the current device. A grid is outstanding
                                          from the point of launch up until the grid is known to have been completed. Device runtime launches which violate this limitation
                                          fail and return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382372902b9ffd65825d138e16125b1376" shape="rect">
     cudaErrorLaunchPendingCountExceeded
    </a>
    when
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html#group__CUDART__ERROR_1g3529f94cb530a83a76613616782bd233" shape="rect" title="Returns the last error from a runtime call.">
     cudaGetLastError()
    </a>
    is called after launch. If more pending launches than the default (2048 launches) are needed for a module using the device
                                          runtime, this limit can be increased. Keep in mind that being able to sustain additional pending launches will require the
                                          runtime to reserve larger amounts of device memory upfront which can no longer be used for allocations. If these reservations
                                          fail,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g05956f16eaa47ef3a4efee84563ccb7d" shape="rect" title="Set resource limits.">
     cudaDeviceSetLimit
    </a>
    will return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
     cudaErrorMemoryAllocation
    </a>
    , and the limit can be reset to a lower value. This limit is only applicable to devices of compute capability 3.5 and higher.
                                          Attempting to set this limit on devices of compute capability less than 3.5 will result in the error
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c3b950b6f8668f7282fae25bfcefd13a" shape="rect">
     cudaErrorUnsupportedLimit
    </a>
    being returned.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc9365168d3522068213e4ba46c4c99ebc4ce12" shape="rect">
     cudaLimitMaxL2FetchGranularity
    </a>
    controls the L2 cache fetch granularity. Values can range from 0B to 128B. This is purely a performance hint and it can be
                                          ignored or clamped depending on the platform.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg4c4b34c054d383b0e9a63ab0ffc93651fc5135f91c07d7aa2d1072db9854b113" shape="rect">
     cudaLimitPersistingL2CacheSize
    </a>
    controls size in bytes available for persisting L2 cache. This is purely a performance hint and it can be ignored or clamped
                                          depending on the platform.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g720e159aeb125910c22aa20fe9611ec2" shape="rect" title="Return resource limits.">
   cudaDeviceGetLimit
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g0651954dfb9788173e60a9af7201e65a" shape="rect" target="_blank">
   cuCtxSetLimit
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" name="group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceSetMemPool (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  )
 </span>
 Sets the current memory pool of a device.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  The memory pool must be local to the specified device. Unless a mempool is specified in the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  call,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  allocates from the current mempool of the provided stream's device. By default, a device's current memory pool is its default
                                 memory pool.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Use
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
  to specify asynchronous allocations from a device different than the one the stream runs on.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g4f2f276b84d9c2eaefdc76d6274db4a0" shape="rect" target="_blank">
   cuDeviceSetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect" title="Creates a memory pool.">
   cudaMemPoolCreate
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g709113128c1c52c3bf170022dc7723dd" shape="rect" title="Destroys the specified memory pool.">
   cudaMemPoolDestroy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" name="group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceSynchronize (  void )
 </span>
 Wait for compute device to finish.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Blocks until the device has completed all preceding requested tasks.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
   cudaDeviceSynchronize()
  </a>
  returns an error if one of the preceding tasks has failed. If the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g057e6912c52708b6aa86e79dd83d007c" shape="rect">
   cudaDeviceScheduleBlockingSync
  </a>
  flag was set for this device, the host thread will block until the device has finished its work.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Use of cudaDeviceSynchronize in device code was deprecated in CUDA 11.6 and removed for compute_90+ compilation. For compute
                                             capability &lt; 9.0, compile-time opt-in by specifying -D CUDA_FORCE_CDP1_IF_SUPPORTED is required to continue using
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d" shape="rect" title="Wait for compute device to finish.">
     cudaDeviceSynchronize()
    </a>
    in device code for now. Note that this is different from host-side cudaDeviceSynchronize, which is still supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" shape="rect" title="Destroy all allocations and reset all state on the current device in the current process.">
   cudaDeviceReset
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g7a54725f28d34b8c6299f0c6ca579616" shape="rect" target="_blank">
   cuCtxSynchronize
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1geeeae22bfbfc38915ed9b7b58376e64d" name="group__CUDART__DEVICE_1geeeae22bfbfc38915ed9b7b58376e64d" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaDeviceUnregisterAsyncNotification (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf5d1b31c73cce10a9ae82d3cc11157d2" shape="rect" title="">
   cudaAsyncCallbackHandle_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   callback
  </span>
  )
 </span>
 Unregisters an async notification callback.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - The device from which to remove
 callback
 .
 <span class="keyword keyword apiItemName">
  callback
 </span>
 - The callback instance to unregister from receiving async notifications.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Unregisters
  callback
  so that the corresponding callback function will stop receiving async notifications.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Note that this function may also return error codes from previous, asynchronous launches.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gcff9794f21aa34d3b5ccc5b6b245da4a" shape="rect" title="Registers a callback function to receive async notifications.">
   cudaDeviceRegisterAsyncNotification
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" name="group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetDevice (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns which device is currently being used.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Returns the device on which the active host thread executes the device code.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  , cudaErrorDeviceUnavailable,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *device
  the current device for the calling host thread.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g8f13165846b73750693640fb3e8380d0" shape="rect" target="_blank">
   cuCtxGetCurrent
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" name="group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetDeviceCount (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 Returns the number of compute-capable devices.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Returns the number of devices with compute capability greater or equal to 2.0
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *count
  the number of devices with compute capability greater or equal to 2.0 that are available for execution.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74" shape="rect" target="_blank">
   cuDeviceGetCount
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" name="group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetDeviceFlags (  unsigned int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Gets the flags for the current device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Pointer to store the device flags
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  flags
  the flags for the current device. If there is a current device for the calling thread, the flags for the device are returned.
                                 If there is no current device, the flags for the first device are returned, which may be the default flags. Compare to the
                                 behavior of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  .
 </p>
 <p class="p">
  Typically, the flags returned should match the behavior that will be seen if the calling thread uses a device after this call,
                                 without any change to the flags or current device inbetween by this or another thread. Note that if the device is not initialized,
                                 it is possible for another thread to change the flags for the current device before it is initialized. Additionally, when
                                 using exclusive mode, if this thread has not requested a specific device, it may use a device other than the first device,
                                 contrary to the assumption made by this function.
 </p>
 <p class="p">
  If a context has been created via the driver API and is current to the calling thread, the flags for that context are always
                                 returned.
 </p>
 <p class="p">
  Flags returned by this function may specifically include
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3762be9cccdd809a4ca128354fd134b0" shape="rect">
   cudaDeviceMapHost
  </a>
  even though it is not accepted by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  because it is implicit in runtime API flags. The reason for this is that the current context may have been created via the
                                 driver API in which case the flag is not implicit and may be unset.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1gf81eef983c1e3b2ef4f166d7a930c86d" shape="rect" target="_blank">
   cuCtxGetFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PRIMARY__CTX.html#group__CUDA__PRIMARY__CTX_1g65f3e018721b6d90aa05cfb56250f469" shape="rect" target="_blank">
   cuDevicePrimaryCtxGetState
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" name="group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetDeviceProperties (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp" shape="rect" title="">
   cudaDeviceProp
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   prop
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns information about the compute-device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  prop
 </span>
 - Properties for the specified device
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device number to get properties for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *prop
  the properties of device
  dev
  . The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp" shape="rect">
   cudaDeviceProp
  </a>
  structure is defined as:
 </p>
 <pre xml:space="preserve">â    struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp" shape="rect">cudaDeviceProp</a> {
              char <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_11e26f1c6bd42f4821b7ef1a4bd3bd25c" shape="rect">name</a>[256];
              cudaUUID_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1626c20637498c7be1381db55a6261308" shape="rect">uuid</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1983c292e2078dd5a4240f49c41d647f3" shape="rect">totalGlobalMem</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_182ec4c5e244addb9cd57f5b9da0eaca7" shape="rect">sharedMemPerBlock</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_184472707f521930fc052663820d635fc" shape="rect">regsPerBlock</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18656f53eb2a7e54500f6fb95a830b47d" shape="rect">warpSize</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_14382eddd3f5836f1195ca988388783bb" shape="rect">memPitch</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_118f38f08c66c8812b1ddeb16e4bf51a4" shape="rect">maxThreadsPerBlock</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_192d195493a9d36b2d827aaf3ffd89f1e" shape="rect">maxThreadsDim</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_17d138a572315b3bbb6caf7ccc914a130" shape="rect">maxGridSize</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1dee14230e417cb3059d697d6804da414" shape="rect">clockRate</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b4047e5e22082b1aefeac3b9ef39d0be" shape="rect">totalConstMem</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_164490976c8e07e028a8f1ce1f5cd42d6" shape="rect">major</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_150d477d8d5d3a04e0785f469277c65bb" shape="rect">minor</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1500248658a996f51752e1ab1769f8a88" shape="rect">textureAlignment</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13a3f10d2833bdc82ceb370a449aafeec" shape="rect">texturePitchAlignment</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13281f4cdba05e2ca43be1caae2bcb29b" shape="rect">deviceOverlap</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13e36d9d236f97095ef2b496cd2f98121" shape="rect">multiProcessorCount</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_19a63114766c4d2309f00403c1bf056c8" shape="rect">kernelExecTimeoutEnabled</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1613bf3e02c6120db852a2ecd5ff9605a" shape="rect">integrated</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_115414c4b1fedd1a22030522d54caa653" shape="rect">canMapHostMemory</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_15458a603dcbca1dd361ac5b99c07675b" shape="rect">computeMode</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_121e1544ca58ec5e559d0d498c5af9061" shape="rect">maxTexture1D</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16875f2ba4ab9d9733948545303786cc4" shape="rect">maxTexture1DMipmap</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_120efbdc4556a390720e0f75b62b8f83d" shape="rect">maxTexture1DLinear</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1618ac703b9a48adf50713897689a3eb2" shape="rect">maxTexture2D</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f227daa1f3c12d90898c77152b1136bf" shape="rect">maxTexture2DMipmap</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1757a4245a175441c2a1535ef9c9524a4" shape="rect">maxTexture2DLinear</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_11468730923ddf5a68ecc9bb42053c1c9" shape="rect">maxTexture2DGather</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16ea5619e4e11617451c6adc8560f068b" shape="rect">maxTexture3D</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16f5f5ba8a7dc088392be0d2f8f51faed" shape="rect">maxTexture3DAlt</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f9076f17639b08ea1783bb3035b1f707" shape="rect">maxTextureCubemap</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_11047afc38a23fcdfd5f202002caa53f5" shape="rect">maxTexture1DLayered</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16011fd7e13a77d58fbbd4a5ba1801fbf" shape="rect">maxTexture2DLayered</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f838fe5c7528d1e345a83659d001d799" shape="rect">maxTextureCubemapLayered</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1fd25f5ae34d7eeb2c52f87b9e932fe05" shape="rect">maxSurface1D</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1a85bc895583a26251fbfef635c7644a9" shape="rect">maxSurface2D</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_14fdf5cd399b60955ee35421a7cc6418a" shape="rect">maxSurface3D</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16cf36809ff5ed6b8aa836177d0292200" shape="rect">maxSurface1DLayered</a>[2];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1edeed8d96d802c4b01149e2e6a7b4ea8" shape="rect">maxSurface2DLayered</a>[3];
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1d170a7ad44ced64478d50fd7b6378b41" shape="rect">maxSurfaceCubemap</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1d4564200e6bc420be63b61251c6d39b8" shape="rect">maxSurfaceCubemapLayered</a>[2];
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18fe20825e4239ff91a7708c9468a02b5" shape="rect">surfaceAlignment</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18e2fe2a3b264901816874516af12a097" shape="rect">concurrentKernels</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_172919e0168f8dc8a719e2c38355b80ab" shape="rect">ECCEnabled</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1c5adc2ef8c6b89fb139b4684175db54a" shape="rect">pciBusID</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_156978c2bfc433d26ac3b4c765ee536bb" shape="rect">pciDeviceID</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f3a69f0796e32c0e32d17c151443fab0" shape="rect">pciDomainID</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1fcc96a9e56f84f4a0e853c18ce8e2c0d" shape="rect">tccDriver</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_105a89c028bee8fe480d0f44ddd43357b" shape="rect">asyncEngineCount</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_107b0114cefb43da05e05c65ec859542c" shape="rect">unifiedAddressing</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b200f01a8ec81912285c2633117109c4" shape="rect">memoryClockRate</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e764fca4d15a459279b31cb533435c19" shape="rect">memoryBusWidth</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b40b9ed0e542e9f09667b0a89fb6ad85" shape="rect">l2CacheSize</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1708c0ea6df419516e4bd702dd26f802c" shape="rect">persistingL2CacheMaxSize</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_196dac83c7095e29b86300cc02851844c" shape="rect">maxThreadsPerMultiProcessor</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_143e968b12978ffd2a80bde224d7dc782" shape="rect">streamPrioritiesSupported</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1551ac00fc5ba827a91d705b164288bff" shape="rect">globalL1CacheSupported</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e1772eeb293a76aae0bbf7f965a403d5" shape="rect">localL1CacheSupported</a>;
              size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16cede1829516e86917f0842a5f6498c8" shape="rect">sharedMemPerMultiprocessor</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1de02e669caefcadadaaa42877b08e80a" shape="rect">regsPerMultiprocessor</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f7230860be3e37047c7ce5d32542b54b" shape="rect">managedMemory</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1512d849f57e6a6a0ece1d21879c3ae35" shape="rect">isMultiGpuBoard</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_163af976611c9d29f169882f5c32472d4" shape="rect">multiGpuBoardGroupID</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_14bd4d531bf2ac497d659b03910440315" shape="rect">singleToDoublePrecisionPerfRatio</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_146116bab1064b5d7d0642d78f6c27ce1" shape="rect">pageableMemoryAccess</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_116f9619ccc85e93bc456b8c69c80e78b" shape="rect">concurrentManagedAccess</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_154a9a6e0067360f23dc91e60e7cf88d1" shape="rect">computePreemptionSupported</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1ae79e062f076b0270625b38bb91285b8" shape="rect">canUseHostPointerForRegisteredMem</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13c26ab51c96f39b115d7826337541914" shape="rect">cooperativeLaunch</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_183271637b431ccb5f5b58c46d0bd8cc9" shape="rect">cooperativeMultiDeviceLaunch</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e9f1ed6bffd5606eb81d438728a844ca" shape="rect">pageableMemoryAccessUsesHostPageTables</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b47773cf29bec05e6f1ba569346889e8" shape="rect">directManagedMemAccessFromHost</a>;
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_192470653c71f372dbec29bd693d55316" shape="rect">accessPolicyMaxWindowSize</a>;
          }</pre>
 where:
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_11e26f1c6bd42f4821b7ef1a4bd3bd25c" shape="rect">
     name[256]
    </a>
    is an ASCII string identifying the device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1626c20637498c7be1381db55a6261308" shape="rect">
     uuid
    </a>
    is a 16-byte unique identifier.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1983c292e2078dd5a4240f49c41d647f3" shape="rect">
     totalGlobalMem
    </a>
    is the total amount of global memory available on the device in bytes.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_182ec4c5e244addb9cd57f5b9da0eaca7" shape="rect">
     sharedMemPerBlock
    </a>
    is the maximum amount of shared memory available to a thread block in bytes.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_184472707f521930fc052663820d635fc" shape="rect">
     regsPerBlock
    </a>
    is the maximum number of 32-bit registers available to a thread block.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18656f53eb2a7e54500f6fb95a830b47d" shape="rect">
     warpSize
    </a>
    is the warp size in threads.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_14382eddd3f5836f1195ca988388783bb" shape="rect">
     memPitch
    </a>
    is the maximum pitch in bytes allowed by the memory copy functions that involve memory regions allocated through
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
     cudaMallocPitch()
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_118f38f08c66c8812b1ddeb16e4bf51a4" shape="rect">
     maxThreadsPerBlock
    </a>
    is the maximum number of threads per block.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_192d195493a9d36b2d827aaf3ffd89f1e" shape="rect">
     maxThreadsDim[3]
    </a>
    contains the maximum size of each dimension of a block.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_17d138a572315b3bbb6caf7ccc914a130" shape="rect">
     maxGridSize[3]
    </a>
    contains the maximum size of each dimension of a grid.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1dee14230e417cb3059d697d6804da414" shape="rect">
     clockRate
    </a>
    is the clock frequency in kilohertz.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b4047e5e22082b1aefeac3b9ef39d0be" shape="rect">
     totalConstMem
    </a>
    is the total amount of constant memory available on the device in bytes.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_164490976c8e07e028a8f1ce1f5cd42d6" shape="rect">
     major
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_150d477d8d5d3a04e0785f469277c65bb" shape="rect">
     minor
    </a>
    are the major and minor revision numbers defining the device's compute capability.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1500248658a996f51752e1ab1769f8a88" shape="rect">
     textureAlignment
    </a>
    is the alignment requirement; texture base addresses that are aligned to
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1500248658a996f51752e1ab1769f8a88" shape="rect">
     textureAlignment
    </a>
    bytes do not need an offset applied to texture fetches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13a3f10d2833bdc82ceb370a449aafeec" shape="rect">
     texturePitchAlignment
    </a>
    is the pitch alignment requirement for 2D texture references that are bound to pitched memory.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13281f4cdba05e2ca43be1caae2bcb29b" shape="rect">
     deviceOverlap
    </a>
    is 1 if the device can concurrently copy memory between host and device while executing a kernel, or 0 if not. Deprecated,
                                          use instead asyncEngineCount.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13e36d9d236f97095ef2b496cd2f98121" shape="rect">
     multiProcessorCount
    </a>
    is the number of multiprocessors on the device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_19a63114766c4d2309f00403c1bf056c8" shape="rect">
     kernelExecTimeoutEnabled
    </a>
    is 1 if there is a run time limit for kernels executed on the device, or 0 if not.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1613bf3e02c6120db852a2ecd5ff9605a" shape="rect">
     integrated
    </a>
    is 1 if the device is an integrated (motherboard) GPU and 0 if it is a discrete (card) component.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_115414c4b1fedd1a22030522d54caa653" shape="rect">
     canMapHostMemory
    </a>
    is 1 if the device can map host memory into the CUDA address space for use with
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
     cudaHostAlloc()
    </a>
    /
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
     cudaHostGetDevicePointer()
    </a>
    , or 0 if not.
   </p>
  </li>
  <li class="li">
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_15458a603dcbca1dd361ac5b99c07675b" shape="rect">
    computeMode
   </a>
   is the compute mode that the device is currently in. Available modes are as follows:
   <ul class="ul">
    <li class="li">
     <p class="p">
      cudaComputeModeDefault: Default mode - Device is not restricted and multiple threads can use
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice()
      </a>
      with this device.
     </p>
    </li>
    <li class="li">
     <p class="p">
      cudaComputeModeProhibited: Compute-prohibited mode - No threads can use
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice()
      </a>
      with this device.
     </p>
    </li>
    <li class="li">
     <p class="p">
      cudaComputeModeExclusiveProcess: Compute-exclusive-process mode - Many threads in one process will be able to use
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice()
      </a>
      with this device.
     </p>
     <p class="p">
      When an occupied exclusive mode device is chosen with
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
       cudaSetDevice
      </a>
      , all subsequent non-device management runtime functions will return
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038a2ab67256308f82a7be0fcd9fb145ad7" shape="rect">
       cudaErrorDevicesUnavailable
      </a>
      .
     </p>
    </li>
   </ul>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_121e1544ca58ec5e559d0d498c5af9061" shape="rect">
     maxTexture1D
    </a>
    is the maximum 1D texture size.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16875f2ba4ab9d9733948545303786cc4" shape="rect">
     maxTexture1DMipmap
    </a>
    is the maximum 1D mipmapped texture texture size.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_120efbdc4556a390720e0f75b62b8f83d" shape="rect">
     maxTexture1DLinear
    </a>
    is the maximum 1D texture size for textures bound to linear memory.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1618ac703b9a48adf50713897689a3eb2" shape="rect">
     maxTexture2D[2]
    </a>
    contains the maximum 2D texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f227daa1f3c12d90898c77152b1136bf" shape="rect">
     maxTexture2DMipmap[2]
    </a>
    contains the maximum 2D mipmapped texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1757a4245a175441c2a1535ef9c9524a4" shape="rect">
     maxTexture2DLinear[3]
    </a>
    contains the maximum 2D texture dimensions for 2D textures bound to pitch linear memory.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_11468730923ddf5a68ecc9bb42053c1c9" shape="rect">
     maxTexture2DGather[2]
    </a>
    contains the maximum 2D texture dimensions if texture gather operations have to be performed.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16ea5619e4e11617451c6adc8560f068b" shape="rect">
     maxTexture3D[3]
    </a>
    contains the maximum 3D texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16f5f5ba8a7dc088392be0d2f8f51faed" shape="rect">
     maxTexture3DAlt[3]
    </a>
    contains the maximum alternate 3D texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f9076f17639b08ea1783bb3035b1f707" shape="rect">
     maxTextureCubemap
    </a>
    is the maximum cubemap texture width or height.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_11047afc38a23fcdfd5f202002caa53f5" shape="rect">
     maxTexture1DLayered[2]
    </a>
    contains the maximum 1D layered texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16011fd7e13a77d58fbbd4a5ba1801fbf" shape="rect">
     maxTexture2DLayered[3]
    </a>
    contains the maximum 2D layered texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f838fe5c7528d1e345a83659d001d799" shape="rect">
     maxTextureCubemapLayered[2]
    </a>
    contains the maximum cubemap layered texture dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1fd25f5ae34d7eeb2c52f87b9e932fe05" shape="rect">
     maxSurface1D
    </a>
    is the maximum 1D surface size.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1a85bc895583a26251fbfef635c7644a9" shape="rect">
     maxSurface2D[2]
    </a>
    contains the maximum 2D surface dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_14fdf5cd399b60955ee35421a7cc6418a" shape="rect">
     maxSurface3D[3]
    </a>
    contains the maximum 3D surface dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16cf36809ff5ed6b8aa836177d0292200" shape="rect">
     maxSurface1DLayered[2]
    </a>
    contains the maximum 1D layered surface dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1edeed8d96d802c4b01149e2e6a7b4ea8" shape="rect">
     maxSurface2DLayered[3]
    </a>
    contains the maximum 2D layered surface dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1d170a7ad44ced64478d50fd7b6378b41" shape="rect">
     maxSurfaceCubemap
    </a>
    is the maximum cubemap surface width or height.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1d4564200e6bc420be63b61251c6d39b8" shape="rect">
     maxSurfaceCubemapLayered[2]
    </a>
    contains the maximum cubemap layered surface dimensions.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18fe20825e4239ff91a7708c9468a02b5" shape="rect">
     surfaceAlignment
    </a>
    specifies the alignment requirements for surfaces.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18e2fe2a3b264901816874516af12a097" shape="rect">
     concurrentKernels
    </a>
    is 1 if the device supports executing multiple kernels within the same context simultaneously, or 0 if not. It is not guaranteed
                                          that multiple kernels will be resident on the device concurrently so this feature should not be relied upon for correctness.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_172919e0168f8dc8a719e2c38355b80ab" shape="rect">
     ECCEnabled
    </a>
    is 1 if the device has ECC support turned on, or 0 if not.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1c5adc2ef8c6b89fb139b4684175db54a" shape="rect">
     pciBusID
    </a>
    is the PCI bus identifier of the device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_156978c2bfc433d26ac3b4c765ee536bb" shape="rect">
     pciDeviceID
    </a>
    is the PCI device (sometimes called slot) identifier of the device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f3a69f0796e32c0e32d17c151443fab0" shape="rect">
     pciDomainID
    </a>
    is the PCI domain identifier of the device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1fcc96a9e56f84f4a0e853c18ce8e2c0d" shape="rect">
     tccDriver
    </a>
    is 1 if the device is using a TCC driver or 0 if not.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_105a89c028bee8fe480d0f44ddd43357b" shape="rect">
     asyncEngineCount
    </a>
    is 1 when the device can concurrently copy memory between host and device while executing a kernel. It is 2 when the device
                                          can concurrently copy memory between host and device in both directions and execute a kernel at the same time. It is 0 if
                                          neither of these is supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_107b0114cefb43da05e05c65ec859542c" shape="rect">
     unifiedAddressing
    </a>
    is 1 if the device shares a unified address space with the host and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b200f01a8ec81912285c2633117109c4" shape="rect">
     memoryClockRate
    </a>
    is the peak memory clock frequency in kilohertz.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e764fca4d15a459279b31cb533435c19" shape="rect">
     memoryBusWidth
    </a>
    is the memory bus width in bits.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b40b9ed0e542e9f09667b0a89fb6ad85" shape="rect">
     l2CacheSize
    </a>
    is L2 cache size in bytes.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1708c0ea6df419516e4bd702dd26f802c" shape="rect">
     persistingL2CacheMaxSize
    </a>
    is L2 cache's maximum persisting lines size in bytes.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_196dac83c7095e29b86300cc02851844c" shape="rect">
     maxThreadsPerMultiProcessor
    </a>
    is the number of maximum resident threads per multiprocessor.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_143e968b12978ffd2a80bde224d7dc782" shape="rect">
     streamPrioritiesSupported
    </a>
    is 1 if the device supports stream priorities, or 0 if it is not supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1551ac00fc5ba827a91d705b164288bff" shape="rect">
     globalL1CacheSupported
    </a>
    is 1 if the device supports caching of globals in L1 cache, or 0 if it is not supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e1772eeb293a76aae0bbf7f965a403d5" shape="rect">
     localL1CacheSupported
    </a>
    is 1 if the device supports caching of locals in L1 cache, or 0 if it is not supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16cede1829516e86917f0842a5f6498c8" shape="rect">
     sharedMemPerMultiprocessor
    </a>
    is the maximum amount of shared memory available to a multiprocessor in bytes; this amount is shared by all thread blocks
                                          simultaneously resident on a multiprocessor.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1de02e669caefcadadaaa42877b08e80a" shape="rect">
     regsPerMultiprocessor
    </a>
    is the maximum number of 32-bit registers available to a multiprocessor; this number is shared by all thread blocks simultaneously
                                          resident on a multiprocessor.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f7230860be3e37047c7ce5d32542b54b" shape="rect">
     managedMemory
    </a>
    is 1 if the device supports allocating managed memory on this system, or 0 if it is not supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1512d849f57e6a6a0ece1d21879c3ae35" shape="rect">
     isMultiGpuBoard
    </a>
    is 1 if the device is on a multi-GPU board (e.g. Gemini cards), and 0 if not;
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_163af976611c9d29f169882f5c32472d4" shape="rect">
     multiGpuBoardGroupID
    </a>
    is a unique identifier for a group of devices associated with the same board. Devices on the same multi-GPU board will share
                                          the same identifier.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1ef82fd7d1d0413c7d6f33287e5b6306f" shape="rect">
     hostNativeAtomicSupported
    </a>
    is 1 if the link between the device and the host supports native atomic operations, or 0 if it is not supported.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_14bd4d531bf2ac497d659b03910440315" shape="rect">
     singleToDoublePrecisionPerfRatio
    </a>
    is the ratio of single precision performance (in floating-point operations per second) to double precision performance.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_146116bab1064b5d7d0642d78f6c27ce1" shape="rect">
     pageableMemoryAccess
    </a>
    is 1 if the device supports coherently accessing pageable memory without calling cudaHostRegister on it, and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_116f9619ccc85e93bc456b8c69c80e78b" shape="rect">
     concurrentManagedAccess
    </a>
    is 1 if the device can coherently access managed memory concurrently with the CPU, and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_154a9a6e0067360f23dc91e60e7cf88d1" shape="rect">
     computePreemptionSupported
    </a>
    is 1 if the device supports Compute Preemption, and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1ae79e062f076b0270625b38bb91285b8" shape="rect">
     canUseHostPointerForRegisteredMem
    </a>
    is 1 if the device can access host registered memory at the same virtual address as the CPU, and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13c26ab51c96f39b115d7826337541914" shape="rect">
     cooperativeLaunch
    </a>
    is 1 if the device supports launching cooperative kernels via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gc0210b928f9bf4e212af07d35ac11d67" shape="rect" title="Launches a device function.">
     cudaLaunchCooperativeKernel
    </a>
    , and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_183271637b431ccb5f5b58c46d0bd8cc9" shape="rect">
     cooperativeMultiDeviceLaunch
    </a>
    is 1 if the device supports launching cooperative kernels via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g63685d849da7565b5774f5321a342f05" shape="rect" title="Launches device functions on multiple devices where thread blocks can cooperate and synchronize as they execute.">
     cudaLaunchCooperativeKernelMultiDevice
    </a>
    , and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1c23eacaeeb59e1798d6d442be70f1c3e" shape="rect">
     sharedMemPerBlockOptin
    </a>
    is the per device maximum shared memory per block usable by special opt in
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e9f1ed6bffd5606eb81d438728a844ca" shape="rect">
     pageableMemoryAccessUsesHostPageTables
    </a>
    is 1 if the device accesses pageable memory via the host's page tables, and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1b47773cf29bec05e6f1ba569346889e8" shape="rect">
     directManagedMemAccessFromHost
    </a>
    is 1 if the host can directly access managed memory on the device without migration, and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_17f337476973ea65db85c277f4646f0b3" shape="rect">
     maxBlocksPerMultiProcessor
    </a>
    is the maximum number of thread blocks that can reside on a multiprocessor.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_192470653c71f372dbec29bd693d55316" shape="rect">
     accessPolicyMaxWindowSize
    </a>
    is the maximum value of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html#structcudaAccessPolicyWindow_1bbd68021cb5c3cb1928bee0a2941eb24" shape="rect">
     cudaAccessPolicyWindow::num_bytes
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_15a1f6049e9e9fd8af0d2a8a5df289ab7" shape="rect">
     reservedSharedMemPerBlock
    </a>
    is the shared memory reserved by CUDA driver per block in bytes
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1861e700db4605a3fb81cb994e3d2d9c2" shape="rect">
     hostRegisterSupported
    </a>
    is 1 if the device supports host memory registration via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
     cudaHostRegister
    </a>
    , and 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_13237d19d8b4f8ed68411937b4ea001b8" shape="rect">
     sparseCudaArraySupported
    </a>
    is 1 if the device supports sparse CUDA arrays and sparse CUDA mipmapped arrays, 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_17e123c52deb1c940d9e0dc4bbac64a76" shape="rect">
     hostRegisterReadOnlySupported
    </a>
    is 1 if the device supports using the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
     cudaHostRegister
    </a>
    flag cudaHostRegisterReadOnly to register memory that must be mapped as read-only to the GPU
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f2eb506be3f63db30715725d2e19ac1d" shape="rect">
     timelineSemaphoreInteropSupported
    </a>
    is 1 if external timeline semaphore interop is supported on the device, 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_16c4af6a4889a35c0bc21bbd3dd7443bb" shape="rect">
     memoryPoolsSupported
    </a>
    is 1 if the device supports using the cudaMallocAsync and cudaMemPool family of APIs, 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_18365322f55133cf8226f59aebff0b49f" shape="rect">
     gpuDirectRDMASupported
    </a>
    is 1 if the device supports GPUDirect RDMA APIs, 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_179f31a48236e1100df36df98c63d8f47" shape="rect">
     gpuDirectRDMAFlushWritesOptions
    </a>
    is a bitmask to be interpreted according to the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g08213e5a1b0dfdeeb88ed0146ca86f63" shape="rect">
     cudaFlushGPUDirectRDMAWritesOptions
    </a>
    enum
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_10b1f11deaf3873f4c365036d2a530695" shape="rect">
     gpuDirectRDMAWritesOrdering
    </a>
    See the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd945c8e3f04e38760c1dac290519eb19" shape="rect">
     cudaGPUDirectRDMAWritesOrdering
    </a>
    enum for numerical values
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1e885cf451108cf85dc3b313bce0c9026" shape="rect">
     memoryPoolSupportedHandleTypes
    </a>
    is a bitmask of handle types supported with mempool-based IPC
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_1f557e52f68c1844a785aa6c1c187acca" shape="rect">
     deferredMappingCudaArraySupported
    </a>
    is 1 if the device supports deferred mapping CUDA arrays and CUDA mipmapped arrays
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_15a49ec0bc568c80b40fcbb76cbaa5089" shape="rect">
     ipcEventSupported
    </a>
    is 1 if the device supports IPC Events, and 0 otherwise
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp_19f94309e6d30a640821cc9de9591e565" shape="rect">
     unifiedFunctionPointers
    </a>
    is 1 if the device support unified pointers, and 0 otherwise
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g9c3e1414f0ad901d3278a4d6645fc266" shape="rect" target="_blank">
   cuDeviceGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f" shape="rect" target="_blank">
   cuDeviceGetName
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" name="group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaInitDevice (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   deviceFlags
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Initialize device to be used for GPU executions.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device on which the runtime will initialize itself.
 <span class="keyword keyword apiItemName">
  deviceFlags
 </span>
 - Parameters for device operation.
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Flags for controlling the device initialization.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  This function will initialize the CUDA Runtime structures and primary context on
  device
  when called, but the context will not be made current to
  device
  .
 </p>
 <p class="p">
  When
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2ff861a477ec064dcf01977194158e49" shape="rect">
   cudaInitDeviceFlagsAreValid
  </a>
  is set in
  flags
  , deviceFlags are applied to the requested device. The values of deviceFlags match those of the flags parameters in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  . The effect may be verified by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" shape="rect" title="Gets the flags for the current device.">
   cudaGetDeviceFlags
  </a>
  .
 </p>
 <p class="p">
  This function will return an error if the device is in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d02cd032834fecbec513ea1018145b111d" shape="rect">
   cudaComputeModeExclusiveProcess
  </a>
  and is occupied by another process or if the device is in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d0fc71b88518e4501544d6e65b5f3671b6" shape="rect">
   cudaComputeModeProhibited
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1gbe562ee6258b4fcc272ca6478ca2a2f7" shape="rect" target="_blank">
   cuCtxSetCurrent
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" name="group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaIpcCloseMemHandle (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  )
 </span>
 Attempts to close memory mapped with cudaIpcOpenMemHandle.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Device pointer returned by
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
  cudaIpcOpenMemHandle
 </a>
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038a2625b63c0940c54ed07f2986b12e0f1" shape="rect">
   cudaErrorMapBufferObjectFailed
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Decrements the reference count of the memory returnd by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  by 1. When the reference count reaches 0, this API unmaps the memory. The original allocation in the exporting process as
                                 well as imported mappings in other processes will be unaffected.
 </p>
 <p class="p">
  Any resources used to enable peer access will be freed if this is the last mapping using them.
 </p>
 <p class="p">
  IPC functionality is restricted to devices with support for unified addressing on Linux and Windows operating systems. IPC
                                 functionality on Windows is supported for compatibility purposes but not recommended as it comes with performance cost. Users
                                 can test their device for IPC functionality by calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0ab012a7c597ffbe86090ee2f9e1758c" shape="rect">
   cudaDevAttrIpcEventSupport
  </a>
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect" title="Gets an interprocess handle for a previously allocated event.">
   cudaIpcGetEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect" title="Opens an interprocess event handle for use in the current process.">
   cudaIpcOpenEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect" title="Gets an interprocess memory handle for an existing device memory allocation.">
   cudaIpcGetMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gd6f5d5bcf6376c6853b64635b0157b9e" shape="rect" target="_blank">
   cuIpcCloseMemHandle
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" name="group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaIpcGetEventHandle (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t" shape="rect" title="">
   cudaIpcEventHandle_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gea2f543a9fc0e52fe4ae712920fd1247" shape="rect" title="">
   cudaEvent_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   event
  </span>
  )
 </span>
 Gets an interprocess handle for a previously allocated event.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  handle
 </span>
 - Pointer to a user allocated cudaIpcEventHandle in which to return the opaque event handle
 <span class="keyword keyword apiItemName">
  event
 </span>
 - Event allocated with
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g49ec9cd742f8a3f6fde4ee72a66326f6" shape="rect">
  cudaEventInterprocess
 </a>
 and
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ga5d3eff7c3623e2be533968d9cc1ee7e" shape="rect">
  cudaEventDisableTiming
 </a>
 flags.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c4673247aee4d1ab8d07871f376e0273" shape="rect">
   cudaErrorInvalidResourceHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038a2625b63c0940c54ed07f2986b12e0f1" shape="rect">
   cudaErrorMapBufferObjectFailed
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Takes as input a previously allocated event. This event must have been created with the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g49ec9cd742f8a3f6fde4ee72a66326f6" shape="rect">
   cudaEventInterprocess
  </a>
  and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ga5d3eff7c3623e2be533968d9cc1ee7e" shape="rect">
   cudaEventDisableTiming
  </a>
  flags set. This opaque handle may be copied into other processes and opened with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect" title="Opens an interprocess event handle for use in the current process.">
   cudaIpcOpenEventHandle
  </a>
  to allow efficient hardware synchronization between GPU work in different processes.
 </p>
 <p class="p">
  After the event has been been opened in the importing process,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1gf4fcb74343aa689f4159791967868446" shape="rect" title="Records an event.">
   cudaEventRecord
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g949aa42b30ae9e622f6ba0787129ff22" shape="rect" title="Waits for an event to complete.">
   cudaEventSynchronize
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g7840e3984799941a61839de40413d1d9" shape="rect" title="Make a compute stream wait on an event.">
   cudaStreamWaitEvent
  </a>
  and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2bf738909b4a059023537eaa29d8a5b7" shape="rect" title="Queries an event's status.">
   cudaEventQuery
  </a>
  may be used in either process. Performing operations on the imported event after the exported event has been freed with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2cb6baa0830a1cd0bd957bfd8705045b" shape="rect" title="Destroys an event object.">
   cudaEventDestroy
  </a>
  will result in undefined behavior.
 </p>
 <p class="p">
  IPC functionality is restricted to devices with support for unified addressing on Linux and Windows operating systems. IPC
                                 functionality on Windows is supported for compatibility purposes but not recommended as it comes with performance cost. Users
                                 can test their device for IPC functionality by calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0ab012a7c597ffbe86090ee2f9e1758c" shape="rect">
   cudaDevAttrIpcEventSupport
  </a>
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4b5fdb19d7fb5f6f8862559f9279f6c3" shape="rect" title="[C++ API] Creates an event object with the specified flags">
   cudaEventCreate
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2cb6baa0830a1cd0bd957bfd8705045b" shape="rect" title="Destroys an event object.">
   cudaEventDestroy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g949aa42b30ae9e622f6ba0787129ff22" shape="rect" title="Waits for an event to complete.">
   cudaEventSynchronize
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2bf738909b4a059023537eaa29d8a5b7" shape="rect" title="Queries an event's status.">
   cudaEventQuery
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g7840e3984799941a61839de40413d1d9" shape="rect" title="Make a compute stream wait on an event.">
   cudaStreamWaitEvent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect" title="Opens an interprocess event handle for use in the current process.">
   cudaIpcOpenEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect" title="Gets an interprocess memory handle for an existing device memory allocation.">
   cudaIpcGetMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect" title="Attempts to close memory mapped with cudaIpcOpenMemHandle.">
   cudaIpcCloseMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gea02eadd12483de5305878b13288a86c" shape="rect" target="_blank">
   cuIpcGetEventHandle
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" name="group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaIpcGetMemHandle (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t" shape="rect" title="">
   cudaIpcMemHandle_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  )
 </span>
 Gets an interprocess memory handle for an existing device memory allocation.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  handle
 </span>
 - Pointer to user allocated cudaIpcMemHandle to return the handle in.
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Base pointer to previously allocated device memory
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038a2625b63c0940c54ed07f2986b12e0f1" shape="rect">
   cudaErrorMapBufferObjectFailed
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Takes a pointer to the base of an existing device memory allocation created with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  and exports it for use in another process. This is a lightweight operation and may be called multiple times on an allocation
                                 without adverse effects.
 </p>
 <p class="p">
  If a region of memory is freed with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  and a subsequent call to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  returns memory with the same device address,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect" title="Gets an interprocess memory handle for an existing device memory allocation.">
   cudaIpcGetMemHandle
  </a>
  will return a unique handle for the new memory.
 </p>
 <p class="p">
  IPC functionality is restricted to devices with support for unified addressing on Linux and Windows operating systems. IPC
                                 functionality on Windows is supported for compatibility purposes but not recommended as it comes with performance cost. Users
                                 can test their device for IPC functionality by calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0ab012a7c597ffbe86090ee2f9e1758c" shape="rect">
   cudaDevAttrIpcEventSupport
  </a>
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect" title="Gets an interprocess handle for a previously allocated event.">
   cudaIpcGetEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect" title="Opens an interprocess event handle for use in the current process.">
   cudaIpcOpenEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect" title="Attempts to close memory mapped with cudaIpcOpenMemHandle.">
   cudaIpcCloseMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g6f1b5be767b275f016523b2ac49ebec1" shape="rect" target="_blank">
   cuIpcGetMemHandle
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" name="group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaIpcOpenEventHandle (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gea2f543a9fc0e52fe4ae712920fd1247" shape="rect" title="">
   cudaEvent_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   event
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t" shape="rect" title="">
   cudaIpcEventHandle_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  )
 </span>
 Opens an interprocess event handle for use in the current process.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  event
 </span>
 - Returns the imported event
 <span class="keyword keyword apiItemName">
  handle
 </span>
 - Interprocess handle to open
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038a2625b63c0940c54ed07f2986b12e0f1" shape="rect">
   cudaErrorMapBufferObjectFailed
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00389e95927732f0d5a68151c72296581504" shape="rect">
   cudaErrorDeviceUninitialized
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Opens an interprocess event handle exported from another process with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect" title="Gets an interprocess handle for a previously allocated event.">
   cudaIpcGetEventHandle
  </a>
  . This function returns a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gea2f543a9fc0e52fe4ae712920fd1247" shape="rect">
   cudaEvent_t
  </a>
  that behaves like a locally created event with the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ga5d3eff7c3623e2be533968d9cc1ee7e" shape="rect">
   cudaEventDisableTiming
  </a>
  flag specified. This event must be freed with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2cb6baa0830a1cd0bd957bfd8705045b" shape="rect" title="Destroys an event object.">
   cudaEventDestroy
  </a>
  .
 </p>
 <p class="p">
  Performing operations on the imported event after the exported event has been freed with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2cb6baa0830a1cd0bd957bfd8705045b" shape="rect" title="Destroys an event object.">
   cudaEventDestroy
  </a>
  will result in undefined behavior.
 </p>
 <p class="p">
  IPC functionality is restricted to devices with support for unified addressing on Linux and Windows operating systems. IPC
                                 functionality on Windows is supported for compatibility purposes but not recommended as it comes with performance cost. Users
                                 can test their device for IPC functionality by calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0ab012a7c597ffbe86090ee2f9e1758c" shape="rect">
   cudaDevAttrIpcEventSupport
  </a>
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4b5fdb19d7fb5f6f8862559f9279f6c3" shape="rect" title="[C++ API] Creates an event object with the specified flags">
   cudaEventCreate
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2cb6baa0830a1cd0bd957bfd8705045b" shape="rect" title="Destroys an event object.">
   cudaEventDestroy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g949aa42b30ae9e622f6ba0787129ff22" shape="rect" title="Waits for an event to complete.">
   cudaEventSynchronize
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT_1g2bf738909b4a059023537eaa29d8a5b7" shape="rect" title="Queries an event's status.">
   cudaEventQuery
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g7840e3984799941a61839de40413d1d9" shape="rect" title="Make a compute stream wait on an event.">
   cudaStreamWaitEvent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect" title="Gets an interprocess handle for a previously allocated event.">
   cudaIpcGetEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect" title="Gets an interprocess memory handle for an existing device memory allocation.">
   cudaIpcGetMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect" title="Attempts to close memory mapped with cudaIpcOpenMemHandle.">
   cudaIpcCloseMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gf1d525918b6c643b99ca8c8e42e36c2e" shape="rect" target="_blank">
   cuIpcOpenEventHandle
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" name="group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaIpcOpenMemHandle (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t" shape="rect" title="">
   cudaIpcMemHandle_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handle
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Returned device pointer
 <span class="keyword keyword apiItemName">
  handle
 </span>
 - cudaIpcMemHandle to open
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Flags for this operation. Must be specified as
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g60f28a5142ee7ae0336dfa83fd54e006" shape="rect">
  cudaIpcMemLazyEnablePeerAccess
 </a>
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038a2625b63c0940c54ed07f2986b12e0f1" shape="rect">
   cudaErrorMapBufferObjectFailed
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c4673247aee4d1ab8d07871f376e0273" shape="rect">
   cudaErrorInvalidResourceHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00389e95927732f0d5a68151c72296581504" shape="rect">
   cudaErrorDeviceUninitialized
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388f0bc63a488221933dbf7cd67305b666" shape="rect">
   cudaErrorTooManyPeers
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Maps memory exported from another process with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect" title="Gets an interprocess memory handle for an existing device memory allocation.">
   cudaIpcGetMemHandle
  </a>
  into the current device address space. For contexts on different devices
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  can attempt to enable peer access between the devices as if the user called
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g2b0adabf90db37e5cfddc92cbb2589f3" shape="rect" title="Enables direct access to memory allocations on a peer device.">
   cudaDeviceEnablePeerAccess
  </a>
  . This behavior is controlled by the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g60f28a5142ee7ae0336dfa83fd54e006" shape="rect">
   cudaIpcMemLazyEnablePeerAccess
  </a>
  flag.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g4db0d04e44995d5c1c34be4ecc863f22" shape="rect" title="Queries if a device may directly access a peer device's memory.">
   cudaDeviceCanAccessPeer
  </a>
  can determine if a mapping is possible.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  can open handles to devices that may not be visible in the process calling the API.
 </p>
 <p class="p">
  Contexts that may open cudaIpcMemHandles are restricted in the following way. cudaIpcMemHandles from each device in a given
                                 process may only be opened by one context per device per other process.
 </p>
 <p class="p">
  If the memory handle has already been opened by the current context, the reference count on the handle is incremented by 1
                                 and the existing device pointer is returned.
 </p>
 <p class="p">
  Memory returned from
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g01050a29fefde385b1042081ada4cde9" shape="rect" title="Opens an interprocess memory handle exported from another process and returns a device pointer usable in the local process.">
   cudaIpcOpenMemHandle
  </a>
  must be freed with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect" title="Attempts to close memory mapped with cudaIpcOpenMemHandle.">
   cudaIpcCloseMemHandle
  </a>
  .
 </p>
 <p class="p">
  Calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  on an exported memory region before calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect" title="Attempts to close memory mapped with cudaIpcOpenMemHandle.">
   cudaIpcCloseMemHandle
  </a>
  in the importing context will result in undefined behavior.
 </p>
 <p class="p">
  IPC functionality is restricted to devices with support for unified addressing on Linux and Windows operating systems. IPC
                                 functionality on Windows is supported for compatibility purposes but not recommended as it comes with performance cost. Users
                                 can test their device for IPC functionality by calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0ab012a7c597ffbe86090ee2f9e1758c" shape="rect">
   cudaDevAttrIpcEventSupport
  </a>
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    No guarantees are made about the address returned in
    *devPtr
    . In particular, multiple processes may not receive the same address for the same
    handle
    .
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g89a3abe1e9a11d08c665176669109784" shape="rect" title="Gets an interprocess handle for a previously allocated event.">
   cudaIpcGetEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9691446ab0aec1d6e528357387ed87b2" shape="rect" title="Opens an interprocess event handle for use in the current process.">
   cudaIpcOpenEventHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g8a37f7dfafaca652391d0758b3667539" shape="rect" title="Gets an interprocess memory handle for an existing device memory allocation.">
   cudaIpcGetMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb3632b5d223db6acae5f8744e2c91" shape="rect" title="Attempts to close memory mapped with cudaIpcOpenMemHandle.">
   cudaIpcCloseMemHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g2b0adabf90db37e5cfddc92cbb2589f3" shape="rect" title="Enables direct access to memory allocations on a peer device.">
   cudaDeviceEnablePeerAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER_1g4db0d04e44995d5c1c34be4ecc863f22" shape="rect" title="Queries if a device may directly access a peer device's memory.">
   cudaDeviceCanAccessPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ga8bd126fcff919a0c996b7640f197b79" shape="rect" target="_blank">
   cuIpcOpenMemHandle
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" name="group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaSetDevice (  int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Set device to be used for GPU executions.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device on which the active host thread should execute the device code.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  , cudaErrorDeviceUnavailable,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Sets
  device
  as the current device for the calling host thread. Valid device id's are 0 to (
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount()
  </a>
  - 1).
 </p>
 <p class="p">
  Any device memory subsequently allocated from this host thread using
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc()
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray()
  </a>
  will be physically resident on
  device
  . Any host memory allocated from this host thread using
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost()
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc()
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
   cudaHostRegister()
  </a>
  will have its lifetime associated with
  device
  . Any streams or events created from this host thread will be associated with
  device
  . Any kernels launched from this host thread using the &lt;&lt;&lt;&gt;&gt;&gt; operator or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g5064cdf5d8e6741ace56fd8be951783c" shape="rect" title="Launches a device function.">
   cudaLaunchKernel()
  </a>
  will be executed on
  device
  .
 </p>
 <p class="p">
  This call may be made from any host thread, to any device, and at any time. This function will do no synchronization with
                                 the previous or new device, and should only take significant time when it initializes the runtime's context state. This call
                                 will bind the primary context of the specified device to the calling thread and all the subsequent memory allocations, stream
                                 and event creations, and kernel launches will be associated with the primary context. This function will also immediately
                                 initialize the runtime state on the primary context, and the context will be current on
  device
  immediately. This function will return an error if the device is in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d02cd032834fecbec513ea1018145b111d" shape="rect">
   cudaComputeModeExclusiveProcess
  </a>
  and is occupied by another process or if the device is in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg7eb25f5413a962faad0956d92bae10d0fc71b88518e4501544d6e65b5f3671b6" shape="rect">
   cudaComputeModeProhibited
  </a>
  .
 </p>
 <p class="p">
  It is not required to call
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  before using this function.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1gbe562ee6258b4fcc272ca6478ca2a2f7" shape="rect" target="_blank">
   cuCtxSetCurrent
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" name="group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaSetDeviceFlags (  unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Sets flags to be used for device executions.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Parameters for device operation
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Records
  flags
  as the flags for the current device. If the current device has been set and that device has already been initialized, the
                                 previous flags are overwritten. If the current device has not been initialized, it is initialized with the provided flags.
                                 If no device has been made current to the calling thread, a default device is selected and initialized with the provided flags.
 </p>
 <p class="p">
  The two LSBs of the
  flags
  parameter can be used to control how the CPU thread interacts with the OS scheduler when waiting for results from the device.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3ade1dbaf4b222b22733cdfdcc026075" shape="rect">
     cudaDeviceScheduleAuto
    </a>
    : The default value if the
    flags
    parameter is zero, uses a heuristic based on the number of active CUDA contexts in the process
    C
    and the number of logical processors in the system
    P
    . If
    C
    &gt;
    P
    , then CUDA will yield to other OS threads when waiting for the device, otherwise CUDA will not yield while waiting for results
                                          and actively spin on the processor. Additionally, on Tegra devices,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3ade1dbaf4b222b22733cdfdcc026075" shape="rect">
     cudaDeviceScheduleAuto
    </a>
    uses a heuristic based on the power profile of the platform and may choose
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g057e6912c52708b6aa86e79dd83d007c" shape="rect">
     cudaDeviceScheduleBlockingSync
    </a>
    for low-powered devices.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf01347c3dafebf07e1a0b4321a030a63" shape="rect">
     cudaDeviceScheduleSpin
    </a>
    : Instruct CUDA to actively spin when waiting for results from the device. This can decrease latency when waiting for the
                                          device, but may lower the performance of CPU threads if they are performing work in parallel with the CUDA thread.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gbc13c52d342c67ebf0f1f7af937735a8" shape="rect">
     cudaDeviceScheduleYield
    </a>
    : Instruct CUDA to yield its thread when waiting for results from the device. This can increase latency when waiting for the
                                          device, but can increase the performance of CPU threads performing work in parallel with the device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g057e6912c52708b6aa86e79dd83d007c" shape="rect">
     cudaDeviceScheduleBlockingSync
    </a>
    : Instruct CUDA to block the CPU thread on a synchronization primitive when waiting for the device to finish work.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g130ddae663f1873258fee5a6e0808b71" shape="rect">
     cudaDeviceBlockingSync
    </a>
    : Instruct CUDA to block the CPU thread on a synchronization primitive when waiting for the device to finish work.
   </p>
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated" shape="rect">
     Deprecated:
    </a>
    This flag was deprecated as of CUDA 4.0 and replaced with
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g057e6912c52708b6aa86e79dd83d007c" shape="rect">
     cudaDeviceScheduleBlockingSync
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3762be9cccdd809a4ca128354fd134b0" shape="rect">
     cudaDeviceMapHost
    </a>
    : This flag enables allocating pinned host memory that is accessible to the device. It is implicit for the runtime but may
                                          be absent if a context is created using the driver API. If this flag is not set,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
     cudaHostGetDevicePointer()
    </a>
    will always return a failure code.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gda5f97298bf704dd3b04cbac4819e6e3" shape="rect">
     cudaDeviceLmemResizeToMax
    </a>
    : Instruct CUDA to not reduce local memory after resizing local memory for a kernel. This can prevent thrashing by local memory
                                          allocations when launching many kernels with high local memory usage at the cost of potentially increased memory usage.
   </p>
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated" shape="rect">
     Deprecated:
    </a>
    This flag is deprecated and the behavior enabled by this flag is now the default and cannot be disabled.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gb5cbd9be7931e6c68d11e1175aa14c23" shape="rect">
     cudaDeviceSyncMemops
    </a>
    : Ensures that synchronous memory operations initiated on this context will always synchronize. See further documentation
                                          in the section titled "API Synchronization behavior" to learn more about cases when synchronous memory operations can exhibit
                                          asynchronous behavior.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" shape="rect" title="Gets the flags for the current device.">
   cudaGetDeviceFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78" shape="rect" title="Returns which device is currently being used.">
   cudaGetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1b9336c70f2299405f67a4f8496d7cfe" shape="rect" title="Set a list of devices that can be used for CUDA.">
   cudaSetValidDevices
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gac04a5d82168676b20121ca870919419" shape="rect" title="Initialize device to be used for GPU executions.">
   cudaInitDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PRIMARY__CTX.html#group__CUDA__PRIMARY__CTX_1gd779a84f17acdad0d9143d9fe719cfdf" shape="rect" target="_blank">
   cuDevicePrimaryCtxSetFlags
  </a>
 </p>
 <a id="group__CUDART__DEVICE_1g1b9336c70f2299405f67a4f8496d7cfe" name="group__CUDART__DEVICE_1g1b9336c70f2299405f67a4f8496d7cfe" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaSetValidDevices (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device_arr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   len
  </span>
  )
 </span>
 Set a list of devices that can be used for CUDA.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  device_arr
 </span>
 - List of devices to try
 <span class="keyword keyword apiItemName">
  len
 </span>
 - Number of devices in specified list
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Sets a list of devices for CUDA execution in priority order using
  device_arr
  . The parameter
  len
  specifies the number of elements in the list. CUDA will try devices from the list sequentially until it finds one that works.
                                 If this function is not called, or if it is called with a
  len
  of 0, then CUDA will go back to its default behavior of trying devices sequentially from a default list containing all of
                                 the available CUDA devices in the system. If a specified device ID in the list does not exist, this function will return
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  . If
  len
  is not 0 and
  device_arr
  is NULL or if
  len
  exceeds the number of devices in the system, then
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  is returned.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f" shape="rect" title="Returns the number of compute-capable devices.">
   cudaGetDeviceCount
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g159587909ffa0791bbe4b40187a4c6bb" shape="rect" title="Set device to be used for GPU executions.">
   cudaSetDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0" shape="rect" title="Returns information about the compute-device.">
   cudaGetDeviceProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf61f9ae0fe2d93b5b968756684a49460" shape="rect" title="Select compute-device which best matches criteria.">
   cudaChooseDevice
  </a>
 </p>
 <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
  Privacy Policy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
  Manage My Privacy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
  Do Not Sell or Share My Data
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
  Terms of Service
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
  Accessibility
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
  Corporate Policies
 </a>
 |
 <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
  Product Security
 </a>
 |
 <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
  Contact
 </a>
 Copyright Â© 2007-2024 NVIDIA Corporation
</body>
</body></html>