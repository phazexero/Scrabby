<html><head><title>cuFile API Reference Guide - NVIDIA Docs</title></head><body><body class="Page-body">
 <!-- Putting icons here, so we don't have to include in a bunch of -body hbs's -->
 <span class="sr-only">
  Submit Search
 </span>
 <!--***********************************************************************************************************************************************************************************
        This script code is added only when moreAttributes is "mobile-only" just because on Books and Topics "mobile-only" search is the last added, so I've added with the last one
        because the external script "nvidia-in-book-search-page-widget.js" searches for the hidden fields for both desktop and mobile, so if I load the script before all fields are
        rendered, the script fails
    **************************************************************************************************************************************************************************************-->
 <ul class="Navigation-items">
  <li class="Navigation-items-item">
   <a href="https://developer.nvidia.com/" target="_blank">
    NVIDIA Developer
   </a>
  </li>
  <li class="Navigation-items-item">
   <a href="https://developer.nvidia.com/blog/" target="_blank">
    Blog
   </a>
  </li>
  <li class="Navigation-items-item">
   <a href="https://forums.developer.nvidia.com/" target="_blank">
    Forums
   </a>
  </li>
  <li class="Navigation-items-item">
   <a class="Button" data-size="small" data-theme="secondary" href="https://docs.nvidia.com/login" rel="nofollow noopener" style="--button-border-radius: 0px">
    Join
   </a>
  </li>
 </ul>
 <a aria-label="home page" href="https://docs.nvidia.com/">
 </a>
 <span class="sr-only">
  Submit Search
 </span>
 <!--***********************************************************************************************************************************************************************************
        This script code is added only when moreAttributes is "mobile-only" just because on Books and Topics "mobile-only" search is the last added, so I've added with the last one
        because the external script "nvidia-in-book-search-page-widget.js" searches for the hidden fields for both desktop and mobile, so if I load the script before all fields are
        rendered, the script fails
    **************************************************************************************************************************************************************************************-->
 <ul class="Navigation-items">
  <li class="Navigation-items-item">
   <a data-cms-ai="0" href="https://developer.nvidia.com/" target="_blank">
    NVIDIA Developer
   </a>
  </li>
  <li class="Navigation-items-item">
   <a data-cms-ai="0" href="https://developer.nvidia.com/blog/" target="_blank">
    Blog
   </a>
  </li>
  <li class="Navigation-items-item">
   <a data-cms-ai="0" href="https://forums.developer.nvidia.com/" target="_blank">
    Forums
   </a>
  </li>
  <li class="Navigation-items-item">
   <a class="Button" data-cms-ai="0" data-size="small" data-theme="secondary" href="https://docs.nvidia.com/login" rel="nofollow noopener" style="--button-border-radius: 0px">
    Join
   </a>
  </li>
 </ul>
 <span class="label">
  Menu
 </span>
 <a class="Page-BackToTop" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html">
 </a>
 <h1 class="PageHeading-title">
  cuFile API Reference Guide
 </h1>
 <span class="sr-only">
  Submit Search
 </span>
 <!--***********************************************************************************************************************************************************************************
        This script code is added only when moreAttributes is "mobile-only" just because on Books and Topics "mobile-only" search is the last added, so I've added with the last one
        because the external script "nvidia-in-book-search-page-widget.js" searches for the hidden fields for both desktop and mobile, so if I load the script before all fields are
        rendered, the script fails
    **************************************************************************************************************************************************************************************-->
 <span class="sr-only">
  Submit Search
 </span>
 <!--***********************************************************************************************************************************************************************************
        This script code is added only when moreAttributes is "mobile-only" just because on Books and Topics "mobile-only" search is the last added, so I've added with the last one
        because the external script "nvidia-in-book-search-page-widget.js" searches for the hidden fields for both desktop and mobile, so if I load the script before all fields are
        rendered, the script fails
    **************************************************************************************************************************************************************************************-->
 <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/">
  NVIDIA Docs Hub
 </a>
 <span class="Link">
  NVIDIA GPUDirect Storage (GDS)
 </span>
 <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/index.html">
  NVIDIA GPUDirect Storage
 </a>
 <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html">
  cuFile API Reference Guide
 </a>
 <span class="TopicPage-version">
  NVIDIA GPUDirect Storage (GDS) (Latest Release)
 </span>
 <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/pdf/api-reference-guide.pdf">
  Download PDF
 </a>
 <h2>
  <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#abstract" id="abstract" name="abstract" shape="rect">
   GDS cuFile API Reference
  </a>
 </h2>
 <p>
  The NVIDIA® GPUDirect® Storage cuFile API Reference Guide provides information about the cuFile API reference that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs, which are part of the GDS technology.
 </p>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#introduction">
   1. Introduction
  </a>
 </h2>
 <p>
  <a class="Link" data-cms-ai="0" id="introduction" name="introduction" shape="rect">
  </a>
  NVIDIA® Magnum IO GPUDirect® Storage (GDS) is part of the GPUDirect family. GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer through the CPU. This direct path increases system bandwidth and decreases the latency and utilization load on the CPU.
 </p>
 <p>
  This document provides information about the cuFile APIs that are used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs which are part of the GDS technology.
 </p>
 Note:
 <p>
  The APIs and descriptions are subject to change without notice.
 </p>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#usage">
   2. Usage
  </a>
 </h2>
 <p>
  <a class="Link" data-cms-ai="0" id="usage" name="usage" shape="rect">
  </a>
  This section describes the operation of the cuFile APIs.
 </p>
 <p>
  Because the functionality is part of the CUDA Driver C API, the APIs use the
  <span>
   cuFile
  </span>
  prefix and camel case motif of the CUDA Driver.
 </p>
 <ul>
  <li>
   All APIs are thread-safe.
  </li>
  <li>
   The fork system call should not be used after the library is initialized. The behavior of the APIs after the fork system call is undefined in the child process.
  </li>
  <li>
   The APIs with GPU buffers should be called in a valid CUDA context and stream if applicable.
  </li>
  <li>
   All APIs are issued from the CPU, not the GPU.
  </li>
 </ul>
 Note:
 <p>
  Starting from CUDA toolkit 12.2 (GDS version 1.7.x) release cuFile APIs support memory allocated on GPU device as well as host memory. peer to peer transfer using GPUDirect™ is supported to and from device memory on supported file system and hardware configurations. The APIs will refer to this memory address as buffer pointer unless the API specifically applies to a particular type of memory.
 </p>
 <h3 id="dynamic-interactions">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#dynamic-interactions">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#dynamic-interactions" id="dynamic-interactions" name="dynamic-interactions" shape="rect">
    2.1. Dynamic Interactions
   </a>
  </a>
 </h3>
 <p>
  The following describes the dynamic interactions between the cuFile APIs.
 </p>
 <p>
  Some of the cuFile APIs are optional. If they are not called proactively, their actions will occur reactively:
 </p>
 <p>
  If
  <span>
   cuFile{DriverOpen, HandleRegister, BufRegister}
  </span>
  is called on a driver, file, or buffer, respectively that has been opened or registered by a previous
  <span>
   cuFile
  </span>
  * API call, this will result in an error. Calling
  <span>
   cuFile{BufDeregister, HandleDeregister, DriverClose}
  </span>
  on a buffer, file, or driver, respectively that has never been opened or registered by a previous
  <span>
   cuFile
  </span>
  * API call results in an error. For these errors, the output parameters of the APIs are left in an undefined state, and there are no other side effects.
 </p>
 <ul>
  <li>
   <p>
    <span>
     cuFileDriverOpen
    </span>
    explicitly causes driver initialization.
   </p>
   <p>
    Its use is optional. If it is not used, driver initialization happens implicitly at the first use of the
    <span>
     cuFile{HandleRegister, Read, Write, BufRegister}
    </span>
    APIs.
   </p>
  </li>
 </ul>
 <ul>
  <li>
   (Mandatory)
   <span>
    cuFileHandleRegister
   </span>
   turns an OS-specific file descriptor into a
   <span>
    CUfileHandle_t
   </span>
   and performs checking on the GDS supportability based on the mount point and the way that the file was opened.
  </li>
  <li>
   <p>
    <span>
     cuFileBufRegister
    </span>
    explicitly registers a memory buffer.
   </p>
   <p>
    If this API is not called, an internal registered memory is used if required on the first time the buffer is used, for example, in
    <span>
     cuFile{Read, Write}
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    <span>
     cuFile{BufDeregister, HandleDeregister}
    </span>
    explicitly frees a buffer and file resources, respectively.
   </p>
   <p>
    If this API is not called, the buffer and resources are implicitly freed when the driver is closed using
    <span>
     cuFileDriverClose
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    <span>
     cuFileDriverClose
    </span>
    explicitly frees driver resources.
   </p>
   <p>
    If this API is not called, the driver resources are implicitly freed when
    <span>
     dlclose()
    </span>
    is performed on the library handle or when the process is terminated.
   </p>
  </li>
 </ul>
 <h3 id="driver-file-buffer">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#driver-file-buffer">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#driver-file-buffer" id="driver-file-buffer" name="driver-file-buffer" shape="rect">
    2.2. Driver, File, and Buffer Management
   </a>
  </a>
 </h3>
 <p>
  This section describes the overall workflow to manage the driver, the file, and buffer management:
 </p>
 <ol>
  <li>
   Call
   <span>
    cuFileDriverOpen()
   </span>
   to initialize the state of the critical performance path.
  </li>
  <li>
   Allocate GPU memory with cudaMalloc,
   <span>
    cudaMallocManaged
   </span>
   ,
   <span>
    cuMem*
   </span>
   APIs or host memory using
   <span>
    cudaMallocHost
   </span>
   ,
   <span>
    malloc
   </span>
   or
   <span>
    mmap
   </span>
   .
  </li>
  <li>
   To register the buffer, call
   <span>
    cuFileBufRegister
   </span>
   to initialize the buffer state of the critical performance path.
  </li>
  <li>
   Complete the following IO workflow:
   <ol>
    <li>
     For Linux, open a file with POSIX open.
    </li>
    <li>
     Call
     <span>
      cuFileHandleRegister
     </span>
     to wrap an existing file descriptor in an OS-agnostic
     <span>
      CUfileHandle_t
     </span>
     . This step evaluates the suitability of the file state and the file mount for GDS and initializes the file state of the critical performance path.
    </li>
    <li>
     Call IO APIs such as
     <span>
      cuFileRead
     </span>
     /
     <span>
      cuFileWrite
     </span>
     on an existing cuFile handle and existing buffer.
     <ul class="ul">
      <li class="li">
       If the
       <span>
        cuFileBufRegister
       </span>
       has not been previously called on the buffer pointer,
       <span>
        cuFileRead/cuFileWrite
       </span>
       will use internal registered buffers when required.
      </li>
      <li class="li">
       <p>
        Not using cuFileBufRegister might not be performant for small IO sizes.
       </p>
      </li>
      <li class="li">
       <p>
        Refer to the
        <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html" shape="rect">
         GPUDirect Best Practices Guide
        </a>
        for more information.
       </p>
      </li>
     </ul>
    </li>
    <li>
     Unless an error condition is returned, the IO is performed successfully.
    </li>
   </ol>
  </li>
  <li>
   Call
   <span>
    cuFileBufDeregister
   </span>
   to free the buffer-specific cuFile state.
  </li>
  <li>
   Call
   <span>
    cuFileHandleDeregister
   </span>
   to free the file-specific cuFile state.
  </li>
  <li>
   Call
   <span>
    cuFileDriverClose
   </span>
   to free up the cuFile state.
  </li>
 </ol>
 Note:
 <p>
  Not using the
  <span>
   cuFileDeregister
  </span>
  and
  <span>
   cuFileDriverClose
  </span>
  APIs (steps 5, 6, and 7) might unnecessarily consume resources, as shown by tools such as valgrind. The best practice is to always call these APIs in the application cleanup paths.
 </p>
 <h3 id="cufile-compatibility-mode">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-compatibility-mode">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-compatibility-mode" id="cufile-compatibility-mode" name="cufile-compatibility-mode" shape="rect">
    2.3. cuFile Compatibility Mode
   </a>
  </a>
 </h3>
 <p>
  Use Cases
  cuFile APIs can be used in different scenarios:
 </p>
 <ul>
  <li>
   Developers building GPUDirect Storage applications with cuFile APIs, but don’t have the supported hardware configurations.
  </li>
  <li>
   Developers building applications running on GPU cards that have CUDA compute capability &gt; 6, but don’t have BAR space exposed.
  </li>
  <li>
   Deployments where
   <span>
    nvidia-fs.ko
   </span>
   is not loaded or cannot be loaded.
  </li>
  <li>
   Deployments where the Linux distribution does not support GPUDirect Storage.
  </li>
  <li>
   Deployments where the filesystem may be not supported with GPUDirect Storage.
  </li>
  <li>
   Deployments where the network links are not enabled with RDMA support.
  </li>
  <li>
   Deployment where the configuration is not optimal for GPUDirect Storage.
  </li>
 </ul>
 Behavior
 The cuFile library provides a mechanism for cuFile reads and writes to use compatibility mode using POSIX
 <span>
  pread
 </span>
 ,
 <span>
  pwrite
 </span>
 , and
 <span>
  aio_submit
 </span>
 APIS respectively to host memory and copying to GPU memory when applicable. The behavior of compatibility mode with cuFile APIs is determined by the following configuration parameters.
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <tr class="row">
   <th align="left" class="entry" colspan="1" id="d54e411" rowspan="1" valign="top" width="50%">
    Configuration Option (default)
   </th>
   <th align="left" class="entry" colspan="1" id="d54e414" rowspan="1" valign="top" width="50%">
    cuFile IO Behavior
   </th>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “allow_compat_mode": true
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    If
    <span>
     true
    </span>
    , falls back to using compatibility mode when the library detects that the buffer file descriptor opened cannot use GPUDirect Storage.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “force_compat_mode": false
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    If
    <span>
     true
    </span>
    , this option can be used to force all IO to use compatibility mode. Alternatively the admin can unload the nvidia_fs.ko or not expose the character devices in the docker container environment.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “gds_rdma_write_support": true
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    If
    <span>
     false
    </span>
    , forces compatibility mode to be used for writes even when the underlying file system is capable of performing GPUDirect Storage writes.
    <p>
     Note:
     If the option is “false”, this option will override and disable any filesystem-specific option to enable RDMA writes.
    </p>
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “posix_unaligned_writes” : false
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    <p>
     If
     <span>
      true
     </span>
     , forces compatibility mode to be used for writes where the file offset and/or IO size is not aligned to Page Boundary (4KB).
    </p>
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “lustre:posix_gds_min_kb” : 0
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    <p>
     For a lustre filesystem, if greater than
     <span>
      0
     </span>
     , compatibility mode is used for IO sizes between [1 -
     <span>
      posix_gds_min_kb
     </span>
     ] specified in kB.
    </p>
    <p>
     Note:
     This option will force posix mode even if “
     <span>
      allow_compat_mode
     </span>
     ” is set to
     “false”
     .
    </p>
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “weka:rdma_write_support” : false
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    <p>
     If this option is
     <span>
      false
     </span>
     , all writes to WekaFS will use compatibility mode.
    </p>
    <p>
     Note:
     If the option is set to
     “false”
     , cuFile library will use the posix path even if the
     <span>
      allow_compat_mode
     </span>
     option is
     <span>
      true
     </span>
     or
     <span>
      false
     </span>
     .
    </p>
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <span>
     “gpfs:gds_write_support” : false
    </span>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    <p>
     <a class="Link" data-cms-ai="0" id="cufile-compatibility-mode__docs-internal-guid-6bb6f315-7fff-6d09-7646-9138210fee4e" name="cufile-compatibility-mode__docs-internal-guid-6bb6f315-7fff-6d09-7646-9138210fee4e" shape="rect">
     </a>
     If this option is false, all writes to IBM Spectrum Scale will use compatibility mode.
    </p>
    <p>
     Note:
     If the option is set to
     “false”
     , cuFile library will use the posix path even if the allow_compat_mode option is true or false.
    </p>
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e411" rowspan="1" valign="top" width="50%">
    <p>
     <span>
      “rdma_dynamic_routing": false,
     </span>
    </p>
    <p>
     <span>
      “rdma_dynamic_routing_order": [ " “SYS_MEM” ]
     </span>
    </p>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e414" rowspan="1" valign="top" width="50%">
    If
    <span>
     rdma_dynamic_routing
    </span>
    is set to
    <span>
     true
    </span>
    and
    <span>
     rdma_dynamic_routing_order
    </span>
    is set to
    <span>
     [“SYS_MEM”]
    </span>
    , then all IO for DFS will use compatibility mode.
   </td>
  </tr>
 </table>
 In addition to the above configuration options, compatibility mode will be used as a fallback option for following use cases.
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <tr class="row">
   <th align="left" class="entry" colspan="1" id="d54e604" rowspan="1" valign="top" width="50%">
    Use Case
   </th>
   <th align="left" class="entry" colspan="1" id="d54e607" rowspan="1" valign="top" width="50%">
    cuFile IO Behavior
   </th>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e604" rowspan="1" valign="top" width="50%">
    No BAR1 memory in GPU.
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e607" rowspan="1" valign="top" width="50%">
    Use compatibility mode.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e604" rowspan="1" valign="top" width="50%">
    <p>
     For wekaFS or IBM Spectrum Scale mounts: If there are no
     <span>
      rdma_dev_addr_list
     </span>
     specified, or failure to register MR with ib device.
    </p>
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e607" rowspan="1" valign="top" width="50%">
    Use compatibility mode.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e604" rowspan="1" valign="top" width="50%">
    Bounce buffers cannot be allocated in GPU memory.
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e607" rowspan="1" valign="top" width="50%">
    Use compatibility mode.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e604" rowspan="1" valign="top" width="50%">
    For WekaFS and IBM Spectrum Scale: If the kernel returns
    <span>
     -ENOTSUP
    </span>
    for GPUDirect Storage read/write.
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e607" rowspan="1" valign="top" width="50%">
    Retry the IO operation internally using compatibility mode.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e604" rowspan="1" valign="top" width="50%">
    cuFile Stream and cuFile Batch APIs on IBM Spectrum Scale or WekaFS
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e607" rowspan="1" valign="top" width="50%">
    All Async and batch operations will internally use compatibility mode IO.
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e604" rowspan="1" valign="top" width="50%">
    The
    <span>
     nvidia_fs.ko
    </span>
    driver is not loaded.
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e607" rowspan="1" valign="top" width="50%">
    All IO operations will use compatibility mode.
   </td>
  </tr>
 </table>
 <p>
  Limitations
 </p>
 <ul>
  <li>
   Compatible mode does not work in cases where the GPUs have CUDA compute capability less than 6.
  </li>
  <li>
   GDS Compat mode has been tested and works with GDS enabled file systems and environments. It has not been tested to work on all other filesystems.
  </li>
 </ul>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-api-specification">
   3. cuFile API Specification
  </a>
 </h2>
 <p>
  <a class="Link" data-cms-ai="0" id="cufile-api-specification" name="cufile-api-specification" shape="rect">
  </a>
  This section provides information about the cuFile APIs that are used from the CPU to enable applications and frameworks.
 </p>
 <h3 id="data-types">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#data-types">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#data-types" id="data-types" name="data-types" shape="rect">
    3.1. Data Types
   </a>
  </a>
 </h3>
 <h3 id="declarations-and-definitions">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#declarations-and-definitions">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#declarations-and-definitions" id="declarations-and-definitions" name="declarations-and-definitions" shape="rect">
    3.1.1. Declarations and Definitions
   </a>
  </a>
 </h3>
 <p>
  Here are the relevant cuFile enums and their descriptions.
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>typedef struct CUfileError {
        CUfileOpError err; // cufile error
        enum CUresult cu_err; // for CUDA-specific errors
} CUfileError_t;

/**
 * error macros to inspect error status of type CUfileOpError
 */
 
#define IS_CUFILE_ERR(err) \
        (abs((err)) &gt; CUFILEOP_BASE_ERR)
 
#define CUFILE_ERRSTR(err) \
        cufileop_status_error(static_cast&lt;CUfileOpError&gt;(abs((err))))
 
#define IS_CUDA_ERR(status) \
        ((status).err == CU_FILE_CUDA_DRIVER_ERROR)
 
#define CU_FILE_CUDA_ERR(status) ((status).cu_</p>
        </pre>
 <p>
  The following enum and two structures enable broader cross-OS support:
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>enum CUfileFileHandleType { 
    CU_FILE_HANDLE_TYPE_OPAQUE_FD = 1, /* linux based fd    */
    CU_FILE_HANDLE_TYPE_OPAQUE_WIN32 = 2, /* windows based handle */
CU_FILE_HANDLE_TYPE_USERSPACE_FS  = 3, /* userspace based FS */
}; 
 
typedef struct CUfileDescr_t {
CUfileFileHandleType type; /* type of file being registered */
union { 
int fd;             /* Linux   */
void *handle;         /* Windows */
} handle;
const CUfileFSOps_t *fs_ops;     /* file system operation table */ 
}CUfileDescr_t;
 
/* cuFile handle type */
typedef void*  CUfileHandle_t;
 
typedef struct cufileRDMAInfo
{
        int version;
        int desc_len;
        const char *desc_str;
}cufileRDMAInfo_t;
 
typedef struct CUfileFSOps {
      /* NULL means discover using fstat */
      const char* (*fs_type) (void *handle);
 
      /* list of host addresses to use,  NULL means no restriction */
      int (*getRDMADeviceList)(void *handle, sockaddr_t **hostaddrs);
 
      /* -1 no pref */
      int (*getRDMADevicePriority)(void *handle, char*, size_t,
                                loff_t, sockaddr_t* hostaddr);
 
      /* NULL means try VFS */
      ssize_t (*read) (void *handle, char*, size_t, loff_t, cufileRDMAInfo_t*);
      ssize_t (*write) (void *handle, const char *, size_t, loff_t , cufileRDMAInfo_t*);
}CUfileFSOps_t;

typedef enum CUfileDriverStatusFlags {
        CU_FILE_LUSTRE_SUPPORTED = 0,        /*!&lt; Support for DDN LUSTRE */
        CU_FILE_WEKAFS_SUPPORTED = 1,        /*!&lt; Support for WEKAFS */
        CU_FILE_NFS_SUPPORTED = 2,           /*!&lt; Support for NFS */
        CU_FILE_GPFS_SUPPORTED = 3,          /*! &lt; Support for GPFS */
        CU_FILE_NVME_SUPPORTED = 4,          /*!&lt; Support for NVMe */
        CU_FILE_NVMEOF_SUPPORTED = 5,        /*!&lt; Support for NVMeOF */
        CU_FILE_SCSI_SUPPORTED = 6,          /*!&lt; Support for SCSI */
        CU_FILE_SCALEFLUX_CSD_SUPPORTED = 7, /*!&lt; Support for Scaleflux CSD*/
        CU_FILE_NVMESH_SUPPORTED = 8,        /*!&lt; Support for NVMesh Block Dev*/
        CU_FILE_BEEGFS_SUPPORTED = 9,        /*!&lt; Support for BeeGFS */
}CUfileDriverStatusFlags_t;

 
enum CUfileDriverControlFlags {
      CU_FILE_USE_POLL_MODE = 0, /*!&lt; use POLL mode. properties.use_poll_mode*/
      CU_FILE_ALLOW_COMPAT_MODE = 1 /*!&lt; allow COMPATIBILITY mode. properties.allow_compat_mode*/
};
 
typedef enum CUfileFeatureFlags {
    CU_FILE_DYN_ROUTING_SUPPORTED =0,
    CU_FILE_BATCH_IO_SUPPORTED = 1,
    CU_FILE_STREAMS_SUPPORTED = 2
} CUfileFeatureFlags_t;;
 
/* cuFileDriverGetProperties describes this structure’s members */
typedef struct CUfileDrvProps {
   struct {
     unsigned int major_version;
     unsigned int minor_version;
     size_t poll_thresh_size;
     size_t max_direct_io_size;
     unsigned int dstatusflags;
     unsigned int dcontrolflags;
   } nvfs;
   CUfileFeatureFlags_t fflags;
   unsigned int max_device_cache_size;
   unsigned int per_buffer_cache_size;
   unsigned int max_pinned_memory_size;
   unsigned int max_batch_io_timeout_msecs;
}CUfileDrvProps_t;

/* Parameter block for async cuFile IO */ 
/* Batch APIs use an array of these    */
/* Status must be CU_FILE_WAITING when submitted, and is
   updated when enqueued and when complete, so this user-allocated
   structure is live until the operation completes.    */
typedef enum CUFILEStatus_enum {
        CUFILE_WAITING = 0x000001,  /* required value prior to submission */
        CUFILE_PENDING = 0x000002,  /* once enqueued */
        CUFILE_INVALID = 0x000004,  /* request was ill-formed or could not be enqueued */
        CUFILE_CANCELED = 0x000008, /* request successfully canceled */
        CUFILE_COMPLETE = 0x0000010, /* request successfully completed */
        CUFILE_TIMEOUT = 0x0000020,  /* request timed out */
        CUFILE_FAILED  = 0x0000040  /* unable to complete */
}CUfileStatus_t;

typedef enum cufileBatchMode {
        CUFILE_BATCH = 1,
} CUfileBatchMode_t;
 
typedef struct CUfileIOParams {
        CUfileBatchMode_t mode; // Must be the very first field.
        union {
                struct  {
                        void *devPtr_base;
                        off_t file_offset;
                        off_t devPtr_offset;
                        size_t size;
                }batch;
        }u;
        CUfileHandle_t fh;
        CUfileOpcode_t opcode;
        void *cookie;
}CUfileIOParams_t;
 
typedef struct CUfileIOEvents {
        void *cookie;
        CUfileStatus_t   status;      /* status of the operation */
        size_t ret;       /* -ve error or amount of I/O done. */
}CUfileIOEvents_t;</p>
        </pre>
 <h3 id="typedefs">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#typedefs">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#typedefs" id="typedefs" name="typedefs" shape="rect">
    3.1.2. Typedefs
   </a>
  </a>
 </h3>
 <p>
  cuFile typedefs:
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>typedef struct CUfileDescr CUfileDesr_t
typedef struct CUfileError CUfileError_t
typedef struct CUfileDrvProps CUfileDrvProps_t
typedef enum CUfileFeatureFlags CUfileFeatureFlags_t
typedef enum CUfileDriverStatusFlags_enum CUfileDriverStatusFlags_t
typedef enum CUfileDriverControlFlags_enum CUfileDriverControlFlags_t
typedef struct CUfileIOParams CUfileIOParams_t
typedef enum CUfileBatchOpcode CUfileBatchOpcode_t</p>
        </pre>
 <h3 id="enumerations">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#enumerations">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#enumerations" id="enumerations" name="enumerations" shape="rect">
    3.1.3. Enumerations
   </a>
  </a>
 </h3>
 <p>
  cuFile enums:
 </p>
 <ul>
  <li>
   <span>
    enum CUfileOpcode_enum
   </span>
   <p>
    This is the cuFile operation code for batch mode.
   </p>
   <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
    <tr class="row">
     <th class="entry" colspan="1" id="d54e795" rowspan="1" valign="top" width="33.33333333333333%">
      OpCode
     </th>
     <th class="entry" colspan="1" id="d54e798" rowspan="1" valign="top" width="33.33333333333333%">
      Value
     </th>
     <th class="entry" colspan="1" id="d54e801" rowspan="1" valign="top" width="33.33333333333333%">
      Description
     </th>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e795" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CU_FILE_READ
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e798" rowspan="1" valign="top" width="33.33333333333333%">
      0
     </td>
     <td class="entry" colspan="1" headers="d54e801" rowspan="1" valign="top" width="33.33333333333333%">
      Batch Read
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e795" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CU_FILE_WRITE
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e798" rowspan="1" valign="top" width="33.33333333333333%">
      1
     </td>
     <td class="entry" colspan="1" headers="d54e801" rowspan="1" valign="top" width="33.33333333333333%">
      Batch Write
     </td>
    </tr>
   </table>
   Copy
   Copied!
   <pre class="language-" data-line="" id="play">
            
            <p>/* cuFile Batch IO operation kind */
enum CUfileOpcode { 
     CU_FILE_READ,
     CU_FILE_WRITE,
};</p>
        </pre>
  </li>
  <li>
   <span>
    enum CUfileStatus
   </span>
   <p>
    The cuFile Status codes for batch mode.
   </p>
   <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
    <tr class="row">
     <th class="entry" colspan="1" id="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      Status
     </th>
     <th class="entry" colspan="1" id="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      Value
     </th>
     <th class="entry" colspan="1" id="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      Description
     </th>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_WAITING
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x01
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      The initial value.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_PENDING
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x02
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      Set once enqueued into the driver.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_INVALID
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x04
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      Invalid parameters.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_CANCELED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x08
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      Request successfully canceled.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_COMPLETE
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x10
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      Successfully completed.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_TIMEOUT
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x20
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      The operation has timed out.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e863" rowspan="1" valign="top" width="33.33333333333333%">
      <span>
       CUFILE_FAILED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e866" rowspan="1" valign="top" width="33.33333333333333%">
      0x40
     </td>
     <td class="entry" colspan="1" headers="d54e869" rowspan="1" valign="top" width="33.33333333333333%">
      IO has failed.
     </td>
    </tr>
   </table>
  </li>
  <li>
   <span>
    enum CUfileOpError
   </span>
   <ul>
    <li>
     The cuFile Operation error types.
    </li>
    <li>
     All error code values, other than
     <span>
      CU_FILE_SUCCESS
     </span>
     , are considered failures that might leave the output and input parameter values of APIs in an undefined state.
     <p>
      These values cannot have any side effects on the file system, the application process, and the larger system.
     </p>
     Note:
     <p>
      cuFile-specific errors will be greater than
      <span>
       CUFILEOP_BASE_ERR
      </span>
      to enable users to distinguish between POSIX errors and cuFile errors.
     </p>
     Copy
     Copied!
     <pre class="language-" data-line="" id="play">
            
            <p>#define CUFILEOP_BASE_ERR 5000</p>
        </pre>
    </li>
   </ul>
   <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
    <tr class="row">
     <th class="entry" colspan="1" id="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      Error Code
     </th>
     <th class="entry" colspan="1" id="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      Value
     </th>
     <th class="entry" colspan="1" id="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Description
     </th>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_SUCCESS
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      0
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The cufile is successful.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_NOT_INITIALIZED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5001
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The nvidia-fs driver is not loaded.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_INVALID_PROPS
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5002
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An invalid property.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_UNSUPPORTED_LIMIT
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5003
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      A property range error.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_VERSION_MISMATCH
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5004
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An nvidia-fs driver version mismatch.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_VERSION_READ_ERROR
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5005
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An nvidia-fs driver version read error.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_CLOSING
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5006
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Driver shutdown in progress.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_PLATFORM_NOT_SUPPORTED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5007
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      GDS is not supported on the current platform.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_IO_NOT_SUPPORTED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5008
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      GDS is not supported on the current file.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DEVICE_NOT_SUPPORTED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5009
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      GDS is not supported on the current GPU.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_NVFS_DRIVER_ERROR
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5010
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An nvidia-fs driver ioctl error.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_CUDA_DRIVER_ERROR
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5011
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      <p>
       <a class="Link" data-cms-ai="0" id="enumerations__docs-internal-guid-54828736-7fff-b74a-007a-157fb5915065" name="enumerations__docs-internal-guid-54828736-7fff-b74a-007a-157fb5915065" shape="rect">
       </a>
       A CUDA Driver API error.
      </p>
      <p>
       This error indicates a CUDA driver-api error. If this is set, a CUDA-specific error code is set in the cu_err field for cuFileError.
      </p>
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_CUDA_POINTER_INVALID
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5012
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An invalid device pointer.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_CUDA_MEMORY_TYPE_INVALID
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5013
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An invalid pointer memory type.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_CUDA_POINTER_RANGE_ERROR
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5014
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The pointer range exceeds the allocated address range.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_CUDA_CONTEXT_MISMATCH
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5015
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      A CUDA context mismatch.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_INVALID_MAPPING_SIZE
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5016
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Access beyond the maximum pinned memory size.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_INVALID_MAPPING_RANGE
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5017
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Access beyond the mapped size.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_INVALID_FILE_TYPE
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5018
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An unsupported file type.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_INVALID_FILE_OPEN_FLAG
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5019
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Unsupported file open flags.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DIO_NOT_SET
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5020
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The fd direct IO is not set.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_INVALID_VALUE
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5022
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Invalid API arguments.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_MEMORY_ALREADY_REGISTERED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5023
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Device pointer is already registered.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_MEMORY_NOT_REGISTERED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5024
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      A device pointer lookup failure has occurred.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_PERMISSION_DENIED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5025
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      A driver or file access error.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DRIVER_ALREADY_OPEN
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5026
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The driver is already open.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_HANDLE_NOT_REGISTERED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5027
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The file descriptor is not registered.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_HANDLE_ALREADY_REGISTERED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5028
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The file descriptor is already registered.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_DEVICE_NOT_FOUND
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5029
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      The GPU device cannot be not found.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_INTERNAL_ERROR
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5030
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An internal error has occurred. Refer to
      <span>
       cufile.log
      </span>
      for more details.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_GETNEWFD_FAILED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5031
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Failed to obtain a new file descriptor.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_NVFS_SETUP_ERROR
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5033
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      An NVFS driver initialization error has occurred.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_IO_DISABLED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5034
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      GDS is disabled by config on the current file.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_BATCH_SUBMIT_FAILED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5035
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Failed to submit a batch operation.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_GPU_MEMORY_PINNING_FAILED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5036
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Failed to allocate pinned GPU memory.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_BATCH_FULL
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5037
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      Queue full for batch operation.
     </td>
    </tr>
    <tr class="row">
     <td class="entry" colspan="1" headers="d54e1012" rowspan="1" valign="top" width="56.54952076677316%">
      <span>
       CU_FILE_ASYNC_NOT_SUPPORTED
      </span>
     </td>
     <td class="entry" colspan="1" headers="d54e1015" rowspan="1" valign="top" width="7.987220447284344%">
      5038
     </td>
     <td class="entry" colspan="1" headers="d54e1018" rowspan="1" valign="top" width="35.4632587859425%">
      cuFile stream operation is not supported.
     </td>
    </tr>
   </table>
   Note:
   <p>
    Data path errors are captured via standard error codes by using errno. The APIs will return -1 on error.
   </p>
  </li>
 </ul>
 <h3 id="cufile-driver-api">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-driver-api">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-driver-api" id="cufile-driver-api" name="cufile-driver-api" shape="rect">
    3.2. cuFile Driver APIs
   </a>
  </a>
 </h3>
 <p>
  The following cuFile APIs that are used to initialize, finalize, query, and tune settings for the cuFile system.
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>/* Initialize the cuFile infrastructure */
CUfileError_t cuFileDriverOpen();  

/* Finalize the cuFile system */
CUfileError_t cuFileDriverClose();

/* Query capabilities based on current versions, installed functionality */
CUfileError_t cuFileGetDriverProperties(CUfileDrvProps_t *props);

/*API to set whether the Read/Write APIs use polling to do IO operations */
CUfileError_t cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size);

/*API to set max IO size(KB) used by the library to talk to nvidia-fs driver */
CUfileError_t cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size);

/* API to set maximum GPU memory reserved per device by the library for internal buffering */
CUfileError_t cuFileDriverSetMaxCacheSize(size_t max_cache_size);

/* Sets maximum buffer space that is pinned in KB for use by  cuFileBufRegister
CUfileError_t cuFileDriverSetMaxPinnedMemSize(size_t
   max_pinned_memory_size);</p>
        </pre>
 Note:
 <p>
  Refer to
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_007.cc" shape="rect">
   sample_007
  </a>
  for usage.
 </p>
 <h3 id="cufile-io-api">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api" id="cufile-io-api" name="cufile-io-api" shape="rect">
    3.3. cuFile Synchronous IO APIs
   </a>
  </a>
 </h3>
 <p>
  The core of the cuFile IO APIs are the read and write functions.
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>ssize_t cuFileRead(CUFileHandle_t fh, void *bufPtr_base, size_t size, off_t file_offset, off_t devPtr_offset);
ssize_t cuFileWrite(CUFileHandle_t fh, const void *bufPtr_base, size_t size, off_t file_offset, off_t devPtr_offset);</p>
        </pre>
 <p>
  The starting offset of the buffer on the device or host is determined by a base (
  <span>
   bufPtr_base
  </span>
  ) and offset (
  <span>
   bufPtr_offset
  </span>
  ). This offset is distinct from the offset in the file.
 </p>
 Note:
 <p>
  To use the registered buffer, the bufPtr_base must be the buffer pointer used to register during
  <span>
   cuFileBufRegister
  </span>
  . Otherwise
  <span>
   cuFileRead
  </span>
  and
  <span>
   cuFileWrite
  </span>
  APIs may use internal memory buffers for GPUDirect Storage peer to peer operations.
 </p>
 Note:
 <p>
  The default behavior for all paths where GDS is not supported is for the cuFile IO API to attempt IO using file system supported posix mode APIs when
  <span>
   properties.allow_compat_mode
  </span>
  is set to true. In order to disable cuFile APIs falling back to posix APIs for unsupported GDS paths,
  <span>
   properties.allow_compat_mode
  </span>
  in the
  <span>
   /etc/cufile.json
  </span>
  file should be set to false.
 </p>
 Note:
 <p>
  Refer to sample
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_003.cc" shape="rect">
   sample_003
  </a>
  for usage.
 </p>
 <h3 id="cufile-file-handle-api">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-file-handle-api">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-file-handle-api" id="cufile-file-handle-api" name="cufile-file-handle-api" shape="rect">
    3.4. cuFile File Handle APIs
   </a>
  </a>
 </h3>
 <p>
  Here is some information about the cuFile Handle APIs.
 </p>
 <p>
  The
  <span>
   cuFileHandleRegister
  </span>
  API makes a file descriptor or handle that is known to the cuFile subsystem by using an OS-agnostic interface. The API returns an opaque handle that is owned by the cuFile subsystem.
 </p>
 <p>
  To conserve memory, the
  <span>
   cuFileHandleDeregister
  </span>
  API is used to release cuFile-related memory objects. Using only the POSIX close will not clean up resources that were used by cuFile. Additionally, the clean up of cuFile objects associated with the files that were operated on in the cuFile context will occur at
  <span>
   cuFileDriverClose
  </span>
  .
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileHandleRegister(CUFileHandle_t *fh, CUFileDescr_t *descr);
void cuFileHandleDeregister(CUFileHandle_t fh);</p>
        </pre>
 Note:
 <p>
  Refer to
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_003.cc" shape="rect">
   sample_003
  </a>
  for usage.
 </p>
 <h3 id="cufile-buffer-api">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-buffer-api">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-buffer-api" id="cufile-buffer-api" name="cufile-buffer-api" shape="rect">
    3.5. cuFile Buffer APIs
   </a>
  </a>
 </h3>
 <p>
  The
  <span>
   cuFileBufRegister
  </span>
  API incurs a significant performance cost, so registration costs should be amortized where possible. Developers must ensure that buffers are registered up front and off the critical path.
 </p>
 <p>
  The
  <span>
   cuFileBufRegister
  </span>
  API is optional. If this is not used, instead of pinning the user’s memory, cuFile-managed and internally pinned buffers are used.
 </p>
 <p>
  The
  <span>
   cuFileBufDeregister
  </span>
  API is used to optimally clean up cuFile-related memory objects, but CUDA currently has no analog to
  <span>
   cuFileBufDeregister
  </span>
  . The cleaning up of objects associated with the buffers operated on in the cuFile context occurs at
  <span>
   cuFileDriverClose
  </span>
  . If explicit APIs are used, the incurred errors are reported immediately, but if the operations of these explicit APIs are performed implicitly, error reporting and handling are less clear.
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileBufRegister(const void *devPtr_base, size_t size, int flags);
CUfileError_t cuFileBufDeregister(const void *devPtr_base);</p>
        </pre>
 Note:
 <p>
  Refer to
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_005.cc" shape="rect">
   sample_005
  </a>
  for usage.
 </p>
 <h3 id="cufile-stream-api">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-stream-api">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-stream-api" id="cufile-stream-api" name="cufile-stream-api" shape="rect">
    3.6. cuFile Stream APIs
   </a>
  </a>
 </h3>
 <p>
  Operations that are enqueued with cuFile Stream APIs are FIFO ordered with respect to other work on the stream and must be completed before continuing with the next action in the stream.
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileReadAsync(CUFileHandle_t fh, void *bufPtr_base, 
                  size_t *size_p, off_t *file_offset_p, off_t *bufPtr_offset_p,
                  ssize_t *bytes_read_p, CUStream stream);
CUfileError_t cuFileWriteAsync(CUFileHandle_t fh, void *bufPtr_base, 
                  size_t *size_p, off_t *file_offset_p, off_t *bufPtr_offse_pt,
                  ssize_t *bytes_written_p, CUstream stream);</p>
        </pre>
 Note:
 <p>
  Refer to samples
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_031.cc" shape="rect">
   sample_031
  </a>
  ,
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_032.cc" shape="rect">
   sample_032
  </a>
  ,
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_033.cc" shape="rect">
   sample_033
  </a>
  , and
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_034.cc" shape="rect">
   sample_034
  </a>
  for usage.
 </p>
 <h3 id="cufile-batch-api">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-batch-api">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-batch-api" id="cufile-batch-api" name="cufile-batch-api" shape="rect">
    3.7. cuFile Batch APIs
   </a>
  </a>
 </h3>
 <p>
  Batch APIs are submitted synchronously, but executed asynchronously with respect to host thread.
 </p>
 <p>
  These operations can be submitted on different files, different locations in the same file, or a mix. Completion of IO can be checked asynchronously using a status API in the same host thread or in a different thread. The
  <span>
   cuFileBatchIOGetStatus
  </span>
  API takes an array of
  <span>
   CUfileIOEvents_t
  </span>
  and minimum number of elements to poll for. which describes the IO action, status, errors, and bytes transacted for each instance. The bytes transacted field is valid only when the status indicates a successful completion.
 </p>
 Note:
 <p>
  Refer to samples
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_020.cc" shape="rect">
   sample_019, sample_020
  </a>
  ,
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_021.cc" shape="rect">
   sample_021
  </a>
  , and
  <a class="xref" data-cms-ai="0" href="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_022.cc" shape="rect">
   sample_022
  </a>
  for usage.
 </p>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-api-functional-specification">
   4. cuFile API Functional Specification
  </a>
 </h2>
 <p>
  <a class="Link" data-cms-ai="0" id="cufile-api-functional-specification" name="cufile-api-functional-specification" shape="rect">
  </a>
  This section provides information about the cuFile API functional specification.
 </p>
 <p>
  See the
  <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html" shape="rect">
   GPUDirect Storage Overview Guide
  </a>
  for a high-level analysis of the set of functions and their relation to each other. We anticipate adding additional return codes for some of these functions.
 </p>
 <p>
  All cuFile APIs are called from the host code.
  <a class="Link" data-cms-ai="0" id="cufiledriver-api-functional-specification" name="cufiledriver-api-functional-specification" shape="rect">
  </a>
 </p>
 <h3 id="cufiledriver-api-functional-specification">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriver-api-functional-specification">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriver-api-functional-specification" id="cufiledriver-api-functional-specification" name="cufiledriver-api-functional-specification" shape="rect">
    4.1. cuFileDriver API Functional Specification
   </a>
  </a>
 </h3>
 <p>
  This section provides information about the cuFileDriver API functional specification.
 </p>
 <h3 id="cufiledriveropen">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriveropen">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriveropen" id="cufiledriveropen" name="cufiledriveropen" shape="rect">
    4.1.1. cuFileDriverOpen
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverOpen();</p>
        </pre>
 <p>
  Opens the Driver session to support GDS IO operations.
 </p>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   None
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful open, or if the driver is already open.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on a failure to open the driver.
  </li>
  <li>
   <span>
    CU_FILE_PERMISSION_DENIED
   </span>
   on a failure to open.
   <p>
    This can happen when the character device
    <span>
     (/dev/nvidia_fs[0-15]
    </span>
    ) is restricted to certain users by an administrator, for example, admin, where
    <span>
     /dev
    </span>
    is not exposed with read permissions in the container.
   </p>
  </li>
  <li>
   <p>
    <span>
     CU_FILE_DRIVER_VERSION_MISMATCH
    </span>
    , when there is a mismatch between the cuFile library and its kernel driver.
   </p>
  </li>
  <li>
   <span>
    CU_FILE_CUDA_DRIVER_ERROR
   </span>
   if the CUDA driver failed to initialize.
   <span>
    CU_FILE_PLATFORM_NOT_SUPPORTED
   </span>
   if the current platform is not supported by GDS.
  </li>
  <li>
   <span>
    CU_FILE_NVFS_SETUP_ERROR
   </span>
   for a cuFile-specific internal error.
  </li>
 </ul>
 <p>
  Refer to the
  <span>
   cufile.log
  </span>
  file for more information.
 </p>
 <p>
  Description
 </p>
 <ul>
  <li>
   This API opens the session with the NVFS kernel driver to communicate from userspace to kernel space and calls the GDS driver to set up the resources required to support GDS IO operations.
  </li>
  <li>
   The API checks whether the current platform supports GDS and initializes the cuFile library.
  </li>
  <li>
   This API loads the cuFile settings from a JSON configuration file in
   <span>
    /etc/cufile.JSON
   </span>
   .
   <p>
    If the JSON configuration file does not exist, the API loads the default library settings. To modify this default config file, administrative privileges are needed. The administrator can modify it to grant cuFile access to the specified devices and mount paths and also tune IO parameters (in KB, 4K aligned) that are based on the type of workload. Refer to the
    <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-parameters" shape="rect">
     default config file
    </a>
    (/etc/cufile.json) for more information.
   </p>
  </li>
 </ul>
 <h3 id="cufiledriverclose">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriverclose">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriverclose" id="cufiledriverclose" name="cufiledriverclose" shape="rect">
    4.1.2. cuFileDriverClose
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverClose();</p>
        </pre>
 <ul>
  <li>
   Closes the driver session and frees any associated resources for GDS.
  </li>
  <li>
   This happens implicitly upon process exit.
  </li>
  <li>
   The driver can be reopened once it is closed.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   None
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful close.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure.
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   Close the GDS session and any associated memory resources. If there are buffers registered by using
   <span>
    cuFileBufRegister
   </span>
   , which are not unregistered, a
   <span>
    cuFileDriverClose
   </span>
   implicitly unregisters those buffers. Any in-flight IO when
   <span>
    cuFileDriverClose
   </span>
   is in-progress will receive an error.
  </li>
 </ul>
 <h3 id="cufiledrivergetproperties">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties" id="cufiledrivergetproperties" name="cufiledrivergetproperties" shape="rect">
    4.1.3. cuFileDriverGetProperties
   </a>
  </a>
 </h3>
 <p>
  The
  <span>
   cuFileDrvProps_t
  </span>
  structure can be queried with
  <span>
   cuFileDriverGetProperties
  </span>
  and selectively modified with
  <span>
   cuFileDriverSetProperties
  </span>
  . The structure is self-describing, and its fields are consistent with the major and minor API version parameters.
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverGetProperties(cuFileDrvProps_t *props);</p>
        </pre>
 <ul>
  <li>
   Gets the Driver session properties for GDS functionality.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <p>
  <span>
   props
  </span>
 </p>
 <ul>
  <li>
   Pointer to the cuFile Driver properties.
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful completion.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_VERSION_MISMATCH
   </span>
   on a driver version mismatch.
  </li>
  <li>
   <span>
    CU_FILE_INVALID_VALUE
   </span>
   if input is invalid.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API is used to get current GDS properties and nvidia-fs driver properties and functionality, such as support for SCSI, NVMe, and NVMe-OF.
 </p>
 <p>
  This API is used to get the current
  <span>
   nvidia-fs
  </span>
  drivers-specific properties such as the following:
 </p>
 <ul>
  <li>
   <span>
    major_version
   </span>
   : the cuFile major version
  </li>
  <li>
   <span>
    minor_version
   </span>
   : the cuFile minor version
  </li>
  <li>
   <span>
    props.nvfs.dstatusflags
   </span>
   , which are bit flags that indicate support for the following driver features:
   <ul>
    <li>
     <span>
      CU_FILE_EXASCALER_SUPPORTED
     </span>
     , a bit to check whether the DDN EXAScaler parallel filesystem solutions (based on the Lustre filesystem) client supports GDS.
    </li>
    <li>
     <span>
      CU_FILE_WEKAFS_SUPPORTED
     </span>
     , a bit to check whether WekaFS supports GDS.
    </li>
   </ul>
  </li>
  <li>
   <span>
    Props.nvfs.dcontrolflags
   </span>
   , which are bit flags that indicate the current activation for driver features:
   <ul>
    <li>
     <span>
      CU_FILE_USE_POLL_MODE
     </span>
     , when bit is set, IO uses polling mode.
    </li>
    <li>
     <span>
      CU_FILE_ALLOW_COMPAT_MODE
     </span>
     , if the value is 1 compatible mode is set.
     <p>
      Otherwise, the compatible mode is disabled.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <span>
    Props.fflags
   </span>
   , which are bit flags that indicate whether the following library features are supported:
   <ul>
    <li>
     <span>
      CU_FILE_STREAMS_SUPPORTED
     </span>
     , an attribute that checks whether CUDA-streams are supported.
    </li>
    <li>
     <span>
      CU_FILE_DYN_ROUTING_SUPPORTED
     </span>
     , an attribute that checks whether dynamic routing feature is supported.
    </li>
   </ul>
  </li>
  <li>
   <span>
    Props.nvfs.poll_thresh_size
   </span>
   , a maximum IO size, in KB and must be 4K-aligned, that is used for the POLLING mode.
  </li>
  <li>
   <span>
    Props.nvfs.max_direct_io_size
   </span>
   , a maximum GDS IO size, in KB and must be 4K-aligned, that is requested by the nvidia-fs driver to the underlying filesystem.
  </li>
  <li>
   <span>
    Props.max_device_cache_size
   </span>
   , a maximum GPU buffer space per device, in KB and must be 4K-aligned. Used internally, for example, to handle unaligned IO and optimal IO path routing. This value might be rounded down to the nearest GPU page size.
  </li>
  <li>
   <span>
    Props.max_device_pinned_mem_size
   </span>
   , a maximum buffer space, in KB and must be 4K-aligned, that is pinned and mapped to the GPU BAR space. This might be rounded down to the nearest GPU page size.
  </li>
  <li>
   <span>
    Props.per_buffer_cache_size
   </span>
   , a GPU bounce buffer size, in KB, used for internal pools.
  </li>
 </ul>
 <p>
  Additional Information
  See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetpollmode" shape="rect" title="cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size) API">
    cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size)
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxdirectiosize" shape="rect">
    cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size)
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxcachesize" shape="rect">
    cuFileDriverSetMaxCacheSize(size_t max_cache_size)
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxpinnedmemsize" shape="rect">
    cuFileDriverSetMaxPinnedMemSize(size_t max_pinned_memory_size)
   </a>
  </li>
 </ul>
 <h3 id="cufiledriversetpollmode">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetpollmode">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetpollmode" id="cufiledriversetpollmode" name="cufiledriversetpollmode" shape="rect">
    4.1.4. cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size)
   </a>
  </a>
 </h3>
 <p>
  <span>
   cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size)
  </span>
  API
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverSetPollMode(bool poll,
                                       size_t poll_threshold_size);</p>
        </pre>
 <ul>
  <li>
   Sets whether the Read/Write APIs use polling to complete IO operations. If poll mode is enabled, an IO size less than or equal to the threshold value is used for polling.
  </li>
  <li>
   The
   <span>
    poll_threshold_size
   </span>
   must be 4K aligned.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <p>
  <span>
   poll
  </span>
 </p>
 <ul>
  <li>
   Boolean to indicate whether to use the poll mode.
  </li>
 </ul>
 <p>
  <span>
   poll_threshold_size
  </span>
 </p>
 <ul>
  <li>
   IO size to use for POLLING mode in KB.
  </li>
  <li>
   The default value is 4KB.
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful completion.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure to load the driver.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_UNSUPPORTED_LIMIT
   </span>
   on failure to set with valid threshold size
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API is used in conjunction with
  <span>
   cuFileGetDriverProperties
  </span>
  . This API is used to set whether the library should use polling and the maximum IO threshold size less than or equal to which it will poll.
 </p>
 <p>
  This API overrides the default value that may be set through the JSON configuration file using the config keys
  <span>
   properties.poll_mode
  </span>
  and
  <span>
   properties.poll_max_size_kb
  </span>
  for the current process. See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties" shape="rect" title="The cuFileDrvProps_t structure can be queried with cuFileDriverGetProperties and selectively modified with cuFileDriverSetProperties. The structure is self-describing, and its fields are consistent with the major and minor API version parameters.">
    cuFileDriverGetProperties
   </a>
  </li>
 </ul>
 <h3 id="cufiledriversetmaxdirectiosize">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxdirectiosize">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxdirectiosize" id="cufiledriversetmaxdirectiosize" name="cufiledriversetmaxdirectiosize" shape="rect">
    4.1.5. cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size)
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size);</p>
        </pre>
 <ul>
  <li>
   Sets the max IO size, in KB.
   <p>
    This parameter is used by the nvidia-fs driver as the maximum IO chunk size in which IO is issued to the underlying filesystem. In compatible mode, this is the maximum IO chunk size that the library uses to issue POSIX read/writes.
   </p>
  </li>
  <li>
   The max direct IO size must be 4K aligned.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <p>
  <span>
   max_direct_io_size
  </span>
 </p>
 <ul>
  <li>
   The maximum allowed direct IO size in KB.
  </li>
  <li>
   The default value is 16384KB. This is because typically parallel-file systems perform better with bulk read/writes.
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on successful completion.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure to load the driver.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_UNSUPPORTED_LIMIT
   </span>
   on failure to set with valid size.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API is used with
  <span>
   cuFileGetDriverProperties
  </span>
  and is used to set the maximum direct IO size used by the library to specify the nvidia-fs kernel driver the maximum chunk size in which the latter can issue IO to the underlying filesystem. In compatible mode, this is the maximum IO chunk size which the library uses for issuing POSIX read/writes. This parameter is dependent on the underlying GPU hardware and system memory.
 </p>
 <p>
  This API overrides the default value that might be set through the JSON configuration file by using the
  <span>
   properties.max_direct_io_size_kb
  </span>
  config key for the current process. Refer to the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties" shape="rect" title="The cuFileDrvProps_t structure can be queried with cuFileDriverGetProperties and selectively modified with cuFileDriverSetProperties. The structure is self-describing, and its fields are consistent with the major and minor API version parameters.">
    cuFileDriverGetProperties
   </a>
  </li>
 </ul>
 <h3 id="cufiledriversetmaxcachesize">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxcachesize">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxcachesize" id="cufiledriversetmaxcachesize" name="cufiledriversetmaxcachesize" shape="rect">
    4.1.6. cuFileDriverSetMaxCacheSize(size_t max_cache_size)
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverSetMaxCacheSize(size_t max_cache_size);</p>
        </pre>
 <ul>
  <li>
   Sets the maximum GPU buffer space, in KB, per device and is used for internal use, for example, to handle unaligned IO and optimal IO path routing. This value might be rounded down to the nearest GPU page size.
  </li>
  <li>
   The max cache size must be 4K aligned.
  </li>
  <li>
   This API overrides the default value that might be set through the JSON configuration file using the
   <span>
    properties.max_device_cache_size_kb
   </span>
   config key for the current process.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <p>
  <span>
   max_cache_size
  </span>
 </p>
 <ul>
  <li>
   The maximum GPU buffer space, in KB, per device used for internal use, for example, to handle unaligned IO and optimal IO path routing. This value might be rounded down to the nearest GPU page size.
  </li>
  <li>
   The default value is 131072KB.
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on successful completion.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure to load the driver.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_UNSUPPORTED_LIMIT
   </span>
   on failure to set with valid IO size
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API is used with
  <span>
   cuFileGetDriverProperties
  </span>
  and is used to set the upper limit on the cache size per device for internal use by the library.
 </p>
 <p>
  See
  <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties" shape="rect" title="The cuFileDrvProps_t structure can be queried with cuFileDriverGetProperties and selectively modified with cuFileDriverSetProperties. The structure is self-describing, and its fields are consistent with the major and minor API version parameters.">
   cuFileDriverGetProperties
  </a>
  for more information.
 </p>
 <h3 id="cufiledriversetmaxpinnedmemsize">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxpinnedmemsize">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxpinnedmemsize" id="cufiledriversetmaxpinnedmemsize" name="cufiledriversetmaxpinnedmemsize" shape="rect">
    4.1.7. cuFileDriverSetMaxPinnedMemSize(size_t max_pinned_memory_size)
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileDriverSetMaxPinnedMemSize(size_t max_pinned_mem_size);</p>
        </pre>
 <ul>
  <li>
   Sets the maximum GPU buffer space, in KB, that is pinned and mapped. This value might be rounded down to the nearest GPU page size.
  </li>
  <li>
   The max pinned size must be 4K aligned.
  </li>
  <li>
   The default value corresponds to the maximum
   <span>
    PinnedMemory
   </span>
   or the physical memory size of the device.
  </li>
  <li>
   This API overrides the default value that may be set by the
   <span>
    properties.max_device_pinned_mem_size_kb
   </span>
   JSON config key for the current process.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <p>
  <span>
   max_pinned_memory_size
  </span>
 </p>
 <ul>
  <li>
   The maximum buffer space, in KB, that is pinned and mapped to the GPU BAR space.
  </li>
  <li>
   This value might be rounded down to the nearest GPU page size.
  </li>
  <li>
   The maximum limit may be set to UINT64_MAX, which is equivalent to no enforced limit. It may be set to something smaller than the size of the GPU’s physical memory.
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on successful completion.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure to load driver.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_UNSUPPORTED_LIMIT
   </span>
   on failure to set with valid size.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API is used with
  <span>
   cuFileGetDriverProperties
  </span>
  and is used to set an upper limit on the maximum size of GPU memory that can be pinned and mapped and is dependent on the underlying GPU hardware and system memory. This API is related to
  <span>
   cuFileBufRegister
  </span>
  , which is used to register GPU device memory. See
  <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties" shape="rect" title="The cuFileDrvProps_t structure can be queried with cuFileDriverGetProperties and selectively modified with cuFileDriverSetProperties. The structure is self-describing, and its fields are consistent with the major and minor API version parameters.">
   cuFileDriverGetProperties
  </a>
  for more information.
 </p>
 <h3 id="cufile-io-api-functional-specification">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api-functional-specification">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api-functional-specification" id="cufile-io-api-functional-specification" name="cufile-io-api-functional-specification" shape="rect">
    4.2. cuFile IO API Functional Specification
   </a>
  </a>
 </h3>
 <p>
  This section provides information about the cuFile IO API function specification.
 </p>
 <p>
  The device pointer addresses referred to in these APIs pertain to the current context for the caller.
 </p>
 <p>
  Unlike the non-async version of
  <span>
   cuMemcpy
  </span>
  , the
  <span>
   cuFileHandleRegister
  </span>
  ,
  <span>
   cuFileHandleDeregister
  </span>
  ,
  <span>
   cuFileRead
  </span>
  , and
  <span>
   cuFileWrite
  </span>
  APIs do not have the semantic of being ordered with respect to other work in the null stream.
  <a class="Link" data-cms-ai="0" id="cufilehandleregister" name="cufilehandleregister" shape="rect">
  </a>
 </p>
 <h3 id="cufilehandleregister">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilehandleregister">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilehandleregister" id="cufilehandleregister" name="cufilehandleregister" shape="rect">
    4.2.1. cuFileHandleRegister
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileHandleRegister(CUFileHandle_t *fh, CUfileDescr_t *descr);</p>
        </pre>
 <ul>
  <li>
   Register an open file.
  </li>
  <li>
   <span>
    cuFileHandleRegister
   </span>
   is required and performs extra checking that is memoized to provide increased performance on later cuFile operations.
  </li>
  <li>
   This API is OS agnostic.
   Note:
   <p>
    CUDA toolkit 12.2 (GDS version 1.7.x) supports non O_DIRECT open flags as well as O_DIRECT. Application is allowed to open a file in non O_DIRECT mode in compat mode and also with nvidia-fs.ko installed. In the latter case, an O_DIRECT path between GPU and Storage will be used if such a path exists.
   </p>
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    fh
   </span>
   <p>
    Valid pointer to the OS-neutral cuFile handle structure supplied by the user but populated and maintained by the cuFile runtime.
   </p>
  </li>
  <li>
   <span>
    desc
   </span>
   <p>
    Valid pointer to the OS-neutral file descriptor supplied by the user carrying details regarding the file to be opened such as fd for Linux-based files.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on successful completion.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_NOT_INITIALIZED
   </span>
   on failure to load the driver.
  </li>
  <li>
   <span>
    CU_FILE_IO_NOT_SUPPORTED
   </span>
   , if the filesystem is not supported.
  </li>
  <li>
   <span>
    CU_FILE_INVALID_VALUE
   </span>
   if there are null or bad API arguments.
  </li>
  <li>
   <span>
    CU_FILE_INVALID_FILE_OPEN_FLAG
   </span>
   , if the file is opened with unsupported modes such as no
   <span>
    O_APPEND
   </span>
   ,
   <span>
    O_NOCTTY
   </span>
   ,
   <span>
    O_NONBLOCK
   </span>
   ,
   <span>
    O_DIRECTORY
   </span>
   ,
   <span>
    O_NOFOLLOW
   </span>
   ,
   <span>
    O_NOATIME
   </span>
   , and
   <span>
    O_TMPFILE
   </span>
   .
  </li>
  <li>
   <span>
    CU_FILE_INVALID_FILE_TYPE
   </span>
   , if the file path is not valid, not a regular file, not a symbolic link, or not a device file.
  </li>
  <li>
   <span>
    CU_FILE_HANDLE_ALREADY_REGISTERED
   </span>
   if the file is already registered using the same file-descriptor.
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   Given a file-descriptor will populate and return the
   <span>
    CUfileHandle_t
   </span>
   needed for issuing IO with cuFile APIs.
  </li>
  <li>
   A return value of anything other than CU_FILE_SUCCESS leaves fh in an undefined state but has no other side effects.
  </li>
  <li>
   By default this API accepts whether the file descriptor is opened with O_DIRECT mode or non O_DIRECT mode.
  </li>
 </ul>
 <p>
  Refer to the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
    cuFileRead
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" shape="rect">
    cuFileReadAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" shape="rect">
    cuFileWriteAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#unique_1423451733" shape="rect">
    cuFileHandleDeregister
   </a>
  </li>
 </ul>
 <h3 id="unique_1423451733">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#unique_1423451733">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#unique_1423451733" id="unique_1423451733" name="unique_1423451733" shape="rect">
    cuFileHandleDeregister
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileHandleDeregister(CUFileHandle_t *fh);</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    fh
   </span>
   <p>
    The file handle obtained from cuFileHandleRegister.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <p>
  None
 </p>
 Note:
 <p>
  This API only logs an ERROR level message in the cufile.log file for valid inputs.
 </p>
 <p>
  Description
 </p>
 <ul>
  <li>
   The API is used to release resources that are claimed by
   <span>
    cuFileHandleRegister
   </span>
   .
   <p>
    This API should be invoked only after the application ensures there are no outstanding IO operations with the handle. If
    <span>
     cuFileHandleDeregister
    </span>
    is called while IO on the file is in progress might result in undefined behavior.
   </p>
  </li>
  <li>
   The user is still expected to close the file descriptor outside the cuFile subsystem after calling this API using
   <span>
    close
   </span>
   system call.
   <p>
    Closing a file handle without calling
    <span>
     cuFileHandleDeregister
    </span>
    does not release the resources that are held in the cuFile library. If this API is not called, the cuFile subsystem releases the resources lazily or when the application exits.
   </p>
  </li>
 </ul>
 <p>
  See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
    cuFileRead
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#unique_1423451733" shape="rect">
    cuFileHandleDeregister
   </a>
  </li>
 </ul>
 <h3 id="cufileread">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" id="cufileread" name="cufileread" shape="rect">
    4.2.3. cuFileRead
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>ssize_t cuFileRead(CUfileHandle_tfh, void *bufPtr_base, size_t size, off_t file_offset, off_t bufPtr_offset);</p>
        </pre>
 <ul>
  <li>
   Reads specified bytes from the file descriptor into the device memory or the host memory.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    fh
   </span>
   <p>
    File descriptor for the file.
   </p>
  </li>
  <li>
   <span>
    bufPtr_base
   </span>
   <p>
    Base address of buffer in device memory or host memory. For registered buffers,
    <span>
     bufPtr_base
    </span>
    must remain set to the base address used in the
    <span>
     cuFileBufRegister
    </span>
    call.
   </p>
  </li>
  <li>
   <span>
    size
   </span>
   <p>
    Size in bytes to read.
   </p>
  </li>
  <li>
   <span>
    file_offset
   </span>
   <p>
    Offset in the file to read from.
   </p>
  </li>
  <li>
   <span>
    bufPtr_offset
   </span>
   <p>
    Offset relative to the
    <span>
     bufPtr_base
    </span>
    pointer to read into. This parameter should be used only with registered buffers.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   Size of bytes that were successfully read.
  </li>
  <li>
   -1 on an error, so errno is set to indicate filesystem errors.
  </li>
  <li>
   All other errors return a negative integer value of the
   <span>
    CUfileOpError
   </span>
   enum value.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API reads the data from a specified file handle at a specified offset and size bytes into the GPU memory by using GDS functionality or into the host memory based on the type of memory pointer. The API works correctly for unaligned offsets and any data size, although the performance might not match the performance of aligned reads.This is a synchronous call and blocks until the IO is complete.
 </p>
 Note:
 <p>
  For the
  <span>
   bufPtr_offset
  </span>
  , if data will be read starting exactly from the
  <span>
   bufPtr_base
  </span>
  that is registered with
  <span>
   cuFileBufRegister
  </span>
  ,
  <span>
   bufPtr_offset
  </span>
  should be set to 0. To read starting from an offset in the registered buffer range, the relative offset should be specified in the
  <span>
   bufPtr_offset,
  </span>
  and the
  <span>
   bufPtr_base
  </span>
  must remain set to the base address that was used in the
  <span>
   cuFileBufRegister
  </span>
  call.
 </p>
 <p>
  See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" shape="rect">
    cuFileReadAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" shape="rect">
    cuFileWriteAsync
   </a>
  </li>
 </ul>
 <h3 id="cufilewrite">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" id="cufilewrite" name="cufilewrite" shape="rect">
    4.2.4. cuFileWrite
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>ssize_t cuFileWrite(CUfileHandle_t fh, const void *bufPtr_base, size_t size, off_t file_offset, off_t bufPtr_offset);</p>
        </pre>
 <ul>
  <li>
   Writes specified bytes from the device memory into the file descriptor using GDS.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    fh
   </span>
   <p>
    File descriptor for the file
   </p>
  </li>
  <li>
   <span>
    bufPtr_base
   </span>
   <p>
    Base address of buffer in device memory or host memory. For registered buffers,
    <span>
     bufPtr_base
    </span>
    must remain set to the base address used in the
    <span>
     cuFileBufRegister
    </span>
    call.
   </p>
  </li>
  <li>
   <span>
    size
   </span>
   <p>
    Size in bytes to which to write.
   </p>
  </li>
  <li>
   <span>
    file_offset
   </span>
   <p>
    Offset in the file to which to write.
   </p>
  </li>
  <li>
   <span>
    bufPtr_offset
   </span>
   <p>
    Offset relative to the
    <span>
     bufPtr_base
    </span>
    pointer from which to write. This parameter should be used only with registered buffers.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   Size of bytes that were successfully written.
  </li>
  <li>
   -1 on an error, so errno is set to indicate filesystem errors.
  </li>
  <li>
   All other errors return a negative integer value of the
   <span>
    CUfileOpError
   </span>
   enum value.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API writes the data from the GPU memory or the host memory to a file specified by the file handle at a specified offset and size bytes by using GDS functionality. The API works correctly for unaligned offset and data sizes, although the performance is not on-par with aligned writes.This is a synchronous call and will block until the IO is complete.
 </p>
 Note:
 <p>
  GDS functionality modified the standard file system metadata in SysMem. However, GDS functionality does not take any special responsibility for writing that metadata back to permanent storage. The data is not guaranteed to be present after a system crash unless the application uses an explicit
  <span>
   fsync(2)
  </span>
  call. If the file is opened with an
  <span>
   O_SYNC
  </span>
  flag, the metadata will be written to the disk before the call is complete.
 </p>
 <p>
  Refer to the note in
  <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
   cuFileRead
  </a>
  for more information about
  <span>
   bufPtr_offset:
  </span>
  . Refer to the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" shape="rect">
    cuFileReadAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" shape="rect">
    cuFileWriteAsync
   </a>
  </li>
 </ul>
 <h3 id="cufile-memory-mgmt-functional-specification">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-memory-mgmt-functional-specification">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-memory-mgmt-functional-specification" id="cufile-memory-mgmt-functional-specification" name="cufile-memory-mgmt-functional-specification" shape="rect">
    4.3. cuFile Memory Management Functional Specification
   </a>
  </a>
 </h3>
 <p>
  The device pointer addresses that are mentioned in the APIs in this section pertain to the current context for the caller. cuFile relies on users to complete their own allocation before using the
  <span>
   cuFileBufRegister
  </span>
  API and free after using the
  <span>
   cuFileBufDeregister
  </span>
  API.
 </p>
 <h3 id="cufilebufregister">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufregister">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufregister" id="cufilebufregister" name="cufilebufregister" shape="rect">
    4.3.1. cuFileBufRegister
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileBufRegister(const void *bufPtr_base,
                                size_t size, int flags);</p>
        </pre>
 <ul>
  <li>
   Based on the memory type, this API registers existing cuMemAlloc’d (pinned) memory for GDS IO operations or host memory for IO operations.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    bufPtr_base
   </span>
   <p>
    Address of device pointer.
    <span>
     cuFileRead
    </span>
    and
    <span>
     cuFileWrite
    </span>
    must
    use this
    <span>
     bufPtr_base
    </span>
    as the base address.
   </p>
  </li>
  <li>
   <span>
    size
   </span>
   <p>
    Size in bytes from the start of memory to map.
   </p>
  </li>
  <li>
   <span>
    flags
   </span>
   <p>
    Reserved for future use, must be 0.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful registration.
  </li>
  <li>
   <span>
    CU_FILE_NVFS_DRIVER_ERROR
   </span>
   if the nvidia-fs driver cannot handle the request.
  </li>
  <li>
   <span>
    CU_FILE_INVALID_VALUE
   </span>
   on a failure.
  </li>
  <li>
   <span>
    CU_FILE_CUDA_DRIVER_ERROR
   </span>
   on CUDA-specific errors. CUresult code can be obtained using
   <span>
    CU_FILE_CUDA_ERR
   </span>
   (err).
  </li>
  <li>
   <span>
    CU_FILE_MEMORY_ALREADY_REGISTERED
   </span>
   , if memory is already registered.
  </li>
  <li>
   <span>
    CU_FILE_INTERNAL_ERROR
   </span>
   , an internal library-specific error.
  </li>
  <li>
   <span>
    CU_FILE_CUDA_MEMORY_TYPE_INVALID
   </span>
   , for device memory that is not allocated via
   <span>
    cudaMalloc
   </span>
   or
   <span>
    cuMemAlloc
   </span>
   .
  </li>
  <li>
   <span>
    CU_FILE_CUDA_POINTER_RANGE_ERROR
   </span>
   , if the size exceeds the bounds of the allocated memory.
  </li>
  <li>
   <span>
    CU_FILE_INVALID_MAPPING_SIZE
   </span>
   , if the size exceeds the GPU resource limits.
  </li>
  <li>
   <span>
    CU_FILE_GPU_MEMORY_PINNING_FAILED
   </span>
   , if not enough pinned memory is available.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  Based on the memory type, this API either registers the specified GPU address or host memory address and size for use with the
  <span>
   cuFileRead
  </span>
  and
  <span>
   cuFileWrite
  </span>
  operations. The user must call
  <span>
   cuFileBufDeregister
  </span>
  to release the pinned memory mappings for GPU memory if needed. See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufderegister" shape="rect">
    cuFileBufDeregister
   </a>
  </li>
 </ul>
 <h3 id="cufilebufderegister">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufderegister">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufderegister" id="cufilebufderegister" name="cufilebufderegister" shape="rect">
    4.3.2. cuFileBufDeregister
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileBufDeregister(const void *bufPtr_base);</p>
        </pre>
 <ul>
  <li>
   Based on the memory type, this API either deregisters CUDA memory or the host memory registered using the
   <span>
    cuFileBufRegister
   </span>
   API.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    bufPtr_base
   </span>
   <p>
    Address of device pointer to release the mappings that were provided to
    <span>
     cuFileBufRegister
    </span>
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful deregistration.
  </li>
  <li>
   <span>
    CU_FILE_MEMORY_NOT_REGISTERED
   </span>
   , if
   <span>
    bufPtr_base
   </span>
   was not registered.
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   on failure to find the registration for the specified memory.
  </li>
  <li>
   <span>
    CU_FILE_INTERNAL_ERROR
   </span>
   , an internal library-specific error.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This API deregisters memory mappings that were registered by
  <span>
   cuFileBufRegister
  </span>
  . Refer to
  <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufregister" shape="rect">
   cuFileBufRegister
  </a>
  for more information.
 </p>
 <h3 id="cufile-stream-api-functional-specification">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-stream-api-functional-specification">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-stream-api-functional-specification" id="cufile-stream-api-functional-specification" name="cufile-stream-api-functional-specification" shape="rect">
    4.4. cuFile Stream API Functional Specification
   </a>
  </a>
 </h3>
 <p>
  This section provides information about the cuFile stream API functional specification.
 </p>
 <p>
  The stream APIs are similar to Read and Write, but they take a stream parameter to support asynchronous operations and execute in the CUDA stream order.
  <a class="Link" data-cms-ai="0" id="cufilestreamregister" name="cufilestreamregister" shape="rect">
  </a>
 </p>
 <h3 id="cufilestreamregister">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilestreamregister">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilestreamregister" id="cufilestreamregister" name="cufilestreamregister" shape="rect">
    4.4.1. cuFileStreamRegister
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileStreamRegister(CUStream_t stream, unsigned flags);</p>
        </pre>
 <ul>
  <li>
   <p>
    Defines the input behavior for stream I/O APIs.
   </p>
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    stream
   </span>
   <p>
    CUDA stream in which to enqueue the operation. If NULL, make this operation in the default CUDA stream.
   </p>
  </li>
  <li>
   <span>
    flags
   </span>
   <p>
    The following are valid values:
   </p>
   <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
    <tr class="row">
     <th align="left" class="entry" colspan="1" id="d54e3448" rowspan="1" valign="top" width="50%">
      Value
     </th>
     <th align="left" class="entry" colspan="1" id="d54e3451" rowspan="1" valign="top" width="50%">
      Description
     </th>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e3448" rowspan="1" valign="top" width="50%">
      0x0
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e3451" rowspan="1" valign="top" width="50%">
      All the I/O parameters are valid only at the time of execution.
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e3448" rowspan="1" valign="top" width="50%">
      0x1
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e3451" rowspan="1" valign="top" width="50%">
      Buffer offset value is valid at submission time.
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e3448" rowspan="1" valign="top" width="50%">
      0x2
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e3451" rowspan="1" valign="top" width="50%">
      File offset value is valid at submission time.
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e3448" rowspan="1" valign="top" width="50%">
      0x4
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e3451" rowspan="1" valign="top" width="50%">
      Size is valid at submission time.
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e3448" rowspan="1" valign="top" width="50%">
      0x8
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e3451" rowspan="1" valign="top" width="50%">
      All inputs i.e. buffer offset, file offset and size are 4K aligned.
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e3448" rowspan="1" valign="top" width="50%">
      0xf
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e3451" rowspan="1" valign="top" width="50%">
      All inputs are aligned and known at submission time.
     </td>
    </tr>
   </table>
  </li>
 </ul>
 Note:
 <p>
  Using the flag ‘0XF’ will perform best as the workflow can be optimized during submission time.
 </p>
 <p>
  Description
 </p>
 <p>
  This optional API registers the stream with the cuFile subsystem.
 </p>
 <p>
  This API will allocate resources to handle stream operations for cuFile.
 </p>
 <p>
  The API will synchronize on the stream before allocating resources.
 </p>
 <p>
  The stream pointer is expected to be a valid pointer.
 </p>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful submission.
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   on a invalid stream specification.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_ERROR
   </span>
   if the NVIDIA-fs driver cannot handle the request.
  </li>
  <li>
   <span>
    CU_FILE_PLATFORM_NOT_SUPPORTED
   </span>
   on unsupported platforms.
  </li>
 </ul>
 <h3 id="cufilestreamderegister">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilestreamderegister">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilestreamderegister" id="cufilestreamderegister" name="cufilestreamderegister" shape="rect">
    4.4.2. cuFileStreamDeregister
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileStreamDeregister(CUStream_t stream);</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    stream
   </span>
   <p>
    CUDA stream in which to enqueue the operation. If NULL, make this operation in the default CUDA stream.
   </p>
  </li>
  <li>
   <span>
    flags
   </span>
   <p>
    Reserved for future use.
   </p>
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This optional API deregisters the stream with the cuFile subsystem.
 </p>
 <p>
  This API will free allocated cuFile resources associated with the stream.
 </p>
 <p>
  The API will synchronize on the stream before releasing resources.
 </p>
 <p>
  The stream pointer is expected to be a valid pointer.
 </p>
 <p>
  The stream will be automatically deregistered as part of
  <span>
   cuFileDriverClose
  </span>
  .
 </p>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful submission.
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   on a invalid stream specification.
  </li>
  <li>
   <span>
    CU_FILE_PLATFORM_NOT_SUPPORTED
   </span>
   on unsupported platforms.
  </li>
 </ul>
 <h3 id="cufilereadasync">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" id="cufilereadasync" name="cufilereadasync" shape="rect">
    4.4.3. cuFileReadAsync
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileReadAsync(CUFileHandle_t fh,
                        void *bufPtr_base, 
                        size_t *size_p,
                        off_t *file_offset_p, 
                        off_t *bufPtr_offset_p,
                        int *bytes_read_p,
                        CUstream stream);</p>
        </pre>
 <ul>
  <li>
   Enqueues a read operation for the specified bytes from the cuFile handle into the device memory by using GDS functionality or to the host memory based on the type of memory pointer.
  </li>
  <li>
   If non-NULL, the action is ordered in the stream.
  </li>
  <li>
   <p>
    The current context of the caller is assumed.
   </p>
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul class="ul">
  <li class="li">
   <span>
    fh
   </span>
   <p>
    The cuFile handle for the file.
   </p>
  </li>
  <li class="li">
   <span>
    bufPtr_base
   </span>
   <ul>
    <li>
     The base address of the buffer in the memory into which to read.
    </li>
    <li>
     The buffer can be allocated using either
     <span>
      cudaMemory
     </span>
     /
     <span>
      cudaMallocHost
     </span>
     /
     <span>
      malloc
     </span>
     /
     <span>
      mmap
     </span>
     .
    </li>
    <li>
     For registered buffers,
     <span>
      bufPtr_base
     </span>
     must remain set to the base address used in
     <span>
      cuFileBufRegister
     </span>
     call.
    </li>
   </ul>
  </li>
  <li class="li">
   <span>
    size_p
   </span>
   <p>
    Pointer to size in bytes to read. If the exact size is not known at the time of I/O submission, then you must set it to the maximum possible I/O size for that stream I/O.
   </p>
  </li>
  <li class="li">
   <span>
    file_offset_p
   </span>
   <p>
    Pointer to offset in the file from which to read. Unless otherwise set using
    <span>
     cuFileStreamRegister
    </span>
    API, this value will not be evaluated until execution time.
   </p>
  </li>
  <li class="li">
   <span>
    bufPtr_offset_p
   </span>
   <p>
    Pointer to the offset relative to the
    <span>
     bufPtr_base
    </span>
    pointer from which to write. Unless otherwise set using cuFileStreamRegister API, this value will not be evaluated until execution time.
   </p>
  </li>
  <li class="li">
   <span>
    bytes_read_p
   </span>
   <p>
    Pointer to the bytes read from the specified filehandle. This pointer should be a non NULL value and
    <span>
     *bytes_read_p
    </span>
    set to 0. After successful execution of the operation in the stream, the value
    <span>
     *bytes_read_p
    </span>
    will contain either:
   </p>
   <ul>
    <li>
     The number of bytes successfully read.
    </li>
    <li>
     -1 on IO errors.
    </li>
    <li>
     All other errors return a negative integer value of the
     <span>
      CUfileOpError
     </span>
     enum value.
    </li>
   </ul>
  </li>
  <li class="li">
   <span>
    stream
   </span>
   <ul>
    <li>
     CUDA stream in which to enqueue the operation.
    </li>
    <li>
     If NULL, make this operation synchronous.
    </li>
   </ul>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful submission.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_ERROR
   </span>
   , if the nvidia-fs driver cannot handle the request.
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   on an input failure.
  </li>
  <li>
   <span>
    CU_FILE_CUDA_ERROR
   </span>
   on CUDA-specific errors.
   <p>
    CUresult code can be obtained by using
    <span>
     CU_FILE_CUDA_ERR(err)
    </span>
    .
   </p>
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   This API reads the data from the specified file handle at the specified offset and size bytes into the GPU memory using GDS functionality.
   <p>
    This is an asynchronous call and enqueues the operation into the specified CUDA stream and will not block the host thread for IO completion. The operation can be waited upon using
    <span>
     cuStreamSynchronize(stream)
    </span>
    .
   </p>
  </li>
  <li>
   The
   <span>
    bytes_read_p
   </span>
   memory should be allocated with
   <span>
    cuMemHostAlloc/malloc/mmap
   </span>
   or registered with
   <span>
    cuMemHostRegister
   </span>
   .
   <p>
    The pointer to access that memory from the device can be obtained by using
    <span>
     cuMemHostGetDevicePointer
    </span>
    .
   </p>
  </li>
  <li>
   Operations that are enqueued with cuFile Stream APIs are FIFO ordered with respect to other work on the stream and must be completed before continuing to the next action in the stream.
  </li>
  <li>
   Unless otherwise specified through
   <span>
    cuFileStreamRegister
   </span>
   API, file offset, buffer offset or size parameter will not be evaluated until execution time. In these scenarios, size parameters should be set to the maximum possible I/O size at the time of submission and can be set to the actual size prior to the stream I/O execution.
  </li>
 </ul>
 <p>
  Refer to the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
    cuFileRead
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" shape="rect">
    cuFileWriteAsync
   </a>
  </li>
 </ul>
 <h3 id="cufilewriteasync">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" id="cufilewriteasync" name="cufilewriteasync" shape="rect">
    4.4.4. cuFileWriteAsync
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileWriteAsync(CUFileHandle_t fh,
                        void *bufPtr_base, 
                        size_t *size_p,
                        off_t file_offset_p, 
                        off_t bufPtr_offset_p,
                        int *bytes_written_p,
                        CUstream_t stream);</p>
        </pre>
 <ul>
  <li>
   Queues Write operation for the specified bytes from the device memory into the cuFile handle by using GDS.
  </li>
 </ul>
 <p>
  Parameters
 </p>
 <ul class="ul">
  <li class="li">
   <span>
    fh
   </span>
   <p>
    The cuFile handle for the file.
   </p>
  </li>
  <li class="li">
   <span>
    bufPtr_base
   </span>
   <p>
    The base address of the buffer in the memory from which to write. The buffer can be allocated using either
    <span>
     cudaMemory/cudaMallocHost/malloc/mmap
    </span>
    . For registered buffers,
    <span>
     bufPtr_base
    </span>
    must remain set to the base address used in the
    <span>
     cuFileBufRegister
    </span>
    call.
   </p>
  </li>
  <li class="li">
   <span>
    size_p
   </span>
   <p>
    Pointer to the size in bytes to write. If the exact size is not known at the time of I/O submission, then you must set it to the maximum possible I/O size for that stream I/O.
   </p>
  </li>
  <li class="li">
   <span>
    file_offset_p
   </span>
   <p>
    Pointer to the offset in the file from which to write. Unless otherwise set using
    <span>
     cuFileStreamRegister
    </span>
    API, this value will not be evaluated until execution time.
   </p>
  </li>
  <li class="li">
   <span>
    bufPtr_offset_p
   </span>
   <p>
    Pointer to the offset relative to the
    <span>
     bufPtr_base
    </span>
    pointer from which to write. Unless otherwise set using cuFileStreamRegister API, this value will not be evaluated until execution time.
   </p>
  </li>
  <li class="li">
   <span>
    bytes_written_p
   </span>
   <p>
    Pointer to the bytes written to the specified filehandle.This pointer should be a non NULL value and
    <span>
     *bytes_written_p
    </span>
    set to 0. After successful execution of the operation in the stream, the value
    <span>
     *bytes_written_p
    </span>
    will contain either:
   </p>
   <ul>
    <li>
     The number of bytes successfully written.
    </li>
    <li>
     -1 on IO errors.
    </li>
    <li>
     All other errors will return a negative integer value of the
     <span>
      CUfileOpError
     </span>
     enum value.
    </li>
   </ul>
  </li>
  <li class="li">
   <span>
    stream
   </span>
   <p>
    The CUDA stream to enqueue the operation.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on a successful submission.
  </li>
  <li>
   <span>
    CU_FILE_DRIVER_ERROR
   </span>
   , if the nvidia-fs driver cannot handle the request.
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   on an input failure.
  </li>
  <li>
   <span>
    CU_FILE_CUDA_ERROR
   </span>
   on CUDA-specific errors.
   <p>
    The CUresult code can be obtained by using
    <span>
     CU_FILE_CUDA_ERR(err)
    </span>
    .
   </p>
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   This API writes the data from the GPU memory to a file specified by the file handle at a specified offset and size bytes by using GDS functionality. This is an asynchronous call and enqueues the operation into the specified CUDA stream and will not block the host thread for IO completion. The operation can be waited upon by using
   <span>
    cuStreamSynchronize(stream)
   </span>
   .
  </li>
  <li>
   The
   <span>
    bytes_written
   </span>
   pointer should be allocated with
   <span>
    cuMemHostAlloc
   </span>
   or registered with
   <span>
    cuMemHostRegister
   </span>
   , and the pointer to access that memory from the device can be obtained by using
   <span>
    cuMemHostGetDevicePointer
   </span>
   .
  </li>
  <li>
   Operations that are enqueued with cuFile Stream APIs are FIFO ordered with respect to other work on the stream and must be completed before continuing to the next action in the stream.
  </li>
  <li>
   Unless otherwise specified through
   <span>
    cuFileStreamRegister
   </span>
   API, file offset, buffer offset or size parameter will not be evaluated until execution time. In these scenarios, size parameters should be set to the maximum possible I/O size at the time of submission and can be set to the actual size prior to the stream I/O execution.
  </li>
 </ul>
 <p>
  See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
    cuFileRead
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" shape="rect">
    cuFileReadAsync
   </a>
  </li>
 </ul>
 <h3 id="cufile-batch-api-functional-specification">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-batch-api-functional-specification">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-batch-api-functional-specification" id="cufile-batch-api-functional-specification" name="cufile-batch-api-functional-specification" shape="rect">
    4.5. cuFile Batch API Functional Specification
   </a>
  </a>
 </h3>
 <p>
  This section provides information about the cuFile Batch API functional specification.
 </p>
 <h3 id="cufilebatchiosetup">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosetup">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosetup" id="cufilebatchiosetup" name="cufilebatchiosetup" shape="rect">
    4.5.1. cuFileBatchIOSetUp
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t
cuFileBatchIOSetUp(CUfileBatchHandle_t *batch_idp, int max_nr);</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    max_nr
   </span>
   (Input) The maximum number of events this batch will hold.
   Note:
   <p>
    The number should be between 1 - “
    <span>
     properties.io_batch_size
    </span>
    ”
   </p>
  </li>
  <li>
   <span>
    batch_idp
   </span>
   <p>
    (Output) Will be used in subsequent batch IO calls.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on success.
  </li>
  <li>
   <span>
    CU_FILE_INTERNAL_ERROR
   </span>
   on on any failures.
  </li>
 </ul>
 <p>
  Description
 </p>
 <p>
  This interface should be the first call in the sequence of batch I/O operation. This takes the maximum number of batch entries the caller intends to use and returns a
  <span>
   CUFileBatchHandle_t
  </span>
  which should be used by the caller for subsequent batch I/O calls. See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
    cuFileRead
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" shape="rect">
    cuFileReadAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" shape="rect">
    cuFileWriteAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus" shape="rect">
    cuFileBatchIOGetStatus
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiocancel" shape="rect">
    cuFileBatchIOCancel
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy" shape="rect">
    cuFileBatchIODestroy
   </a>
  </li>
 </ul>
 <h3 id="cufilebatchiosubmit">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosubmit">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosubmit" id="cufilebatchiosubmit" name="cufilebatchiosubmit" shape="rect">
    4.5.2. cuFileBatchIOSubmit
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileBatchIOSubmit(CUfileBatchHandle_t batch_idp,
                                 unsigned nr, 
                                 CUfileIOParams_t *iocbp,
                                 unsigned int flags)</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul class="ul">
  <li class="li">
   <span>
    batch_idp
   </span>
   <p>
    The address of the output parameter for the newly created batch ID, which was obtained from a
    <span>
     cuFileBatchSetup
    </span>
    call.
   </p>
  </li>
  <li class="li">
   <span>
    nr
   </span>
   <ul>
    <li>
     The number of requests for the batch request.
    </li>
    <li>
     The value must be greater than 0 and less than or equal to
     <span>
      max_nr
     </span>
     specified in
     <span>
      cuFileBatchIOSetup
     </span>
     .
    </li>
   </ul>
  </li>
  <li class="li">
   <span>
    iocbp
   </span>
   <p>
    The pointer contains the
    <span>
     CUfileIOParams_t
    </span>
    array structures of the length
    <span>
     nr
    </span>
    array.
   </p>
  </li>
  <li class="li">
   <span>
    flags
   </span>
   <p>
    Reserved for future use. Should be set to 0.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on success.
  </li>
  <li>
   <span>
    CU_FILE_INTERNAL_ERROR
   </span>
   on any failures.
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   This API will need to be used to submit a read/write operation on an array of GPU/CPU data pointers from their respective file handle, offset, and size bytes.
   <p>
    Based on the type of memory pointer, the data is transferred to/from the GPU memory by using GDS or the data is transferred to/from the CPU memory.
   </p>
   <ul>
    <li>
     This is an asynchronous call and will enqueue the operation on a
     <span>
      batch_id
     </span>
     provided by the
     <span>
      cuFileIOSetup
     </span>
     API. The operation can be monitored when using this
     <span>
      batch_id
     </span>
     through
     <span>
      cuFileBatchIOGetStatus
     </span>
     .
    </li>
    <li>
     The operation can be canceled by calling
     <span>
      cuFileBatchIOCancel
     </span>
     or destroyed by
     <span>
      cuFileBatchIODestroy
     </span>
     .
    </li>
   </ul>
  </li>
  <li>
   The entries in the
   <span>
    CUfileIOParams_t
   </span>
   array describe individual IOs.
   <p>
    The bytes transacted field is valid only when the status indicates a completion.
   </p>
  </li>
  <li>
   Operations that are enqueued with cuFile Batch APIs are FIFO ordered with respect to other work on the stream and must be completed before continuing to the next action in the stream. Operations in each batch might be reordered with respect to each other.
  </li>
  <li>
   The status field of individual IO operations via
   <span>
    CUfileIOParams_t
   </span>
   entries will have undefined values before the entire batch is complete. This definition is subject to change.
  </li>
 </ul>
 <p>
  See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread" shape="rect">
    cuFileRead
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite" shape="rect">
    cuFileWrite
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync" shape="rect">
    cuFileReadAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync" shape="rect">
    cuFileWriteAsync
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus" shape="rect">
    cuFileBatchIOGetStatus
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiocancel" shape="rect">
    cuFileBatchIOCancel
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy" shape="rect">
    cuFileBatchIODestroy
   </a>
  </li>
 </ul>
 <h3 id="cufilebatchiogetstatus">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus" id="cufilebatchiogetstatus" name="cufilebatchiogetstatus" shape="rect">
    4.5.3. cuFileBatchIOGetStatus
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileBatchIOGetStatus(CUfileBatchHandle_t batch_idp, 
                                     unsigned min_nr,
                                     unsigned *nr,
                                     CUfileIOEvents_t *iocbp,
                                     struct timespec* timeout));</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    batch_idp
   </span>
   <p>
    Obtained during setup.
   </p>
  </li>
  <li>
   <span>
    min_nr
   </span>
   <p>
    The minimum number of IO entries for which status is requested. The
    <span>
     min_nr
    </span>
    should be greater than or equal to zero and less than or equal to
    <span>
     *nr
    </span>
    .
   </p>
  </li>
  <li>
   <span>
    nr
   </span>
   <p>
    This is a pointer to max requested IO entries to poll for completion and is used as an Input/Output parameter. As an input
    <span>
     *nr
    </span>
    must be set to pass the maximum number of IO requests to poll for. As an output,
    <span>
     *nr
    </span>
    returns the number of completed I/Os.
   </p>
  </li>
  <li>
   <span>
    iocbp
   </span>
   <p>
    <span>
     CUFileIOEvents_t
    </span>
    array containing the status of completed I/Os in that batch.
   </p>
  </li>
  <li>
   <span>
    timeout
   </span>
   <p>
    This parameter is used to specify the amount of time to wait for in this API, even if the minimum number of requests have not completed. If the timeout hits, it is possible that the number of returned IOs can be less than
    <span>
     min_nr
    </span>
    .
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on success.
   <p>
    The success here refers to the completion of the API. Individual IO status and error can be obtained by examining the returned status and error in the array iocbp.
   </p>
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   for an invalid batch ID.
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   This is a batch API to monitor the status of batch IO operations by using the
   <span>
    batch_id
   </span>
   that was returned by
   <span>
    cuFileBatchIOSubmit
   </span>
   . The operation will be canceled automatically if
   <span>
    cuFileBatchIOCancel
   </span>
   is called and the status will reflect
   <span>
    CU_FILE_CANCELED
   </span>
   for all canceled IO operations.
  </li>
  <li>
   The status of each member of the batch is queried, which would not be possible with one
   <span>
    CUEvent
   </span>
   . The status field of individual IO operations via
   <span>
    CUfileIOParams_t
   </span>
   entries will have undefined values before the entire batch is completed. This definition is subject to change.
  </li>
 </ul>
 <p>
  See the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosubmit" shape="rect">
    cuFileBatchIOSubmit
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy" shape="rect">
    cuFileBatchIODestroy
   </a>
  </li>
 </ul>
 <h3 id="cufilebatchiocancel">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiocancel">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiocancel" id="cufilebatchiocancel" name="cufilebatchiocancel" shape="rect">
    4.5.4. cuFileBatchIOCancel
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>CUfileError_t cuFileBatchIOCancel(CUfileBatchHandle_t batch_idp)</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    batch_idp
   </span>
   <p>
    The batch ID to cancel.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <ul>
  <li>
   <span>
    CU_FILE_SUCCESS
   </span>
   on success.
  </li>
  <li>
   <span>
    CU_FILE_ERROR_INVALID_VALUE
   </span>
   on any failures.
  </li>
 </ul>
 <p>
  Description
 </p>
 <ul>
  <li>
   This is a batch API to cancel an ongoing IO batch operation by using the
   <span>
    batch_id
   </span>
   that was returned by
   <span>
    cuFileBatchIOSubmit
   </span>
   . This API tries to cancel an individual IO operation in the batch if possible and provides no guarantee about canceling an ongoing operation.
  </li>
 </ul>
 <p>
  Refer to the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus" shape="rect">
    cuFileBatchIOGetStatus
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosubmit" shape="rect">
    cuFileBatchIOSubmit
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy" shape="rect">
    cuFileBatchIODestroy
   </a>
  </li>
 </ul>
 <h3 id="cufilebatchiodestroy">
  <a data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy" id="cufilebatchiodestroy" name="cufilebatchiodestroy" shape="rect">
    4.5.5. cuFileBatchIODestroy
   </a>
  </a>
 </h3>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>void cuFileBatchIODestroy(CUfileBatchHandle_t batch_idp)</p>
        </pre>
 <p>
  Parameters
 </p>
 <ul>
  <li>
   <span>
    batch_idp
   </span>
   <p>
    The batch handle to be destroyed.
   </p>
  </li>
 </ul>
 <p>
  Returns
 </p>
 <p>
  void
 </p>
 <p>
  Description
 </p>
 <p>
  This is a batch API that destroys a batch context and the resources that are allocated with
  <span>
   cuFileBatchIOSetup
  </span>
  . Refer to the following for more information:
 </p>
 <ul>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus" shape="rect">
    cuFileBatchIOGetStatus
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosubmit" shape="rect">
    cuFileBatchIOSubmit
   </a>
  </li>
  <li>
   <a class="xref" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiocancel" shape="rect">
    cuFileBatchIOCancel
   </a>
  </li>
 </ul>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#sample-program">
   5. Sample Program with cuFile APIs
  </a>
 </h2>
 <p>
  The following sample program uses the cuFile APIs:
 </p>
 Copy
 Copied!
 <pre class="language-" data-line="" id="play">
            
            <p>// To compile this sample code:
//
// nvcc gds_helloworld.cxx -o gds_helloworld -lcufile
//
// Set the environment variable TESTFILE
// to specify the name of the file on a GDS enabled filesystem
//
// Ex:   TESTFILE=/mnt/gds/gds_test ./gds_helloworld
//
//
#include &lt;fcntl.h&gt;
#include &lt;errno.h&gt;
#include &lt;unistd.h&gt;

#include &lt;cstdlib&gt;
#include &lt;cstring&gt;
#include &lt;iostream&gt;
#include &lt;cuda_runtime.h&gt;
#include "cufile.h"

//#include "cufile_sample_utils.h"
using namespace std;

int main(void) {
        int fd;
        ssize_t ret;
        void *devPtr_base;
        off_t file_offset = 0x2000;
        off_t devPtr_offset = 0x1000;
        ssize_t IO_size = 1UL &lt;&lt; 24;
        size_t buff_size = IO_size + 0x1000;
        CUfileError_t status;
        // CUResult cuda_result;
        int cuda_result;
        CUfileDescr_t cf_descr;
        CUfileHandle_t cf_handle;
        char *testfn;
        
        testfn=getenv("TESTFILE");
        if (testfn==NULL) {
            std::cerr &lt;&lt; "No testfile defined via TESTFILE.  Exiting." &lt;&lt; std::endl;
            return -1;
        } 
       
        cout &lt;&lt; std::endl; 
        cout &lt;&lt; "Opening File " &lt;&lt; testfn &lt;&lt; std::endl;

        fd = open(testfn, O_CREAT|O_WRONLY|O_DIRECT, 0644);
        if(fd &lt; 0) {
                std::cerr &lt;&lt; "file open " &lt;&lt; testfn &lt;&lt; "errno " &lt;&lt; errno &lt;&lt; std::endl;
                return -1;
        }

        // the above fd could also have been opened without O_DIRECT starting CUDA toolkit 12.2
        // (gds 1.7.x version) as follows
        // fd = open(testfn, O_CREAT|O_WRONLY, 0644);

        cout &lt;&lt; "Opening cuFileDriver." &lt;&lt; std::endl;
        status = cuFileDriverOpen();
        if (status.err != CU_FILE_SUCCESS) {
                std::cerr &lt;&lt; " cuFile driver failed to open " &lt;&lt; std::endl;
                close(fd);
                return -1;
        }

        cout &lt;&lt; "Registering cuFile handle to " &lt;&lt; testfn &lt;&lt; "." &lt;&lt; std::endl;

        memset((void *)&amp;cf_descr, 0, sizeof(CUfileDescr_t));
        cf_descr.handle.fd = fd;
        cf_descr.type = CU_FILE_HANDLE_TYPE_OPAQUE_FD;
        status = cuFileHandleRegister(&amp;cf_handle, &amp;cf_descr);
        if (status.err != CU_FILE_SUCCESS) {
                std::cerr &lt;&lt; "cuFileHandleRegister fd " &lt;&lt; fd &lt;&lt; " status " &lt;&lt; status.err &lt;&lt; std::endl;
                close(fd);
                return -1;
        }

        cout &lt;&lt; "Allocating CUDA buffer of " &lt;&lt; buff_size &lt;&lt; " bytes." &lt;&lt; std::endl;

        cuda_result = cudaMalloc(&amp;devPtr_base, buff_size);
        if (cuda_result != CUDA_SUCCESS) {
                std::cerr &lt;&lt; "buffer allocation failed " &lt;&lt; cuda_result &lt;&lt; std::endl;
                cuFileHandleDeregister(cf_handle);
                close(fd);
                return -1;
        }

        cout &lt;&lt; "Registering Buffer of " &lt;&lt; buff_size &lt;&lt; " bytes." &lt;&lt; std::endl;
        status = cuFileBufRegister(devPtr_base, buff_size, 0);
        if (status.err != CU_FILE_SUCCESS) {
                std::cerr &lt;&lt; "buffer registration failed " &lt;&lt; status.err &lt;&lt; std::endl;
                cuFileHandleDeregister(cf_handle);
                close(fd);
                cudaFree(devPtr_base);
                return -1;
        }

        // fill a pattern
        cout &lt;&lt; "Filling memory." &lt;&lt; std::endl;

        cudaMemset((void *) devPtr_base, 0xab, buff_size);
        cuStreamSynchronize(0);

        // perform write operation directly from GPU mem to file
        cout &lt;&lt; "Writing buffer to file." &lt;&lt; std::endl;
        ret = cuFileWrite(cf_handle, devPtr_base, IO_size, file_offset, devPtr_offset);

        if (ret &lt; 0 || ret != IO_size) {
                std::cerr &lt;&lt; "cuFileWrite failed " &lt;&lt; ret &lt;&lt; std::endl;
        }

        // release the GPU memory pinning
        cout &lt;&lt; "Releasing cuFile buffer." &lt;&lt; std::endl;
        status = cuFileBufDeregister(devPtr_base);
        if (status.err != CU_FILE_SUCCESS) {
                std::cerr &lt;&lt; "buffer deregister failed" &lt;&lt; std::endl;
                cudaFree(devPtr_base);
                cuFileHandleDeregister(cf_handle);
                close(fd);
                return -1;
        }

        cout &lt;&lt; "Freeing CUDA buffer." &lt;&lt; std::endl;
        cudaFree(devPtr_base);
        // deregister the handle from cuFile
        cout &lt;&lt; "Releasing file handle. " &lt;&lt; std::endl;
        (void) cuFileHandleDeregister(cf_handle);
        close(fd);

        // release all cuFile resources
        cout &lt;&lt; "Closing File Driver." &lt;&lt; std::endl;
        (void) cuFileDriverClose();

        cout &lt;&lt; std::endl; 

        return 0;
}</p>
        </pre>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#batch-api-known-limitations">
   6. Known Limitations of cuFile Batch APIs
  </a>
 </h2>
 <p>
  <a class="Link" data-cms-ai="0" id="batch-api-known-limitations" name="batch-api-known-limitations" shape="rect">
  </a>
  This section provides information about the known limitations of cuFile Batch APIs in this release of GDS.
 </p>
 <ul>
  <li>
   Batch I/Os will be supported mainly by either the local file systems which are hosted on NVMe or NVMeOF devices or by the native file system that supports Linux AIO. Following table provides an overview of the cuFile batch API support with respect to different file systems.
   <p>
    The following table provides an overview of cuFile batch API support with respect to distributed file systems:
   </p>
   <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
    <tr class="row">
     <th align="left" class="entry" colspan="1" id="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      File System
     </th>
     <th align="left" class="entry" colspan="1" id="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      GDS Batch Mode
     </th>
     <th align="left" class="entry" colspan="1" id="d54e4683" rowspan="1" valign="top" width="33.33333333333333%">
      Comments
     </th>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      Ext4/XFS
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      Read/Write support
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      DDN EXAScaler
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      Read/Write support
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      NFS
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      Read/Write support
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      IBM Spectrum Scale
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      Not available
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4683" rowspan="1" valign="top" width="33.33333333333333%">
      Will work in compat mode
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      Weka
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      Not available
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4683" rowspan="1" valign="top" width="33.33333333333333%">
      Will work in compat mode
     </td>
    </tr>
    <tr class="row">
     <td align="left" class="entry" colspan="1" headers="d54e4677" rowspan="1" valign="top" width="33.33333333333333%">
      BeeGFS
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4680" rowspan="1" valign="top" width="33.33333333333333%">
      Not available
     </td>
     <td align="left" class="entry" colspan="1" headers="d54e4683" rowspan="1" valign="top" width="33.33333333333333%">
      Will work in compat mode
     </td>
    </tr>
   </table>
  </li>
 </ul>
 <h2 class="StepModuleHeader-title">
  <a class="StepModuleHeader-anchorLink" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#notices-header">
   Notices
  </a>
 </h2>
 <h3>
  Notice
 </h3>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-1" name="notice__notice-para-1" shape="rect">
  </a>
  This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product. NVIDIA Corporation (“NVIDIA”) makes no representations or warranties, expressed or implied, as to the accuracy or completeness of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use. This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-2" name="notice__notice-para-2" shape="rect">
  </a>
  NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any time without notice.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-3" name="notice__notice-para-3" shape="rect">
  </a>
  Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-4" name="notice__notice-para-4" shape="rect">
  </a>
  NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (“Terms of Sale”). NVIDIA hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in this document. No contractual obligations are formed either directly or indirectly by this document.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-5" name="notice__notice-para-5" shape="rect">
  </a>
  NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications and therefore such inclusion and/or use is at customer’s own risk.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-6" name="notice__notice-para-6" shape="rect">
  </a>
  NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is customer’s sole responsibility to evaluate and determine the applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer, and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customer’s product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product designs.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-7" name="notice__notice-para-7" shape="rect">
  </a>
  No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights of NVIDIA.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-8" name="notice__notice-para-8" shape="rect">
  </a>
  Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices.
 </p>
 <p>
  <a class="Link" data-cms-ai="0" id="notice__notice-para-9" name="notice__notice-para-9" shape="rect">
  </a>
  THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, “MATERIALS”) ARE BEING PROVIDED “AS IS.” NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any reason whatsoever, NVIDIA’s aggregate and cumulative liability towards customer for the products described herein shall be limited in accordance with the Terms of Sale for the product.
 </p>
 <h3>
  OpenCL
 </h3>
 <p>
  OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc.
 </p>
 <h3>
  Trademarks
 </h3>
 <p>
  NVIDIA, the NVIDIA logo, DGX, DGX-1, DGX-2, DGX-A100, Tesla, and Quadro are trademarks and/or registered trademarks of NVIDIA Corporation in the United States and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.
 </p>
 <span class="Page-copyright-text">
  © 2020-2024 NVIDIA Corporation and affiliates. All rights reserved.
 </span>
 <span class="Page-copyright-update">
  Last updated on Jun 14, 2024.
 </span>
 Topics
 <ul class="Book-items">
  <li class="Book-items-item">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/index.html">
    NVIDIA GPUDirect Storage
   </a>
  </li>
  <li class="Book-items-item">
   <span class="Link">
    NVIDIA GPUDirect Storage
   </span>
   <ul class="Chapter-chapters">
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html">
      NVIDIA GPUDirect Storage Design Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#design-intro">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#data-transfer-gpu-storage">
        2. Data Transfer Issues for GPU and Storage
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#gds-storage-benefits">
        3. GPUDirect Storage Benefits
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#app-sustain">
        4. Application Suitability
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#transfers-to-from-gpu">
          4.1. Transfers To and From the GPU
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#io-bottleneck">
          4.2. Understanding IO Bottlenecks
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#explicit">
          4.3. Explicit GDS APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#pinned">
          4.4. Pinned Memory for DMA Transfers
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#cufile-apis">
          4.5. cuFile APIs
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#plat-perf-stable">
        5. Platform Performance Suitability
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#bandw-from-storage">
          5.1. Bandwidth from Storage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#path-storage-gpu">
          5.2. Paths from Storage to GPUs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#gpu-bar1-size">
          5.3. GPU BAR1 Size
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/design-guide/index.html#call-to-action">
        6. Call to Action
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html">
      NVIDIA GPUDirect Storage Overview Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#overview-intro">
        1. Introduction
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#related-docs">
          1.1. Related Documents
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#dev-benefits">
          1.2. Benefits for a Developer
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#intended-uses">
          1.3. Intended Uses
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#func-overview">
        2. Functional Overview
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#explicit-and-direct">
          2.1. Explicit and Direct
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#perf-optimize">
          2.2. Performance Optimizations
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#imp-perf-enhance">
            2.2.1. Implementation Performance Enhancements
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#concurrency-across-threads">
            2.2.2. Concurrency Across Threads
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#asychrony">
            2.2.3. Asynchrony
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#batching">
            2.2.4. Batching
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#streams">
            2.2.5. Use of CUDA Streams in cuFile
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#comp-and-gen">
          2.3. Compatibility and Generality
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#monitoring">
          2.4. Monitoring
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#solution-scope">
          2.5. Scope of the Solutions in GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#dynamic-routing-overview">
          2.6. Dynamic Routing
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#cufile-config-dynamic-routing">
            2.6.1. cuFile Configuration for Dynamic Routing
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#cufile-config-for-dfs-mount">
            2.6.2. cuFile Configuration for DFS Mount
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#dynamic-routing-cufile-config-validation">
            2.6.3. cuFile Configuration Validation for Dynamic Routing
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#software-arch">
        3. Software Architecture
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#software-comp">
          3.1. Software Components
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#prim-comp">
          3.2. Primary Components
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#gds-workflows">
            3.2.1. Workflows for GDS Functionality
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#workflow-1">
            3.2.2. Workflow 1
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#workflow-2">
            3.2.3. Workflow 2
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#align-linux-initiatives">
          3.3. Aligning with Other Linux Initiatives
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#deployment">
        4. Deployment
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#deploy-software-comp">
          4.1. Software Components for Deployment
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html#using-gds-containers">
          4.2. Using GPUDirect Storage in Containers
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html">
      cuFile API Reference Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#introduction">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#usage">
        2. Usage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#dynamic-interactions">
          2.1. Dynamic Interactions
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#driver-file-buffer">
          2.2. Driver, File, and Buffer Management
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-compatibility-mode">
          2.3. cuFile Compatibility Mode
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-api-specification">
        3. cuFile API Specification
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#data-types">
          3.1. Data Types
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#declarations-and-definitions">
            3.1.1. Declarations and Definitions
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#typedefs">
            3.1.2. Typedefs
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#enumerations">
            3.1.3. Enumerations
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-driver-api">
          3.2. cuFile Driver APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api">
          3.3. cuFile Synchronous IO APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-file-handle-api">
          3.4. cuFile File Handle APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-buffer-api">
          3.5. cuFile Buffer APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-stream-api">
          3.6. cuFile Stream APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-batch-api">
          3.7. cuFile Batch APIs
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-api-functional-specification">
        4. cuFile API Functional Specification
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriver-api-functional-specification">
          4.1. cuFileDriver API Functional Specification
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriveropen">
            4.1.1. cuFileDriverOpen
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriverclose">
            4.1.2. cuFileDriverClose
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledrivergetproperties">
            4.1.3. cuFileDriverGetProperties
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetpollmode">
            4.1.4. cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size)
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxdirectiosize">
            4.1.5. cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size)
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxcachesize">
            4.1.6. cuFileDriverSetMaxCacheSize(size_t max_cache_size)
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufiledriversetmaxpinnedmemsize">
            4.1.7. cuFileDriverSetMaxPinnedMemSize(size_t max_pinned_memory_size)
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-io-api-functional-specification">
          4.2. cuFile IO API Functional Specification
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilehandleregister">
            4.2.1. cuFileHandleRegister
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#unique_1423451733">
            4.2.2. cuFileHandleDeregister
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufileread">
            4.2.3. cuFileRead
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewrite">
            4.2.4. cuFileWrite
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-memory-mgmt-functional-specification">
          4.3. cuFile Memory Management Functional Specification
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufregister">
            4.3.1. cuFileBufRegister
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebufderegister">
            4.3.2. cuFileBufDeregister
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-stream-api-functional-specification">
          4.4. cuFile Stream API Functional Specification
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilestreamregister">
            4.4.1. cuFileStreamRegister
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilestreamderegister">
            4.4.2. cuFileStreamDeregister
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilereadasync">
            4.4.3. cuFileReadAsync
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilewriteasync">
            4.4.4. cuFileWriteAsync
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufile-batch-api-functional-specification">
          4.5. cuFile Batch API Functional Specification
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosetup">
            4.5.1. cuFileBatchIOSetUp
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiosubmit">
            4.5.2. cuFileBatchIOSubmit
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiogetstatus">
            4.5.3. cuFileBatchIOGetStatus
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiocancel">
            4.5.4. cuFileBatchIOCancel
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#cufilebatchiodestroy">
            4.5.5. cuFileBatchIODestroy
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#sample-program">
        5. Sample Program with cuFile APIs
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html#batch-api-known-limitations">
        6. Known Limitations of cuFile Batch APIs
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html">
      NVIDIA GPUDirect Storage Release Notes
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#rn-intro">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#new-features">
        2. New Features and Changes
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#mofed-fs-req">
        3. MLNX_OFED and Filesystem Requirements
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#support-matrix">
        4. Support Matrix
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#gds-enabled-libraries">
        5. GDS Enabled Libraries/Frameworks
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#included-packages">
        6. Included Packages
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#updates-bug-fixes">
        7. Minor Updates and Bug Fixes
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#known-issues">
        8. Known Issues
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/release-notes/index.html#known-limitations">
        9. Known Limitations
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/getting-started/index.html">
      Getting Started with NVIDIA GPUDirect Storage
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/getting-started/index.html#gs-intro">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/getting-started/index.html#sys-admin">
        2. If you are a system administrator or a performance engineer
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/getting-started/index.html#developer">
        3. If you are a developer
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/getting-started/index.html#oem-odm-csp">
        4. If you are OEM, ODM, CSP
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/getting-started/index.html#troubleshoting-issues">
        5. Troubleshooting GDS issues
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="Book-items-item">
   <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/index.html#understanding-gpudirect-storage">
    Understanding GPUDirect Storage
   </a>
   <ul class="Chapter-chapters">
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html">
      NVIDIA GPUDirect Storage Best Practices Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#gds-bp-intro">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#settings">
        2. Software Settings
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#system-settings">
          2.1. System Settings
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cuda-context-in-gpu-kernels">
          2.2. Use of CUDA Context in GPU Kernels and Storage IO
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-config">
          2.3. cuFile Configuration Settings
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#api-usage">
        3. API Usage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-driveropen">
          3.1. cuFileDriverOpen
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-handle-register">
          3.2. cuFileHandleRegister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-bufregister-fileread-filewrite">
          3.3. cuFileBufRegister, cuFileRead, cuFileWrite, cuFileBatchIOSubmit, cuFileBatchIOGetStatus, cuFileReadAsync, cuFileWriteAsync, and cuFileStreamRegister
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-1">
            3.3.1. IO Pattern 1
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-2">
            3.3.2. IO Pattern 2
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-3">
            3.3.3. IO Pattern 3
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-4">
            3.3.4. IO Pattern 4
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-5">
            3.3.5. IO Pattern 5
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-6">
            3.3.6. IO Pattern 6
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#io-pattern-7">
            3.3.7. IO Pattern 7
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-handle-deregister">
          3.4. cuFileHandleDeregister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-buf-deregister">
          3.5. cuFileBufDeregister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-stream-register">
          3.6. cuFileStreamRegister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#unique_880314822">
          3.7. cuFileStreamDeregister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html#cufile-driver-close">
          3.8. cuFileDriverClose
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html">
      NVIDIA GPUDirect Storage Benchmarking and Configuration Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#introduction">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#about-this-guide">
        2. About this Guide
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#benchmarking-gds">
        3. Benchmarking GPUDirect Storage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#determining-pcie-device-affinity">
          3.1. Determining PCIe Device Affinity
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-configuration-parameters">
          3.2. GPUDirect Storage Configuration Parameters
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#system-parameters">
            3.2.1. System Parameters
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-parameters">
            3.2.2. GPUDirect Storage Parameters
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-benchmarking-tools">
          3.3. GPUDirect Storage Benchmarking Tools
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gdsio">
            3.3.1. gdsio Utility
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-stats">
            3.3.2. gds-stats Tool
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-benchmarking-on-direct-attached-storage-das">
        4. GPUDirect Storage Benchmarking on Direct Attached Storage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-perf-dgx2">
          4.1. GPUDirect Storage Performance on DGX-2 System
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-perf-dgx-a100">
          4.2. GPUDirect Storage Performance on a DGX A100 System
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-benchmarking-on-nas">
        5. GPUDirect Storage Benchmarking on Network Attached Storage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#gds-benchmarking-on-nfs">
          5.1. GPUDirect Storage Benchmarking on NFS
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#summary">
        6. Summary
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#benchmarking-and-performance">
        A. Benchmarking and Performance
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#the-language-of-performance">
          A.1. The Language of Performance
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/configuration-guide/index.html#benchmarking-storage-performance">
          A.2. Benchmarking Storage Performance
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html">
      NVIDIA GPUDirect Storage Installation and Troubleshooting Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#intro">
        1. Introduction
       </a>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#troubleshoot-install">
        2. Installing GPUDirect Storage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#install-prereqs">
          2.1. Before You Install GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-installing">
          2.2. Installing GDS
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#config-file-system-settings">
            2.2.1. Configuring File System Settings for GDS
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#verify-suc-install">
            2.2.2. Verifying a Successful GDS Installation
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-lib-tools">
          2.3. Installed GDS Libraries and Tools
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#uninstall-gds">
          2.4. Uninstalling GPUDirect Storage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#environment-variables">
          2.5. Environment Variables Used by GPUDirect Storage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#json-config-params">
          2.6. JSON Config Parameters Used by GPUDirect Storage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dynamic-routing-config">
          2.7. GDS Configuration File Changes to Support Dynamic Routing
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#det-installed-version">
          2.8. Determining Which Version of GDS is Installed
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#experimental-repos-dgx">
          2.9. Experimental Repos for Network Install of GDS Packages for DGX Systems
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#api-errors">
        3. API Errors
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#api-error-1">
          3.1. CU_FILE_DRIVER_NOT_INITIALIZED
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#api-error-2">
          3.2. CU_FILE_DEVICE_NOT_SUPPORTED
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#api-error-3">
          3.3. CU_FILE_IO_NOT_SUPPORTED
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#api-error-4">
          3.4. CU_FILE_CUDA_MEMORY_TYPE_INVALID
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#basic-troubleshooting">
        4. Basic Troubleshooting
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#log-files-gds-lib">
          4.1. Log Files for the GDS Library
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#enable-diff-log-file-app">
          4.2. Enabling a Different cufile.log File for Each Application
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#enable-trace-lib-calls">
          4.3. Enabling Tracing GDS Library API Calls
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#api-error-5">
          4.4. cuFileHandleRegister Error
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#troubleshoot-cufile-errors">
          4.5. Troubleshooting Applications that Return cuFile Errors
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#error-no-activity-gds-stats">
          4.6. cuFile-* Errors with No Activity in GPUDirect Storage Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cuda-error-35">
          4.7. CUDA Runtime and Driver Mismatch with Error Code 35
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cuda-api-errors">
          4.8. CUDA API Errors when Running the cuFile-* APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#find-driver-stats">
          4.9. Finding GDS Driver Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#track-io-activity-gds-driver">
          4.10. Tracking IO Activity that Goes Through the GDS Driver
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#read-write-bandwidth-latency-nos">
          4.11. Read/Write Bandwidth and Latency Numbers in GDS Stats
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#track-regis-deregis-gpu-buffers">
          4.12. Tracking Registration and Deregistration of GPU Buffers
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#enabling-rdma-logging">
          4.13. Enabling RDMA-specific Logging for Userspace File Systems
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#system-not-ready">
          4.14. CUDA_ERROR_SYSTEM_NOT_READY After Installation
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#adding-udev-rules">
          4.15. Adding udev Rules for RAID Volumes
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#incomplete-write-on-nvme-drives">
          4.16. When You Observe “Incomplete write” on NVME Drives
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cufile-async-io-failing">
          4.17. CUFILE async I/O is failing
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#advanced-troubleshooting">
        5. Advanced Troubleshooting
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#hung-cufile-no-response">
          5.1. Resolving Hung cuFile* APIs with No Response
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#kernel-panic-stack-traces">
          5.2. Sending Relevant Data to Customer Support
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#io-failure-stack-trace-warning">
          5.3. Resolving an IO Failure with EIO and Stack Trace Warning
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#control-gpu-bar-usage">
          5.4. Controlling GPU BAR Memory Usage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#det-how-much-cache">
          5.5. Determining the Amount of Cache to Set Aside
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#monitor-bar-mem-usage">
          5.6. Monitoring BAR Memory Usage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#enomem-error-code">
          5.7. Resolving an ENOMEM Error Code
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-comp-mode">
          5.8. GDS and Compatibility Mode
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#enable-comp-mode">
          5.9. Enabling Compatibility Mode
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#track-enable-comp-mode">
          5.10. Tracking the IO After Enabling Compatibility Mode
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#bypass-gds">
          5.11. Bypassing GPUDirect Storage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-not-working-mount">
          5.12. GDS Does Not Work for a Mount
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-posix-io-same-file">
          5.13. Simultaneously Running the GPUDirect Storage IO and POSIX IO on the Same File
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-data-verif-tests">
          5.14. Running Data Verification Tests Using GPUDirect Storage
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html">
          NVIDIA GPUDirect Storage Installation and Troubleshooting Guide
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#troubleshoot-perf">
        6. Troubleshooting Performance
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#perf-benchmark-examples">
          6.1. Running Performance Benchmarks with GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-internal-cache">
          6.2. Tracking Whether GPUDirect Storage is Using an Internal Cache
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#io-cross-pcie-root-complex">
          6.3. Tracking when IO Crosses the PCIe Root Complex and Impacts Performance
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#monitor-cpu-usage">
          6.4. Using GPUDirect Statistics to Monitor CPU Activity
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#monit-perf-tracing">
          6.5. Monitoring Performance and Tracing with cuFile-* APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#ex-linux-tools">
          6.6. Example: Using Linux Tracing Tools
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#trace-cufile-apis">
          6.7. Tracing the cuFile-* APIs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dynamic-routing-improving-performance">
          6.8. Improving Performance using Dynamic Routing
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#trouble-io-activity">
        7. Troubleshooting IO Activity
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#manage-coherency-page-cache">
          7.1. Managing Coherency of Data in the Page Cache and on Disk
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#exascaler-fs-lnet">
        8. EXAScaler Filesystem LNet Troubleshooting
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#exascaler-client-mod-version">
          8.1. Determining the EXAScaler Filesystem Client Module Version
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#lnet-network-setup">
          8.2. Checking the LNet Network Setup on a Client
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-peer-health">
          8.3. Checking the Health of the Peers
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#multi-rail-support">
          8.4. Checking for Multi-Rail Support
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-peer-affinity">
          8.5. Checking GDS Peer Affinity
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-lnet-errors">
          8.6. Checking for LNet-Level Errors
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#lnet-nids-deg-timeouts">
          8.7. Resolving LNet NIDs Health Degradation from Timeouts
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#multi-osts-peer-sel">
          8.8. Configuring LNet Networks with Multiple OSTs for Optimal Peer Selection
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#exascaler-fs-perf">
        9. Understanding EXAScaler Filesystem Performance
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#osc-tune-perf-param">
          9.1. osc Tuning Performance Parameters
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#misc-comms">
          9.2. Miscellaneous Commands for osc, mdc, and stripesize
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#num-config-disks">
          9.3. Getting the Number of Configured Object-Based Disks
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#addl-stats-exascaler-fs">
          9.4. Getting Additional Statistics related to the EXAScaler Filesystem
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#get-md-stats">
          9.5. Getting Metadata Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-exist-mount-lustre">
          9.6. Checking for an Existing Mount
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#unmount-fs-cluster">
          9.7. Unmounting an EXAScaler Filesystem Cluster
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#sum-exacaler-fs-stats">
          9.8. Getting a Summary of EXAScaler Filesystem Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-poll-mode">
          9.9. Using GPUDirect Storage in Poll Mode
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#trouble-faq-wekafs">
        10. Troubleshooting and FAQ for the WekaIO Filesystem
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#download-wekaio-cp">
          10.1. Downloading the WekaIO Client Package
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#wekaio-version-gds">
          10.2. Determining Whether the WekaIO Version is Ready for GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#mount-wekaio-fs-cluster">
          10.3. Mounting a WekaIO File System Cluster
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#resolve-fail-mount">
          10.4. Resolving a Failing Mount
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#resolve-wekaio-usage">
          10.5. Resolving 100% Usage for WekaIO for Two Cores
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-existing-mount-wekafs">
          10.6. Checking for an Existing Mount in the Weka File System
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-summ-wekaio">
          10.7. Checking for a Summary of the WekaIO Filesystem Status
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#summ-wekaio-stats">
          10.8. Displaying the Summary of the WekaIO Filesystem Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#wekaio-writes-posix">
          10.9. Why WekaIO Writes Go Through POSIX
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-nvdiafsko-support">
          10.10. Checking for nvidia-fs.ko Support for Memory Peer Direct
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-mem-peer-stats">
          10.11. Checking Memory Peer Direct Stats
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#rel-nvidia-fs-stats">
          10.12. Checking for Relevant nvidia-fs Statistics for the WekaIO Filesystem
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#basic-wekaio-fs-test">
          10.13. Conducting a Basic WekaIO Filesystem Test
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#unmount-wekaio-fs-cluster">
          10.14. Unmounting a WekaIO File System Cluster
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#verify-installed-libs-wekaio-fs">
          10.15. Verify the Installed Libraries for the WekaIO Filesystem
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-config-file-changes">
          10.16. GDS Configuration File Changes to Support the WekaIO Filesystem
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#relevant-userspace-stats-wekaio-fs">
          10.17. Check for Relevant User-Space Statistics for the WekaIO Filesystem
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-wekafs-support">
          10.18. Check for WekaFS Support
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#spectrum-scale-intro">
        11. Enabling IBM Spectrum Scale Support with GDS
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#spectrum-scale-limitations-with-gds">
          11.1. IBM Spectrum Scale Limitations with GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#checking-for-peerdirect-support">
          11.2. Checking nvidia-fs.ko Support for Mellanox PeerDirect
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#verifying-libraries-for-spectrum-scale">
          11.3. Verifying Installed Libraries for IBM Spectrum Scale
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#checking-peerdirect-stats">
          11.4. Checking PeerDirect Stats
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#checking-for-relevant-stats">
          11.5. Checking for Relevant nvidia-fs Stats with IBM Spectrum Scale
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-user-space-stats">
          11.6. GDS User Space Stats for IBM Spectrum Scale for Each Process
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-configs-to-support-spectrum-scale">
          11.7. GDS Configuration to Support IBM Spectrum Scale
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#scenarios-compat-mode">
          11.8. Scenarios for Falling Back to Compatibility Mode
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-limitations-with-spectrum-scale">
          11.9. GDS Limitations with IBM Spectrum Scale
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-intro">
        12. NetApp E-series BeeGFS with GDS Solution Deployment
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-package-requirements">
          12.1. Netapp BeeGFS/GPUDirect Storage and Package Requirements
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-client-config-for-gds">
          12.2. BeeGFS Client Configuration for GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-gpu-hca-topology">
          12.3. GPU/HCA Topology on the Client - DGX-A100 and OSS servers Client Server
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-verify-setup">
          12.4. Verify the Setup
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-list-management-node">
            12.4.1. List the Management Node
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-list-metadata-nodes">
            12.4.2. List the Metadata Nodes
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-list-storage-nodes">
            12.4.3. List the Storage Nodes
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-list-client-nodes">
            12.4.4. List the Client Nodes
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-display-client-connections">
            12.4.5. Display Client Connections
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-verify-connectivity-svcs">
            12.4.6. Verify Connectivity to the Different Services
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-list-storage-pools">
            12.4.7. List Storage Pools
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-display-free-space-inodes">
            12.4.8. Display the Free Space and inodes on the Storage and Metadata Targets
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-testing">
          12.5. Testing
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-verify-integration">
            12.5.1. Verifying Integration is Working
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#beegfs-conducting-basic-fs-test">
            12.5.2. Conducting a Basic NetApp BeeGFS Filesystem Test
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#troubleshoot-set-up-vast-data">
        13. Setting Up and Troubleshooting VAST Data (NFSoRDMA+MultiPath)
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#install-mofed-vast">
          13.1. Installing MLNX_OFED and VAST NFSoRDMA+Multipath Packages
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#client-software-reqs">
            13.1.1. Client Software Requirements
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#install-vast">
            13.1.2. Install the VAST Multipath Package
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#networking-setup">
          13.2. Set Up the Networking
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#vast-network-config">
            13.2.1. VAST Network Configuration
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cllent-network-config">
            13.2.2. Client Network Configuration
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#verify-network-connect">
            13.2.3. Verify Network Connectivity
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#mount-vast-nfs">
          13.3. Mount VAST NFS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#debug-monitor">
          13.4. Debugging and Monitoring VAST Data
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#nvme-nvmeof-support">
        14. Troubleshooting and FAQ for NVMe and NVMeOF Support
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#mofed-req-install">
          14.1. MLNX_OFED Requirements and Installation
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#det-nvme-support-gds">
          14.2. Determining Whether the NVMe device is Supported for GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#det-raid-level">
          14.3. RAID Support in GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#mount-local-fs">
          14.4. Mounting a Local Filesystem for GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-exist-mount">
          14.5. Check for an Existing EXT4 Mount
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#check-io-stats-block-devmt">
          14.6. Check for IO Statistics with Block Device Mount
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#raid-group-config-gpu-aff">
          14.7. RAID Group Configuration for GPU Affinity
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#basic-ext4-fs-test">
          14.8. Conduct a Basic EXT4 Filesystem Test
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#unmount-ext4-fs">
          14.9. Unmount a EXT4 Filesystem
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#udev-name-conv-block-device">
          14.10. Udev Device Naming for a Block Device
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#batch-io-performance">
          14.11. BATCH I/O Performance
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#display-gds-driver-stats">
        15. Displaying GDS NVIDIA FS Driver Statistics
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#nvidia-fs-stats2">
          15.1. nvidia-fs Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#analyze-per-gpu-stats">
          15.2. Analyze Statistics for each GPU
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#reset-nvidia-fs-stats">
          15.3. Resetting the nvidia-fs Statistics
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#review-peer-aff-stats">
          15.4. Checking Peer Affinity Stats for a Kernel Filesystem and Storage Drivers
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#peer-affinity-usage-kernel-fs-sd">
          15.5. Checking the Peer Affinity Usage for a Kernel File System and Storage Drivers
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gpu-peer-dist-table">
          15.6. Display the GPU-to-Peer Distance Table
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gdsio-tool">
          15.7. The GDSIO Tool
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#tab-fields">
          15.8. Tabulated Fields
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gdscheck">
          15.9. The GDSCHECK Tool
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#nfs-suppport-gds">
          15.10. NFS Support with GPUDirect Storage
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#install-nfs-server-rdma-mofed_5-1">
            15.10.1. Install Linux NFS server with RDMA Support on MLNX_OFED 5.3 or Later
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#install-gds-supp-nfs-client">
            15.10.2. Install GPUDirect Storage Support for the NFS Client
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#nfs-gds-stas-debug">
          15.11. NFS GPUDirect Storage Statistics and Debugging
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-io-behavior">
          15.12. GPUDirect Storage IO Behavior
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#read-write-atomiticity-cons">
            15.12.1. Read/Write Atomicity Consistency with GPUDirect Storage Direct IO
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#write-file-in-o-append-mode">
            15.12.2. Write with File a Opened in O_APPEND Mode (cuFileWrite)
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gpu-nic-peer-aff">
            15.12.3. GPU to NIC Peer Affinity
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#comp-mode-unreg-buffers">
            15.12.4. Compatible Mode with Unregistered Buffers
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#unaligned-writes-non-reg-buff">
            15.12.5. Unaligned writes with Non-Registered Buffers
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#process-hang-nfs">
            15.12.6. Process Hang with NFS
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#tool-limit-cuda-9">
            15.12.7. Tools Support Limitations for CUDA 9 and Earlier
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dynamic-routing-stats">
          15.13. GDS Statistics for Dynamic Routing
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dynamic-routing-peer-affinity">
            15.13.1. Peer Affinity Dynamic Routing
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dynamic-routing-cufile-log">
            15.13.2. cuFile Log Related to Dynamic Routing
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-lib-tracing">
        16. GDS Library Tracing
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#display-tracepoints">
          16.1. Example: Display Tracepoints
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#tracepoint-arguments">
            16.1.1. Example: Tracepoint Arguments
           </a>
          </li>
         </ul>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#track-io-issue-cuapis">
          16.2. Example: Track the IO Activity of a Process that Issues cuFileRead/ cuFileWrite
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#disp-io-patters-through-gds">
          16.3. Example: Display the IO Pattern of all the IOs that Go Through GDS
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#io-pattern-process">
          16.4. Understand the IO Pattern of a Process
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#io-pattern-file-desc">
          16.5. IO Pattern of a Process with the File Descriptor on Different GPUs
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#iops-bandwidth-process-gpu">
          16.6. Determine the IOPS and Bandwidth for a Process in a GPU
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#freq-reads-cufileread-api">
          16.7. Display the Frequency of Reads by Processes that Issue cuFileRead
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#freq-reads-cufileread-0.1-ms">
          16.8. Display the Frequency of Reads when cuFileRead Takes More than 0.1 ms
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#disp-latency-cufileread">
          16.9. Displaying the Latency of cuFileRead for Each Process
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#track-process-cufilebufregister">
          16.10. Example: Tracking the Processes that Issue cuFileBufRegister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#proc-constant-cufilebufregister">
          16.11. Example: Tracking Whether the Process is Constant when Invoking cuFileBufRegister
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#monitor-io-bb">
          16.12. Example: Monitoring IOs that are Going Through the Bounce Buffer
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#trace-cufileread-cufilewrite-issues">
          16.13. Example: Tracing cuFileRead and cuFileWrite Failures, Print, Error Codes, and Time of Failure
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#per-process-user-stats">
          16.14. Example: User-Space Statistics for Each GDS Process
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-stats-tool">
          16.15. Example: Viewing GDS User-Level Statistics for a Process
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#sample-ul-stats-per-process">
          16.16. Example: Displaying Sample User-Level Statistics for each GDS Process
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#gds-space-counters">
        17. User-Space Counters in GPUDirect Storage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dist-io-util-gpu">
          17.1. Distribution of IO Usage in Each GPU
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#dynamic-routing-user-space-stats">
          17.2. User-space Statistics for Dynamic Routing
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#user-space-rdma-counters">
        18. User-Space RDMA Counters in GPUDirect Storage
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cufile-rdma-io-counters">
          18.1. cuFile RDMA IO Counters (PER_GPU RDMA STATS)
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cufile-rdma-mem-reg-counters">
          18.2. cuFile RDMA Memory Registration Counters (RDMA MRSTATS)
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#cheat-sheet">
        19. Cheat Sheet for Diagnosing Problems
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html">
      NVIDIA GPUDirect Storage O_DIRECT Requirements Guide
     </a>
     <ul class="Chapter-chapters">
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#intro">
        1. Introduction
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#rel-docs">
          1.1. Related Documents
         </a>
        </li>
       </ul>
      </li>
      <li>
       <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#gds-req">
        2. GPUDirect Storage Requirements
       </a>
       <ul class="Chapter-chapters">
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#summ-basic-req">
          2.1. Summary of Basic Requirements
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#client-server">
          2.2. Client and Server
         </a>
        </li>
        <li>
         <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#odirect-not-a-fit">
          2.3. Cases Where O_DIRECT is Not a Fit
         </a>
         <ul class="Chapter-chapters">
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#buffered-io">
            2.3.1. Buffered IO
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#inline-files">
            2.3.2. Inline Files
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#block-alloc-writes">
            2.3.3. Block Allocation For Writes
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#examine-transform-data">
            2.3.4. Examining or Transforming User Data
           </a>
          </li>
          <li>
           <a class="Link" data-cms-ai="0" href="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html#summary">
            2.3.5. Summary
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
     </ul>
    </li>
   </ul>
  </li>
 </ul>
 <ul class="FooterNavigation-items" data-column-count="3">
  <li class="FooterNavigation-items-item">
   <span>
    Corporate Info
   </span>
   <ul class="FooterNavigationItem-items">
    <li class="FooterNavigationItem-items-item">
     <a class="NavigationLink" data-cms-ai="0" href="https://www.nvidia.com/en-us/" target="_blank">
      <span class="NavigationLink-text">
       NVIDIA.com Home
      </span>
     </a>
    </li>
    <li class="FooterNavigationItem-items-item">
     <a class="NavigationLink" data-cms-ai="0" href="https://www.nvidia.com/en-us/about-nvidia/" target="_blank">
      <span class="NavigationLink-text">
       About NVIDIA
      </span>
     </a>
    </li>
   </ul>
  </li>
  <li class="FooterNavigation-items-item">
   <span>
    ‎NVIDIA Developer
   </span>
   <ul class="FooterNavigationItem-items">
    <li class="FooterNavigationItem-items-item">
     <a class="NavigationLink" data-cms-ai="0" href="https://developer.nvidia.com/" target="_blank">
      <span class="NavigationLink-text">
       Developer Home
      </span>
     </a>
    </li>
    <li class="FooterNavigationItem-items-item">
     <a class="NavigationLink" data-cms-ai="0" href="https://blogs.nvidia.com/" target="_blank">
      <span class="NavigationLink-text">
       Blog
      </span>
     </a>
    </li>
   </ul>
  </li>
  <li class="FooterNavigation-items-item">
   <span>
    Resources
   </span>
   <ul class="FooterNavigationItem-items">
    <li class="FooterNavigationItem-items-item">
     <a class="NavigationLink" data-cms-ai="0" href="https://www.nvidia.com/en-us/contact/" target="_blank">
      <span class="NavigationLink-text">
       Contact Us
      </span>
     </a>
    </li>
    <li class="FooterNavigationItem-items-item">
     <a class="NavigationLink" data-cms-ai="0" href="https://developer.nvidia.com/developer-program" target="_blank">
      <span class="NavigationLink-text">
       Developer Program
      </span>
     </a>
    </li>
   </ul>
  </li>
 </ul>
 <p>
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" rel="noopener" target="_blank">
   Privacy Policy
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" rel="noopener" target="_blank">
   Manage My Privacy
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/preferences/start/" rel="noopener" target="_blank">
   Do Not Sell or Share My Data
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" rel="noopener" target="_blank">
   Terms of Service
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" rel="noopener" target="_blank">
   Accessibility
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" rel="noopener" target="_blank">
   Corporate Policies
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/product-security/" rel="noopener" target="_blank">
   Product Security
  </a>
  |
  <a class="Link" data-cms-ai="0" href="https://www.nvidia.com/en-us/contact/" rel="noopener" target="_blank">
   Contact
  </a>
 </p>
 <p>
  Copyright © 2024 NVIDIA Corporation
 </p>
</body>
</body></html>