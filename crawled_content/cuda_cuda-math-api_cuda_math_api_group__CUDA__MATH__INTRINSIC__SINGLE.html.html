<html><head><title>5. Single Precision Intrinsics â CUDA Math API Reference Manual 12.5 documentation</title></head><body><body class="wy-body-for-nav">
 <a href="https://docs.nvidia.com/cuda/cuda-math-api/index.html">
 </a>
 <ul class="current">
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__FP8.html">
    1. FP8 Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__HALF.html">
    2. Half Precision Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__BFLOAT16.html">
    3. Bfloat16 Precision Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html">
    4. Single Precision Mathematical Functions
   </a>
  </li>
  <li class="toctree-l1 current">
   <a class="current reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html">
    5. Single Precision Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__DOUBLE.html">
    6. Double Precision Mathematical Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__DOUBLE.html">
    7. Double Precision Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__CAST.html">
    8. Type Casting Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INT.html">
    9. Integer Mathematical Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__INT.html">
    10. Integer Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SIMD.html">
    11. SIMD Intrinsics
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/structs.html">
    12. Structs
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/notices.html">
    13. Notices
   </a>
  </li>
 </ul>
 <a href="https://docs.nvidia.com/cuda/cuda-math-api/index.html">
  CUDA Math API Reference Manual
 </a>
 <ul class="wy-breadcrumbs">
  <li>
   <a class="icon icon-home" href="https://docs.nvidia.com/cuda/index.html">
   </a>
   Â»
  </li>
  <li>
   <span class="section-number">
    5.
   </span>
   Single Precision Intrinsics
  </li>
  <li class="wy-breadcrumbs-aside">
   <span>
    v12.5 |
   </span>
   <a class="reference external" href="https://docs.nvidia.com/cuda/pdf/CUDA_Math_API.pdf">
    PDF
   </a>
   <span>
    |
   </span>
   <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit-archive">
    Archive
   </a>
   <span>
    Â
   </span>
  </li>
 </ul>
 <h1>
  <span class="section-number">
   5.
  </span>
  Single Precision Intrinsics
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#single-precision-intrinsics" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p id="group__cuda__math__intrinsic__single">
  This section describes single precision intrinsic functions that are only supported in device code.
 </p>
 <p>
  To use these functions you do not need to include any additional header files in your program.
 </p>
 <p class="rubric-h2 rubric">
  Functions
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga129ff4afc615da9a5886c77713094c32">
  <span class="std std-ref">
   __cosf
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate cosine of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga35e0d360ac27e6eb9cf1065b847d46af">
  <span class="std std-ref">
   __exp10f
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate base 10 exponential of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga1beeb3ae544cfdde4a0a724ace025aed">
  <span class="std std-ref">
   __expf
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate base
  <span class="math notranslate nohighlight">
   \(e\)
  </span>
  exponential of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gaa8255ea2b671a8488813d9d3527e661a">
  <span class="std std-ref">
   __fadd_rd
  </span>
 </a>
 (float x, float y)
 <p>
  Add two floating-point values in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga34f8d82135041b06099d7709ff0bbe4e">
  <span class="std std-ref">
   __fadd_rn
  </span>
 </a>
 (float x, float y)
 <p>
  Add two floating-point values in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga3ba9e088a1f798c2542fe7d69736ac7e">
  <span class="std std-ref">
   __fadd_ru
  </span>
 </a>
 (float x, float y)
 <p>
  Add two floating-point values in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga8d108dee04b1aa0681fcdfb8f661dc9e">
  <span class="std std-ref">
   __fadd_rz
  </span>
 </a>
 (float x, float y)
 <p>
  Add two floating-point values in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gaa548a4045aee3b2dce24bccb26f90f82">
  <span class="std std-ref">
   __fdiv_rd
  </span>
 </a>
 (float x, float y)
 <p>
  Divide two floating-point values in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga1bd038de4c10eec819e00991fb5acf7e">
  <span class="std std-ref">
   __fdiv_rn
  </span>
 </a>
 (float x, float y)
 <p>
  Divide two floating-point values in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga8089bb061fd076bdb5b08566b4d0e0c2">
  <span class="std std-ref">
   __fdiv_ru
  </span>
 </a>
 (float x, float y)
 <p>
  Divide two floating-point values in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gab1465a09b2a88d1c2048d0b0f612fb5c">
  <span class="std std-ref">
   __fdiv_rz
  </span>
 </a>
 (float x, float y)
 <p>
  Divide two floating-point values in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gac996beec34f94f6376d0674a6860e107">
  <span class="std std-ref">
   __fdividef
  </span>
 </a>
 (float x, float y)
 <p>
  Calculate the fast approximate division of the input arguments.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga5ec4876d85bf5331ac63fa98f3fb57b4">
  <span class="std std-ref">
   __fmaf_ieee_rd
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute fused multiply-add operation in round-down mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga6535eebe86aba96a47c3ff4632640d99">
  <span class="std std-ref">
   __fmaf_ieee_rn
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute fused multiply-add operation in round-to-nearest-even mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga6c50feff625ea8d50ccf7fcfa30383eb">
  <span class="std std-ref">
   __fmaf_ieee_ru
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute fused multiply-add operation in round-up mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gac39a4b9e57049f913213edcb0d855138">
  <span class="std std-ref">
   __fmaf_ieee_rz
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute fused multiply-add operation in round-towards-zero mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga5b12d5103d17eed423f1db706a9c80be">
  <span class="std std-ref">
   __fmaf_rd
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(x \times y + z\)
  </span>
  as a single operation, in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga77b36635a8fbdc96a7e08e201d589316">
  <span class="std std-ref">
   __fmaf_rn
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(x \times y + z\)
  </span>
  as a single operation, in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gafe855a453ea92a580b79ad8a7e72bc49">
  <span class="std std-ref">
   __fmaf_ru
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(x \times y + z\)
  </span>
  as a single operation, in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga42a5f6c99064834ad50b2bfa7aa77731">
  <span class="std std-ref">
   __fmaf_rz
  </span>
 </a>
 (float x, float y, float z)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(x \times y + z\)
  </span>
  as a single operation, in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga28d56d8747ca7960860cd9c67cd3fed6">
  <span class="std std-ref">
   __fmul_rd
  </span>
 </a>
 (float x, float y)
 <p>
  Multiply two floating-point values in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga4b9d2d5cb295c1442b00e6eff5248b97">
  <span class="std std-ref">
   __fmul_rn
  </span>
 </a>
 (float x, float y)
 <p>
  Multiply two floating-point values in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gacd2f8b720306266f6e814345d4cf1b93">
  <span class="std std-ref">
   __fmul_ru
  </span>
 </a>
 (float x, float y)
 <p>
  Multiply two floating-point values in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gaff448e40e1e71eb620159a40e5e62705">
  <span class="std std-ref">
   __fmul_rz
  </span>
 </a>
 (float x, float y)
 <p>
  Multiply two floating-point values in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga4f51ca3e41e5f9369bed0bf0c5f42971">
  <span class="std std-ref">
   __frcp_rd
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\frac{1}{x}\)
  </span>
  in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gaba455801af8ac9af405a5d37ef2f077b">
  <span class="std std-ref">
   __frcp_rn
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\frac{1}{x}\)
  </span>
  in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gad5b3289e40e510c2067c8f7a426aa884">
  <span class="std std-ref">
   __frcp_ru
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\frac{1}{x}\)
  </span>
  in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga64032913321c328ae72111161af32268">
  <span class="std std-ref">
   __frcp_rz
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\frac{1}{x}\)
  </span>
  in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga71ee45580cbeeea206297f0112aff42c">
  <span class="std std-ref">
   __frsqrt_rn
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(1/\sqrt{x}\)
  </span>
  in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga59566bdd0638a5b249dbda757f2bb06b">
  <span class="std std-ref">
   __fsqrt_rd
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\sqrt{x}\)
  </span>
  in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gaf021e85b5e9de141a0fc2ff6fbe85875">
  <span class="std std-ref">
   __fsqrt_rn
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\sqrt{x}\)
  </span>
  in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gab429e39b1790b4dfae0d0c4926f53fe2">
  <span class="std std-ref">
   __fsqrt_ru
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\sqrt{x}\)
  </span>
  in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga094bf489bf492287424b1080569189f1">
  <span class="std std-ref">
   __fsqrt_rz
  </span>
 </a>
 (float x)
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \(\sqrt{x}\)
  </span>
  in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga78502e666a0e6e7690230e118403df54">
  <span class="std std-ref">
   __fsub_rd
  </span>
 </a>
 (float x, float y)
 <p>
  Subtract two floating-point values in round-down mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gae75e42e6637c178cd3c86a6e3774f7cb">
  <span class="std std-ref">
   __fsub_rn
  </span>
 </a>
 (float x, float y)
 <p>
  Subtract two floating-point values in round-to-nearest-even mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga4adc718465695ee57990318d5a650b1c">
  <span class="std std-ref">
   __fsub_ru
  </span>
 </a>
 (float x, float y)
 <p>
  Subtract two floating-point values in round-up mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gac900725c2921068c2ad4f53039b6bacf">
  <span class="std std-ref">
   __fsub_rz
  </span>
 </a>
 (float x, float y)
 <p>
  Subtract two floating-point values in round-towards-zero mode.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga2b7358a27b8231b592da81ff3143b9a8">
  <span class="std std-ref">
   __log10f
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate base 10 logarithm of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gafcc053f9040d50975aab00e44e7c6093">
  <span class="std std-ref">
   __log2f
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate base 2 logarithm of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gaed5cef656578096892f104a27d5287c4">
  <span class="std std-ref">
   __logf
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate base
  <span class="math notranslate nohighlight">
   \(e\)
  </span>
  logarithm of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga2c2b295816185f6ce2423471df529974">
  <span class="std std-ref">
   __powf
  </span>
 </a>
 (float x, float y)
 <p>
  Calculate the fast approximate of
  <span class="math notranslate nohighlight">
   \(x^y\)
  </span>
  .
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga2c84f08e0db7117a14509d21c3aec04e">
  <span class="std std-ref">
   __saturatef
  </span>
 </a>
 (float x)
 <p>
  Clamp the input argument to [+0.0, 1.0].
 </p>
 <span class="tag-as-table-cell">
  __device__ void
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga96089d6195f9befde96e14afafd931fb">
  <span class="std std-ref">
   __sincosf
  </span>
 </a>
 (float x, float *sptr, float *cptr)
 <p>
  Calculate the fast approximate of sine and cosine of the first input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gafa0ea4b2cee94521792ead0deb03addb">
  <span class="std std-ref">
   __sinf
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate sine of the input argument.
 </p>
 <span class="tag-as-table-cell">
  __device__ float
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga4fc8b7c67526a0195b9cb47287b5c121">
  <span class="std std-ref">
   __tanf
  </span>
 </a>
 (float x)
 <p>
  Calculate the fast approximate tangent of the input argument.
 </p>
 <h2>
  <span class="section-number">
   5.1.
  </span>
  Functions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#functions" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __cosf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv46__cosff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate cosine of the input argument.
 </p>
 <p>
  Calculate the fast approximate cosine of the input argument
  <span class="pre">
   x
  </span>
  , measured in radians.
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1ga20858ddd8f75a2c8332bdecd536057bf">
   <span class="std std-ref">
    cosf()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns the approximate cosine of
  <span class="pre">
   x
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __exp10f
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv48__exp10ff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate base 10 exponential of the input argument.
 </p>
 <p>
  Calculate the fast approximate base 10 exponential of the input argument
  <span class="pre">
   x
  </span>
  ,
  <span class="math notranslate nohighlight">
   \( 10^x \)
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1ga60f1de4fe78a907d915a52be29a799e7">
   <span class="std std-ref">
    exp10f()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns an approximation to
  <span class="math notranslate nohighlight">
   \( 10^x \)
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __expf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv46__expff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate base
  <span class="math notranslate nohighlight">
   \( e \)
  </span>
  exponential of the input argument.
 </p>
 <p>
  Calculate the fast approximate base
  <span class="math notranslate nohighlight">
   \( e \)
  </span>
  exponential of the input argument
  <span class="pre">
   x
  </span>
  ,
  <span class="math notranslate nohighlight">
   \( e^x \)
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1gae2d7656fe00f9e750c6f3bde8cc0dca6">
   <span class="std std-ref">
    expf()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns an approximation to
  <span class="math notranslate nohighlight">
   \( e^x \)
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fadd_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fadd_rdff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Add two floating-point values in round-down mode.
 </p>
 <p>
  Compute the sum of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  +
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fadd_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fadd_rd(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fadd_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fadd_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     -x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( -0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fadd_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fadd_rnff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Add two floating-point values in round-to-nearest-even mode.
 </p>
 <p>
  Compute the sum of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-to-nearest-even rounding mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  +
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fadd_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fadd_rn(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fadd_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fadd_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     -x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fadd_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fadd_ruff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Add two floating-point values in round-up mode.
 </p>
 <p>
  Compute the sum of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  +
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fadd_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fadd_ru(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fadd_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fadd_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     -x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fadd_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fadd_rzff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Add two floating-point values in round-towards-zero mode.
 </p>
 <p>
  Compute the sum of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  +
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fadd_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fadd_rz(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fadd_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fadd_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fadd_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     -x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fdiv_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fdiv_rdff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Divide two floating-point values in round-down mode.
 </p>
 <p>
  Divide two floating-point values
  <span class="pre">
   x
  </span>
  by
  <span class="pre">
   y
  </span>
  in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  /
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the quotient
    <span class="pre">
     x
    </span>
    /
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for
    <span class="pre">
     y
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fdiv_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fdiv_rnff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Divide two floating-point values in round-to-nearest-even mode.
 </p>
 <p>
  Divide two floating-point values
  <span class="pre">
   x
  </span>
  by
  <span class="pre">
   y
  </span>
  in round-to-nearest-even mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  /
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the quotient
    <span class="pre">
     x
    </span>
    /
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for
    <span class="pre">
     y
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fdiv_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fdiv_ruff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Divide two floating-point values in round-up mode.
 </p>
 <p>
  Divide two floating-point values
  <span class="pre">
   x
  </span>
  by
  <span class="pre">
   y
  </span>
  in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  /
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the quotient
    <span class="pre">
     x
    </span>
    /
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for
    <span class="pre">
     y
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fdiv_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fdiv_rzff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Divide two floating-point values in round-towards-zero mode.
 </p>
 <p>
  Divide two floating-point values
  <span class="pre">
   x
  </span>
  by
  <span class="pre">
   y
  </span>
  in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  /
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the quotient
    <span class="pre">
     x
    </span>
    /
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fdiv_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdiv_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for
    <span class="pre">
     y
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fdividef
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv410__fdividefff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate division of the input arguments.
 </p>
 <p>
  Calculate the fast approximate division of
  <span class="pre">
   x
  </span>
  by
  <span class="pre">
   y
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga1bd038de4c10eec819e00991fb5acf7e">
   <span class="std std-ref">
    __fdiv_rn()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  /
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fdividef(
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns NaN for
    <span class="math notranslate nohighlight">
     \( 2^{126} &lt; |y| &lt; 2^{128} \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fdividef(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns 0 for
    <span class="math notranslate nohighlight">
     \( 2^{126} &lt; |y| &lt; 2^{128} \)
    </span>
    and finite
    <span class="math notranslate nohighlight">
     \( x \)
    </span>
    .
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_ieee_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv414__fmaf_ieee_rdfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute fused multiply-add operation in round-down mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <p>
  Behavior is the same as
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga5b12d5103d17eed423f1db706a9c80be">
   <span class="std std-ref">
    __fmaf_rd
   </span>
  </a>
  (
  <span class="pre">
   x
  </span>
  ,
  <span class="pre">
   y
  </span>
  ,
  <span class="pre">
   z
  </span>
  ), the difference is in handling denormalized inputs and outputs:
  <span class="pre">
   -ftz
  </span>
  compiler flag has no effect.
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_ieee_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv414__fmaf_ieee_rnfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute fused multiply-add operation in round-to-nearest-even mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <p>
  Behavior is the same as
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga77b36635a8fbdc96a7e08e201d589316">
   <span class="std std-ref">
    __fmaf_rn
   </span>
  </a>
  (
  <span class="pre">
   x
  </span>
  ,
  <span class="pre">
   y
  </span>
  ,
  <span class="pre">
   z
  </span>
  ), the difference is in handling denormalized inputs and outputs:
  <span class="pre">
   -ftz
  </span>
  compiler flag has no effect.
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_ieee_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv414__fmaf_ieee_rufff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute fused multiply-add operation in round-up mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <p>
  Behavior is the same as
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gafe855a453ea92a580b79ad8a7e72bc49">
   <span class="std std-ref">
    __fmaf_ru
   </span>
  </a>
  (
  <span class="pre">
   x
  </span>
  ,
  <span class="pre">
   y
  </span>
  ,
  <span class="pre">
   z
  </span>
  ), the difference is in handling denormalized inputs and outputs:
  <span class="pre">
   -ftz
  </span>
  compiler flag has no effect.
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_ieee_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv414__fmaf_ieee_rzfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute fused multiply-add operation in round-towards-zero mode, ignore
  <span class="pre">
   -ftz=true
  </span>
  compiler flag.
 </p>
 <p>
  Behavior is the same as
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga42a5f6c99064834ad50b2bfa7aa77731">
   <span class="std std-ref">
    __fmaf_rz
   </span>
  </a>
  (
  <span class="pre">
   x
  </span>
  ,
  <span class="pre">
   y
  </span>
  ,
  <span class="pre">
   z
  </span>
  ), the difference is in handling denormalized inputs and outputs:
  <span class="pre">
   -ftz
  </span>
  compiler flag has no effect.
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmaf_rdfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation, in round-down mode.
 </p>
 <p>
  Computes the value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single ternary operation, rounding the result once in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns the rounded value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation.
 </p>
 <ul class="simple">
  <li>
   <p>
    __fmaf_rd(
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( -0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( -0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y + z \)
    </span>
    is exactly zero and
    <span class="math notranslate nohighlight">
     \( z \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmaf_rnfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation, in round-to-nearest-even mode.
 </p>
 <p>
  Computes the value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single ternary operation, rounding the result once in round-to-nearest-even mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns the rounded value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation.
 </p>
 <ul class="simple">
  <li>
   <p>
    __fmaf_rn(
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y + z \)
    </span>
    is exactly zero and
    <span class="math notranslate nohighlight">
     \( z \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmaf_rufff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation, in round-up mode.
 </p>
 <p>
  Computes the value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single ternary operation, rounding the result once in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns the rounded value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation.
 </p>
 <ul class="simple">
  <li>
   <p>
    __fmaf_ru(
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y + z \)
    </span>
    is exactly zero and
    <span class="math notranslate nohighlight">
     \( z \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmaf_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   z
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmaf_rzfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation, in round-towards-zero mode.
 </p>
 <p>
  Computes the value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single ternary operation, rounding the result once in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns the rounded value of
  <span class="math notranslate nohighlight">
   \( x \times y + z \)
  </span>
  as a single operation.
 </p>
 <ul class="simple">
  <li>
   <p>
    __fmaf_rz(
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm \infty \)
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmaf_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns NaN if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is an exact
    <span class="math notranslate nohighlight">
     \( -\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y \)
    </span>
    is exact
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmaf_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     z
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    if
    <span class="math notranslate nohighlight">
     \( x \times y + z \)
    </span>
    is exactly zero and
    <span class="math notranslate nohighlight">
     \( z \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmul_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmul_rdff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Multiply two floating-point values in round-down mode.
 </p>
 <p>
  Compute the product of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  *
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the product
    <span class="pre">
     x
    </span>
    *
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fmul_rd(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fmul_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmul_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmul_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmul_rnff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Multiply two floating-point values in round-to-nearest-even mode.
 </p>
 <p>
  Compute the product of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-to-nearest-even mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  *
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the product
    <span class="pre">
     x
    </span>
    *
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fmul_rn(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fmul_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmul_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmul_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmul_ruff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Multiply two floating-point values in round-up mode.
 </p>
 <p>
  Compute the product of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  *
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the product
    <span class="pre">
     x
    </span>
    *
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fmul_ru(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fmul_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmul_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fmul_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fmul_rzff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Multiply two floating-point values in round-towards-zero mode.
 </p>
 <p>
  Compute the product of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  *
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    sign of the product
    <span class="pre">
     x
    </span>
    *
    <span class="pre">
     y
    </span>
    is XOR of the signs of
    <span class="pre">
     x
    </span>
    and
    <span class="pre">
     y
    </span>
    when neither inputs nor result are NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) is equivalent to __fmul_rz(
    <span class="pre">
     y
    </span>
    ,
    <span class="pre">
     x
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    __fmul_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \infty \)
    </span>
    of appropriate sign for
    <span class="pre">
     x
    </span>
    <span class="math notranslate nohighlight">
     \( \neq 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fmul_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fmul_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( 0 \)
    </span>
    of appropriate sign for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __frcp_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__frcp_rdf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  in round-down mode.
 </p>
 <p>
  Compute the reciprocal of
  <span class="pre">
   x
  </span>
  in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __frcp_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_rd(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __frcp_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__frcp_rnf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  in round-to-nearest-even mode.
 </p>
 <p>
  Compute the reciprocal of
  <span class="pre">
   x
  </span>
  in round-to-nearest-even mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __frcp_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_rn(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __frcp_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__frcp_ruf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  in round-up mode.
 </p>
 <p>
  Compute the reciprocal of
  <span class="pre">
   x
  </span>
  in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __frcp_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_ru(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __frcp_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__frcp_rzf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  in round-towards-zero mode.
 </p>
 <p>
  Compute the reciprocal of
  <span class="pre">
   x
  </span>
  in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \frac{1}{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __frcp_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frcp_rz(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __frsqrt_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv411__frsqrt_rnf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( 1/\sqrt{x} \)
  </span>
  in round-to-nearest-even mode.
 </p>
 <p>
  Compute the reciprocal square root of
  <span class="pre">
   x
  </span>
  in round-to-nearest-even mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( 1/\sqrt{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __frsqrt_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frsqrt_rn(
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __frsqrt_rn(
    <span class="pre">
     x
    </span>
    ) returns NaN for
    <span class="pre">
     x
    </span>
    &lt; 0.
   </p>
  </li>
  <li>
   <p>
    __frsqrt_rn(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsqrt_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv410__fsqrt_rdf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  in round-down mode.
 </p>
 <p>
  Compute the square root of
  <span class="pre">
   x
  </span>
  in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsqrt_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rd(
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rd(
    <span class="pre">
     x
    </span>
    ) returns NaN for
    <span class="pre">
     x
    </span>
    &lt; 0.
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rd(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsqrt_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv410__fsqrt_rnf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  in round-to-nearest-even mode.
 </p>
 <p>
  Compute the square root of
  <span class="pre">
   x
  </span>
  in round-to-nearest-even mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsqrt_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rn(
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rn(
    <span class="pre">
     x
    </span>
    ) returns NaN for
    <span class="pre">
     x
    </span>
    &lt; 0.
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rn(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsqrt_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv410__fsqrt_ruf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  in round-up mode.
 </p>
 <p>
  Compute the square root of
  <span class="pre">
   x
  </span>
  in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsqrt_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_ru(
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_ru(
    <span class="pre">
     x
    </span>
    ) returns NaN for
    <span class="pre">
     x
    </span>
    &lt; 0.
   </p>
  </li>
  <li>
   <p>
    __fsqrt_ru(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsqrt_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv410__fsqrt_rzf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Compute
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  in round-towards-zero mode.
 </p>
 <p>
  Compute the square root of
  <span class="pre">
   x
  </span>
  in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns
  <span class="math notranslate nohighlight">
   \( \sqrt{x} \)
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsqrt_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rz(
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rz(
    <span class="pre">
     x
    </span>
    ) returns NaN for
    <span class="pre">
     x
    </span>
    &lt; 0.
   </p>
  </li>
  <li>
   <p>
    __fsqrt_rz(NaN) returns NaN.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsub_rd
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fsub_rdff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Subtract two floating-point values in round-down mode.
 </p>
 <p>
  Compute the difference of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-down (to negative infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  -
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsub_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fsub_rd(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rd(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rd(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( -0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsub_rn
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fsub_rnff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Subtract two floating-point values in round-to-nearest-even mode.
 </p>
 <p>
  Compute the difference of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-to-nearest-even rounding mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  -
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsub_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fsub_rn(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rn(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rn(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsub_ru
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fsub_ruff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Subtract two floating-point values in round-up mode.
 </p>
 <p>
  Compute the difference of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-up (to positive infinity) mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  -
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsub_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fsub_ru(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_ru(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_ru(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __fsub_rz
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__fsub_rzff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Subtract two floating-point values in round-towards-zero mode.
 </p>
 <p>
  Compute the difference of
  <span class="pre">
   x
  </span>
  and
  <span class="pre">
   y
  </span>
  in round-towards-zero mode.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This operation will never be merged into a single multiply-add instruction.
 </p>
 Returns
 <p>
  Returns
  <span class="pre">
   x
  </span>
  -
  <span class="pre">
   y
  </span>
  .
 </p>
 <ul class="simple">
  <li>
   <p>
    __fsub_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="pre">
     y
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    for finite
    <span class="pre">
     y
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ) returns NaN.
   </p>
  </li>
  <li>
   <p>
    __fsub_rz(
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp\infty \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm\infty \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rz(
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    ,
    <span class="math notranslate nohighlight">
     \( \mp 0 \)
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __fsub_rz(
    <span class="pre">
     x
    </span>
    ,
    <span class="pre">
     x
    </span>
    ) returns
    <span class="math notranslate nohighlight">
     \( +0 \)
    </span>
    for finite
    <span class="pre">
     x
    </span>
    , including
    <span class="math notranslate nohighlight">
     \( \pm 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    If either argument is NaN, NaN is returned.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __log10f
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv48__log10ff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate base 10 logarithm of the input argument.
 </p>
 <p>
  Calculate the fast approximate base 10 logarithm of the input argument
  <span class="pre">
   x
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1gab49e218cf742a0eb08e5516dd5160585">
   <span class="std std-ref">
    log10f()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns an approximation to
  <span class="math notranslate nohighlight">
   \( \log_{10}(x) \)
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __log2f
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv47__log2ff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate base 2 logarithm of the input argument.
 </p>
 <p>
  Calculate the fast approximate base 2 logarithm of the input argument
  <span class="pre">
   x
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1gafc9ae1bd4ebb4cd9533a50f1bf486f08">
   <span class="std std-ref">
    log2f()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns an approximation to
  <span class="math notranslate nohighlight">
   \( \log_2(x) \)
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __logf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv46__logff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate base
  <span class="math notranslate nohighlight">
   \( e \)
  </span>
  logarithm of the input argument.
 </p>
 <p>
  Calculate the fast approximate base
  <span class="math notranslate nohighlight">
   \( e \)
  </span>
  logarithm of the input argument
  <span class="pre">
   x
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1gacdaf041c4071f63cba0e51658b89ffa4">
   <span class="std std-ref">
    logf()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns an approximation to
  <span class="math notranslate nohighlight">
   \( \log_e(x) \)
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __powf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   y
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv46__powfff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate of
  <span class="math notranslate nohighlight">
   \( x^y \)
  </span>
  .
 </p>
 <p>
  Calculate the fast approximate of
  <span class="pre">
   x
  </span>
  , the first input argument, raised to the power of
  <span class="pre">
   y
  </span>
  , the second input argument,
  <span class="math notranslate nohighlight">
   \( x^y \)
  </span>
  .
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 Returns
 <p>
  Returns an approximation to
  <span class="math notranslate nohighlight">
   \( x^y \)
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __saturatef
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv411__saturateff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Clamp the input argument to [+0.0, 1.0].
 </p>
 <p>
  Clamp the input argument
  <span class="pre">
   x
  </span>
  to be within the interval [+0.0, 1.0].
 </p>
 Returns
 <ul class="simple">
  <li>
   <p>
    __saturatef(
    <span class="pre">
     x
    </span>
    ) returns +0 if
    <span class="math notranslate nohighlight">
     \( x \le 0 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __saturatef(
    <span class="pre">
     x
    </span>
    ) returns 1 if
    <span class="math notranslate nohighlight">
     \( x \ge 1 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __saturatef(
    <span class="pre">
     x
    </span>
    ) returns
    <span class="pre">
     x
    </span>
    if
    <span class="math notranslate nohighlight">
     \( 0 &lt; x &lt; 1 \)
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    __saturatef(NaN) returns +0.
   </p>
  </li>
 </ul>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __sincosf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   sptr
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   cptr
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv49__sincosffPfPf" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate of sine and cosine of the first input argument.
 </p>
 <p>
  Calculate the fast approximate of sine and cosine of the first input argument
  <span class="pre">
   x
  </span>
  (measured in radians). The results for sine and cosine are written into the second argument,
  <span class="pre">
   sptr
  </span>
  , and, respectively, third argument,
  <span class="pre">
   cptr
  </span>
  .
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gafa0ea4b2cee94521792ead0deb03addb">
   <span class="std std-ref">
    __sinf()
   </span>
  </a>
  and
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga129ff4afc615da9a5886c77713094c32">
   <span class="std std-ref">
    __cosf()
   </span>
  </a>
  .
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Denorm input/output is flushed to sign preserving 0.0.
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __sinf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv46__sinff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate sine of the input argument.
 </p>
 <p>
  Calculate the fast approximate sine of the input argument
  <span class="pre">
   x
  </span>
  , measured in radians.
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__SINGLE.html#group__cuda__math__single_1ga4677d53159664972c54bb697b9c1bace">
   <span class="std std-ref">
    sinf()
   </span>
  </a>
  for further special case behavior specification.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Output in the denormal range is flushed to sign preserving 0.0.
 </p>
 Returns
 <p>
  Returns the approximate sine of
  <span class="pre">
   x
  </span>
  .
 </p>
 <span class="pre">
  __device__
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    __tanf
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   float
  </span>
 </span>
 <span class="n sig-param">
  <span class="pre">
   x
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#_CPPv46__tanff" title="Permalink to this definition">
  ï
 </a>
 <p>
  Calculate the fast approximate tangent of the input argument.
 </p>
 <p>
  Calculate the fast approximate tangent of the input argument
  <span class="pre">
   x
  </span>
  , measured in radians.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For accuracy information see the CUDA C++ Programming Guide, Mathematical Functions Appendix, Intrinsic Functions section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  The result is computed as the fast divide of
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1gafa0ea4b2cee94521792ead0deb03addb">
   <span class="std std-ref">
    __sinf()
   </span>
  </a>
  by
  <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-math-api/cuda_math_api/group__CUDA__MATH__INTRINSIC__SINGLE.html#group__cuda__math__intrinsic__single_1ga129ff4afc615da9a5886c77713094c32">
   <span class="std std-ref">
    __cosf()
   </span>
  </a>
  . Denormal output is flushed to sign-preserving 0.0.
 </p>
 Returns
 <p>
  Returns the approximate tangent of
  <span class="pre">
   x
  </span>
  .
 </p>
 <p class="notices">
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
   Privacy Policy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">
   Manage My Privacy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">
   Do Not Sell or Share My Data
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
   Terms of Service
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
   Accessibility
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
   Corporate Policies
  </a>
  |
  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
   Product Security
  </a>
  |
  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
   Contact
  </a>
 </p>
 <p>
  Copyright Â© 2007-2024, NVIDIA Corporation &amp; affiliates. All rights reserved.
 </p>
 <p>
  <span class="lastupdated">
   Last updated on Jul 1, 2024.
  </span>
 </p>
</body>
</body></html>