<html><head><title>CUDA Runtime API :: CUDA Toolkit Documentation</title></head><body><body>
 <span id="company">
  NVIDIA
 </span>
 <span id="site-title">
  CUDA Toolkit Documentation
 </span>
 Search In:
 Entire Site
 Just This Document
 clear search
 search
 <a href="https://docs.nvidia.com/cuda/index.html" title="The root of the site.">
  CUDA Toolkit 
                  
                  
                  v12.5.1
 </a>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html" title="CUDA Runtime API">
  CUDA Runtime API
 </a>
 <ul>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/driver-vs-runtime-api.html#driver-vs-runtime-api">
    1.Â Difference between the driver and runtime APIs
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior">
    2.Â API synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior">
    3.Â Stream synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/graphs-thread-safety.html#graphs-thread-safety">
    4.Â Graph object thread safety
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/version-mixing-rules.html#version-mixing-rules">
    5.Â Rules for version mixing
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/modules.html#modules">
    6.Â Modules
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE">
      6.1.Â Device Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE__DEPRECATED.html#group__CUDART__DEVICE__DEPRECATED">
      6.2.Â Device Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__THREAD__DEPRECATED.html#group__CUDART__THREAD__DEPRECATED">
      6.3.Â Thread Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html#group__CUDART__ERROR">
      6.4.Â Error Handling
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM">
      6.5.Â Stream Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT">
      6.6.Â Event Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP">
      6.7.Â External Resource Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION">
      6.8.Â Execution Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html#group__CUDART__EXECUTION__DEPRECATED">
      6.9.Â Execution Control [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY">
      6.10.Â Occupancy
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY">
      6.11.Â Memory Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__DEPRECATED.html#group__CUDART__MEMORY__DEPRECATED">
      6.12.Â Memory Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS">
      6.13.Â Stream Ordered Memory Allocator
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__UNIFIED.html#group__CUDART__UNIFIED">
      6.14.Â Unified Addressing
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER">
      6.15.Â Peer Device Memory Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL.html#group__CUDART__OPENGL">
      6.16.Â OpenGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL__DEPRECATED.html#group__CUDART__OPENGL__DEPRECATED">
      6.17.Â OpenGL Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9.html#group__CUDART__D3D9">
      6.18.Â Direct3D 9 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9__DEPRECATED.html#group__CUDART__D3D9__DEPRECATED">
      6.19.Â Direct3D 9 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10.html#group__CUDART__D3D10">
      6.20.Â Direct3D 10 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10__DEPRECATED.html#group__CUDART__D3D10__DEPRECATED">
      6.21.Â Direct3D 10 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11.html#group__CUDART__D3D11">
      6.22.Â Direct3D 11 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11__DEPRECATED.html#group__CUDART__D3D11__DEPRECATED">
      6.23.Â Direct3D 11 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__VDPAU.html#group__CUDART__VDPAU">
      6.24.Â VDPAU Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EGL.html#group__CUDART__EGL">
      6.25.Â EGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__INTEROP.html#group__CUDART__INTEROP">
      6.26.Â Graphics Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TEXTURE__OBJECT.html#group__CUDART__TEXTURE__OBJECT">
      6.27.Â Texture Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__SURFACE__OBJECT.html#group__CUDART__SURFACE__OBJECT">
      6.28.Â Surface Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART____VERSION.html#group__CUDART____VERSION">
      6.29.Â Version Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">
      6.30.Â Graph Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER__ENTRY__POINT.html#group__CUDART__DRIVER__ENTRY__POINT">
      6.31.Â Driver Entry Point Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL">
      6.32.Â C++ API Routines
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER.html#group__CUDART__DRIVER">
      6.33.Â Interactions with the CUDA Driver API
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER">
      6.34.Â Profiler Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES">
      6.35.Â Data types used by CUDA Runtime
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/annotated.html#annotated">
    7.Â Data Structures
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/class____cudaOccupancyB2DHelper.html#class____cudaOccupancyB2DHelper">
      7.1.Â __cudaOccupancyB2DHelper
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html#structcudaAccessPolicyWindow">
      7.2.Â cudaAccessPolicyWindow
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements">
      7.3.Â cudaArrayMemoryRequirements
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties">
      7.4.Â cudaArraySparseProperties
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAsyncNotificationInfo__t.html#structcudaAsyncNotificationInfo__t">
      7.5.Â cudaAsyncNotificationInfo_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc">
      7.6.Â cudaChannelFormatDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChildGraphNodeParams.html#structcudaChildGraphNodeParams">
      7.7.Â cudaChildGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaConditionalNodeParams.html#structcudaConditionalNodeParams">
      7.8.Â cudaConditionalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp">
      7.9.Â cudaDeviceProp
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglFrame.html#structcudaEglFrame">
      7.10.Â cudaEglFrame
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglPlaneDesc.html#structcudaEglPlaneDesc">
      7.11.Â cudaEglPlaneDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventRecordNodeParams.html#structcudaEventRecordNodeParams">
      7.12.Â cudaEventRecordNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventWaitNodeParams.html#structcudaEventWaitNodeParams">
      7.13.Â cudaEventWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent">
      7.14.Â cudaExtent
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryBufferDesc.html#structcudaExternalMemoryBufferDesc">
      7.15.Â cudaExternalMemoryBufferDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryHandleDesc.html#structcudaExternalMemoryHandleDesc">
      7.16.Â cudaExternalMemoryHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryMipmappedArrayDesc.html#structcudaExternalMemoryMipmappedArrayDesc">
      7.17.Â cudaExternalMemoryMipmappedArrayDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreHandleDesc.html#structcudaExternalSemaphoreHandleDesc">
      7.18.Â cudaExternalSemaphoreHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParams.html#structcudaExternalSemaphoreSignalNodeParams">
      7.19.Â cudaExternalSemaphoreSignalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParamsV2.html#structcudaExternalSemaphoreSignalNodeParamsV2">
      7.20.Â cudaExternalSemaphoreSignalNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams.html#structcudaExternalSemaphoreSignalParams">
      7.21.Â cudaExternalSemaphoreSignalParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams__v1.html#structcudaExternalSemaphoreSignalParams__v1">
      7.22.Â cudaExternalSemaphoreSignalParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParams.html#structcudaExternalSemaphoreWaitNodeParams">
      7.23.Â cudaExternalSemaphoreWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParamsV2.html#structcudaExternalSemaphoreWaitNodeParamsV2">
      7.24.Â cudaExternalSemaphoreWaitNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams.html#structcudaExternalSemaphoreWaitParams">
      7.25.Â cudaExternalSemaphoreWaitParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams__v1.html#structcudaExternalSemaphoreWaitParams__v1">
      7.26.Â cudaExternalSemaphoreWaitParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaFuncAttributes.html#structcudaFuncAttributes">
      7.27.Â cudaFuncAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphEdgeData.html#structcudaGraphEdgeData">
      7.28.Â cudaGraphEdgeData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphExecUpdateResultInfo.html#structcudaGraphExecUpdateResultInfo">
      7.29.Â cudaGraphExecUpdateResultInfo
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphInstantiateParams.html#structcudaGraphInstantiateParams">
      7.30.Â cudaGraphInstantiateParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphKernelNodeUpdate.html#structcudaGraphKernelNodeUpdate">
      7.31.Â cudaGraphKernelNodeUpdate
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphNodeParams.html#structcudaGraphNodeParams">
      7.32.Â cudaGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParams.html#structcudaHostNodeParams">
      7.33.Â cudaHostNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParamsV2.html#structcudaHostNodeParamsV2">
      7.34.Â cudaHostNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t">
      7.35.Â cudaIpcEventHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t">
      7.36.Â cudaIpcMemHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParams.html#structcudaKernelNodeParams">
      7.37.Â cudaKernelNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParamsV2.html#structcudaKernelNodeParamsV2">
      7.38.Â cudaKernelNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchAttribute.html#structcudaLaunchAttribute">
      7.39.Â cudaLaunchAttribute
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/unioncudaLaunchAttributeValue.html#unioncudaLaunchAttributeValue">
      7.40.Â cudaLaunchAttributeValue
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t">
      7.41.Â cudaLaunchConfig_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchMemSyncDomainMap.html#structcudaLaunchMemSyncDomainMap">
      7.42.Â cudaLaunchMemSyncDomainMap
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchParams.html#structcudaLaunchParams">
      7.43.Â cudaLaunchParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAccessDesc.html#structcudaMemAccessDesc">
      7.44.Â cudaMemAccessDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParams.html#structcudaMemAllocNodeParams">
      7.45.Â cudaMemAllocNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParamsV2.html#structcudaMemAllocNodeParamsV2">
      7.46.Â cudaMemAllocNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms">
      7.47.Â cudaMemcpy3DParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms">
      7.48.Â cudaMemcpy3DPeerParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpyNodeParams.html#structcudaMemcpyNodeParams">
      7.49.Â cudaMemcpyNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemFreeNodeParams.html#structcudaMemFreeNodeParams">
      7.50.Â cudaMemFreeNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation">
      7.51.Â cudaMemLocation
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps">
      7.52.Â cudaMemPoolProps
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData">
      7.53.Â cudaMemPoolPtrExportData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParams.html#structcudaMemsetParams">
      7.54.Â cudaMemsetParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParamsV2.html#structcudaMemsetParamsV2">
      7.55.Â cudaMemsetParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr">
      7.56.Â cudaPitchedPtr
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPointerAttributes.html#structcudaPointerAttributes">
      7.57.Â cudaPointerAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos">
      7.58.Â cudaPos
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceDesc.html#structcudaResourceDesc">
      7.59.Â cudaResourceDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceViewDesc.html#structcudaResourceViewDesc">
      7.60.Â cudaResourceViewDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaTextureDesc.html#structcudaTextureDesc">
      7.61.Â cudaTextureDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structCUuuid__st.html#structCUuuid__st">
      7.62.Â CUuuid_st
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/functions.html#functions">
    8.Â Data Fields
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated">
    9.Â Deprecated List
   </a>
  </li>
 </ul>
 <h2>
  Search Results
 </h2>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__DEPRECATED.html" shape="rect">
  &lt; Previous
 </a>
 |
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__UNIFIED.html" shape="rect">
  Next &gt;
 </a>
 CUDA Runtime API
                  (
 <a href="https://docs.nvidia.com/cuda/pdf/CUDA_Runtime_API.pdf">
  PDF
 </a>
 )
                  -
                   
                  
                  
                  v12.5.1
                  (
 <a href="https://developer.nvidia.com/cuda-toolkit-archive">
  older
 </a>
 )
                  -
                  Last updated July 1, 2024
                  -
 <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA%20Toolkit%20Documentation%20Feedback:%20CUDA%20Runtime%20API">
  Send Feedback
 </a>
 <a name="group__CUDART__MEMORY__POOLS" shape="rect">
  <!-- -->
 </a>
 <h2 class="topictitle2 cppModule">
  6.13.Â Stream Ordered Memory Allocator
 </h2>
 <p outputclass="apiDesc_subtitle">
  overview
 </p>
 <p class="p">
  The asynchronous allocator allows the user to allocate and free in stream order. All asynchronous accesses of the allocation
                        must happen between the stream executions of the allocation and the free. If the memory is accessed outside of the promised
                        stream order, a use before allocation / use after free error will cause undefined behavior.
 </p>
 <p class="p">
  The allocator is free to reallocate the memory as long as it can guarantee that compliant memory accesses will not overlap
                        temporally. The allocator may refer to internal stream ordering as well as inter-stream dependencies (such as CUDA events
                        and null stream dependencies) when establishing the temporal guarantee. The allocator may also insert inter-stream dependencies
                        to establish the temporal guarantee.
 </p>
 <p class="p apiDesc_subtitle">
  Supported Platforms
 </p>
 <p class="p">
  Whether or not a device supports the integrated stream ordered memory allocator may be queried by calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute()
  </a>
  with the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd0876515d3b274cb0b40f8a7d913fb1aa" shape="rect">
   cudaDevAttrMemoryPoolsSupported
  </a>
  .
 </p>
 <h3 class="fake_sectiontitle member_header">
  Functions
 </h3>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect">
   cudaFreeAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hStream
  </span>
  )
 </span>
 <span class="desc">
  Frees memory with stream ordered semantics.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gbbf70065888d61853c047513baa14081" shape="rect">
   cudaMallocAsync
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hStream
  </span>
  )
 </span>
 <span class="desc">
  Allocates memory with stream ordered semantics.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect">
   cudaMallocFromPoolAsync
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  )
 </span>
 <span class="desc">
  Allocates memory from a specified pool with stream ordered semantics.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect">
   cudaMemPoolCreate
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps" shape="rect" title="">
   cudaMemPoolProps
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   poolProps
  </span>
  )
 </span>
 <span class="desc">
  Creates a memory pool.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g709113128c1c52c3bf170022dc7723dd" shape="rect">
   cudaMemPoolDestroy
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  )
 </span>
 <span class="desc">
  Destroys the specified memory pool.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" shape="rect">
   cudaMemPoolExportPointer
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData" shape="rect" title="">
   cudaMemPoolPtrExportData
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   exportData
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  )
 </span>
 <span class="desc">
  Export data to share a memory pool allocation between processes.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" shape="rect">
   cudaMemPoolExportToShareableHandle
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   shareableHandle
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gabde707dfb8a602b917e0b177f77f365" shape="rect" title="">
   cudaMemAllocationHandleType
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handleType
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Exports a memory pool to the requested handle type.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gc75ce545e1052e9b13174c2c0892778b" shape="rect">
   cudaMemPoolGetAccess
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6b0a86e7509e3c9a188cf2e809aef0be" shape="rect" title="">
   cudaMemAccessFlags
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation" shape="rect" title="">
   cudaMemLocation
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   location
  </span>
  )
 </span>
 <span class="desc">
  Returns the accessibility of a pool from a device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4ff47ef59413a4ed9d760c0841ce4a99" shape="rect">
   cudaMemPoolGetAttribute
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1geb088e985dfbf286005a684095501a03" shape="rect" title="">
   cudaMemPoolAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  )
 </span>
 <span class="desc">
  Gets attributes of a memory pool.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" shape="rect">
   cudaMemPoolImportFromShareableHandle
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   shareableHandle
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gabde707dfb8a602b917e0b177f77f365" shape="rect" title="">
   cudaMemAllocationHandleType
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handleType
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  imports a memory pool from a shared handle.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect">
   cudaMemPoolImportPointer
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData" shape="rect" title="">
   cudaMemPoolPtrExportData
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   exportData
  </span>
  )
 </span>
 <span class="desc">
  Import a memory pool allocation from another process.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" shape="rect">
   cudaMemPoolSetAccess
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAccessDesc.html#structcudaMemAccessDesc" shape="rect" title="">
   cudaMemAccessDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   descList
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 <span class="desc">
  Controls visibility of pools between devices.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g0229135f7ef724b4f479a435ca300af5" shape="rect">
   cudaMemPoolSetAttribute
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1geb088e985dfbf286005a684095501a03" shape="rect" title="">
   cudaMemPoolAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  )
 </span>
 <span class="desc">
  Sets attributes of a memory pool.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g0faf526bcfffd835aa95a4514fb2f7d5" shape="rect">
   cudaMemPoolTrimTo
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   minBytesToKeep
  </span>
  )
 </span>
 <span class="desc">
  Tries to release memory back to the OS.
 </span>
 <h3 class="sectiontitle">
  Functions
 </h3>
 <a id="group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" name="group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaFreeAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hStream
  </span>
  )
 </span>
 Frees memory with stream ordered semantics.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 <span class="keyword keyword apiItemName">
  hStream
 </span>
 - The stream establishing the stream ordering promise
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Inserts a free operation into
  hStream
  . The allocation must not be accessed after stream execution reaches the free. After this API returns, accessing the memory
                                 from any subsequent work launched on the GPU or querying its pointer attributes results in undefined behavior.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  During stream capture, this function results in the creation of a free node and must therefore be passed the address of a
                                       graph allocation.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g41acf4131f672a2a75cd93d3241f10cf" shape="rect" target="_blank">
   cuMemFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1gbbf70065888d61853c047513baa14081" name="group__CUDART__MEMORY__POOLS_1gbbf70065888d61853c047513baa14081" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocAsync (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hStream
  </span>
  )
 </span>
 Allocates memory with stream ordered semantics.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Returned device pointer
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Number of bytes to allocate
 <span class="keyword keyword apiItemName">
  hStream
 </span>
 - The stream establishing the stream ordering contract and the memory pool to allocate from
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  , cudaErrorOutOfMemory,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Inserts an allocation operation into
  hStream
  . A pointer to the allocated memory is returned immediately in *dptr. The allocation must not be accessed until the the allocation
                                 operation completes. The allocation comes from the memory pool associated with the stream's device.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    The default memory pool of a device contains device memory from that device.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Basic stream ordering allows future work submitted into the same stream to use the allocation. Stream query, stream synchronize,
                                             and CUDA events can be used to guarantee that the allocation operation completes before work submitted in a separate stream
                                             runs.
   </p>
  </li>
  <li class="li">
   <p class="p">
    During stream capture, this function results in the creation of an allocation node. In this case, the allocation is owned
                                             by the graph instead of the memory pool. The memory pool's properties are used to set the node's creation parameters.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g13413273e84a641bce1929eae9e6501f" shape="rect" target="_blank">
   cuMemAllocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" shape="rect" title="Controls visibility of pools between devices.">
   cudaMemPoolSetAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g0229135f7ef724b4f479a435ca300af5" shape="rect" title="Sets attributes of a memory pool.">
   cudaMemPoolSetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4ff47ef59413a4ed9d760c0841ce4a99" shape="rect" title="Gets attributes of a memory pool.">
   cudaMemPoolGetAttribute
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" name="group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocFromPoolAsync (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  )
 </span>
 Allocates memory from a specified pool with stream ordered semantics.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  ptr
 </span>
 - Returned device pointer
 <span class="keyword keyword apiItemName">
  size
 </span>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 - The pool to allocate from
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - The stream establishing the stream ordering semantic
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  , cudaErrorOutOfMemory
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Inserts an allocation operation into
  hStream
  . A pointer to the allocated memory is returned immediately in *dptr. The allocation must not be accessed until the the allocation
                                 operation completes. The allocation comes from the specified memory pool.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    The specified memory pool may be from a device different than that of the specified
    hStream
    .
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Basic stream ordering allows future work submitted into the same stream to use the allocation. Stream query, stream synchronize,
                                          and CUDA events can be used to guarantee that the allocation operation completes before work submitted in a separate stream
                                          runs.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  During stream capture, this function results in the creation of an allocation node. In this case, the allocation is owned
                                       by the graph instead of the memory pool. The memory pool's properties are used to set the node's creation parameters.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1gf1dd6e1e2e8f767a5e0ea63f38ff260b" shape="rect" target="_blank">
   cuMemAllocFromPoolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect" title="Creates a memory pool.">
   cudaMemPoolCreate
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" shape="rect" title="Controls visibility of pools between devices.">
   cudaMemPoolSetAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g0229135f7ef724b4f479a435ca300af5" shape="rect" title="Sets attributes of a memory pool.">
   cudaMemPoolSetAttribute
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" name="group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolCreate (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps" shape="rect" title="">
   cudaMemPoolProps
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   poolProps
  </span>
  )
 </span>
 Creates a memory pool.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Creates a CUDA memory pool and returns the handle in
  pool
  . The
  poolProps
  determines the properties of the pool such as the backing device and IPC capabilities.
 </p>
 <p class="p">
  To create a memory pool targeting a specific host NUMA node, applications must set cudaMemPoolProps::cudaMemLocation::type
                                 to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
   cudaMemLocationTypeHostNuma
  </a>
  and cudaMemPoolProps::cudaMemLocation::id must specify the NUMA ID of the host memory node. By default, the pool's memory
                                 will be accessible from the device it is allocated on. In the case of pools created with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
   cudaMemLocationTypeHostNuma
  </a>
  , their default accessibility will be from the host CPU. Applications can control the maximum size of the pool by specifying
                                 a non-zero value for
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps_12d90e82afb8d577a2aee847d082e145d" shape="rect">
   cudaMemPoolProps::maxSize
  </a>
  . If set to 0, the maximum size of the pool will default to a system dependent value.
 </p>
 <p class="p">
  Applications can set
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps_14cf896bffe71384e374c4d2decca9a53" shape="rect">
   cudaMemPoolProps::handleTypes
  </a>
  to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggabde707dfb8a602b917e0b177f77f3655a7fe2446df5bfa18e5ffbb84b3eba5d" shape="rect">
   cudaMemHandleTypeFabric
  </a>
  in order to create
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect">
   cudaMemPool_t
  </a>
  suitable for sharing within an IMEX domain. An IMEX domain is either an OS instance or a group of securely connected OS instances
                                 using the NVIDIA IMEX daemon. An IMEX channel is a global resource within the IMEX domain that represents a logical entity
                                 that aims to provide fine grained accessibility control for the participating processes. When exporter and importer CUDA processes
                                 have been granted access to the same IMEX channel, they can securely share memory. If the allocating process does not have
                                 access setup for an IMEX channel, attempting to export a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1g3b96b1ef79f0cb312b51169e9f50e722" shape="rect" target="_blank">
   CUmemoryPool
  </a>
  with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggabde707dfb8a602b917e0b177f77f3655a7fe2446df5bfa18e5ffbb84b3eba5d" shape="rect">
   cudaMemHandleTypeFabric
  </a>
  will result in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  . The nvidia-modprobe CLI provides more information regarding setting up of IMEX channels.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Specifying cudaMemHandleTypeNone creates a memory pool that will not support IPC.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g8aa4c143dbc20293659cd883232b95f2" shape="rect" target="_blank">
   cuMemPoolCreate
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" shape="rect" title="Exports a memory pool to the requested handle type.">
   cudaMemPoolExportToShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g709113128c1c52c3bf170022dc7723dd" name="group__CUDART__MEMORY__POOLS_1g709113128c1c52c3bf170022dc7723dd" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolDestroy (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  )
 </span>
 Destroys the specified memory pool.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  If any pointers obtained from this pool haven't been freed or the pool has free operations that haven't completed when
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g709113128c1c52c3bf170022dc7723dd" shape="rect" title="Destroys the specified memory pool.">
   cudaMemPoolDestroy
  </a>
  is invoked, the function will return immediately and the resources associated with the pool will be released automatically
                                 once there are no more outstanding allocations.
 </p>
 <p class="p">
  Destroying the current mempool of a device sets the default mempool of that device as the current mempool for that device.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  A device's default memory pool cannot be destroyed.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1ge0e211115e5ad1c79250b9dd425b77f7" shape="rect" target="_blank">
   cuMemPoolDestroy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect" title="Creates a memory pool.">
   cudaMemPoolCreate
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" name="group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolExportPointer (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData" shape="rect" title="">
   cudaMemPoolPtrExportData
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   exportData
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  )
 </span>
 Export data to share a memory pool allocation between processes.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  exportData
 </span>
 <span class="keyword keyword apiItemName">
  ptr
 </span>
 - pointer to memory being exported
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  , cudaErrorOutOfMemory
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Constructs
  shareData_out
  for sharing a specific allocation from an already shared memory pool. The recipient process can import the allocation with
                                 the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect" title="Import a memory pool allocation from another process.">
   cudaMemPoolImportPointer
  </a>
  api. The data is not a handle and may be shared through any IPC mechanism.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1gfe89f0478d26edaa91eb8a2e0349329d" shape="rect" target="_blank">
   cuMemPoolExportPointer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" shape="rect" title="Exports a memory pool to the requested handle type.">
   cudaMemPoolExportToShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" shape="rect" title="imports a memory pool from a shared handle.">
   cudaMemPoolImportFromShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect" title="Import a memory pool allocation from another process.">
   cudaMemPoolImportPointer
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" name="group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolExportToShareableHandle (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   shareableHandle
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gabde707dfb8a602b917e0b177f77f365" shape="rect" title="">
   cudaMemAllocationHandleType
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handleType
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Exports a memory pool to the requested handle type.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  shareableHandle
 </span>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 <span class="keyword keyword apiItemName">
  handleType
 </span>
 - the type of handle to create
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - must be 0
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  , cudaErrorOutOfMemory
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Given an IPC capable mempool, create an OS handle to share the pool with another process. A recipient process can convert
                                 the shareable handle into a mempool with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" shape="rect" title="imports a memory pool from a shared handle.">
   cudaMemPoolImportFromShareableHandle
  </a>
  . Individual pointers can then be shared with the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" shape="rect" title="Export data to share a memory pool allocation between processes.">
   cudaMemPoolExportPointer
  </a>
  and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect" title="Import a memory pool allocation from another process.">
   cudaMemPoolImportPointer
  </a>
  APIs. The implementation of what the shareable handle is and how it can be transferred is defined by the requested handle
                                 type.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  : To create an IPC capable mempool, create a mempool with a CUmemAllocationHandleType other than cudaMemHandleTypeNone.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g79ed285fdfffb76932871fb96fbba8f8" shape="rect" target="_blank">
   cuMemPoolExportToShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" shape="rect" title="imports a memory pool from a shared handle.">
   cudaMemPoolImportFromShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" shape="rect" title="Export data to share a memory pool allocation between processes.">
   cudaMemPoolExportPointer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect" title="Import a memory pool allocation from another process.">
   cudaMemPoolImportPointer
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1gc75ce545e1052e9b13174c2c0892778b" name="group__CUDART__MEMORY__POOLS_1gc75ce545e1052e9b13174c2c0892778b" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolGetAccess (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6b0a86e7509e3c9a188cf2e809aef0be" shape="rect" title="">
   cudaMemAccessFlags
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation" shape="rect" title="">
   cudaMemLocation
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   location
  </span>
  )
 </span>
 Returns the accessibility of a pool from a device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - the accessibility of the pool from the specified location
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 - the pool being queried
 <span class="keyword keyword apiItemName">
  location
 </span>
 - the location accessing the pool
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns the accessibility of the pool's memory from the specified location.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g838f28fd535a1cbd06c5f7fe0edbdcc7" shape="rect" target="_blank">
   cuMemPoolGetAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" shape="rect" title="Controls visibility of pools between devices.">
   cudaMemPoolSetAccess
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g4ff47ef59413a4ed9d760c0841ce4a99" name="group__CUDART__MEMORY__POOLS_1g4ff47ef59413a4ed9d760c0841ce4a99" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolGetAttribute (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1geb088e985dfbf286005a684095501a03" shape="rect" title="">
   cudaMemPoolAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  )
 </span>
 Gets attributes of a memory pool.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 <span class="keyword keyword apiItemName">
  attr
 </span>
 - The attribute to get
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Retrieved value
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03e0451f4d34d8f3c418882b3ba5259f37" shape="rect">
     cudaMemPoolAttrReleaseThreshold
    </a>
    : (value type = cuuint64_t) Amount of reserved memory in bytes to hold onto before trying to release memory back to the OS.
                                          When more than the release threshold bytes of memory are held by the memory pool, the allocator will try to release memory
                                          back to the OS on the next call to stream, event or context synchronize. (default 0)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03d75287b5752ea45a3d98b9a339f797ce" shape="rect">
     cudaMemPoolReuseFollowEventDependencies
    </a>
    : (value type = int) Allow
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
     cudaMallocAsync
    </a>
    to use memory asynchronously freed in another stream as long as a stream ordering dependency of the allocating stream on
                                          the free action exists. Cuda events and null stream interactions can create the required stream ordered dependencies. (default
                                          enabled)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03858390d544051a61033a05e1a4005d01" shape="rect">
     cudaMemPoolReuseAllowOpportunistic
    </a>
    : (value type = int) Allow reuse of already completed frees when there is no dependency between the free and allocation. (default
                                          enabled)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a031a545a7d23c103583900e784360f9d2a" shape="rect">
     cudaMemPoolReuseAllowInternalDependencies
    </a>
    : (value type = int) Allow
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
     cudaMallocAsync
    </a>
    to insert new stream dependencies in order to establish the stream ordering required to reuse a piece of memory released
                                          by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
     cudaFreeAsync
    </a>
    (default enabled).
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03accd25158875da327b34d1ee63847b02" shape="rect">
     cudaMemPoolAttrReservedMemCurrent
    </a>
    : (value type = cuuint64_t) Amount of backing memory currently allocated for the mempool.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a035cd74d683873f75a8b4bd27b7511d9fc" shape="rect">
     cudaMemPoolAttrReservedMemHigh
    </a>
    : (value type = cuuint64_t) High watermark of backing memory allocated for the mempool since the last time it was reset.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03627447991490641c9fcacbfe7b54c5a4" shape="rect">
     cudaMemPoolAttrUsedMemCurrent
    </a>
    : (value type = cuuint64_t) Amount of memory from the pool that is currently in use by the application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03eb9b02506f4844de4ea40f01538bc85c" shape="rect">
     cudaMemPoolAttrUsedMemHigh
    </a>
    : (value type = cuuint64_t) High watermark of the amount of memory from the pool that was in use by the application since
                                          the last time it was reset.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Note that as specified by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
   cudaStreamAddCallback
  </a>
  no CUDA function may be called from callback.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  may, but is not guaranteed to, be returned as a diagnostic in such case.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1gd45ea7c43e4a1add4b971d06fa72eda4" shape="rect" target="_blank">
   cuMemPoolGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect" title="Creates a memory pool.">
   cudaMemPoolCreate
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" name="group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolImportFromShareableHandle (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   shareableHandle
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gabde707dfb8a602b917e0b177f77f365" shape="rect" title="">
   cudaMemAllocationHandleType
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   handleType
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 imports a memory pool from a shared handle.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 <span class="keyword keyword apiItemName">
  shareableHandle
 </span>
 <span class="keyword keyword apiItemName">
  handleType
 </span>
 - The type of handle being imported
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - must be 0
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  , cudaErrorOutOfMemory
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Specific allocations can be imported from the imported pool with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect" title="Import a memory pool allocation from another process.">
   cudaMemPoolImportPointer
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Imported memory pools do not support creating new allocations. As such imported memory pools may not be used in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g02bb50d2e2af83e5f24d0b2ab9dadc82" shape="rect" title="Sets the current memory pool of a device.">
   cudaDeviceSetMemPool
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
  calls.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g02b4f18dd8a1c45b7f302800e90cec5b" shape="rect" target="_blank">
   cuMemPoolImportFromShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" shape="rect" title="Exports a memory pool to the requested handle type.">
   cudaMemPoolExportToShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" shape="rect" title="Export data to share a memory pool allocation between processes.">
   cudaMemPoolExportPointer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect" title="Import a memory pool allocation from another process.">
   cudaMemPoolImportPointer
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" name="group__CUDART__MEMORY__POOLS_1g07d753c8bb9b8b789b975777ff83d574" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolImportPointer (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData" shape="rect" title="">
   cudaMemPoolPtrExportData
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   exportData
  </span>
  )
 </span>
 Import a memory pool allocation from another process.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a0eed720f8a87cd1c5fd1c453bc7a03d" shape="rect" target="_blank">
   CUDA_SUCCESS
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e990696c86fcee1f536a1ec7d25867feeb" shape="rect" target="_blank">
   CUDA_ERROR_INVALID_VALUE
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e98feb999f0af99b4a25ab26b3866f4df8" shape="rect" target="_blank">
   CUDA_ERROR_NOT_INITIALIZED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9264c50688ed110e8476b591befe60c02" shape="rect" target="_blank">
   CUDA_ERROR_OUT_OF_MEMORY
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  ptr_out
  a pointer to the imported memory. The imported memory must not be accessed before the allocation operation completes in the
                                 exporting process. The imported memory must be freed from all importing processes before being freed in the exporting process.
                                 The pointer may be freed with cudaFree or cudaFreeAsync. If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  is used, the free must be completed on the importing process before the free operation on the exporting process.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  api may be used in the exporting process before the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  operation completes in its stream as long as the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  in the exporting process specifies a stream with a stream dependency on the importing process's
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  .
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g2620bb972ed5edcce312d3689454acbd" shape="rect" target="_blank">
   cuMemPoolImportPointer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gd2d30535ebd78b44957ff76f3f3ea8dd" shape="rect" title="Exports a memory pool to the requested handle type.">
   cudaMemPoolExportToShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g29c5389e957a281969fac357fc852c8e" shape="rect" title="imports a memory pool from a shared handle.">
   cudaMemPoolImportFromShareableHandle
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gb2f607ca635363ea7d1ecbf61b725168" shape="rect" title="Export data to share a memory pool allocation between processes.">
   cudaMemPoolExportPointer
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" name="group__CUDART__MEMORY__POOLS_1g4210da54ee5a810945da586e00cb3019" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolSetAccess (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAccessDesc.html#structcudaMemAccessDesc" shape="rect" title="">
   cudaMemAccessDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   descList
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 Controls visibility of pools between devices.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 <span class="keyword keyword apiItemName">
  descList
 </span>
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Number of descriptors in the map array.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1gff3ce33e252443f4b087b94e42913406" shape="rect" target="_blank">
   cuMemPoolSetAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gc75ce545e1052e9b13174c2c0892778b" shape="rect" title="Returns the accessibility of a pool from a device.">
   cudaMemPoolGetAccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g0229135f7ef724b4f479a435ca300af5" name="group__CUDART__MEMORY__POOLS_1g0229135f7ef724b4f479a435ca300af5" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolSetAttribute (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1geb088e985dfbf286005a684095501a03" shape="rect" title="">
   cudaMemPoolAttr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attr
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  )
 </span>
 Sets attributes of a memory pool.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 <span class="keyword keyword apiItemName">
  attr
 </span>
 - The attribute to modify
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Pointer to the value to assign
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03e0451f4d34d8f3c418882b3ba5259f37" shape="rect">
     cudaMemPoolAttrReleaseThreshold
    </a>
    : (value type = cuuint64_t) Amount of reserved memory in bytes to hold onto before trying to release memory back to the OS.
                                          When more than the release threshold bytes of memory are held by the memory pool, the allocator will try to release memory
                                          back to the OS on the next call to stream, event or context synchronize. (default 0)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03d75287b5752ea45a3d98b9a339f797ce" shape="rect">
     cudaMemPoolReuseFollowEventDependencies
    </a>
    : (value type = int) Allow
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
     cudaMallocAsync
    </a>
    to use memory asynchronously freed in another stream as long as a stream ordering dependency of the allocating stream on
                                          the free action exists. Cuda events and null stream interactions can create the required stream ordered dependencies. (default
                                          enabled)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03858390d544051a61033a05e1a4005d01" shape="rect">
     cudaMemPoolReuseAllowOpportunistic
    </a>
    : (value type = int) Allow reuse of already completed frees when there is no dependency between the free and allocation. (default
                                          enabled)
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a031a545a7d23c103583900e784360f9d2a" shape="rect">
     cudaMemPoolReuseAllowInternalDependencies
    </a>
    : (value type = int) Allow
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
     cudaMallocAsync
    </a>
    to insert new stream dependencies in order to establish the stream ordering required to reuse a piece of memory released
                                          by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
     cudaFreeAsync
    </a>
    (default enabled).
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a035cd74d683873f75a8b4bd27b7511d9fc" shape="rect">
     cudaMemPoolAttrReservedMemHigh
    </a>
    : (value type = cuuint64_t) Reset the high watermark that tracks the amount of backing memory that was allocated for the memory
                                          pool. It is illegal to set this attribute to a non-zero value.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggeb088e985dfbf286005a684095501a03eb9b02506f4844de4ea40f01538bc85c" shape="rect">
     cudaMemPoolAttrUsedMemHigh
    </a>
    : (value type = cuuint64_t) Reset the high watermark that tracks the amount of used memory that was allocated for the memory
                                          pool. It is illegal to set this attribute to a non-zero value.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Note that as specified by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
   cudaStreamAddCallback
  </a>
  no CUDA function may be called from callback.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  may, but is not guaranteed to, be returned as a diagnostic in such case.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g223e786cb217709235a06e41bccaec00" shape="rect" target="_blank">
   cuMemPoolSetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect" title="Creates a memory pool.">
   cudaMemPoolCreate
  </a>
 </p>
 <a id="group__CUDART__MEMORY__POOLS_1g0faf526bcfffd835aa95a4514fb2f7d5" name="group__CUDART__MEMORY__POOLS_1g0faf526bcfffd835aa95a4514fb2f7d5" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPoolTrimTo (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gd7121b19b2347b777c07223c6ff4cdad" shape="rect" title="">
   cudaMemPool_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memPool
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   minBytesToKeep
  </span>
  )
 </span>
 Tries to release memory back to the OS.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memPool
 </span>
 <span class="keyword keyword apiItemName">
  minBytesToKeep
 </span>
 - If the pool has less than minBytesToKeep reserved, the TrimTo operation is a no-op. Otherwise the pool will be guaranteed
                                    to have at least minBytesToKeep bytes reserved after the operation.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Releases memory back to the OS until the pool contains fewer than minBytesToKeep reserved bytes, or there is no more memory
                                 that the allocator can safely release. The allocator cannot release OS allocations that back outstanding asynchronous allocations.
                                 The OS allocations may happen at different granularity from the user allocations.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    : Allocations that have not been freed count as outstanding.
   </p>
  </li>
  <li class="li">
   <p class="p">
    : Allocations that have been asynchronously freed but whose completion has not been observed on the host (eg. by a synchronize)
                                             can count as outstanding.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Note that as specified by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
   cudaStreamAddCallback
  </a>
  no CUDA function may be called from callback.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
   cudaErrorNotPermitted
  </a>
  may, but is not guaranteed to, be returned as a diagnostic in such case.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g9c7e267e3460945b0ca76c48314bb669" shape="rect" target="_blank">
   cuMemPoolTrimTo
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69aee77b793f13fa79c5bc0b566845b7" shape="rect" title="Returns the default mempool of a device.">
   cudaDeviceGetDefaultMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g9001cd1b2301101e81508f4b7714c97e" shape="rect" title="Gets the current mempool for a device.">
   cudaDeviceGetMemPool
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g8158cc4b2c0d2c2c771f9d1af3cf386e" shape="rect" title="Creates a memory pool.">
   cudaMemPoolCreate
  </a>
 </p>
 <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
  Privacy Policy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
  Manage My Privacy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
  Do Not Sell or Share My Data
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
  Terms of Service
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
  Accessibility
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
  Corporate Policies
 </a>
 |
 <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
  Product Security
 </a>
 |
 <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
  Contact
 </a>
 Copyright Â© 2007-2024 NVIDIA Corporation
</body>
</body></html>