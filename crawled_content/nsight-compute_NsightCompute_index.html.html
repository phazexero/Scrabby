<html><head><title>3. Nsight Compute — NsightCompute 12.5 documentation</title></head><body><body class="wy-body-for-nav">
 <a href="https://docs.nvidia.com/nsight-compute/index.html">
 </a>
 <p class="caption" role="heading">
  <span class="caption-text">
   Nsight Compute
  </span>
 </p>
 <ul class="current">
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/ReleaseNotes/index.html">
    1. Release Notes
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html">
    2. Kernel Profiling Guide
   </a>
  </li>
  <li class="toctree-l1 current">
   <a class="current reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html">
    3. Nsight Compute
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#introduction">
      3.1. Introduction
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#overview">
        3.1.1. Overview
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quickstart">
      3.2. Quickstart
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#interactive-profile-activity">
        3.2.1. Interactive Profile Activity
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#non-interactive-profile-activity">
        3.2.2. Non-Interactive Profile Activity
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#system-trace-activity">
        3.2.3. System Trace Activity
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#navigate-the-report">
        3.2.4. Navigate the Report
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
      3.3. Connection Dialog
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#remote-connections">
        3.3.1. Remote Connections
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-interactive">
        3.3.2. Interactive Profile Activity
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profile-activity">
        3.3.3. Profile Activity
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#reset">
        3.3.4. Reset
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#main-menu-and-toolbar">
      3.4. Main Menu and Toolbar
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id3">
        3.4.1. Main Menu
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#main-toolbar">
        3.4.2. Main Toolbar
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#status-banners">
        3.4.3. Status Banners
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-windows">
      3.5. Tool Windows
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#api-statistics">
        3.5.1. API Statistics
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#api-stream">
        3.5.2. API Stream
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines">
        3.5.3. Baselines
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metric-details">
        3.5.4. Metric Details
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#launch-details">
        3.5.5. Launch Details
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#header">
          Header
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#body">
          Body
         </a>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#nvtx">
        3.5.6. NVTX
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#cpu-call-stack">
        3.5.7. CPU Call Stack
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#resources">
        3.5.8. Resources
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#memory-allocations">
          Memory Allocations
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#graphviz-dot-and-svg-exports">
          Graphviz DOT and SVG exports
         </a>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metric-selection">
        3.5.9. Metric Selection
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report">
      3.6. Profiler Report
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-header">
        3.6.1. Header
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#report-pages">
        3.6.2. Report Pages
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#summary-page">
          Summary Page
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#details-page">
          Details Page
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-page">
          Source Page
         </a>
         <ul>
          <li class="toctree-l5">
           <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#navigation">
            Navigation
           </a>
          </li>
          <li class="toctree-l5">
           <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metrics">
            Metrics
           </a>
          </li>
          <li class="toctree-l5">
           <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiles">
            Profiles
           </a>
          </li>
          <li class="toctree-l5">
           <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#limitations">
            Limitations
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#context-page">
          Context Page
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#comments-page">
          Comments Page
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#raw-page">
          Raw Page
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#session-page">
          Session Page
         </a>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metrics-and-units">
        3.6.3. Metrics and Units
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id8">
      3.7. Baselines
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#standalone-source-viewer">
      3.8. Standalone Source Viewer
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-comparison">
      3.9. Source Comparison
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator">
      3.10. Occupancy Calculator
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tables">
        3.10.1. Tables
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#graphs">
        3.10.2. Graphs
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#gpu-data">
        3.10.3. GPU Data
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#acceleration-structure-viewer">
      3.11. Acceleration Structure Viewer
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#as-viewer-nav">
        3.11.1. Navigation
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#filtering-and-highlighting">
        3.11.2. Filtering and Highlighting
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#rendering-options">
        3.11.3. Rendering Options
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#exporting">
        3.11.4. Exporting
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options">
      3.12. Options
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profile">
        3.12.1. Profile
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#environment">
        3.12.2. Environment
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection">
        3.12.3. Connection
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#target-connection-properties">
          Target Connection Properties
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#host-connection-properties">
          Host Connection Properties
         </a>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-lookup">
        3.12.4. Source Lookup
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#send-feedback">
        3.12.5. Send Feedback
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects">
      3.13. Projects
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#project-dialogs">
        3.13.1. Project Dialogs
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#project-explorer">
        3.13.2. Project Explorer
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#visual-profiler-transition-guide">
      3.14. Visual Profiler Transition Guide
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#trace">
        3.14.1. Trace
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#sessions">
        3.14.2. Sessions
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#timeline">
        3.14.3. Timeline
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#analysis">
        3.14.4. Analysis
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#command-line-arguments">
        3.14.5. Command Line Arguments
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#visual-studio-integration-guide">
      3.15. Visual Studio Integration Guide
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#visual-studio-integration-overview">
        3.15.1. Visual Studio Integration Overview
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html">
    4. Nsight Compute CLI
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Developer Interfaces
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/CustomizationGuide/index.html">
    1. Customization Guide
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/NvRulesAPI/index.html">
    2. NvRules API
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Training
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/Training/index.html">
    Training
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Release Information
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/Archives/index.html">
    Archives
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Copyright and Licenses
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-compute/CopyrightAndLicenses/index.html">
    Copyright and Licenses
   </a>
  </li>
 </ul>
 <a href="https://docs.nvidia.com/nsight-compute/index.html">
  NsightCompute
 </a>
 <ul class="wy-breadcrumbs">
  <li>
   <a class="icon icon-home" href="https://docs.nvidia.com/nsight-compute/index.html">
   </a>
   »
  </li>
  <li>
   <span class="section-number">
    3.
   </span>
   Nsight Compute
  </li>
  <li class="wy-breadcrumbs-aside">
   <span>
    v2024.2.1 |
   </span>
   <a class="reference external" href="https://developer.nvidia.com/nsight-compute-history">
    Archive
   </a>
  </li>
 </ul>
 <h1>
  <span class="section-number">
   3.
  </span>
  Nsight Compute
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#nsight-compute" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  The User Guide for Nsight Compute.
 </p>
 <h2>
  <span class="section-number">
   3.1.
  </span>
  Introduction
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#introduction" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  For users migrating from Visual Profiler to NVIDIA Nsight Compute, please see the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#nvvp-guide">
   Visual Profiler Transition Guide
  </a>
  for comparison of features and workflows.
 </p>
 <h3>
  <span class="section-number">
   3.1.1.
  </span>
  Overview
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#overview" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p id="about-nsight-compute">
  This document is a user guide to the next-generation NVIDIA Nsight Compute profiling tools. NVIDIA Nsight Compute is an interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool. In addition, its baseline feature allows users to compare results within the tool. NVIDIA Nsight Compute provides a customizable and data-driven user interface and metric collection and can be extended with analysis scripts for post-processing results.
 </p>
 <p>
  Important Features
 </p>
 <ul class="simple">
  <li>
   <p>
    Interactive kernel profiler and API debugger
   </p>
  </li>
  <li>
   <p>
    Graphical profile report
   </p>
  </li>
  <li>
   <p>
    Result comparison across one or multiple reports within the tool
   </p>
  </li>
  <li>
   <p>
    Fast Data Collection
   </p>
  </li>
  <li>
   <p>
    UI and Command Line interface
   </p>
  </li>
  <li>
   <p>
    Fully customizable reports and analysis rules
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.2.
  </span>
  Quickstart
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quickstart" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The following sections provide brief step-by-step guides of how to setup and run NVIDIA Nsight Compute to collect profile information. All directories are relative to the base directory of NVIDIA Nsight Compute, unless specified otherwise.
 </p>
 <p>
  The UI executable is called ncu-ui. A shortcut with this name is located in the base directory of the NVIDIA Nsight Compute installation. The actual executable is located in the folder
  <span class="pre">
   host\windows-desktop-win7-x64
  </span>
  on Windows or
  <span class="pre">
   host/linux-desktop-glibc_2_11_3-x64
  </span>
  on Linux. By default, when installing from a Linux
  <span class="pre">
   .run
  </span>
  file, NVIDIA Nsight Compute is located in
  <span class="pre">
   /usr/local/cuda-&lt;cuda-version&gt;/nsight-compute-&lt;version&gt;
  </span>
  . When installing from a
  <span class="pre">
   .deb
  </span>
  or
  <span class="pre">
   .rpm
  </span>
  package, it is located in
  <span class="pre">
   /opt/nvidia/nsight-compute/&lt;version&gt;
  </span>
  to be consistent with
  <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
   Nsight Systems
  </a>
  . In Windows, the default path is
  <span class="pre">
   C:\Program
  </span>
  <span class="pre">
   Files\NVIDIA
  </span>
  <span class="pre">
   Corporation\Nsight
  </span>
  <span class="pre">
   Compute
  </span>
  <span class="pre">
   &lt;version&gt;
  </span>
  .
 </p>
 <p>
  After starting NVIDIA Nsight Compute, by default the
  Welcome Page
  is opened. The
  Start
  section allows the user to start a new activity, open an existing report, create a new project or load an existing project. The
  Continue
  section provides links to recently opened reports and projects. The
  Explore
  section provides information about what is new in the latest release, as well as links to additional training. See
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-environment">
   Environment
  </a>
  on how to change the start-up action.
 </p>
 <p>
  <span class="caption-text">
   Welcome Page
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quick-start-fig-welcome-page" title="Permalink to this image">
   ï
  </a>
 </p>
 <h3>
  <span class="section-number">
   3.2.1.
  </span>
  Interactive Profile Activity
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#interactive-profile-activity" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Launch the target application from NVIDIA Nsight Compute
   </p>
   <p>
    When starting NVIDIA Nsight Compute, the
    Welcome Page
    will appear. Click on
    Quick Launch
    to open the
    Connection
    dialog. If the
    Connection
    dialog doesnât appear, you can open it using the
    Connect
    button from the main toolbar, as long as you are not currently connected. Select your target platform on the left-hand side and your connection target (machine) from the
    Connection
    drop down. If you have your local target platform selected,
    <span class="pre">
     localhost
    </span>
    will become available as a connection. Use the + button to add a new connection target. Then, continue by filling in the details in the
    Launch
    tab. In the
    Activity
    panel, select the Interactive Profile activity to initiate a session that allows controlling the execution of the target application and selecting the kernels of interest interactively. Press
    Launch
    to start the session.
   </p>
  </li>
  <li>
   <p>
    Launch the target application with tools instrumentation from the command line
   </p>
   <p>
    The ncu can act as a simple wrapper that forces the target application to load the necessary libraries for tools instrumentation. The parameter
    <span class="pre">
     --mode=launch
    </span>
    specifies that the target application should be launched and suspended before the first instrumented API call. That way the application waits until we connect with the UI.
   </p>
   <pre>$ ncu --mode=launch CuVectorAddDrv.exe
</pre>
  </li>
  <li>
   <p>
    Launch NVIDIA Nsight Compute and connect to target application
   </p>
   <p>
    Select the target machine at the top of the dialog to connect and update the list of attachable applications. By default,
    localhost
    is pre-selected if the target matches your current local platform. Select the
    Attach
    tab and the target application of interest and press
    Attach
    . Once connected, the layout of NVIDIA Nsight Compute changes into stepping mode that allows you to control the execution of any calls into the instrumented API. When connected, the
    API Stream
    window indicates that the target application waits before the very first API call.
   </p>
  </li>
  <li>
   <p>
    Control application execution
   </p>
   <p>
    Use the
    API Stream
    window to step the calls into the instrumented API. The dropdown at the top allows switching between different CPU threads of the application.
    Step In
    (F11),
    Step Over
    (F10), and
    Step Out
    (Shift + F11) are available from the
    Debug
    menu or the corresponding toolbar buttons. While stepping, function return values and function parameters are captured.
   </p>
   <p>
    Use
    Resume
    (F5) and
    Pause
    to allow the program to run freely. Freeze control is available to define the behavior of threads currently not in focus, i.e. selected in the thread drop down. By default, the
    API Stream
    stops on any API call that returns an error code. This can be toggled in the
    Debug
    menu by
    Break On API Error
    .
   </p>
  </li>
  <li>
   <p>
    Isolate a kernel launch
   </p>
   <p>
    To quickly isolate a kernel launch for profiling, use the
    Run to Next Kernel
    button in the toolbar of the
    API Stream
    window to jump to the next kernel launch. The execution will stop before the kernel launch is executed.
   </p>
  </li>
  <li>
   <p>
    Profile a kernel launch
   </p>
   <p>
    Once the execution of the target application is suspended at a kernel launch, additional actions become available in the UI. These actions are either available from the menu or from the toolbar. Please note that the actions are disabled, if the API stream is not at a qualifying state (not at a kernel launch or launching on an unsupported GPU). To profile, press
    Profile Kernel
    and wait until the result is shown in the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report">
     Profiler Report
    </a>
    . Profiling progress is reported in the lower right corner status bar.
   </p>
   <p>
    Instead of manually selecting
    Profile
    , it is also possible to enable
    Auto Profile
    from the
    Profile
    menu. If enabled, each kernel matching the current kernel filter (if any) will be profiled using the current section configuration. This is especially useful if an application is to be profiled unattended, or the number of kernel launches to be profiled is very large. Sections can be enabled or disabled using the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-sections-info">
     Metric Selection
    </a>
    tool window.
   </p>
   <p>
    Profile Series
    allows to configure the collection of a set of profile results at once. Each result in the set is profiled with varying parameters. Series are useful to investigate the behavior of a kernel across a large set of parameters without the need to recompile and rerun the application many times.
   </p>
  </li>
 </ol>
 <p>
  For a detailed description of the options available in this activity, see
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-interactive">
   Interactive Profile Activity
  </a>
  .
 </p>
 <h3>
  <span class="section-number">
   3.2.2.
  </span>
  Non-Interactive Profile Activity
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#non-interactive-profile-activity" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Launch the target application from NVIDIA Nsight Compute
   </p>
   <p>
    When starting NVIDIA Nsight Compute, the
    Welcome Page
    will appear. Click on
    Quick Launch
    to open the
    Connection
    dialog. If the
    Connection
    dialog doesnât appear, you can open it using the
    Connect
    button from the main toolbar, as long as you are not currently connected. Select your target platform on the left-hand side and your localhost from the
    Connection
    drop down. Then, fill in the launch details. In the
    Activity
    panel, select the
    Profile
    activity to initiate a session that pre-configures the profile session and launches the command line profiler to collect the data. Provide the
    Output File
    name to enable starting the session with the
    Launch
    button.
   </p>
  </li>
  <li>
   <p>
    Additional Launch Options
   </p>
   <p>
    For more details on these options, see
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#command-line-options">
     Command Line Options
    </a>
    . The options are grouped into tabs: The
    Filter
    tab exposes the options to specify which kernels should be profiled. Options include the kernel regex filter, the number of launches to skip, and the total number of launches to profile. The
    Sections
    tab allows you to select which sections should be collected for each kernel launch. Hover over a section to see its description as a tool-tip. To change the sections that are enabled by default, use the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-sections-info">
     Metric Selection
    </a>
    tool window. The
    Sampling
    tab allows you to configure sampling options for each kernel launch. The
    Other
    tab includes the option to collect NVTX information or custom metrics via the
    <span class="pre">
     --metrics
    </span>
    option.
   </p>
  </li>
 </ol>
 <p>
  For a detailed description of the options available in this activity, see
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-non-interactive">
   Profile Activity
  </a>
  .
 </p>
 <h3>
  <span class="section-number">
   3.2.3.
  </span>
  System Trace Activity
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#system-trace-activity" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Launch the target application from NVIDIA Nsight Compute
   </p>
   <p>
    When starting NVIDIA Nsight Compute, the
    Welcome Page
    will appear. Click on
    Quick Launch
    to open the
    Connection
    dialog. If the
    Connection
    dialog doesnât appear, you can open it using the
    Connect
    button from the main toolbar, as long as you are not currently connected. Select your local target platform on the left-hand side and your localhost from the
    Connection
    drop down. Then, fill in the launch details. In the
    Activity
    panel, select the
    System Trace
    activity to initiate a session with pre-configured settings. Press
    Launch
    to start the session.
   </p>
  </li>
  <li>
   <p>
    Additional Launch Options
   </p>
   <p>
    For more details on these options, see
    <a class="reference external" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html#linux-system-wide-profiling-options">
     System-Wide Profiling Options
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    Once the session is completed, the
    <a class="reference external" href="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">
     Nsight Systems
    </a>
    report is opened in a new document. By default, the timeline view is shown. It provides detailed information of the activity of the CPU and GPUs and helps understanding the overall behavior and performance of application. Once a CUDA kernel is identified to be on the critical path and not meeting the performance expectations, right click on the kernel launch on timeline and select
    Profile Kernel
    from the context menu. A new
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
     Connection Dialog
    </a>
    opens up that is already preconfigured to profile the selected kernel launch. Proceed with optimizing the selected kernel using
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quick-start-non-interactive">
     Non-Interactive Profile Activity
    </a>
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.2.4.
  </span>
  Navigate the Report
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#navigate-the-report" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Navigate the report
   </p>
   <p>
    The profile report comes up by default on the
    Summary
    page. It shows an overview table to summarize all results in the report. It also shows rule information for the selected row.
   </p>
   <p>
    You can switch between different
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages">
     Report Pages
    </a>
    using the tab bar on the top-left of the report.
You can also use
    Ctrl + Shift + N
    and
    Ctrl + Shift + P
    shortcut keys or corresponding toolbar button to navigate next and previous pages, respectively.
A report can contain any number of results. The
    Current
    dropdown allows switching between the different results in a report.
   </p>
  </li>
  <li>
   <p>
    Diffing multiple results
   </p>
   <p>
    On the
    Details
    page, use the
    Compare - Add Baseline
    button for the current result to become the baseline all other results from this report and any other report opened in the same instance of NVIDIA Nsight Compute get compared to.
When a baseline is set, every element on the Details page shows two values: The current value of the result in focus and the corresponding value of the baseline or the percentage of change from the corresponding baseline value.
   </p>
   <p>
    Use the
    Clear Baselines
    entry from the same group button, the Profile menu or the corresponding toolbar button to remove all baselines. For more information see
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines">
     Baselines
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    Following rules
   </p>
   <p>
    On the
    Details
    page, many sections provide rules with valuable information on detected problems and optimization suggestions.
Rules can be user-defined too. For more information, see the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/CustomizationGuide/index.html#rule-system">
     Customization Guide
    </a>
    .
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.3.
  </span>
  Connection Dialog
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Use the
  Connection Dialog
  to launch and attach to applications on your local and remote platforms. Start by selecting the
  Target Platform
  for profiling. By default (and if supported) your local platform will be selected. Select the platform on which you would like to start the target application or connect to a running process.
 </p>
 <p>
  When using a remote platform, you will be asked to select or create a
  Connection
  in the top drop down. To create a new connection, select
  +
  and enter your connection details. When using the local platform,
  localhost
  will be selected as the default and no further connection settings are required. You can still create or select a remote connection, if profiling will be on a remote system of the same platform.
 </p>
 <p>
  Depending on your target platform, select either
  Launch
  or
  Remote Launch
  to launch an application for profiling on the target. Note that
  Remote Launch
  will only be available if supported on the target platform.
 </p>
 <p>
  Fill in the following launch details for the application:
 </p>
 <ul class="simple">
  <li>
   <p>
    Application Executable:
    Specifies the root application to launch. Note that this may not be the final application that you wish to profile. It can be a script or launcher that creates other processes.
   </p>
  </li>
  <li>
   <p>
    Working Directory:
    The directory in which the application will be launched.
   </p>
  </li>
  <li>
   <p>
    Command Line Arguments:
    Specify the arguments to pass to the application executable.
   </p>
  </li>
  <li>
   <p>
    Environment:
    The environment variables to set for the launched application.
   </p>
  </li>
 </ul>
 <p>
  Select
  Attach
  to attach the profiler to an application already running on the target platform. This application must have been started using another NVIDIA Nsight Compute CLI instance. The list will show all application processes running on the target system which can be attached. Select the refresh button to re-create this list.
 </p>
 <p>
  Finally, select the
  Activity
  to be run on the target for the launched or attached application. Note that not all activities are necessarily compatible with all targets and connection options. Currently, the following activities exist:
 </p>
 <ul class="simple">
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-interactive">
     Interactive Profile Activity
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-non-interactive">
     Profile Activity
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quick-start-system-trace">
     System Trace Activity
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator">
     Occupancy Calculator
    </a>
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.1.
  </span>
  Remote Connections
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#remote-connections" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Remote devices that support SSH can also be configured as a target in the
  Connection Dialog
  . To configure a remote device, ensure an SSH-capable
  Target Platform
  is selected, then press the
  +
  button. The following configuration dialog will be presented.
 </p>
 <p>
  NVIDIA Nsight Compute supports both password and private key authentication methods. In this dialog, select the authentication method and enter the following information:
 </p>
 <ul>
  <li>
   <p>
    Password
   </p>
   <ul class="simple">
    <li>
     <p>
      IP/Host Name:
      The IP address or host name of the target device.
     </p>
    </li>
    <li>
     <p>
      User Name:
      The user name to be used for the SSH connection.
     </p>
    </li>
    <li>
     <p>
      Password:
      The user password to be used for the SSH connection.
     </p>
    </li>
    <li>
     <p>
      Port:
      The port to be used for the SSH connection. (The default value is 22)
     </p>
    </li>
    <li>
     <p>
      Deployment Directory:
      The directory to use on the target device to deploy supporting files. The specified user must have write permissions to this location.
     </p>
    </li>
    <li>
     <p>
      Connection Name:
      The name of the remote connection that will show up in the
      Connection Dialog
      . If not set, it will default to &lt;User&gt;@&lt;Host&gt;:&lt;Port&gt;.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Private Key
   </p>
   <ul class="simple">
    <li>
     <p>
      IP/Host Name:
      The IP address or host name of the target device.
     </p>
    </li>
    <li>
     <p>
      User Name:
      The user name to be used for the SSH connection.
     </p>
    </li>
    <li>
     <p>
      SSH Private Key:
      The private key that is used to authenticate to SSH server.
     </p>
    </li>
    <li>
     <p>
      SSH Key Passphrase:
      The passphrase for your private key.
     </p>
    </li>
    <li>
     <p>
      Port:
      The port to be used for the SSH connection. (The default value is 22)
     </p>
    </li>
    <li>
     <p>
      Deployment Directory:
      The directory to use on the target device to deploy supporting files. The specified user must have write permissions to this location.
     </p>
    </li>
    <li>
     <p>
      Connection Name:
      The name of the remote connection that will show up in the
      Connection Dialog
      . If not set, it will default to &lt;User&gt;@&lt;Host&gt;:&lt;Port&gt;.
     </p>
    </li>
   </ul>
  </li>
 </ul>
 <p>
  In addition to keyfiles specified by path and plain password authentication, NVIDIA Nsight Compute supports keyboard-interactive authentication, standard keyfile path searching and SSH agents.
 </p>
 <p>
  When all information is entered, click the
  Add
  button to make use of this new connection.
 </p>
 <p>
  When a remote connection is selected in the
  Connection Dialog
  , the
  Application Executable
  file browser will browse the remote file system using the configured SSH connection, allowing the user to select the target application on the remote device.
 </p>
 <p>
  When an activity is launched on a remote device, the following steps are taken:
 </p>
 <ol class="arabic simple">
  <li>
   <p>
    The command line profiler and supporting files are copied into the
    Deployment Directory
    on the the remote device. (Only files that do not exist or are out of date are copied.)
   </p>
  </li>
  <li>
   <p>
    Communication channels are opened to prepare for the traffic between the UI and the
    Application Executable
    .
   </p>
   <ul class="simple">
    <li>
     <p>
      For
      Interactive Profile
      activities, a
      SOCKS proxy
      is started on the host machine.
     </p>
    </li>
    <li>
     <p>
      For
      Non-Interactive Profile
      activities, a remote forwarding channel is opened on the target machine to tunnel profiling information back to the host.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    The
    Application Executable
    is executed on the remote device.
   </p>
   <ul class="simple">
    <li>
     <p>
      For
      Interactive Profile
      activities, a connection is established to the remote application and the profiling session begins.
     </p>
    </li>
    <li>
     <p>
      For
      Non-Interactive Profile
      activities, the remote application is executed under the command line profiler and the specified report file is generated.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    For non-interactive profiling activities, the generated report file is copied back to the host, and opened.
   </p>
  </li>
 </ol>
 <p>
  The progress of each of these steps is presented in the
  Progress Log
  .
 </p>
 <p>
  <span class="caption-text">
   Progress Log
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#progress-log" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Note that once either activity type has been launched remotely, the tools necessary for further profiling sessions can be found in the
  Deployment Directory
  on the remote device.
 </p>
 <p>
  On Linux and Mac host platforms, NVIDIA Nsight Compute supports SSH remote profiling on target machines which are not directly addressable from the machine the UI is running on through the
  <span class="pre">
   ProxyJump
  </span>
  and
  <span class="pre">
   ProxyCommand
  </span>
  SSH options.
 </p>
 <p>
  These options can be used to specify intermediate hosts to connect to or actual commands to run to obtain a socket connected to the SSH server on the target host and can be added to your SSH configuration file.
 </p>
 <p>
  Note that for both options, NVIDIA Nsight Compute runs external commands and does not implement any mechanism to authenticate to the intermediate hosts using the credentials entered in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
   Connection Dialog
  </a>
  . These credentials will only be used to authenticate to the final target in the chain of machines.
 </p>
 <p>
  When using the
  <span class="pre">
   ProxyJump
  </span>
  option NVIDIA Nsight Compute uses the
  OpenSSH client
  to establish the connection to the intermediate hosts. This means that in order to use
  <span class="pre">
   ProxyJump
  </span>
  or
  <span class="pre">
   ProxyCommand
  </span>
  , a version of OpenSSH supporting these options must be installed on the host machine.
 </p>
 <p>
  A common way to authenticate to the intermediate hosts in this case is to use a
  SSH agent
  and have it hold the private keys used for authentication.
 </p>
 <p>
  Since the
  OpenSSH SSH client
  is used, you can also use the
  SSH askpass
  mechanism to handle these authentications in an interactive manner.
 </p>
 <p>
  It might happen on slow networks that connections used for remote profiling through SSH time out. If this is the case, the
  <span class="pre">
   ConnectTimeout
  </span>
  option can be used to set the desired timeout value.
 </p>
 <p>
  A known limitation of the remote profiling through SSH is that problems may arise if NVIDIA Nsight Compute tries to do remote profiling through
  SSH
  by connecting to the same machine it is running on. In this case, the workaround is to do local profiling through
  <span class="pre">
   localhost
  </span>
  .
 </p>
 <p>
  For more information about available options for the
  OpenSSH client
  and the ecosystem of tools it can be used with for authentication refer to the official
  <a class="reference external" href="https://www.openssh.com/manual.html">
   manual pages
  </a>
  .
 </p>
 <h3>
  <span class="section-number">
   3.3.2.
  </span>
  Interactive Profile Activity
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-interactive" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Interactive Profile
  activity allows you to initiate a session that controls the execution of the target application, similar to a debugger. You can step API calls and workloads (CUDA kernels), pause and resume, and interactively select the kernels of interest and which metrics to collect.
 </p>
 <p>
  This activity does currently not support profiling or attaching to child processes.
 </p>
 <ul>
  <li>
   <p>
    Enable CPU Call Stack
   </p>
   <p>
    Collect the CPU-sided Call Stack at the location of each profiled kernel launch.
   </p>
  </li>
  <li>
   <p>
    CPU Call Stack Types
   </p>
   <p>
    If âEnable CPU Call Stackâ is set to âYesâ, the type(s) of call stack may be selected here.
   </p>
  </li>
  <li>
   <p>
    Enable NVTX Support
   </p>
   <p>
    Collect NVTX information provided by the application or its libraries. Required to support stepping to specific NVTX contexts.
   </p>
  </li>
  <li>
   <p>
    Disable Profiling Start/Stop
   </p>
   <p>
    Ignore calls to
    <span class="pre">
     cu(da)ProfilerStart
    </span>
    or
    <span class="pre">
     cu(da)ProfilerStop
    </span>
    made by the application.
   </p>
  </li>
  <li>
   <p>
    Enable Profiling From Start
   </p>
   <p>
    Enables profiling from the application start. Disabling this is useful if the application calls
    <span class="pre">
     cu(da)ProfilerStart
    </span>
    and kernels before the first call to this API should not be profiled. Note that disabling this does not prevent you from manually profiling kernels.
   </p>
  </li>
  <li>
   <p>
    Cache Control
   </p>
   <p>
    Control the behavior of the GPU caches during profiling. Allowed values: For
    Flush All
    , all GPU caches are flushed before each kernel replay iteration during profiling. While metric values in the execution environment of the application might be slightly different without invalidating the caches, this mode offers the most reproducible metric results across the replay passes and also across multiple runs of the target application.
   </p>
   <p>
    For
    Flush None
    , no GPU caches are flushed during profiling. This can improve performance and better replicates the application behavior if only a single kernel replay pass is necessary for metric collection. However, some metric results will vary depending on prior GPU work, and between replay iterations. This can lead to inconsistent and out-of-bounds metric values.
   </p>
  </li>
  <li>
   <p>
    Clock Control
   </p>
   <p>
    Control the behavior of the GPU clocks during profiling. Allowed values: For
    Base
    , GPC and memory clocks are locked to their respective base frequency during profiling. This has no impact on thermal throttling. For
    None
    , no GPC or memory frequencies are changed during profiling.
   </p>
  </li>
  <li>
   <p>
    Import Source
   </p>
   <p>
    Enables permanently importing available source files into the report. Missing source files are searched in
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-source-lookup">
     Source Lookup
    </a>
    folders. Source information must be embedded in the executable, e.g. via the
    <span class="pre">
     -lineinfo
    </span>
    compiler option. Imported files are used in the
    CUDA-C
    view on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page">
     Source Page
    </a>
    .
   </p>
  </li>
 </ul>
 <ul>
  <li>
   <p>
    Graph Profiling
   </p>
   <p>
    Set if CUDA graphs should be stepped and profiled as individual
    Nodes
    or as complete
    Graphs
    . See the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#graph-profiling">
     Kernel Profiling Guide
    </a>
    for more information on this mode.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.3.
  </span>
  Profile Activity
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profile-activity" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Profile
  activity provides a traditional, pre-configurable profiler. After configuring which kernels to profile, which metrics to collect, etc, the application is run under the profiler without interactive control. The activity completes once the application terminates. For applications that normally do not terminate on their own, e.g. interactive user interfaces, you can cancel the activity once all expected kernels are profiled.
 </p>
 <p>
  This activity does not support attaching to processes previously launched via NVIDIA Nsight Compute. These processes will be shown grayed out in the
  Attach
  tab.
 </p>
 <ul>
  <li>
   <p>
    Output File
   </p>
   <p>
    Path to report file where the collected profile should be stored. If not present, the report extension
    <span class="pre">
     .ncu-rep
    </span>
    is added automatically. The placeholder
    <span class="pre">
     %i
    </span>
    is supported for the filename component. It is replaced by a sequentially increasing number to create a unique filename. This maps to the
    <span class="pre">
     --export
    </span>
    command line option.
   </p>
  </li>
  <li>
   <p>
    Force Overwrite
   </p>
   <p>
    If set, existing report file are overwritten. This maps to the
    <span class="pre">
     --force-overwrite
    </span>
    command line option.
   </p>
  </li>
  <li>
   <p>
    Target Processes
   </p>
   <p>
    Select the processes you want to profile. In mode
    Application Only
    , only the root application process is profiled. In mode
    all
    , the root application process and all its child processes are profiled. This maps to the
    <span class="pre">
     --target-processes
    </span>
    command line option.
   </p>
  </li>
  <li>
   <p>
    Replay Mode
   </p>
   <p>
    Select the method for replaying kernel launches multiple times. In mode
    Kernel
    , individual kernel launches are replayed transparently during the single execution of the target application. In mode
    Application
    , the entire target application is relaunched multiple times. In each iteration, additional data for the target kernel launches is collected. Application replay requires the program execution to be deterministic. This maps to the
    <span class="pre">
     --replay-mode
    </span>
    command line option. See the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#kernel-replay">
     Kernel Profiling Guide
    </a>
    for more details on the replay modes.
   </p>
  </li>
 </ul>
 <ul>
  <li>
   <p>
    Graph Profiling
   </p>
   <p>
    Set if CUDA graphs should be profiled as individual
    Nodes
    or as complete
    Graphs
    .
   </p>
  </li>
 </ul>
 <ul>
  <li>
   <p>
    Additional Options
   </p>
   <p>
    All remaining options map to their command line profiler equivalents. See the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#command-line-options">
     Command Line Options
    </a>
    for details.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.4.
  </span>
  Reset
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#reset" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Entries in the connection dialog are saved as part of the current
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects">
   project
  </a>
  . When working in a custom project, simply close the project to reset the dialog.
 </p>
 <p>
  When not working in a custom project, entries are stored as part of the
  default project
  . You can delete all information from the default project by closing NVIDIA Nsight Compute and then
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects">
   deleting the project file from disk
  </a>
  .
 </p>
 <h2>
  <span class="section-number">
   3.4.
  </span>
  Main Menu and Toolbar
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#main-menu-and-toolbar" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Information on the main menu and toolbar.
 </p>
 <h3>
  <span class="section-number">
   3.4.1.
  </span>
  Main Menu
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id3" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ul>
  <li>
   <p>
    File
   </p>
   <ul>
    <li>
     <p>
      New Project
      Create new profiling
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects">
       Projects
      </a>
      with the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects-dialog">
       New Project Dialog
      </a>
      .
     </p>
    </li>
    <li>
     <p>
      Open Project
      Open an existing profiling project.
     </p>
    </li>
    <li>
     <p>
      Recent Projects
      Open an existing profiling project from the list of recently used projects.
     </p>
    </li>
    <li>
     <p>
      Save Project
      Save the current profiling project.
     </p>
    </li>
    <li>
     <p>
      Save Project As
      Save the current profiling project with a new filename.
     </p>
    </li>
    <li>
     <p>
      Close Project
      Close the current profiling project.
     </p>
    </li>
    <li>
     <p>
      New File
      Create a new file.
     </p>
    </li>
    <li>
     <p>
      Open File
      Open an existing file.
     </p>
    </li>
    <li>
     <p>
      Open Remote File
     </p>
     <p>
      Download an existing file from a remote host and open it locally. The opened file will only exist in memory and will not be written to the local machineâs disk unless the user explicitly saves it. For more information concerning the selection of a remote host to download the file from, see the section about
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#remote-connections">
       Remote Connections
      </a>
      .
     </p>
     <p>
      Only a subset of file types that are supported locally can be opened from a remote target. The following table lists file types that can be opened remotely.
     </p>
     <table class="table-no-stripes docutils align-default" id="id11">
      <span class="caption-text">
       Remote File Type Support
      </span>
      <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id11" title="Permalink to this table">
       ï
      </a>
      <tr class="row-odd">
       <th class="head">
        <p>
         Extensions
        </p>
       </th>
       <th class="head">
        <p>
         Description
        </p>
       </th>
       <th class="head">
        <p>
         Supported
        </p>
       </th>
      </tr>
      <tr class="row-even">
       <td>
        <p>
         ncu-rep
        </p>
       </td>
       <td>
        <p>
         Nsight Compute Profiler Report
        </p>
       </td>
       <td>
        <p>
         Yes
        </p>
       </td>
      </tr>
      <tr class="row-odd">
       <td>
        <p>
         ncu-occ
        </p>
       </td>
       <td>
        <p>
         Occupancy Calculator File
        </p>
       </td>
       <td>
        <p>
         Yes
        </p>
       </td>
      </tr>
      <tr class="row-even">
       <td>
        <p>
         ncu-bvh
        </p>
       </td>
       <td>
        <p>
         OptiX AS Viewer File
        </p>
       </td>
       <td>
        <p>
         Yes (except on MacOSX)
        </p>
       </td>
      </tr>
      <tr class="row-odd">
       <td>
        <p>
         section
        </p>
       </td>
       <td>
        <p>
         Section Description
        </p>
       </td>
       <td>
        <p>
         No
        </p>
       </td>
      </tr>
      <tr class="row-even">
       <td>
        <p>
         cubin
        </p>
       </td>
       <td>
        <p>
         Cubin File
        </p>
       </td>
       <td>
        <p>
         No
        </p>
       </td>
      </tr>
      <tr class="row-odd">
       <td>
        <p>
         cuh,h,hpp
        </p>
       </td>
       <td>
        <p>
         Header File
        </p>
       </td>
       <td>
        <p>
         No
        </p>
       </td>
      </tr>
      <tr class="row-even">
       <td>
        <p>
         c,cpp,cu
        </p>
       </td>
       <td>
        <p>
         Source File
        </p>
       </td>
       <td>
        <p>
         No
        </p>
       </td>
      </tr>
      <tr class="row-odd">
       <td>
        <p>
         txt
        </p>
       </td>
       <td>
        <p>
         Text file
        </p>
       </td>
       <td>
        <p>
         No
        </p>
       </td>
      </tr>
      <tr class="row-even">
       <td>
        <p>
         nsight-cuprof-report
        </p>
       </td>
       <td>
        <p>
         Nsight Compute Profiler Report (legacy)
        </p>
       </td>
       <td>
        <p>
         Yes
        </p>
       </td>
      </tr>
     </table>
    </li>
    <li>
     <p>
      Save
      Save the current file
     </p>
    </li>
    <li>
     <p>
      Save As
      Save a copy of the current file with a different name or type or in a different location.
     </p>
    </li>
    <li>
     <p>
      Save All Files
      Save all open files.
     </p>
    </li>
    <li>
     <p>
      Close
      Close the current file.
     </p>
    </li>
    <li>
     <p>
      Close All Files
      Close all open files.
     </p>
    </li>
    <li>
     <p>
      Recent Files
      Open an existing file from the list of recently used files.
     </p>
    </li>
    <li>
     <p>
      Exit
      Exit Nsight Compute.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Connection
   </p>
   <ul class="simple">
    <li>
     <p>
      Connect
      Open the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
       Connection Dialog
      </a>
      to launch or attach to a target application. Disabled when already connected.
     </p>
    </li>
    <li>
     <p>
      Disconnect
      Disconnect from the current target application, allows the application to continue normally and potentially re-attach.
     </p>
    </li>
    <li>
     <p>
      Terminate
      Disconnect from and terminate the current target application immediately.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Debug
   </p>
   <ul>
    <li>
     <p>
      Pause
      Pause the target application at the next intercepted API call or launch.
     </p>
    </li>
    <li>
     <p>
      Resume
      Resume the target application.
     </p>
    </li>
    <li>
     <p>
      Step In
      Step into the current API call or launch to the next nested call, if any, or the subsequent API call, otherwise.
     </p>
    </li>
    <li>
     <p>
      Step Over
      Step over the current API call or launch and suspend at the next, non-nested API call or launch.
     </p>
    </li>
    <li>
     <p>
      Step Out
      Step out of the current nested API call or launch to the next, non-parent API call or launch one level above.
     </p>
    </li>
    <li>
     <p>
      Freeze API
     </p>
     <p>
      When disabled, all CPU threads are enabled and continue to run during stepping or resume, and all threads stop as soon as at least one thread arrives at the next API call or launch. This also means that during stepping or resume the currently selected thread might change as the old selected thread makes no forward progress and the API Stream automatically switches to the thread with a new API call or launch. When enabled, only the currently selected CPU thread is enabled. All other threads are disabled and blocked.
     </p>
     <p>
      Stepping now completes if the current thread arrives at the next API call or launch. The selected thread never changes. However, if the selected thread does not call any further API calls or waits at a barrier for another thread to make progress, stepping may not complete and hang indefinitely. In this case, pause, select another thread, and continue stepping until the original thread is unblocked. In this mode, only the selected thread will ever make forward progress.
     </p>
    </li>
    <li>
     <p>
      Break On API Error
      When enabled, during resume or stepping, execution is suspended as soon as an API call returns an error code.
     </p>
    </li>
    <li>
     <p>
      Run to Next Kernel
      See
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
       API Stream
      </a>
      tool window.
     </p>
    </li>
    <li>
     <p>
      Run to Next API Call
      See
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
       API Stream
      </a>
      tool window.
     </p>
    </li>
    <li>
     <p>
      Run to Next Range Start
      See
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
       API Stream
      </a>
      tool window.
     </p>
    </li>
    <li>
     <p>
      Run to Next Range End
      See
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
       API Stream
      </a>
      tool window.
     </p>
    </li>
    <li>
     <p>
      API Statistics
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-statistics">
       API Statistics
      </a>
      tool window
     </p>
    </li>
    <li>
     <p>
      API Stream
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
       API Stream
      </a>
      tool window
     </p>
    </li>
    <li>
     <p>
      Resources
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-resources">
       Resources
      </a>
      tool window
     </p>
    </li>
    <li>
     <p>
      NVTX
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-nvtx">
       NVTX
      </a>
      tool window
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Profile
   </p>
   <ul class="simple">
    <li>
     <p>
      Profile Kernel
      When suspended at a kernel launch, select the profile using the current configuration.
     </p>
    </li>
    <li>
     <p>
      Profile Series
      When suspended at a kernel launch, open the Profile Series configuration dialog to setup and collect a series of profile results.
     </p>
    </li>
    <li>
     <p>
      Auto Profile
      Enable or disable auto profiling. If enabled, each kernel matching the current kernel filter (if any) will be profiled using the current section configuration.
     </p>
    </li>
    <li>
     <p>
      Baselines
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-baselines">
       Baselines
      </a>
      tool window.
     </p>
    </li>
    <li>
     <p>
      Clear Baselines
      Clear all current baselines.
     </p>
    </li>
    <li>
     <p>
      Import Source
      Permanently import resolved source files into the report. Existing content may be overwritten.
     </p>
    </li>
    <li>
     <p>
      Section/Rules Info
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-sections-info">
       Metric Selection
      </a>
      tool window.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Tools
   </p>
   <ul class="simple">
    <li>
     <p>
      Project Explorer
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects-explorer">
       Project Explorer
      </a>
      tool window.
     </p>
    </li>
    <li>
     <p>
      Output Messages
      Opens the Output Messages tool window.
     </p>
    </li>
    <li>
     <p>
      Options
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options">
       Options
      </a>
      dialog.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Window
   </p>
   <ul class="simple">
    <li>
     <p>
      Save Window Layout
      Allows you to specify a name for the current layout. The layouts are saved to a Layouts folder in the documents directory as named â.nvlayoutâ files.
     </p>
    </li>
    <li>
     <p>
      Apply Window Layout
      Once you have saved a layout, you can restore them by using the âApply Window Layoutâ menu entry. Simply select the entry from sub-menu you want to apply.
     </p>
    </li>
    <li>
     <p>
      Manage Window Layout
      Allows you to delete or rename old layouts.
     </p>
    </li>
    <li>
     <p>
      Restore Default Layout
      Restore views to their original size and position.
     </p>
    </li>
    <li>
     <p>
      Show Welcome Page
      Opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quick-start__fig-welcome-page">
       Welcome Page
      </a>
      .
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Help
   </p>
   <ul class="simple">
    <li>
     <p>
      Documentation
      Opens the latest documentation for NVIDIA Nsight Compute online.
     </p>
    </li>
    <li>
     <p>
      Documentation (local)
      Opens the local HTML documentation for NVIDIA Nsight Compute that has shipped with the tool.
     </p>
    </li>
    <li>
     <p>
      Check For Updates
      Checks online if a newer version of NVIDIA Nsight Compute is available for download.
     </p>
    </li>
    <li>
     <p>
      Reset Application Data
      Reset all NVIDIA Nsight Compute configuration data saved on disk, including option settings, default paths, recent project references etc. This will not delete saved reports.
     </p>
    </li>
    <li>
     <p>
      Send Feedback
      Opens a dialog that allows you to send bug reports and suggestions for features. Optionally, the feedback includes basic system information, screenshots, or additional files (such as profile reports).
     </p>
    </li>
    <li>
     <p>
      About
      Opens the About dialog with information about the version of NVIDIA Nsight Compute.
     </p>
    </li>
   </ul>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.4.2.
  </span>
  Main Toolbar
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#main-toolbar" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The main toolbar shows commonly used operations from the main menu. See
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#main-menu">
   Main Menu
  </a>
  for their description.
 </p>
 <h3>
  <span class="section-number">
   3.4.3.
  </span>
  Status Banners
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#status-banners" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Status banners are used to display important messages, such as profiler errors. The message can be dismissed by clicking the âXâ button. The number of banners shown at the same time is limited and old messages can get dismissed automatically if new ones appear. Use the
  Output Messages
  window to see the complete message history.
 </p>
 <h2>
  <span class="section-number">
   3.5.
  </span>
  Tool Windows
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-windows" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.5.1.
  </span>
  API Statistics
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#api-statistics" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  API Statistics
  window is available when NVIDIA Nsight Compute is connected to a target application. It opens by default as soon as the connection is established. It can be re-opened using
  Debug &gt; API Statistics
  from the main menu.
 </p>
 <p>
  Whenever the target application is suspended, it shows a summary of tracked API calls with some statistical information, such as the number of calls, their total, average, minimum and maximum duration. Note that this view cannot be used as a replacement for
  <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
   Nsight Systems
  </a>
  when trying to optimize CPU performance of your application.
 </p>
 <p>
  The
  Reset
  button deletes all statistics collected to the current point and starts a new collection. Use the
  Export to CSV
  button to export the current statistics to a CSV file.
 </p>
 <h3>
  <span class="section-number">
   3.5.2.
  </span>
  API Stream
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#api-stream" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  API Stream
  window is available when NVIDIA Nsight Compute is connected to a target application. It opens by default as soon as the connection is established. It can be re-opened using
  Debug &gt; API Stream
  from the main menu.
 </p>
 <p>
  Whenever the target application is suspended, the window shows the history of API calls and traced kernel launches. The currently suspended API call or kernel launch (activity) is marked with a yellow arrow. If the suspension is at a subcall, the parent call is marked with a green arrow. The API call or kernel is suspended before being executed.
 </p>
 <p>
  For each activity, further information is shown such as the kernel name or the function parameters (
  Func Parameters
  ) and return value (
  Func Return
  ). Note that the function return value will only become available once you step out or over the API call.
 </p>
 <p>
  Use the
  Current Thread
  dropdown to switch between the active threads. The dropdown shows the thread ID followed by the current API name. One of several options can be chosen in the trigger dropdown, which are executed by the adjacent
  &gt;&gt;
  button.
  Run to Next Kernel
  resumes execution until the next kernel launch is found in any enabled thread.
  Run to Next API Call
  resumes execution until the next API call matching
  Next Trigger
  is found in any enabled thread.
  Run to Next Range Start
  resumes execution until the next start of an active profiler range is found. Profiler ranges are defined by using the
  <span class="pre">
   cu(da)ProfilerStart/Stop
  </span>
  API calls.
  Run to Next Range Stop
  resumes execution until the next stop of an active profiler range is found. The
  API Level
  dropdown changes which API levels are shown in the stream. The
  Export to CSV
  button exports the currently visible stream to a CSV file.
 </p>
 <h3>
  <span class="section-number">
   3.5.3.
  </span>
  Baselines
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Baselines
  tool window can be opened by clicking the
  Baselines
  entry in the
  Profile
  menu. It provides a centralized place from which to manage configured baselines. (Refer to
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines">
   Baselines
  </a>
  , for information on how to create baselines from profile results.)
 </p>
 <p>
  The baseline visibility can be controlled by clicking on the check box in a table row. When the check box is checked, the baseline will be visible in the summary header as well as all graphs in all sections. When unchecked the baseline will be hidden and will not contribute to metric difference calculations.
 </p>
 <p>
  The baseline color can be changed by double-clicking on the color swatch in the table row. The color dialog which is opened provides the ability to choose an arbitrary color as well as offers a palette of predefined colors associated with the stock baseline color rotation.
 </p>
 <p>
  The baseline name can be changed by double-clicking on the
  Name
  column in the table row. The name must not be empty and must be less than the
  Maximum Baseline Name Length
  as specified in the options dialog.
 </p>
 <p>
  The z-order of a selected baseline can be changed by clicking the
  Move Baseline Up
  and
  Move Baseline Down
  buttons in the tool bar. When a baseline is moved up or down its new position will be reflected in the report header as well as in each graph. Currently, only one baseline may be moved at a time.
 </p>
 <p>
  The selected baselines may be removed by clicking on the
  Clear Selected Baselines
  button in the tool bar. All baselines can be removed at once by clicking on the
  Clear All Baselines
  button, from either the global tool bar or the tool window tool bar.
 </p>
 <p>
  The configured baselines can be saved to a file by clicking on the
  Save Baselines
  button in the tool bar. By default baseline files use the
  <span class="pre">
   .ncu-bln
  </span>
  extension. Baseline files can be opened locally and/or shared with other users.
 </p>
 <p>
  Baseline information can be loaded by clicking on the
  Load Baselines
  button in the tool bar. When a baseline file is loaded, currently configured baselines will be replaced. A dialog will be presented to the user to confirm this operation when necessary.
 </p>
 <p>
  Differences between the current result and the baselines can be visualized with graphical bars for metrics in Details page section headers. Use the
  Difference Bars
  drop down to select the visualization mode. Bars are extending from left to right and have a fixed maximum.
 </p>
 <h3>
  <span class="section-number">
   3.5.4.
  </span>
  Metric Details
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metric-details" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Metric Details
  tool window can be opened using the
  Metric Details
  entry in the
  Profile
  menu or the respective tool bar button. When a report and the tool window are open, a metric can be selected in the report to display additional information in the tool window. It also contains a search bar to look up metrics in the focused report.
 </p>
 <p>
  Report metrics can be selected in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
   Details Page
  </a>
  or the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-raw-page">
   Raw Page
  </a>
  . The window will show basic information (name, unit and raw value of the metric) as well as additional information, such as its extended description.
 </p>
 <p>
  The search bar can be used to open metrics in the focused report. It shows available matches as you type. The entered string must match from the start of the metric name.
 </p>
 <p>
  By default, selecting or searching for a new metric updates the current
  Default Tab
  . You can click the pin button located in the upper-left corner of the tab control to create a copy of the default tab, unless the same metric is already pinned. This makes it possible to save multiple tabs and quickly switch between them to compare values.
 </p>
 <p>
  Some metrics contain
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-structure">
   Instance Values
  </a>
  . When available, they are listed in the tool window. Instance values can have a
  Correlation ID
  that allows correlating the individual value with its associated entity, e.g. a function address or instruction name.
 </p>
 <p>
  For metrics collected with
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#pm-sampling">
   PM sampling
  </a>
  , the correlation ID is the GPU timestamp in nanoseconds. It is shown as an absolute value and relative to the first timestamp for this metric.
 </p>
 <h3>
  <span class="section-number">
   3.5.5.
  </span>
  Launch Details
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#launch-details" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Launch Details
  tool window can be opened using the
  Launch Details
  entry
in the
  Profile
  menu or the respective tool bar button. When a result
containing multiple sub-launches is selected and this tool window is open, it
will display information about each sub-launch contained in the result.
 </p>
 <a class="reference internal image-reference" href="https://docs.nvidia.com/nsight-compute/_images/tool-window-launch-details.png">
 </a>
 <p>
  This tool window is split into two sections:
 </p>
 <ul class="simple">
  <li>
   <p>
    a header displaying information applying to the result as a whole
   </p>
  </li>
  <li>
   <p>
    a body displaying information specific to the viewed sub-launch
   </p>
  </li>
 </ul>
 <h4>
  Header
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#header" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  On the left side of its header, this tool window displays the selected resultâs
name and the number of sub-launches it is comprised of.
 </p>
 <p>
  The right side contains a combo box that allows selection of the sub-launch the
body should represent. Each element of the combo box contains an index for the
sub-launch as well as the name of the function that it launched if available.
 </p>
 <h4>
  Body
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#body" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The body of this tool window displays a table with sub-launch-specific metrics.
This table has four columns:
 </p>
 <ul class="simple">
  <li>
   <p>
    Metric Name
    : the name of the metric
   </p>
  </li>
  <li>
   <p>
    Metric Unit
    : the unit for metric values
   </p>
  </li>
  <li>
   <p>
    Instance Value
    : the value of this metric for the selected sub-launch
   </p>
  </li>
  <li>
   <p>
    Aggregate Value
    : the aggregate value for this metric over all sub-launches
in the selected result
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.5.6.
  </span>
  NVTX
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#nvtx" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  NVTX
  window is available when NVIDIA Nsight Compute is connected to a target application. If closed, it can be re-opened using
  Debug &gt; NVTX
  from the main menu. Whenever the target application is suspended, the window shows the state of all active NVTX domains and ranges in the currently selected thread. Note that
  <a class="reference external" href="https://devblogs.nvidia.com/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx/">
   NVTX
  </a>
  information is only tracked if the launching command line profiler instance was started with
  <span class="pre">
   --nvtx
  </span>
  or NVTX was enabled in the NVIDIA Nsight Compute launch dialog.
 </p>
 <p>
  Use the
  Current Thread
  dropdown in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
   API Stream
  </a>
  window to change the currently selected thread. NVIDIA Nsight Compute supports NVTX named resources, such as threads, CUDA devices, CUDA contexts, etc. If a resource is named using NVTX, the appropriate UI elements will be updated.
 </p>
 <h3>
  <span class="section-number">
   3.5.7.
  </span>
  CPU Call Stack
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#cpu-call-stack" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  CPU Call Stack
  window is available when NVIDIA Nsight Compute is connected to a target application.
If closed, it can be re-opened using
  Debug &gt; CPU Call Stack
  from the main menu.
Whenever the target application is suspended, the window shows all enabled CPU call stacks for the currently selected thread.
 </p>
 <p>
  Use the
  Call Stack Type
  dropdown menu to switch between stack types in case multiple stack types were enabled (e.g.,
  Native
  ,
  Python
  ).
Note that Python call stack collection requires CPython version 3.9 or later.
 </p>
 <h3>
  <span class="section-number">
   3.5.8.
  </span>
  Resources
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#resources" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Resources
  window is available when NVIDIA Nsight Compute is connected to a target application. It shows information about the currently known resources, such as CUDA devices, CUDA streams or kernels. The window is updated every time the target application is suspended. If closed, it can be re-opened using
  Debug &gt; Resources
  from the main menu.
 </p>
 <p>
  Using the dropdown on the top, different views can be selected, where each view is specific to one kind of resource (context, stream, kernel, â¦). The
  Filter
  edit allows you to create filter expressions using the column headers of the currently selected resource.
 </p>
 <p>
  The resource table shows all information for each resource instance. Each instance has a unique ID, the
  API Call ID
  when this resource was created, its handle, associated handles, and further parameters. When a resource is destroyed, it is removed from its table.
 </p>
 <h4>
  Memory Allocations
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#memory-allocations" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  When using the asynchronous malloc/free APIs, the resource view for
  Memory Allocation
  will also include the memory objects created in this manner. These memory objects have a non-zero memory pool handle. The
  Mode
  column will indicate which code path was taken during the allocation of the corresponding object. The modes are:
 </p>
 <ul class="simple">
  <li>
   <p>
    REUSE_STREAM_SUBPOOL: The memory object was allocated in memory that was previously freed. The memory was backed by the memory pool set as current for the stream on which the allocation was made.
   </p>
  </li>
  <li>
   <p>
    USE_EXISTING_POOL_MEMORY: The memory object was allocated in memory that was previously freed. The memory is backed by the default memory pool of the stream on which the allocation was made.
   </p>
  </li>
  <li>
   <p>
    REUSE_EVENT_DEPENDENCIES: The memory object was allocated in memory that was previously freed in another stream of the same context. A stream ordering dependency of the allocating stream on the free action existed. Cuda events and null stream interactions can create the required stream ordered dependencies.
   </p>
  </li>
  <li>
   <p>
    REUSE_OPPORTUNISTIC: The memory object was allocated in memory that was previously freed in another stream of the same context. However, no dependency between the free and allocation existed. This mode requires that the free be already committed at the time the allocation is requested. Changes in execution behavior might result in different modes for multiple runs of the application.
   </p>
  </li>
  <li>
   <p>
    REUSE_INTERNAL_DEPENDENCIES: The memory object was allocated in memory that was previously freed in another stream of the same context. New internal stream dependencies may have been added in order to establish the stream ordering required to reuse a piece of memory previously released.
   </p>
  </li>
  <li>
   <p>
    REQUEST_NEW_ALLOCATION: New memory had to be allocated for this memory object as no viable reusable pool memory was found. The allocation performance is comparable to using the non-asynchronous malloc/free APIs.
   </p>
  </li>
 </ul>
 <h4>
  Graphviz DOT and SVG exports
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#graphviz-dot-and-svg-exports" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  Some of the shown
  Resources
  can also be exported to
  GraphViz DOT
  or SVG* files using the
  <span class="pre">
   Export
  </span>
  <span class="pre">
   to
  </span>
  <span class="pre">
   GraphViz
  </span>
  or
  <span class="pre">
   Export
  </span>
  <span class="pre">
   to
  </span>
  <span class="pre">
   SVG
  </span>
  buttons.
 </p>
 <p>
  When exporting
  OptiX traversable handles
  , the traversable graph node types will be encoded using shapes and colors as described in the following table.
 </p>
 <table class="table-no-stripes colwidths-given docutils align-default" id="id12">
  <span class="caption-text">
   Table 2. OptiX Traversable Graph Node Types
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id12" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Node Type
    </p>
   </th>
   <th class="head">
    <p>
     Shape
    </p>
   </th>
   <th class="head">
    <p>
     Color
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     IAS
    </p>
   </td>
   <td>
    <p>
     Hexagon
    </p>
   </td>
   <td>
    <p>
     #8DD3C7
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Triangle GAS
    </p>
   </td>
   <td>
    <p>
     Box
    </p>
   </td>
   <td>
    <p>
     #FFFFB3
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     AABB GAS
    </p>
   </td>
   <td>
    <p>
     Box
    </p>
   </td>
   <td>
    <p>
     #FCCDE5
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Curve GAS
    </p>
   </td>
   <td>
    <p>
     Box
    </p>
   </td>
   <td>
    <p>
     #CCEBC5
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Sphere GAS
    </p>
   </td>
   <td>
    <p>
     Box
    </p>
   </td>
   <td>
    <p>
     #BEBADA
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Static Transform
    </p>
   </td>
   <td>
    <p>
     Diamond
    </p>
   </td>
   <td>
    <p>
     #FB8072
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     SRT Transform
    </p>
   </td>
   <td>
    <p>
     Diamond
    </p>
   </td>
   <td>
    <p>
     #FDB462
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Matrix Motion Transform
    </p>
   </td>
   <td>
    <p>
     Diamond
    </p>
   </td>
   <td>
    <p>
     #80B1D3
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Error
    </p>
   </td>
   <td>
    <p>
     Paralellogram
    </p>
   </td>
   <td>
    <p>
     #D9D9D9
    </p>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.5.9.
  </span>
  Metric Selection
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metric-selection" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Metric Selection
  window can be opened from the main menu using
  Profile &gt; Metric Selection
  . It tracks all metric sets, sections and rules currently loaded in NVIDIA Nsight Compute, independent from a specific connection or report. The directory to load those files from can be configured in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options dialog. It is used to inspect available sets, sections and rules, as well as to configure which should be collected, and which rules should be applied. You can also specify a comma separated list of individual metrics, that should be collected. The window has two views, which can be selected using the dropdown in its header.
 </p>
 <p>
  The
  Metric Sets
  view shows all available metric sets. Each set is associated with a number of metrics sections. You can choose a set appropriate to the level of detail for which you want to collect performance metrics. Sets which collect more detailed information normally incur higher runtime overhead during profiling.
 </p>
 <p>
  When enabling a set in this view, the associated metric sections are enabled in the
  Metric Sections/Rules
  view. When disabling a set in this view, the associated sections in the
  Metric Sections/Rules
  view are disabled. If no set is enabled, or if sections are manually enabled/disabled in the
  Metric Sections/Rules
  view, the &lt;
  custom
  &gt; entry is marked active to represent that no section set is currently enabled. Note that the
  basic
  set is enabled by default.
 </p>
 <p>
  Whenever a kernel is profiled manually, or when auto-profiling is enabled, only sections enabled in the
  Metric Sections/Rules
  view and individual metrics specified in input box are collected. Similarly, whenever rules are applied, only rules enabled in this view are active.
 </p>
 <p>
  The enabled states of sections and rules are persisted across NVIDIA Nsight Compute launches. The
  Reload
  button reloads all sections and rules from disk again. If a new section or rule is found, it will be enabled if possible. If any errors occur while loading a rule, they will be listed in an extra entry with a warning icon and a description of the error.
 </p>
 <p>
  Use the
  Enable All
  and
  Disable All
  checkboxes to enable or disable all sections and rules at once. The Filter text box can be used to filter what is currently shown in the view. It does not alter activation of any entry.
 </p>
 <p>
  The table shows sections and rules with their activation status, their relationship and further parameters, such as associated metrics or the original file on disk. Rules associated with a section are shown as children of their section entry. Rules independent of any section are shown under an additional
  Independent Rules
  entry.
 </p>
 <p>
  Double-clicking an entry in the tableâs
  Filename
  column opens this file as a document. It can be edited and saved directly in NVIDIA Nsight Compute. After editing the file,
  Reload
  must be selected to apply those changes.
 </p>
 <p>
  When a section or rule file is modified, the entry in the
  State
  column will show
  User Modified
  to reflect that it has been modified from its default state. When a
  User Modified
  row is selected, the
  Restore
  button will be enabled. Clicking the Restore button will restore the entry to its default state and automatically
  Reload
  the sections and rules.
 </p>
 <p>
  Similarly, when a stock section or rule file is removed from the configured
  Sections Directory
  (specified in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options dialog), the
  State
  column will show
  User Deleted
  .
  User Deleted
  files can also be restored using the
  Restore
  button.
 </p>
 <p>
  Section and rule files that are created by the user (and not shipped with NVIDIA Nsight Compute) will show up as
  User Created
  in the
  state column
  .
 </p>
 <p>
  See the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#sections-and-rules">
   Sections and Rules
  </a>
  for the list of default sections for NVIDIA Nsight Compute.
 </p>
 <h2>
  <span class="section-number">
   3.6.
  </span>
  Profiler Report
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The profiler report contains all the information collected during profiling for each kernel launch. In the user interface, it consists of a header with general information, as well as controls to switch between report pages or individual collected launches.
 </p>
 <h3>
  <span class="section-number">
   3.6.1.
  </span>
  Header
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-header" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The top of the report shows a table with information about the selected profile result (as
  Current
  ) and potentially additional
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-baselines">
   baselines
  </a>
  .
For many values in this table, tooltips provide additional information or data, e.g., the tooltip of the column
  Attributes
  provides additional information about the context type and resources used for the launch.
 </p>
 <p>
  The
  Result
  dropdown can be used to switch between all collected kernel launches. The information displayed in each page commonly represents the selected launch instance. On some pages (e.g.
  Raw
  ), information for all launches is shown and the selected instance is highlighted. You can type in this dropdown to quickly filter and find a kernel launch.
 </p>
 <p>
  The
  Apply Filters
  button opens the filter dialog. You can use more than one filter to narrow down your results. On the filter dialog, enter your filter parameters and press OK button. The
  Launch
  dropdown,
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-summary-page">
   Summary Page
  </a>
  table, and
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-raw-page">
   Raw Page
  </a>
  table will be filtered accordingly. Select the arrow dropdown to access the
  Clear Filters
  button, which removes all filters.
 </p>
 <p>
  <span class="caption-text">
   Filter Dialog
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-header-filter-dialog" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Underneath the current and baseline results are the tabs for switching between the report pages. The pages themselves are explained in detail in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages">
   next section
  </a>
  .
 </p>
 <p>
  Each group button to the right of the page tabs opens a context menu that features related actions.
Some actions may be enabled only when the related report page is selected.
 </p>
 <ul class="simple">
  <li>
   <p>
    Compare
   </p>
   <ul>
    <li>
     <p>
      Add Baseline
      promotes the current result in focus to become the baseline of all other results from this report and any other report opened in the same instance of NVIDIA Nsight Compute.
     </p>
    </li>
    <li>
     <p>
      Clear Baselines
      removes all currently active baselines. You may also use the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-baselines">
       Baselines
      </a>
      tool window to manage baseline for comparison.
     </p>
    </li>
    <li>
     <p>
      Source Comparison
      navigates to the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-comparison">
       Source Comparison
      </a>
      document in case at least two profile results are available for comparison.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Tools
   </p>
   <ul>
    <li>
     <p>
      Occupancy Calculator
      opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator">
       Occupancy Calculator
      </a>
      in a new document.
     </p>
    </li>
    <li>
     <p>
      Metric Details Windows
      opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-metric-details">
       Metric Details
      </a>
      tool window. When the window is open and a metric is selected elsewhere in the report, it shows detailed information about it.
     </p>
    </li>
    <li>
     <p>
      Launch Details Windows
      opens the
      <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-launch-details">
       Launch Details
      </a>
      tool window. When the window is open and a result containing multiple sub-launches is selected, it displays information about each sub-launch in the result.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    View
   </p>
   <ul>
    <li>
     <p>
      Show/Hide Rules Output
      toggles the visibility of rule results.
     </p>
    </li>
    <li>
     <p>
      Show/Hide Section Descriptions
      toggles the visibiliy of section descriptions on the Details page.
     </p>
    </li>
    <li>
     <p>
      Expand Sections
      expands all sections to show their body contents, not only header and rule output. Note that sections may have multiple bodies and the visible one can be chosen using the dropdown in the section header.
     </p>
    </li>
    <li>
     <p>
      Collapse Sections
      collapses all sections to show only their header and rule output.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Export
   </p>
   <ul>
    <li>
     <p>
      Copy as Image
      - Copies the contents of the page to the clipboard as an image.
     </p>
    </li>
    <li>
     <p>
      Save as Image
      - Saves the contents of the page to a file as an image.
     </p>
    </li>
    <li>
     <p>
      Save as PDF
      - Saves the contents of the page to a file as a PDF.
     </p>
    </li>
    <li>
     <p>
      Export to CSV
      - Exports the contents of the page to CSV format.
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    More (three bars icon)
   </p>
   <ul>
    <li>
     <p>
      Apply Rules
      applies all rules available for this report. If rules had been applied previously, those results will be replaced. By default, rules are applied immediately once the kernel launch has been profiled. This can be changed in the options under
      Tools &gt; Options &gt; Profile &gt; Report UI &gt; Apply Applicable Rules Automatically
      .
     </p>
    </li>
    <li>
     <p>
      Reset to Default
      resets the page to a default state by removing any persisted settings.
     </p>
    </li>
   </ul>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.6.2.
  </span>
  Report Pages
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#report-pages" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Use the
  Page
  dropdown in the header to switch between the report pages.
 </p>
 <p>
  By default, when opening a report with a single profile result, the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
   Details Page
  </a>
  is shown. When opening a report with multiple results, the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-summary-page">
   Summary Page
  </a>
  is selected instead. You can change the default report page in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options.
 </p>
 <h4>
  Summary Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#summary-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  Summary
  page shows a table of all collected results in the report, as well as a list of the most important rule outputs (
  Prioritized Rules
  ) which are ordered by the estimated speedup that could potential be obtained by following their guidance.
  Prioritized Rules
  are shown by default and can be toggled with the [R] button on the upper right of the page.
 </p>
 <p>
  <span class="caption-text">
   Summary page with Summary Table and Prioritized Rules.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-summary-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  The
  Summary Table
  gives you a quick comparison overview across all profiled workloads. It contains a number of important, pre-selected metrics which can be customized as explained below. Its columns can be sorted by clicking the column header. You can transpose the table with the
  Transpose
  button. Aggregate of all results per each counter metric is shown in the table header along with the column name. You can change the aggregated values by selecting the desired results for multiple metrics simultaneously. When selecting any entry by single-click, a list of its
  Prioritized Rules
  will be shown below the table. Double-click any entry to make the result the currently active one and switch to the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
   Details Page
  </a>
  page to inspect its performance data.
By default, kernel demangled names are simplified, renamed and shown in an optimized manner. This behavior can be changed with
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Rename Demangled Names
  </a>
  option. If an auto-simplified name is not useful, you can rename it through a configuration file.
You can also persist the updated names directly in the report by double-clicking on the name, renaming and saving the report.
Use
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Rename Kernels Config Path
  </a>
  option to specify the configuration file which should be used while importing renamed kernels or exporting demangled names with mappings to rename them. To export names to a new file, click
  Export
  button and use
  Rename Kernels Config
  option.
See
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#kernel-renaming">
   Kernel Renaming
  </a>
  for more details on configuration file usage.
 </p>
 <p>
  You can configure the list of metrics included in this table in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options dialog. If a metric has multiple instance values, the number of instances is shown after its standard value. A metric with ten instance values could for example look like this:
  <span class="pre">
   35.48
  </span>
  <span class="pre">
   {10}
  </span>
  . In the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options dialog, you can select that all instance values should be shown individually. You can also inspect the instances values of a metric result in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-metric-details">
   Metric Details
  </a>
  tool window.
 </p>
 <p>
  In addition to metrics, you can also configure the table to include any of the following properties:
 </p>
 <p class="rubric-h3 rubric" id="summary-page-property">
  Properties
 </p>
 <table class="colwidths-auto table-no-stripes docutils align-default" id="id13">
  <span class="caption-text">
   Properties
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id13" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__api_call_id
     </span>
    </p>
   </td>
   <td>
    <p>
     ID of the API call associated with this profile result.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__block_size
     </span>
    </p>
   </td>
   <td>
    <p>
     Block Size. If the result contains multiple launches, this will contain the maximum value for each dimension of the block.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__creation_time
     </span>
    </p>
   </td>
   <td>
    <p>
     Local collection time.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__demangled_name
     </span>
    </p>
   </td>
   <td>
    <p>
     Kernel demangled name, potentially renamed.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__device_name
     </span>
    </p>
   </td>
   <td>
    <p>
     GPU device name.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__estimated_speedup
     </span>
    </p>
   </td>
   <td>
    <p>
     Maximal relative speedup achievable for this profile result as estimated by the guided analysis rules.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__function_name
     </span>
    </p>
   </td>
   <td>
    <p>
     Kernel function name or range name.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__grid_dimensions
     </span>
    </p>
   </td>
   <td>
    <p>
     Grid Dimensions. If the result contains multiple launches, this will contain the maximum value for each dimension of the grid.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__grid_offset
     </span>
    </p>
   </td>
   <td>
    <p>
     Grid Offset.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__grid_size
     </span>
    </p>
   </td>
   <td>
    <p>
     Grid Size. If the result contains multiple launches, this will contain the maximum value for each dimension of the grid.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__issues_detected
     </span>
    </p>
   </td>
   <td>
    <p>
     Number of issues detected by guided analysis rules for this profile result.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__kernel_id
     </span>
    </p>
   </td>
   <td>
    <p>
     Kernel ID.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__mangled_name
     </span>
    </p>
   </td>
   <td>
    <p>
     Kernel mangled name.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__original_demangled_name
     </span>
    </p>
   </td>
   <td>
    <p>
     Original kernel demangled name without any renaming.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__process_name
     </span>
    </p>
   </td>
   <td>
    <p>
     Process name.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__runtime_improvement
     </span>
    </p>
   </td>
   <td>
    <p>
     Runtime improvement corresponding to the estimated speedup.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__series_id
     </span>
    </p>
   </td>
   <td>
    <p>
     ID of the profile series.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      property__series_parameters
     </span>
    </p>
   </td>
   <td>
    <p>
     Profile series parameters.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      property__thread_id
     </span>
    </p>
   </td>
   <td>
    <p>
     CPU thread ID.
    </p>
   </td>
  </tr>
 </table>
 <p>
  For
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#range-replay">
   Range Replay
  </a>
  reports, a smaller set of columns is shown by default, as not all apply to such results.
 </p>
 <p>
  For the currently selected metric result the
  Prioritized Rules
  show the most impactful rule results with respect to the estimated potential speedup. Clicking on any of the rule names on the left allows you to easily navigate to the containing section on the details page. With the downward-facing arrow on the right a table with the relevant
  key performance indicators
  can be toggled. This table contains the metrics which should be tracked when optimizing performance according to the rule guidance.
 </p>
 <p>
  <span class="caption-text">
   Prioritized Rules
   with key performance indicators table.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-summary-rules" title="Permalink to this image">
   ï
  </a>
 </p>
 <h4>
  Details Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#details-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p class="rubric-h4 rubric">
  Overview
 </p>
 <p>
  The
  Details
  page is the main page for all metric data collected during a kernel launch. The page is split into individual sections. Each section consists of a header table and an optional body that can be expanded. The sections are completely user defined and can be changed easily by updating their respective files. For more information on customizing sections, see the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/CustomizationGuide/index.html#abstract">
   Customization Guide
  </a>
  . For a list of sections shipped with NVIDIA Nsight Compute, see
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#sections-and-rules">
   Sections and Rules
  </a>
  .
 </p>
 <p>
  By default, once a new profile result is collected, all applicable rules are applied. Any rule results will be shown as
  Recommendations
  on this page. Most rule results will contain an optimization advice along with an estimate of the improvement that could be achieved when successfully implementing this advice. Other rule results will be purely informative or have a warning icon to indicate a problem that occurred during execution (e.g., an optional metric that could not be collected). Results with error icons typically indicate an error while applying the rule.
 </p>
 <p>
  Estimates of potential improvement are shown below the rule resultâs name and exist in two types.
  Global estimates
  (âEst. Speedupâ) are an approximation of the decrease in workload runtime, whereas
  local estimates
  (âEst. Local Speedupâ) are an approximation of the increase in efficiency of the hardware utilization of the particular performance problem the rule addresses.
 </p>
 <p>
  <span class="caption-text">
   Rule results often point out performance problems and guide through the analysis process.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-section-with-rule" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  If a rule result references another report section, it will appear as a link in the recommendation. Select the link to scroll to the respective section. If the section was not collected in the same profile result, enable it in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-sections-info">
   Metric Selection
  </a>
  tool window.
 </p>
 <p>
  You can add or edit comments in each section of the
  Details
  view by clicking on the comment button (speech bubble). The comment icon will be highlighted in sections that contain a comment. Comments are persisted in the report and are summarized in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-comments-page">
   Comments Page
  </a>
  .
 </p>
 <p>
  <span class="caption-text">
   Use the Comments button to annotate sections.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-details-comments" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Besides their header, sections typically have one or more
  bodies
  with additional charts or tables. Click the triangle
  Expander
  icon in the top-left corner of each section to show or hide those. If a section has multiple bodies, a dropdown in their top-right corner allows you to switch between them.
 </p>
 <p>
  <span class="caption-text">
   Sections with multiple bodies have a dropdown to switch between them.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-section-bodies" title="Permalink to this image">
   ï
  </a>
 </p>
 <p class="rubric-h4 rubric" id="memory">
  Memory
 </p>
 <p>
  If enabled, the
  Memory Workload Analysis
  section contains a Memory chart that visualizes data transfers, cache hit rates, instructions and memory requests. More information on how to use and read this chart can be found in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#memory-chart">
   Kernel Profiling Guide
  </a>
  .
 </p>
 <p class="rubric-h4 rubric">
  Occupancy
 </p>
 <p>
  You can open the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator">
   Occupancy Calculator
  </a>
  by clicking on the calculator button in the report header or in the header of the
  Occupancy Section
  .
 </p>
 <p class="rubric-h4 rubric">
  Range Replay
 </p>
 <p>
  Note that for
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#range-replay">
   Range Replay
  </a>
  results some UI elements, analysis rules, metrics or section body items such as charts or tables might not be available, as they only apply to kernel launch-based results. The filters can be checked in the corresponding section files.
 </p>
 <p class="rubric-h4 rubric">
  Rooflines
 </p>
 <p>
  If enabled, the
  GPU Speed Of Light Roofline Chart
  section contains a Roofline chart that is particularly helpful for visualizing kernel performance at a glance. (To enable roofline charts in the report, ensure that the section is enabled when profiling.) More information on how to use and read this chart can be found in
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline">
   Roofline Charts
  </a>
  . NVIDIA Nsight Compute ships with several different definitions for roofline charts, including hierarchical rooflines. These additional rooflines are defined in different section files. While not part of the
  full
  section set, a new section set called
  roofline
  was added to collect and show all rooflines in one report. The idea of hierarchical rooflines is that they define multiple ceilings that represent the limiters of a hardware hierarchy. For example, a hierarchical roofline focusing on the memory hierarchy could have ceilings for the throughputs of the L1 cache, L2 cache and device memory. If the achieved performance of a kernel is limited by one of the ceilings of a hierarchical roofline, it can indicate that the corresponding unit of the hierarchy is a potential bottleneck.
 </p>
 <p>
  <span class="caption-text">
   Sample roofline chart.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id14" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  The roofline chart can be zoomed and panned for more effective data analysis, using the controls in the table below.
 </p>
 <table class="table-no-stripes docutils align-default" id="id15">
  <span class="caption-text">
   Table 3. Roofline Chart Zoom and Pan Controls
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id15" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Zoom In
    </p>
   </th>
   <th class="head">
    <p>
     Zoom Out
    </p>
   </th>
   <th class="head">
    <p>
     Zoom Reset
    </p>
   </th>
   <th class="head">
    <p>
     Pan
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <ul class="simple">
     <li>
      <p>
       Click the Zoom In button in the top right corner of the chart.
      </p>
     </li>
     <li>
      <p>
       Click the left mouse button and drag to create a rectangle that bounds the area of interest.
      </p>
     </li>
     <li>
      <p>
       Press the plus (+) key.
      </p>
     </li>
     <li>
      <p>
       Use Ctrl + MouseWheel (Windows and Linux only)
      </p>
     </li>
    </ul>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Click the Zoom Out button in the top right corner of the chart.
      </p>
     </li>
     <li>
      <p>
       Click the right mouse button.
      </p>
     </li>
     <li>
      <p>
       Press the minus (-) key.
      </p>
     </li>
     <li>
      <p>
       Use Ctrl + MouseWheel (Windows and Linux only)
      </p>
     </li>
    </ul>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Click the Zoom Reset button in the top right corner of the chart.
      </p>
     </li>
     <li>
      <p>
       Press the Escape (Esc) key.
      </p>
     </li>
    </ul>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Use Ctrl (Command on Mac) + LeftMouseButton to grab the chart, then move the mouse.
      </p>
     </li>
     <li>
      <p>
       Use the cursor keys.
      </p>
     </li>
    </ul>
   </td>
  </tr>
 </table>
 <p class="rubric-h4 rubric">
  Source
 </p>
 <p>
  Sections such as
  Source Counters
  can contain source hot spot tables. These tables indicate the N highest or lowest values of one or more metrics in your kernel source code. Select the location links to navigate directly to this location in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page">
   Source Page
  </a>
  . Hover the mouse over a value to see which metrics contribute to it.
 </p>
 <p>
  <span class="caption-text">
   Hot spot tables point out performance problems in your source.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id16" title="Permalink to this image">
   ï
  </a>
 </p>
 <p class="rubric-h4 rubric">
  Timelines
 </p>
 <p>
  When collecting metrics with
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#pm-sampling">
   PM sampling
  </a>
  , they can be viewed in a
  timeline
  . The timeline shows metrics selected in the respective section file or on the command line with their labels/names and their values over time.
 </p>
 <p>
  Different metrics may be collected in different passes (replays) of the workload, as only a limited number of them can be sampled in the same pass. Context switch trace is used to filter the collected data to only include samples from the profiled contexts and to align it in the timeline.
 </p>
 <p>
  You can hover the mouse over a metric row label to see further information on the metrics in the row. Hovering over a sample on the timeline shows the metric values at that timestamp within the current row. With the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-metric-details">
   Metric Details
  </a>
  tool window open, click to select a value on the timeline and show the metric and all its raw timestamps (absolute and relative) correlated values in the tool window.
 </p>
 <p>
  You can also use the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-metric-details">
   Metric Details
  </a>
  tool window to inspect profiler metrics generated during PM sampling. These provide information about the used sampling intervals, buffer sizes, dropped samples and other properties for each collection pass. A detailed list can be found in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference">
   metrics reference
  </a>
  .
 </p>
 <p>
  The timeline has a context menu for further actions regarding copying content and zooming.
In addition, the
  Enable/Disable Context Switch Filter
  option can be used to enable or disable the filtering of the timeline data with
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#pm-sampling">
   context switch
  </a>
  information, if it is available.
When the context switch filter is enabled (the default), samples from each pass group are only shown for the active contexts.
When the context switch filter is disabled, the raw collected sampling data is shown along with a separate row for each pass groupâs context switch trace.
 </p>
 <p>
  When the context menu option is not available, the report does not include context switch trace data.
In this case, the option
  Enable/Disable Trim Filter
  is shown instead, which, when enabled, tries to align based on the first non-zero value in any sampling metric in this pass group.
However, this fallback does not take into account actual context switches.
 </p>
 <p>
  The timeline row Workload Execution shows each kernelâs start and end timestamp. When the context switch filter is enabled, kernel execution is only shown for one of the passes for the active contexts. When the context switch filter is disabled, kernel execution is shown for all the passes.
 </p>
 <h4>
  Source Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  Source
  page correlates assembly (SASS) with high-level code such as CUDA-C, Python or PTX. In addition, it displays instruction-correlated metrics to help pinpoint performance problems in your code.
 </p>
 <p>
  <span class="caption-text">
   Source Correlation
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  The page can be switched between different
  Views
  to focus on a specific source layer or see two layers side-by-side. This includes SASS, PTX and Source (CUDA-C, Fortran, Python, â¦), as well as their combinations. Which options are available depends on the source information embedded into the executable.
 </p>
 <p>
  The high-level Source (CUDA-C) view is available if the application was built with the
  <span class="pre">
   -lineinfo
  </span>
  or
  <span class="pre">
   --generate-line-info
  </span>
  nvcc flag to correlate SASS and source. When using separate linking at the ELF level, there is no PTX available in the ELF that would correspond to the final SASS. As such, NVIDIA Nsight Compute does not show any PTX even though it would be available statically in the executable and could be shown with
  <span class="pre">
   cuobjdump
  </span>
  <span class="pre">
   -all
  </span>
  <span class="pre">
   -lptx
  </span>
  . However, this is a pre-linked version of the PTX and cannot be reliably used for correlation.
 </p>
 <p>
  The code in the different
  Views
  can also contain warnings, errors or just notifications that are displayed as
  Source Markers
  in the left header, as shown below. These can be generated from multiple systems, but as of now only NvRules are supported.
 </p>
 <p>
  <span class="caption-text">
   Source Markers
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-markers" title="Permalink to this image">
   ï
  </a>
 </p>
 <h5>
  Navigation
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#navigation" title="Permalink to this headline">
   ï
  </a>
 </h5>
 <p>
  The
  View
  dropdown can be used to select different code (correlation) options: SASS, PTX and Source (CUDA-C, Fortran, Python, â¦).
 </p>
 <p>
  In side-by-side views, when selecting a line in the left-hand- or right-hand-side, any correlated lines in the opposite view are highlighted. However, when the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Show Single File For Multi-File Sources
  </a>
  option is set to
  Yes
  , the target file or source object must already be selected in the respective view for those correlated lines to be shown.
 </p>
 <p>
  In side-by-side views, the view which has blue border is called
  focused view
  . Focused view can be changed by clicking anywhere in the other view. Control groups which are bordered with blue color will work for a focused view only.
 </p>
 <p>
  The
  Source
  dropdown allows you to switch between the files or functions that provide the content in the view. When a different source entry is selected, the view scrolls to the start of this file or function.
 </p>
 <p>
  If a view contains multiple source files or functions, [+] and [-] buttons are shown. These can be used to expand or collapse the view, thereby showing or hiding the file or function content except for its header. These will work for both the views if that group is in the linked state otherwise in an unlinked state it will work for a focused view. If collapsed, all
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page-metrics">
   metrics
  </a>
  are shown aggregated to provide a quick overview.
 </p>
 <p>
  <span class="caption-text">
   Collapsed Source View
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-collapse" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  You can use the
  Find
  (source code) line edit to search the
  Source
  column of a focused view. Enter the text to search and use the associated buttons to find the next or previous occurrence in this column. While the line edit is selected, you can also use the
  Enter
  or
  Shift*+*Enter
  keys to search for the next or previous occurrence, respectively.
 </p>
 <p>
  The SASS view is filtered to only show functions that were executed in the launch. You can toggle the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Show Only Executed Functions
  </a>
  option to change this, but performance of this page may be negatively affected for large binaries. It is possible that some SASS instructions are shown as
  N/A
  . Those instructions are not currently exposed publicly.
 </p>
 <p>
  In side-by-side views, the
  Navigate By
  dropdowns are linked with each other by default, thereby changing column names from one dropdown will change it in the other view only if column is available. These dropdowns can be unlinked with the link-unlink button provided just before it.
 </p>
 <p>
  <span class="caption-text">
   Linked state of âNavigate Byâ Dropdowns
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-navigate-by" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Only filenames are shown in the view, together with a
  File Not Found
  error, if the source files cannot be found in their original location. This can occur, for example, if the report was moved to a different system. Select a filename and click the
  Resolve
  button above to specify where this source can be found on the local filesystem. However, the view always shows the source files if the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-activity-interactive">
   import source
  </a>
  option was selected during profiling, and the files were available at that time. If a file is found in its original or any source lookup location, but its attributes donât match, a
  File Mismatch
  error is shown. See the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-source-lookup">
   Source Lookup
  </a>
  options for changing file lookup behavior.
 </p>
 <p>
  <span class="caption-text">
   Resolve Source
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-resolve" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  If the report was collected using remote profiling, and automatic resolution of remote files is enabled in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options, NVIDIA Nsight Compute will attempt to load the source from the remote target. If the connection credentials are not yet available in the current NVIDIA Nsight Compute instance, they are prompted in a dialog. Loading from a remote target is currently only available for Linux x86_64 targets and Linux and Windows hosts.
 </p>
 <h5>
  Metrics
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metrics" title="Permalink to this headline">
   ï
  </a>
 </h5>
 <p class="title sectiontitle rubric" id="metrics-correlation">
  Metrics Correlation
 </p>
 <p>
  The page is most useful when inspecting performance information and metrics correlated with your code. Metrics are shown in columns, which can be enabled or disabled using the
  Column Chooser
  accessible using the column header right click menu.
 </p>
 <p>
  <span class="caption-text">
   Column Chooser
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-column-chooser" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  To not move out of view when scrolling horizontally, columns can be fixed. By default, the
  Source
  column is fixed to the left, enabling easy inspection of all metrics correlated to a source line. To change fixing of columns, right click the column header and select
  Freeze
  or
  Unfreeze
  , respectively.
 </p>
 <p>
  <span class="caption-text">
   Column Freezing/Unfreezing
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-fix-column" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  The heatmap on the right-hand side of each view can be used to quickly identify locations with high metric values of the currently selected metric in the dropdown. The heatmap uses a black-body radiation color scale where black denotes the lowest mapped value and white the highest, respectively. The current scale is shown when clicking and holding the heatmap with the right mouse button.
 </p>
 <p>
  <span class="caption-text">
   Heatmap Color Scale
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-heatmap" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  By default, applicable metrics are shown as percentage values relative to their sum across the launch. A bar is filling from left to right to indicate the value at a specific source location relative to this metricâs maximum within the launch. The [%] and [+-] buttons can be used to switch the display from relative to absolute and from abbreviated absolute to full-precision absolute, respectively. For relative values and bars, the [circle/pie] button can be used to switch the display between relative to global (launch) and relative to local (function/file) scope. This button is disabled when the view is collapsed, as percentages are always relative to the global launch scope in this case.
 </p>
 <p>
  <span class="caption-text">
   Relative and Absolute Metric Values.
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-pages-source-rel-abs" title="Permalink to this image">
   ï
  </a>
 </p>
 <p class="title sectiontitle rubric" id="pre-defined-source-metrics">
  Pre-Defined Source Metrics
 </p>
 <ul>
  <li>
   <p>
    Live Registers
   </p>
   <p>
    Number of registers that need to be kept valid by the compiler. A high value indicates that many registers are required at this code location, potentially increasing the register pressure and the maximum number of register required by the kernel.
   </p>
   <p>
    The total number of registers reported as
    <span class="pre">
     launch__registers_per_thread
    </span>
    may be significantly higher than the maximum live registers. The compiler may need to allocate specific registers that can creates holes in the allocation, thereby affecting
    <span class="pre">
     launch__registers_per_thread
    </span>
    , even if the maximum live registers is smaller. This may happen due to ABI restrictions, or restrictions enforced by particular hardware instructions. The compiler may not have a complete picture of which registers may be used in either callee or caller and has to obey ABI conventions, thereby allocating different registers even if some register could have theoretically been re-used.
   </p>
  </li>
  <li>
   <p>
    Warp Stall Sampling (All Samples)
    <a class="footnote-reference brackets" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#fn1" id="id6">
     1
    </a>
   </p>
   <p>
    The number of samples from the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#statistical-sampler">
     Statistical Sampler
    </a>
    at this program location.
   </p>
  </li>
  <li>
   <p>
    Warp Stall Sampling (Not-issued Samples)
    <a class="footnote-reference brackets" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#fn2" id="id7">
     2
    </a>
   </p>
   <p>
    The number of samples from the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#statistical-sampler">
     Statistical Sampler
    </a>
    at this program location on cycles the warp scheduler issued no instructions. Note that
    (Not Issued)
    samples may be taken on a different profiling pass than
    (All)
    samples mentioned above, so their values do not strictly correlate.
   </p>
   <p>
    This metric is only available on devices with compute capability 7.0 or higher.
   </p>
  </li>
  <li>
   <p>
    Instructions Executed
   </p>
   <p>
    Number of times the source (instruction) was executed per individual warp, independent of the number of participating threads within each warp.
   </p>
  </li>
  <li>
   <p>
    Thread Instructions Executed
   </p>
   <p>
    Number of times the source (instruction) was executed by any thread, regardless of predicate presence or evaluation.
   </p>
  </li>
  <li>
   <p>
    Predicated-On Thread Instructions Executed
   </p>
   <p>
    Number of times the source (instruction) was executed by any active, predicated-on thread. For instructions that are executed unconditionally (i.e. without predicate), this is the number of active threads in the warp, multiplied with the respective
    Instructions Executed
    value.
   </p>
  </li>
  <li>
   <p>
    Avg. Threads Executed
   </p>
   <p>
    Average number of thread-level executed instructions per warp, regardless of their predicate.
   </p>
  </li>
  <li>
   <p>
    Avg. Predicated-On Threads Executed
   </p>
   <p>
    Average number of predicated-on thread-level executed instructions per warp.
   </p>
  </li>
  <li>
   <p>
    Divergent Branches
   </p>
   <p>
    Number of divergent branch targets, including fallthrough. Incremented only when there are two or more active threads with divergent targets. Divergent branches can lead to warp stalls due to resolving the branch or instruction cache misses.
   </p>
  </li>
  <li>
   <p>
    Information on Memory Operations
   </p>
   <table class="table-no-stripes docutils align-default">
    <tr class="row-odd">
     <td>
      <p>
       Label
      </p>
     </td>
     <td>
      <p>
       Name
      </p>
     </td>
     <td>
      <p>
       Description
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       Address Space
      </p>
     </td>
     <td>
      <p>
       memory_type
      </p>
     </td>
     <td>
      <p>
       The accessed address space (global/local/shared).
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       Access Operation
      </p>
     </td>
     <td>
      <p>
       memory_access_type
      </p>
     </td>
     <td>
      <p>
       The type of memory access (e.g. load or store).
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       Access Size
      </p>
     </td>
     <td>
      <p>
       memory_access_size_type
      </p>
     </td>
     <td>
      <p>
       The size of the memory access, in bits.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L1 Tag Requests Global
      </p>
     </td>
     <td>
      <p>
       memory_l1_tag_requests_global
      </p>
     </td>
     <td>
      <p>
       Number of L1 tag requests generated by global memory instructions.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L1 Conflicts Shared N-Way
      </p>
     </td>
     <td>
      <p>
       derived__memory_l1_conflicts_shared_nway
      </p>
     </td>
     <td>
      <p>
       Average N-way conflict in L1 per shared memory instruction. A 1-way access has no conflicts and resolves in a single pass. Note: This is a derived metric which can not be collected directly.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L1 Wavefronts Shared Excessive
      </p>
     </td>
     <td>
      <p>
       derived__memory_l1_wavefronts_shared_excessive
      </p>
     </td>
     <td>
      <p>
       Excessive number of wavefronts in L1 from shared memory instructions, because not all not predicated-off threads performed the operation. Note: This is a derived metric which can not be collected directly.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L1 Wavefronts Shared
      </p>
     </td>
     <td>
      <p>
       memory_l1_wavefronts_shared
      </p>
     </td>
     <td>
      <p>
       Number of wavefronts in L1 from shared memory instructions.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L1 Wavefronts Shared Ideal
      </p>
     </td>
     <td>
      <p>
       memory_l1_wavefronts_shared_ideal
      </p>
     </td>
     <td>
      <p>
       Ideal number of wavefronts in L1 from shared memory instructions, assuming each not predicated-off thread performed the operation.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L2 Theoretical Sectors Global Excessive
      </p>
     </td>
     <td>
      <p>
       derived__memory_l2_theoretical_sectors_global_excessive
      </p>
     </td>
     <td>
      <p>
       Excessive theoretical number of sectors requested in L2 from global memory instructions, because not all not predicated-off threads performed the operation. Note: This is a derived metric which can not be collected directly.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L2 Theoretical Sectors Global
      </p>
     </td>
     <td>
      <p>
       memory_l2_theoretical_sectors_global
      </p>
     </td>
     <td>
      <p>
       Theoretical number of sectors requested in L2 from global memory instructions.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L2 Theoretical Sectors Global Ideal
      </p>
     </td>
     <td>
      <p>
       memory_l2_theoretical_sectors_global_ideal
      </p>
     </td>
     <td>
      <p>
       Ideal number of sectors requested in L2 from global memory instructions, assuming each not predicated-off thread performed the operation.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L2 Theoretical Sectors Local
      </p>
     </td>
     <td>
      <p>
       memory_l2_theoretical_sectors_local
      </p>
     </td>
     <td>
      <p>
       Theoretical number of sectors requested in L2 from local memory instructions.
      </p>
     </td>
    </tr>
   </table>
   <p>
    All
    L1/L2 Sectors/Wavefronts/Requests
    metrics give the number of achieved (actually required), ideal, and excessive (achieved - ideal) sectors/wavefronts/requests.
    Ideal
    metrics indicate the number that would needed, given each not predicated-off thread performed the operation of given width.
    Excessive
    metrics indicate the required surplus over the ideal case. Reducing divergence between threads can reduce the excess amount and result in less work for the respective HW units.
   </p>
  </li>
 </ul>
 <p>
  Several of the above metrics on memory operations were renamed in version 2021.2 as follows:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <td>
    <p>
     Old name
    </p>
   </td>
   <td>
    <p>
     New name
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     memory_l2_sectors_global
    </p>
   </td>
   <td>
    <p>
     memory_l2_theoretical_sectors_global
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     memory_l2_sectors_global_ideal
    </p>
   </td>
   <td>
    <p>
     memory_l2_theoretical_sectors_global_ideal
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     memory_l2_sectors_local
    </p>
   </td>
   <td>
    <p>
     memory_l2_theoretical_sectors_local
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     memory_l1_sectors_global
    </p>
   </td>
   <td>
    <p>
     memory_l1_tag_requests_global
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     memory_l1_sectors_shared
    </p>
   </td>
   <td>
    <p>
     memory_l1_wavefronts_shared
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     memory_l1_sectors_shared_ideal
    </p>
   </td>
   <td>
    <p>
     memory_l1_wavefronts_shared_ideal
    </p>
   </td>
  </tr>
 </table>
 <ul>
  <li>
   <p>
    L2 Explicit Evict Policy Metrics
   </p>
   <p>
    Starting with the NVIDIA Ampere architecture the eviction policy of the L2 cache can be tuned to match the kernelâs access pattern. The eviction policy can be either set implicitly for a memory window (for more details see
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html">
     CUaccessProperty
    </a>
    ) or set explicitly per executed memory instruction. If set explicitly, the desired eviction behavior for the cases of an L2 cache hit or miss are passed as input to the instruction. For more details refer to CUDAâs
    <a class="reference external" href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#cache-eviction-priority-hints">
     Cache Eviction Priority Hints
    </a>
    .
   </p>
   <table class="table-no-stripes docutils align-default">
    <tr class="row-odd">
     <td>
      <p>
       Label
      </p>
     </td>
     <td>
      <p>
       Name
      </p>
     </td>
     <td>
      <p>
       Description
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L2 Explicit Evict Policies
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_evict_type
      </p>
     </td>
     <td>
      <p>
       Comma separated list of configured explicit eviction policies. As the policies can be set dynamically at runtime, this list includes all policies that were part of any executed instruction.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L2 Explicit Hit Policy Evict First
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_hitprop_evict_first
      </p>
     </td>
     <td>
      <p>
       Number of times a memory instruction was executed by any warp which had the
       <span class="pre">
        evict_first
       </span>
       policy set in case the access leads to a cache hit in L2. Data cached with this policy will be first in the eviction priority order and will likely be evicted when cache eviction is required. This policy is suitable for streaming data.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L2 Explicit Hit Policy Evict Last
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_hitprop_evict_last
      </p>
     </td>
     <td>
      <p>
       Number of times a memory instruction was executed by any warp which had the
       <span class="pre">
        evict_last
       </span>
       policy set in case the access leads to a cache hit in L2. Data cached with this policy will be last in the eviction priority order and will likely be evicted only after other data with
       <span class="pre">
        evict_normal
       </span>
       or
       <span class="pre">
        evict_first
       </span>
       eviction policy is already evicted. This policy is suitable for data that should remain persistent in cache.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L2 Explicit Hit Policy Evict Normal
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_hitprop_evict_normal
      </p>
     </td>
     <td>
      <p>
       Number of times a memory instruction was executed by any warp which had the
       <span class="pre">
        evict_normal
       </span>
       (default) policy set in case the access leads to a cache hit in L2.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L2 Explicit Hit Policy Evict Normal Demote
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_hitprop_evict_normal_demote
      </p>
     </td>
     <td>
      <p>
       Number of times a memory instruction was executed by any warp which had the
       <span class="pre">
        evict_normal_demote
       </span>
       policy set in case the access leads to a cache hit in L2.
      </p>
     </td>
    </tr>
    <tr class="row-odd">
     <td>
      <p>
       L2 Explicit Miss Policy Evict First
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_missprop_evict_first
      </p>
     </td>
     <td>
      <p>
       Number of times a memory instruction was executed by any warp which had the
       <span class="pre">
        evict_first
       </span>
       policy set in case the access leads to a cache miss in L2. Data cached with this policy will be first in the eviction priority order and will likely be evicted cache eviction is required. This policy is suitable for streaming data.
      </p>
     </td>
    </tr>
    <tr class="row-even">
     <td>
      <p>
       L2 Explicit Miss Policy Evict Normal
      </p>
     </td>
     <td>
      <p>
       smsp__inst_executed_memdesc_explicit_missprop_evict_normal
      </p>
     </td>
     <td>
      <p>
       Number of times a memory instruction was executed by any warp which had the
       <span class="pre">
        evict_normal
       </span>
       (default) policy set in case the access leads to a cache miss in L2.
      </p>
     </td>
    </tr>
   </table>
  </li>
  <li>
   <p>
    Individual Warp Stall Sampling Metrics
   </p>
   <p>
    All
    stall_*
    metrics show the information combined in
    Warp Stall Sampling
    individually. See
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#statistical-sampler">
     Statistical Sampler
    </a>
    for their descriptions.
   </p>
  </li>
  <li>
   <p>
    See the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/CustomizationGuide/index.html#abstract">
     Customization Guide
    </a>
    on how to add additional metrics for this view and the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference">
     Metrics Reference
    </a>
    for further information on available metrics.
   </p>
  </li>
 </ul>
 <p class="title sectiontitle rubric" id="register-dependencies">
  Register Dependencies
 </p>
 <p>
  Dependencies between registers are displayed in the SASS view. When a register is read, all the potential addresses where it could have been written are found. The links between these lines are drawn in the view. All dependencies for registers, predicates, uniform registers and uniform predicates are shown in their respective columns.
 </p>
 <p>
  The picture above shows some dependencies for a simple CUDA kernel. On the first row, which is line 9 of the SASS code, we can see
  writes
  on registers R2 and R3, represented by
  filled triangles pointing to the left
  . These registers are then read on lines 17, 20 and 23, and this is represented by
  regular triangles pointing to the right
  . There are also some lines where both types of triangles are on the same line, which means that a read and a write occured for the same register.
 </p>
 <p>
  Dependencies across source files and functions are not tracked.
 </p>
 <p>
  The Register Dependencies Tracking feature is enabled by default, but can be disabled completely in
  Tools &gt; Options &gt; Profile &gt; Report Source Page &gt; Enable Register Dependencies
  .
 </p>
 <span class="brackets">
  <a class="fn-backref" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id6">
   1
  </a>
 </span>
 <p>
  This metric was previously called Sampling Data (All).
 </p>
 <span class="brackets">
  <a class="fn-backref" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id7">
   2
  </a>
 </span>
 <p>
  This metric was previously called Sampling Data (Not Issued).
 </p>
 <h5>
  Profiles
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiles" title="Permalink to this headline">
   ï
  </a>
 </h5>
 <p>
  The icon next to the
  View
  dropdown can be used to manage
  Source View Profiles
  .
 </p>
 <p>
  This button opens a dialog that shows you the list of saved source view profiles. Such profiles can be created using the
  Create
  button in the dialog. Profiles let you store the column properties of all views in the report to a file. Such properties include column visibility, freeze state, width, order and the selected navigation metric. A saved profile can be applied to any opened report using the
  Apply
  button. This updates the column properties mentioned above from the selected profile in all views.
 </p>
 <p>
  Profiles are useful for configuring views to your preferences, or for a certain use case. Start by choosing metric columns from the
  Column Chooser
  . Next, configure other properties like freezing column, changing width or order and setting a heatmap metric in the
  Navigation
  dropdown before creating the profile. Once a profile is created, you can always use this profile on any opened report to hide all non-required columns or to restore your configured properties. Simply select the profile from the source view profiles dialog and click the
  Apply
  button.
 </p>
 <p>
  Note that the column properties are stored separately for each
  View
  in the profile and when applied, only those views will be updated which are present in the selected profile. You will not see the metric columns that are not available in your report even if those were configured to be visible in the source profile you have applied.
 </p>
 <h5>
  Limitations
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#limitations" title="Permalink to this headline">
   ï
  </a>
 </h5>
 <p class="rubric-h5 rubric" id="range-replay-1">
  Range Replay
 </p>
 <p>
  When using
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#range-replay">
   Range Replay
  </a>
  mode, instruction-level source metrics are not available.
 </p>
 <p class="rubric-h5 rubric" id="graph-profiling">
  Graph Profiling
 </p>
 <p>
  When profiling complete CUDA graphs, instruction-level source metrics are not available.
 </p>
 <h4>
  Context Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#context-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  CPU Call Stack
  section of this report page shows the CPU call stack(s) for the executing CPU thread at the time the kernel was launched. For this information to show up in the profiler report, the option to collect CPU call stacks had to be enabled in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
   Connection Dialog
  </a>
  or using the corresponding NVIDIA Nsight Compute CLI command line parameter.
 </p>
 <p>
  NVIDIA Nsight Compute supports to collect
  native
  CPU call stacks as well as call stacks for
  Python
  applications.
Either or both types can be selected in the
  Activity
  menu of the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
   Connection Dialog
  </a>
  (via the âCPU Call Stack Typesâ option),
or using the NVIDIA Nsight Compute
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#command-line-options-launch">
   CLI command line parameter
  </a>
  âcall-stack-type
  .
In case both types are enabled, a dropdown menu will appear to select the desired call stack type.
 </p>
 <p>
  Note that Python call stack collection requires CPython version 3.9 or later.
 </p>
 <p>
  The
  NVTX State
  section of this report page shows the NVTX context when the kernel was launched. All thread-specific information is with respect to the thread of the kernelâs launch API call. Note that NVTX information is only collected if the profiler is started with NVTX support enabled, either in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
   Connection Dialog
  </a>
  or using the NVIDIA Nsight Compute CLI command line parameter.
 </p>
 <p>
  This page has been renamed from âCall Stack / NVTX Pageâ.
 </p>
 <h4>
  Comments Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#comments-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  Comments
  page aggregates all section comments in a single view and allows the user to edit those comments on any launch instance or section, as well as on the overall report. Comments are persisted with the report. If a section comment is added, the comment icon of the respective section in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
   Details Page
  </a>
  will be highlighted.
 </p>
 <h4>
  Raw Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#raw-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  Raw
  page shows a list of all collected metrics with their units per profiled kernel launch. It can be exported, for example, to CSV format for further analysis. The page features a filter edit to quickly find specific metrics. You can transpose the table of kernels and metrics by using the
  Transpose
  button.
 </p>
 <p>
  If a metric has multiple instance values, the number of instances is shown after the standard value. This metric for example has ten instance values:
  <span class="pre">
   35.48
  </span>
  <span class="pre">
   {10}
  </span>
  . You can select in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options dialog that all instance values should be shown individually or inspect the metric result in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-metric-details">
   Metric Details
  </a>
  tool window.
 </p>
 <h4>
  Session Page
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#session-page" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  This
  Session
  page contains basic information about the report and the machine, as well as device attributes of all devices for which launches were profiled. When switching between launch instances, the respective device attributes are highlighted.
 </p>
 <h3>
  <span class="section-number">
   3.6.3.
  </span>
  Metrics and Units
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#metrics-and-units" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Numeric metric values are shown in various places in the report, including the header and tables and charts on most pages. NVIDIA Nsight Compute supports various ways to display those metrics and their values.
 </p>
 <p>
  When available and applicable to the UI component, metrics are shown along with their unit. This is to make it apparent if a metric represents cycles, threads, bytes/s, and so on. The unit will normally be shown in rectangular brackets, e.g.
  <span class="pre">
   Metric
  </span>
  <span class="pre">
   Name
  </span>
  <span class="pre">
   [bytes]
  </span>
  <span class="pre">
   128
  </span>
  .
 </p>
 <p>
  By default, units are scaled automatically so that metric values are shown with a reasonable order of magnitude. Units are scaled using their SI-factors, i.e. byte-based units are scaled using a factor of 1000 and the prefixes K, M, G, etc. Time-based units are also scaled using a factor of 1000, with the prefixes n, u and m. This scaling can be disabled in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  options.
 </p>
 <p>
  Metrics which could not be collected are shown as
  <span class="pre">
   n/a
  </span>
  and assigned a warning icon. If the metric floating point value is out of the regular range (i.e.
  <span class="pre">
   nan
  </span>
  (Not a number) or
  <span class="pre">
   inf
  </span>
  (infinite)), they are also assigned a warning icon. The exception are metrics for which these values are expected and which are allow-listed internally.
 </p>
 <h2>
  <span class="section-number">
   3.7.
  </span>
  Baselines
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id8" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA Nsight Compute supports diffing collected results across one or multiple reports using Baselines. Each result in any report can be promoted to a baseline. This causes metric values from all results in all reports to show the difference to the baseline. If multiple baselines are selected simultaneously, metric values are compared to the average across all current baselines. Baselines are not stored with a report and are only available as long as the same NVIDIA Nsight Compute instance is open, unless they are saved to a
  <span class="pre">
   ncu-bln
  </span>
  file from the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-baselines">
   Baselines tool window
  </a>
  .
 </p>
 <p>
  <span class="caption-text">
   Profiler report with one baseline
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id9" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Select
  Add Baseline
  to promote the current result in focus to become a baseline. If a baseline is set, most metrics on the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
   Details Page
  </a>
  ,
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-raw-page">
   Raw Page
  </a>
  and
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-summary-page">
   Summary Page
  </a>
  show two values: the current value of the result in focus, and the corresponding value of the baseline or the percentage of change from the corresponding baseline value. (Note that an infinite percentage gain,
  inf%
  , may be displayed when the baseline value for the metric is zero, while the focus value is not.)
 </p>
 <p>
  If multiple baselines are selected, each metric will show the following notation:
 </p>
 <pre>&lt;focus value&gt; (&lt;difference to baselines average [%]&gt;, z=&lt;standard score&gt;@&lt;number of values&gt;)
</pre>
 <p>
  The standard score is the difference between the current value and the average across all baselines, normalized by the standard deviation. If the number of metric values contributing to the standard score equals the number of results (current and all baselines), the @&lt;number of values&gt; notation is omitted.
 </p>
 <p>
  <span class="caption-text">
   Profiler report with multiple baselines
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines-multiple" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Baseline added for the current result in focus is always shown on the top. However, the actual order of added baselines is shown in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-baselines">
   Baselines tool window
  </a>
  .
 </p>
 <p>
  <span class="caption-text">
   Baselines tool window with mutliple baselines
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines-tool-window" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Double-clicking on a baseline name allows the user to edit the displayed name. Edits are committed by pressing
  <span class="pre">
   Enter/Return
  </span>
  or upon loss of focus, and abandoned by pressing
  <span class="pre">
   Esc
  </span>
  . Hovering over the baseline color icon allows the user to remove this specific baseline from the list.
 </p>
 <p>
  Use the
  Clear Baselines
  entry from the dropdown button, the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
   Profile
  </a>
  menu, or the corresponding toolbar button to remove all baselines.
 </p>
 <p>
  Baseline changes can also be made in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-baselines">
   Baselines tool window
  </a>
  .
 </p>
 <h2>
  <span class="section-number">
   3.8.
  </span>
  Standalone Source Viewer
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#standalone-source-viewer" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA Nsight Compute includes a standalone source viewer for
  cubin
  files. This view is identical to the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page">
   Source Page
  </a>
  , except that it wonât include any performance metrics.
 </p>
 <p>
  Cubin files can be opened from the
  File
  &gt;
  Open
  main menu command. The SM Selection dialog will be shown before opening the standalone source view. If available, the SM version present in the file name is pre-selected. For example, if your file name is
  <span class="pre">
   mergeSort.sm_80.cubin
  </span>
  then SM 8.0 will be pre-selected in the dialog. Choose the appropriate SM version from the drop down menu if itâs not included in the file name.
 </p>
 <p>
  <span class="caption-text">
   SM Selection Dialog
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#baselines-multiple-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Click Ok button to open
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#cubin-viewer">
   Standalone Source Viewer
  </a>
  .
 </p>
 <p>
  <span class="caption-text">
   Standalone Source Viewer
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#standalone-cubin-viewer" title="Permalink to this image">
   ï
  </a>
 </p>
 <h2>
  <span class="section-number">
   3.9.
  </span>
  Source Comparison
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-comparison" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Source comparison provides a way to see the source files of two profile results side by side. It enables to quickly identify source differences and understand changes in metric values.
 </p>
 <p>
  To compare two results side by side add one result as a baseline, navigate to the other result, and then click the
  Source Comparison
  button located in the report header.
 </p>
 <p>
  For example, if you want to compare kernel XYZ from report R1 with kernel XYZ from report R2, first open report R1, add the profile result for kernel XYZ as baseline, open report R2, choose kernel XYZ, and then click the Source Comparison button.
 </p>
 <p>
  Source comparison will be shown only with first added baseline result.
 </p>
 <p>
  <span class="caption-text">
   Source Comparison Button
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-comparison-from-header" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  <span class="caption-text">
   Source Comparison
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-comparison-document" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Currently only high-level Source (CUDA-C) view and SASS view are supported for comparison.
 </p>
 <p>
  Navigation to the previous or next difference is supported using the navigation buttons or the keyboard shortcuts
  Ctrl + 1
  and
  Ctrl + 2
  .
 </p>
 <p>
  <span class="caption-text">
   Source Comparison Navigation Buttons
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-comparison-navigation-buttons" title="Permalink to this image">
   ï
  </a>
 </p>
 <h2>
  <span class="section-number">
   3.10.
  </span>
  Occupancy Calculator
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA Nsight Compute provides an
  Occupancy Calculator
  that allows you to compute the multiprocessor occupancy of a GPU for a given CUDA kernel. It offers feature parity to the CUDA Occupancy Calculator
  <a class="reference external" href="http://docs.nvidia.com/cuda/cuda-occupancy-calculator/index.html">
   spreadsheet
  </a>
  .
 </p>
 <p>
  The Occupancy Calculator can be opened directly from a profile report or as a new activity. The occupancy calculator data can be saved to a file using
  File &gt; Save
  . By default, the file uses the
  <span class="pre">
   .ncu-occ
  </span>
  extension. The occupancy calculator file can be opened using
  File &gt; Open File
 </p>
 <ol class="arabic">
  <li>
   <p>
    Launching from the Connection Dialog
   </p>
   <p>
    Select the Occupancy Calculator activity from the connection dialog. You can optionally specify an occupancy calculator data file, which is used to initialize the calculator with the data from the saved file. Click the
    Launch
    button to open the Occupancy Calculator.
   </p>
  </li>
  <li>
   <p>
    Launching from the Profiler Report
   </p>
   <p>
    The Occupancy Calculator can be opened from the
    Profiler Report
    using the calculator button located in the report header or in the header of the
    Occupancy
    section on the
    Detail Page
    .
   </p>
   <p>
    <span class="caption-text">
     Details page header
    </span>
    <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator-from-header" title="Permalink to this image">
     ï
    </a>
   </p>
   <p>
    <span class="caption-text">
     Occupancy section header
    </span>
    <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator-from-section" title="Permalink to this image">
     ï
    </a>
   </p>
  </li>
 </ol>
 <p>
  The user interface consists of an input section as well as tables and graphs that display information about GPU occupancy. To use the calculator, change the input values in the input section, click the
  Apply
  button and examine the tables and graphs.
 </p>
 <h3>
  <span class="section-number">
   3.10.1.
  </span>
  Tables
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tables" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The tables show the occupancy, as well as the number of active threads, warps, and thread blocks per multiprocessor, and the maximum number of active blocks on the GPU.
 </p>
 <p>
  <span class="caption-text">
   Tables
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator-tables-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <h3>
  <span class="section-number">
   3.10.2.
  </span>
  Graphs
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#graphs" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The graphs show the occupancy for your chosen block size as a blue circle, and for all other possible block sizes as a line graph.
 </p>
 <p>
  <span class="caption-text">
   Graphs
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator-graphs-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <h3>
  <span class="section-number">
   3.10.3.
  </span>
  GPU Data
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#gpu-data" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  GPU Data
  shows the properties of all supported devices.
 </p>
 <p>
  <span class="caption-text">
   GPU Data
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator-gpu-data-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <h2>
  <span class="section-number">
   3.11.
  </span>
  Acceleration Structure Viewer
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#acceleration-structure-viewer" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The
  Acceleration Structure Viewer
  allows inspection of acceleration structures built using the OptiX API. In modern ray tracing APIs like OptiX,
  acceleration structures
  are data structures describing the rendered sceneâs geometries that will be intersected when performing ray tracing operations. More information concerning acceleration structures can be found in the
  <a class="reference external" href="https://raytracing-docs.nvidia.com/optix7/guide/index.html#acceleration_structures#acceleration-structures">
   OptiX programming guide
  </a>
  .
 </p>
 <p>
  It is the responsibility of the user to set these up and pass them to the OptiX API which translates them to internal data structures that perform well on modern GPUs. The description created by the user can be very error-prone and it is sometimes hard to understand why the rendered result is not as expected. The
  Acceleration Structure Viewer
  is a component allowing OptiX users to inspect the acceleration structures they build before launching a ray tracing pipeline.
 </p>
 <p>
  The
  Acceleration Structure Viewer
  is opened through a button in the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-resources">
   Resources
  </a>
  window. The button will only be available when the currently viewed resource is
  OptiX: TraversableHandles
  . It opens the currently selected handle.
 </p>
 <p>
  The viewer is multi-paned: it shows a hierarchical view of the acceleration structure on the left, a graphical view of the acceleration structure in the middle, and controls and options on the right. In the hierarchical tree view on the left of the viewer the
  instance acceleration structures (IAS)
  ,
  geometry acceleration structures (GAS)
  , child instances and child geometries are shown. In addition to this, some general properties for each of them is shown such as their primitive count, surface area and size on the device.
 </p>
 <p>
  In the hierarchical view on the left of the
  Acceleration Structure Viewer
  , the following information is displayed where applicable.
 </p>
 <table class="table-no-stripes docutils align-default" id="id17">
  <span class="caption-text">
   Table 4. Acceleration Structure Hierarchical Columns
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id17" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Column
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Name
    </p>
   </td>
   <td>
    <p>
     An identifier for each row in the hierarchy. Click on the check box next to the name to show or hide the selected geometry or hierarchy. Double-click on this entry to jump to the item in the rendering view.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     # Prims
    </p>
   </td>
   <td>
    <p>
     The number of primitives that make up this acceleration structure.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Surface Area
    </p>
   </td>
   <td>
    <p>
     A calculation of the total surface area for the AABB that bounds the particular entry.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Size
    </p>
   </td>
   <td>
    <p>
     The size of the output buffer on the device holding this
     acceleration structure
     .
    </p>
   </td>
  </tr>
 </table>
 <p>
  Performance analysis tools are accessible in the bottom left corner on the main view. These tools help identify potential performance problems that are outlined in the
  <a class="reference external" href="https://developer.nvidia.com/blog/best-practices-using-nvidia-rtx-ray-tracing">
   RTX Ray Tracing Best Practices Guide
  </a>
  . These analysis tools aim to give a broad picture of acceleration structures that may exhibit sub-optimal performance. To find the most optimal solution, profiling and experimentation is recommended but these tools may paint a better picture as to why one structure performs poorly compared to another.
 </p>
 <table class="table-no-stripes docutils align-default" id="id18">
  <span class="caption-text">
   Table 5. Acceleration Structure Analysis Tools
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id18" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Action
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Instance Overlaps
    </p>
   </td>
   <td>
    <p>
     Identifies instance AABBs that overlap with other instances in 3D. Consider merging GASes when instance world-space AABBs overlap significantly to potentially increase performance.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Instance Heatmap
    </p>
   </td>
   <td>
    <p>
     This allows you to set the threshold used by the AABB heatmap rendered in the visualizer.
    </p>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.11.1.
  </span>
  Navigation
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#as-viewer-nav" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Acceleration Structure Viewer
  supports multiple navigation modes. The navigation mode can be changed using the combo box in the camera controls pane, to the right of the rendering pane. The keyboard and mouse bindings for each mode are as follows:
 </p>
 <table class="table-no-stripes docutils align-default" id="id19">
  <span class="caption-text">
   Table 6. Acceleration Structure Key Bindings
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id19" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Binding
    </p>
   </th>
   <th class="head">
    <p>
     Fly Camera
    </p>
   </th>
   <th class="head">
    <p>
     Dolly Camera
    </p>
   </th>
   <th class="head">
    <p>
     Orbit Camera
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     WASD/Arrow Keys
    </p>
   </td>
   <td>
    <p>
     Move forward, backward, left, right
    </p>
   </td>
   <td>
    <p>
     Move forward, backward, left, right
    </p>
   </td>
   <td>
    <p>
     Track (Move up, down, left, right)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     E/Q
    </p>
   </td>
   <td>
    <p>
     Move up/down
    </p>
   </td>
   <td>
    <p>
     Move up/down
    </p>
   </td>
   <td>
    <p>
     n/a
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Z/C
    </p>
   </td>
   <td>
    <p>
     Increase/decrease field of view
    </p>
   </td>
   <td>
    <p>
     Increase/decrease field of view
    </p>
   </td>
   <td>
    <p>
     Increase/decrease field of view
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Shift/Ctrl
    </p>
   </td>
   <td>
    <p>
     Move faster/slower
    </p>
   </td>
   <td>
    <p>
     Move faster/slower
    </p>
   </td>
   <td>
    <p>
     Move faster/slower
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Mousewheel
    </p>
   </td>
   <td>
    <p>
     Zoom in/out
    </p>
   </td>
   <td>
    <p>
     Zoom in/out
    </p>
   </td>
   <td>
    <p>
     Zoom in/out
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     LMB + Drag
    </p>
   </td>
   <td>
    <p>
     Rotate in place
    </p>
   </td>
   <td>
    <p>
     Rotate left/right, move forward/backward
    </p>
   </td>
   <td>
    <p>
     Rotate around the geometry
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     RMB + Drag
    </p>
   </td>
   <td>
    <p>
     Zoom in/out
    </p>
   </td>
   <td>
    <p>
     Rotate in place
    </p>
   </td>
   <td>
    <p>
     Zoom in/out
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     MMB + Drag
    </p>
   </td>
   <td>
    <p>
     Track (Move up, down, left, right)
    </p>
   </td>
   <td>
    <p>
     Track (Move up, down, left, right)
    </p>
   </td>
   <td>
    <p>
     Track (Move up, down, left, right)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Alt
    </p>
   </td>
   <td>
    <p>
     Temporarily switch to Orbit Camera
    </p>
   </td>
   <td>
    <p>
     Temporarily switch to Orbit Camera
    </p>
   </td>
   <td>
    <p>
     n/a
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     F/Double Click
    </p>
   </td>
   <td>
    <p>
     Focus on the selected geometry
    </p>
   </td>
   <td>
    <p>
     Focus on the selected geometry
    </p>
   </td>
   <td>
    <p>
     Focus on the selected geometry
    </p>
   </td>
  </tr>
 </table>
 <p>
  Based on the coordinate system of the input geometry, you may need to change the
  Up Direction
  setting to Z-Axis or the
  Coordinates
  setting to RHS. To reset the camera to its original location, click
  Reset Camera
  .
 </p>
 <p>
  There are also a selection of Camera Controls for fast and precise navigation. To save a position, use the bookmarks controls. Each node within the acceleration structure hierarchy can also be double-clicked to quickly navigate to that location.
 </p>
 <h3>
  <span class="section-number">
   3.11.2.
  </span>
  Filtering and Highlighting
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#filtering-and-highlighting" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The acceleration structure view supports acceleration structure filtering as well as highlighting of data matching particular characteristics. The checkboxes next to each geometry allow users to toggle the rendering of each traversable.
 </p>
 <p>
  Geometry instances can also be selected by clicking on them in the main graphical view. Additionally, right clicking in the main graphical view gives options to hide or show all geometry, hide the selected geometry, or hide all but the selected geometry.
 </p>
 <p>
  Beyond filtering, the view also supports highlight-based identification of geometry specified with particular flags. Checking each highlight option will identify those resources matching that flag, colorizing for easy identification. Clicking an entry in this section will dim all geometry that does
  not
  meet the filter criteria allowing items that match the filter to standout. Selecting multiple filters requires the passing geometry to meet all selected filters (e.g., AND logic). Additionally, the heading text will be updated to reflect the number of items that meet this filter criteria.
 </p>
 <h3>
  <span class="section-number">
   3.11.3.
  </span>
  Rendering Options
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#rendering-options" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Under the highlight controls, additional rendering options are available. These include methods to control the geometry colors and the ability to toggle the drawing of wireframes for meshes and AABBs.
 </p>
 <h3>
  <span class="section-number">
   3.11.4.
  </span>
  Exporting
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#exporting" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The data displayed in the acceleration structure viewer document can be saved to file. Exporting an
  Acceleration Structure Viewer
  document allows for persisting the data you have collected beyond the immediate analysis session. This capability is particularly valuable for comparing different revisions of your geometry or sharing with others. Bookmarks are persisted as well.
 </p>
 <h2>
  <span class="section-number">
   3.12.
  </span>
  Options
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA Nsight Compute options can be accessed via the main menu under
  Tools
  &gt;
  Options
  . All options are persisted on disk and available the next time NVIDIA Nsight Compute is launched. When an option is changed from its default setting, its label will become bold. You can use the
  Restore Defaults
  button to restore all options to their default values.
 </p>
 <p>
  <span class="caption-text">
   Profile options
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <h3>
  <span class="section-number">
   3.12.1.
  </span>
  Profile
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profile" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <table class="table-no-stripes docutils align-default" id="id20">
  <span class="caption-text">
   Table 7. NVIDIA Nsight Compute Profile Options
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id20" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Name
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Values
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Sections Directory
    </p>
   </td>
   <td>
    <p>
     Directory from which to import section files and rules. Relative paths are with respect to the NVIDIA Nsight Compute installation directory.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Include Sub-Directories
    </p>
   </td>
   <td>
    <p>
     Recursively include section files and rules from sub-directories.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Apply Applicable Rules Automatically
    </p>
   </td>
   <td>
    <p>
     Automatically apply active and applicable rules.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Reload Rules Before Applying
    </p>
   </td>
   <td>
    <p>
     Force a rule reload before applying the rule to ensure changes in the rule script are recognized.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Default Report Page
    </p>
   </td>
   <td>
    <p>
     The report page to show when a report is generated or opened.
     Auto
     lets the tool decide the best page to show when opening a report.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Session
      </p>
     </li>
     <li>
      <p>
       Summary
      </p>
     </li>
     <li>
      <p>
       Details
      </p>
     </li>
     <li>
      <p>
       Source
      </p>
     </li>
     <li>
      <p>
       Comments
      </p>
     </li>
     <li>
      <p>
       Call Stack/NVTX
      </p>
     </li>
     <li>
      <p>
       Raw
      </p>
     </li>
     <li>
      <p>
       Auto (default)
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Function Name Mode
    </p>
   </td>
   <td>
    <p>
     Determines how function/kernel names are shown.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Auto (default): each component uses its preferred mode
      </p>
     </li>
     <li>
      <p>
       Demangled: kernel names are shown demangled with all parameters
      </p>
     </li>
     <li>
      <p>
       Function: kernel names are shown with their demangled function name without parameters
      </p>
     </li>
     <li>
      <p>
       Mangled: kernel names are shown with their mangled name, if applicable
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     NVTX Rename Mode
    </p>
   </td>
   <td>
    <p>
     Determines how NVTX information is used for renaming. Range replay results are always renamed when possible.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       None: no renaming
      </p>
     </li>
     <li>
      <p>
       Kernel: kernel names are renamed using the most recent enclosing push/pop range
      </p>
     </li>
     <li>
      <p>
       Resources (default): resources like CPU threads or CUDA contexts and streams are renamed
      </p>
     </li>
     <li>
      <p>
       All: Kernel and Resources
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Show Metrics Aggregation
    </p>
   </td>
   <td>
    <p>
     Show aggregate of all results per each counter metric in the table header. Also, show aggregated value of all randomly selected metrics from summary or raw page table in the bottom-right label.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Rename Demangled Names
    </p>
   </td>
   <td>
    <p>
     Perform auto-simplification on kernel demangled names or import renamed names from a configuration file. See more unique keywords in kernel demangled names first while expanding the column.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Rename Kernels Config Path
    </p>
   </td>
   <td>
    <p>
     Use a configuration file to rename multiple demangled names. Also, export demangled names from the report to the specified file with mappings for renaming them.
    </p>
   </td>
   <td>
    <p>
     ncu-kernel-renames.yaml
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Maximum Baseline Name Length
    </p>
   </td>
   <td>
    <p>
     The maximum length of baseline names.
    </p>
   </td>
   <td>
    <p>
     1..N (Default: 40)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Number of Full Baselines to Display
    </p>
   </td>
   <td>
    <p>
     Number of baselines to display in the report header with all details in addition to the current result or the baseline added for the current result
    </p>
   </td>
   <td>
    <p>
     0..N (Default: 2)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Auto-Convert Metric Units
    </p>
   </td>
   <td>
    <p>
     Auto-adjust displayed metric units and values (e.g. Bytes to KBytes).
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Show Instanced Metric Values
    </p>
   </td>
   <td>
    <p>
     Show the individual values of instanced metrics in tables.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Show Metrics As Floating Point
    </p>
   </td>
   <td>
    <p>
     Show all numeric metrics as floating-point numbers.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Show Knowledge Base Information
    </p>
   </td>
   <td>
    <p>
     Show information from the knowledge base in (metric) tooltips to explain terminology. Note: Nsight Compute needs to be restarted for this option to take effect.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Metrics/Properties
    </p>
   </td>
   <td>
    <p>
     List of metrics and properties to show on the summary page. Comma-separated list of metric entries. Each entry has the format {Label:MetricName}.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Delay Load âSourceâ Page
    </p>
   </td>
   <td>
    <p>
     Delays loading the content of the report page until the page becomes visible. Avoids processing costs and memory overhead until the report page is opened.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Show Single File For Multi-File Sources
    </p>
   </td>
   <td>
    <p>
     Shows a single file in each Source page view, even for multi-file sources.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Show Only Executed Functions
    </p>
   </td>
   <td>
    <p>
     Shows only executed functions in the source page views. Disabling this can impact performance.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Auto-Resolve Remote Source Files
    </p>
   </td>
   <td>
    <p>
     Automatically try to resolve remote source files on the source page (e.g. via SSH) if the connection is still registered.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Enable Register Dependencies
    </p>
   </td>
   <td>
    <p>
     Track dependencies between SASS registers/predicates and display them in the SASS view.
    </p>
   </td>
   <td>
    <p>
     Yes (Default)/No
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Kernel Analysis Size Threshold (KB)
    </p>
   </td>
   <td>
    <p>
     Enable SASS flow graph analysis for functions below this threshold. SASS analysis is required for Live Register and Register Dependency information. Set to -1 to enable analysis for all functions.
    </p>
   </td>
   <td>
    <p>
     -1..N (Default: 1024)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Enable ELF Verification
    </p>
   </td>
   <td>
    <p>
     Enable ELF (cubin) verification to run every time before SASS analysis. This should only be enabled when working with applications compiled before CUDA 11.0 or when encountering source page issues.
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     API Call History
    </p>
   </td>
   <td>
    <p>
     Number of recent API calls shown in API Stream View.
    </p>
   </td>
   <td>
    <p>
     1..N (Default: 100)
    </p>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.12.2.
  </span>
  Environment
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#environment" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <table class="table-no-stripes docutils align-default" id="id21">
  <span class="caption-text">
   Table 8. NVIDIA Nsight Compute Environment Options
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id21" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Name
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Values
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Color Theme
    </p>
   </td>
   <td>
    <p>
     The currently selected UI color theme.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Dark (Default)
      </p>
     </li>
     <li>
      <p>
       Light
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Mixed DPI Scaling
    </p>
   </td>
   <td>
    <p>
     Disable Mixed DPI Scaling if unwanted artifacts are detected when using monitors with different DPIs.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Auto (Default)
      </p>
     </li>
     <li>
      <p>
       Off
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Default Document Folder
    </p>
   </td>
   <td>
    <p>
     Directory where documents unassociated with a project will be saved.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     At Startup
    </p>
   </td>
   <td>
    <p>
     What to do when NVIDIA Nsight Compute is launched.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Show welcome page (Default)
      </p>
     </li>
     <li>
      <p>
       Show quick launch dialog
      </p>
     </li>
     <li>
      <p>
       Load last project
      </p>
     </li>
     <li>
      <p>
       Show empty environment
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Show version update notifications
    </p>
   </td>
   <td>
    <p>
     Show notifications when a new version of this product is available.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Yes (Default)
      </p>
     </li>
     <li>
      <p>
       No
      </p>
     </li>
    </ul>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.12.3.
  </span>
  Connection
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Connection properties are grouped into
  Target Connection Options
  and
  Host Connection Properties
  .
 </p>
 <h4>
  Target Connection Properties
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#target-connection-properties" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  Target Connection Properties
  determine how the host connects to the target application during an
  Interactive Profile Activity
  . This connection is used to transfer profile information to the host during the profile session.
 </p>
 <table class="table-no-stripes docutils align-default" id="id22">
  <span class="caption-text">
   Table 9. NVIDIA Nsight Compute Target Connection Properties
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id22" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Name
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Values
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Base Port
    </p>
   </td>
   <td>
    <p>
     Base port used to establish a connection from the host to the target application during an
     Interactive Profile
     activity (both local and remote).
    </p>
   </td>
   <td>
    <p>
     1-65535 (Default: 49152)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Maximum Ports
    </p>
   </td>
   <td>
    <p>
     Maximum number of ports to try (starting from
     Base Port
     ) when attempting to connect to the target application.
    </p>
   </td>
   <td>
    <p>
     2-65534 (Default: 64)
    </p>
   </td>
  </tr>
 </table>
 <h4>
  Host Connection Properties
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#host-connection-properties" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  The
  Host Connection Properties
  determine how the command line profiler will connect to the host application during a
  Profile Activity
  . This connection is used to transfer profile information to the host during the profile session.
 </p>
 <table class="table-no-stripes docutils align-default" id="id23">
  <span class="caption-text">
   Table 10. NVIDIA Nsight Compute Host Connection Options
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id23" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Name
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Values
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Base Port
    </p>
   </td>
   <td>
    <p>
     Base port used to establish a connection from the command line profiler to the host application during a
     Profile
     activity (both local and remote).
    </p>
   </td>
   <td>
    <p>
     1-65535 (Default: 50152)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Maximum Ports
    </p>
   </td>
   <td>
    <p>
     Maximum number of ports to try (starting from
     Base Port
     ) when attempting to connect to the host application.
    </p>
   </td>
   <td>
    <p>
     1-100 (Default: 10)
    </p>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.12.4.
  </span>
  Source Lookup
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#source-lookup" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <table class="table-no-stripes docutils align-default" id="id24">
  <span class="caption-text">
   Table 11. NVIDIA Nsight Compute Source Lookup Options
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id24" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Name
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Values
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Program Source Locations
    </p>
   </td>
   <td>
    <p>
     Set program source search paths. These paths are used to resolve CUDA-C source files on the Source page if the respective file cannot be found in its original location. Files which cannot be found are marked with a
     File Not Found
     error. See the
     Ignore File Properties
     option for files that are found but donât match.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Ignore File Properties
    </p>
   </td>
   <td>
    <p>
     Ignore file properties (e.g. timestamp, size) for source resolution. If this is disabled, all file properties like modification timestamp and file size are checked against the information stored by the compiler in the application during compilation. If a file with the same name exists on a source lookup path, but not all properties match, it wonât be used for resolution (and a
     File Mismatch
     error will be shown).
    </p>
   </td>
   <td>
    <p>
     Yes/No (Default)
    </p>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.12.5.
  </span>
  Send Feedback
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#send-feedback" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <table class="table-no-stripes docutils align-default" id="id25">
  <span class="caption-text">
   Table 12. NVIDIA Nsight Compute Send Feedback Options
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#id25" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Name
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Values
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Collect Usage and Platform Data
    </p>
   </td>
   <td>
    <p>
     Choose whether or not you wish to allow NVIDIA Nsight Compute to collect usage and platform data.
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Yes
      </p>
     </li>
     <li>
      <p>
       No (Default)
      </p>
     </li>
    </ul>
   </td>
  </tr>
 </table>
 <h2>
  <span class="section-number">
   3.13.
  </span>
  Projects
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA Nsight Compute uses
  Project Files
  to group and organize profiling reports. At any given time, only one project can be open in NVIDIA Nsight Compute. Collected reports are automatically assigned to the current project. Reports stored on disk can be assigned to a project at any time. In addition to profiling reports, related files such as notes or source code can be associated with the project for future reference.
 </p>
 <p>
  Note that only references to reports or other files are saved in the project file. Those references can become invalid, for example when associated files are deleted, removed or not available on the current system, in case the project file was moved itself.
 </p>
 <p>
  NVIDIA Nsight Compute uses the
  <span class="pre">
   ncu-proj
  </span>
  file extension for project files.
 </p>
 <p>
  When no custom project is current, a
  default project
  is used to store e.g. the current
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
   Connection Dialog
  </a>
  entries. To remove all information from the default project, you must close NVIDIA Nsight Compute and then delete the file from disk.
 </p>
 <ul class="simple">
  <li>
   <p>
    On Windows, the file is located at
    <span class="pre">
     &lt;USER&gt;\AppData\Local\NVIDIA
    </span>
    <span class="pre">
     Corporation\NVIDIA
    </span>
    <span class="pre">
     Nsight
    </span>
    <span class="pre">
     Compute\
    </span>
   </p>
  </li>
  <li>
   <p>
    On Linux, the file is located at
    <span class="pre">
     &lt;USER&gt;/.local/share/NVIDIA
    </span>
    <span class="pre">
     Corporation/NVIDIA
    </span>
    <span class="pre">
     Nsight
    </span>
    <span class="pre">
     Compute/
    </span>
   </p>
  </li>
  <li>
   <p>
    On MacOSX, the file is located at
    <span class="pre">
     &lt;USER&gt;/Library/Application
    </span>
    <span class="pre">
     Support/NVIDIA
    </span>
    <span class="pre">
     Corporation/NVIDIA
    </span>
    <span class="pre">
     Nsight
    </span>
    <span class="pre">
     Compute/
    </span>
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.13.1.
  </span>
  Project Dialogs
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#project-dialogs" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  New Project
 </p>
 <p>
  Creates a new project. The project must be given a name, which will also be used for the project file. You can select the location where the project file should be saved on disk. Select whether a new directory with the project name should be created in that location.
 </p>
 <h3>
  <span class="section-number">
   3.13.2.
  </span>
  Project Explorer
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#project-explorer" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Project Explorer
  window allows you to inspect and manage the current project. It shows the project name as well as all
  Items
  (profile reports and other files) associated with it. Right-click on any entry to see further actions, such as adding, removing or grouping items. Type in the
  Search project
  toolbar at the top to filter the currently shown entries.
 </p>
 <p>
  <span class="caption-text">
   Project Explorer
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects-explorer-fig" title="Permalink to this image">
   ï
  </a>
 </p>
 <h2>
  <span class="section-number">
   3.14.
  </span>
  Visual Profiler Transition Guide
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#visual-profiler-transition-guide" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This guide provides tips for moving from Visual Profiler to NVIDIA Nsight Compute. NVIDIA Nsight Compute tries to provide as much parity as possible with Visual Profilerâs kernel profiling features, but some functionality is now covered by different tools.
 </p>
 <h3>
  <span class="section-number">
   3.14.1.
  </span>
  Trace
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#trace" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  NVIDIA Nsight Compute does not support tracing GPU or API activities on an accurate timeline. This functionality is covered by
  <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
   NVIDIA Nsight Systems
  </a>
  . In the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#quick-start-interactive">
   Interactive Profile Activity
  </a>
  , the
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
   API Stream
  </a>
  tool window provides a stream of recent API calls on each thread. However, since all tracked API calls are serialized by default, it does not collect accurate timestamps.
 </p>
 <h3>
  <span class="section-number">
   3.14.2.
  </span>
  Sessions
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#sessions" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Instead of sessions, NVIDIA Nsight Compute uses
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects">
   Projects
  </a>
  to launch and gather connection details and collected reports.
 </p>
 <ul>
  <li>
   <p>
    Executable and Import Sessions
   </p>
   <p>
    Use the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#projects-explorer">
     Project Explorer
    </a>
    or the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#main-menu">
     Main Menu
    </a>
    to create a new project. Reports collected from the command line, i.e. using NVIDIA Nsight Compute CLI, can be opened directly using the main menu. In addition, you can use the Project Explorer to associate existing reports as well as any other artifacts such as executables, notes, etc., with the project. Note that those associations are only references; in other words, moving or deleting the project file on disk will not update its artifacts.
   </p>
   <p>
    nvprof or command-line profiler output files, as well as Visual Profiler sessions, cannot be imported into NVIDIA Nsight Compute.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.14.3.
  </span>
  Timeline
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#timeline" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Since trace analysis is now covered by Nsight Systems, NVIDIA Nsight Compute does not provide views of the application timeline. The
  <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-api-stream">
   API Stream
  </a>
  tool window does show a per-thread stream of the last captured CUDA API calls. However, those are serialized and do not maintain runtime concurrency or provide accurate timing information.
 </p>
 <h3>
  <span class="section-number">
   3.14.4.
  </span>
  Analysis
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#analysis" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ul>
  <li>
   <p>
    Guided Analysis
   </p>
   <p>
    All trace-based analysis is now covered by
    <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
     NVIDIA Nsight Systems
    </a>
    . This means that NVIDIA Nsight Compute does not include analysis regarding concurrent CUDA streams or (for example) UVM events. For per-kernel analysis, NVIDIA Nsight Compute provides recommendations based on collected performance data on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
     Details Page
    </a>
    . These rules currently require you to collect the required metrics via their sections up front, and do not support partial on-demand profiling.
   </p>
   <p>
    To use the rule-based recommendations, enable the respective rules in the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#tool-window-sections-info">
     Metric Selection
    </a>
    . Before profiling, enable
    Apply Rules
    in the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#options-profile">
     Profile Options
    </a>
    , or click the
    Apply Rules
    button in the report afterward.
   </p>
  </li>
  <li>
   <p>
    Unguided Analysis
   </p>
   <p>
    All trace-based analysis is now covered by Nsight Systems. For per-kernel analysis, Python-based rules provide analysis and recommendations. See
    Guided Analysis
    above for more details.
   </p>
  </li>
  <li>
   <p>
    PC Sampling View
   </p>
   <p>
    Source-correlated PC sampling information can now be viewed in the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page">
     Source Page
    </a>
    . Aggregated warp states are shown on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
     Details Page
    </a>
    in the
    Warp State Statistics
    section.
   </p>
  </li>
  <li>
   <p>
    Memory Statistics
   </p>
   <p>
    Memory Statistics are located on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
     Details Page
    </a>
    . Enable the
    Memory Workload Analysis
    sections to collect the respective information.
   </p>
  </li>
  <li>
   <p>
    NVLink View
   </p>
   <p>
    NVLink topology diagram and NVLink property table are located on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
     Details Page
    </a>
    . Enable the
    NVLink Topology
    and
    NVLink Table
    sections to collect the respective information.
   </p>
   <p>
    Refer to the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/ReleaseNotes/index.html#known-issues">
     Known Issues
    </a>
    section for the limitations related to NVLink.
   </p>
  </li>
  <li>
   <p>
    Source-Disassembly View
   </p>
   <p>
    Source correlated with PTX and SASS disassembly is shown on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page">
     Source Page
    </a>
    . Which information is available depends on your applicationâs compilation/JIT flags.
   </p>
  </li>
  <li>
   <p>
    GPU Details View
   </p>
   <p>
    NVIDIA Nsight Compute does not automatically collect data for each executed kernel, and it does not collect any data for device-side memory copies. Summary information for all profiled kernel launches is shown on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-summary-page">
     Summary Page
    </a>
    . Comprehensive information on all collected metrics for all profiled kernel launches is shown on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-raw-page">
     Raw Page
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    CPU Details View
   </p>
   <p>
    CPU callstack sampling is now covered by
    <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
     NVIDIA Nsight Systems
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    OpenACC Details View
   </p>
   <p>
    OpenACC performance analysis with NVIDIA Nsight Compute is available to limited extent. OpenACC parallel regions are not explicitly recognized, but CUDA kernels generated by the OpenACC compiler can be profiled as regular CUDA kernels. See the
    <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
     NVIDIA Nsight Systems
    </a>
    release notes to check its latest support status.
   </p>
  </li>
  <li>
   <p>
    OpenMP Details View
   </p>
   <p>
    OpenMP performance analysis is not supported by NVIDIA Nsight Compute. See the
    <a class="reference external" href="https://developer.nvidia.com/nsight-systems">
     NVIDIA Nsight Systems
    </a>
    release notes to check its latest support status.
   </p>
  </li>
  <li>
   <p>
    Properties View
   </p>
   <p>
    NVIDIA Nsight Compute does not collect CUDA API and GPU activities and their properties. Performance data for profiled kernel launches is reported (for example) on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-details-page">
     Details Page
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    Console View
   </p>
   <p>
    NVIDIA Nsight Compute does not currently collect stdout/stderr application output.
   </p>
  </li>
  <li>
   <p>
    Settings View
   </p>
   <p>
    Application launch settings are specified in the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#connection-dialog">
     Connection Dialog
    </a>
    . For reports collected from the UI, launch settings can be inspected on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-session-page">
     Session Page
    </a>
    after profiling.
   </p>
  </li>
  <li>
   <p>
    CPU Source View
   </p>
   <p>
    Source for CPU-only APIs is not available. Source for profiled GPU kernel launches is shown on the
    <a class="reference external" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#profiler-report-source-page">
     Source Page
    </a>
    .
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.14.5.
  </span>
  Command Line Arguments
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#command-line-arguments" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Please execute ncu-ui with the
  <span class="pre">
   -h
  </span>
  parameter within a shell window to see the currently supported command line arguments for the NVIDIA Nsight Compute UI.
 </p>
 <p>
  To open a collected profile report with ncu-ui, simply pass the path to the report file as a parameter to the shell command.
 </p>
 <h2>
  <span class="section-number">
   3.15.
  </span>
  Visual Studio Integration Guide
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#visual-studio-integration-guide" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This guide provides information on using NVIDIA Nsight Compute within Microsoft Visual Studio, using the
  <a class="reference external" href="https://developer.nvidia.com/nsight-tools-visual-studio-integration">
   NVIDIA Nsight Integration
  </a>
  Â Visual Studio extension, allowing for a seamless development workflow.
 </p>
 <h3>
  <span class="section-number">
   3.15.1.
  </span>
  Visual Studio Integration Overview
  <a class="headerlink" href="https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#visual-studio-integration-overview" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  NVIDIA Nsight Integration is a Visual Studio extension that allows you to access the power of NVIDIA Nsight Compute from within Visual Studio.
 </p>
 <p>
  When NVIDIA Nsight Compute is installed along with NVIDIA Nsight Integration, NVIDIA Nsight Compute activities will appear under the NVIDIAÂ âNsightâ menu in the Visual Studio menu bar. These activities launch NVIDIA Nsight Compute with the current project settings and executable.
 </p>
 <p>
  For more information about using NVIDIA Nsight Compute from within Visual Studio, please visit
 </p>
 <ul class="simple">
  <li>
   <p>
    <a class="reference external" href="https://developer.nvidia.com/nsight-tools-visual-studio-integration">
     NVIDIA Nsight Integration Overview
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-vs-integration/index.html">
     NVIDIA Nsight Integration User Guide
    </a>
   </p>
  </li>
 </ul>
 <p class="rubric-h1 rubric">
  Notices
 </p>
 <p class="rubric-h2 rubric">
  Notices
 </p>
 <p>
  ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, âMATERIALSâ) ARE BEING PROVIDED âAS IS.â NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.
 </p>
 <p>
  Information furnished is believed to be accurate and reliable. However, NVIDIA Corporation assumes no responsibility for the consequences of use of such information or for any infringement of patents or other rights of third parties that may result from its use. No license is granted by implication of otherwise under any patent rights of NVIDIA Corporation. Specifications mentioned in this publication are subject to change without notice. This publication supersedes and replaces all other information previously supplied. NVIDIA Corporation products are not authorized as critical components in life support devices or systems without express written approval of NVIDIA Corporation.
 </p>
 <p class="rubric-h2 rubric">
  Trademarks
 </p>
 <p>
  NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.
 </p>
 <p>
  © Copyright 2018-2024, NVIDIA Corporation &amp; Affiliates. All rights reserved.
  <span class="lastupdated">
   Last updated on Jun 03, 2024.
  </span>
 </p>
</body>
</body></html>