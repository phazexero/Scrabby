<html><head><title>CUDA Runtime API :: CUDA Toolkit Documentation</title></head><body><body>
 <span id="company">
  NVIDIA
 </span>
 <span id="site-title">
  CUDA Toolkit Documentation
 </span>
 Search In:
 Entire Site
 Just This Document
 clear search
 search
 <a href="https://docs.nvidia.com/cuda/index.html" title="The root of the site.">
  CUDA Toolkit 
                  
                  
                  v12.5.1
 </a>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html" title="CUDA Runtime API">
  CUDA Runtime API
 </a>
 <ul>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/driver-vs-runtime-api.html#driver-vs-runtime-api">
    1.Â Difference between the driver and runtime APIs
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior">
    2.Â API synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior">
    3.Â Stream synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/graphs-thread-safety.html#graphs-thread-safety">
    4.Â Graph object thread safety
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/version-mixing-rules.html#version-mixing-rules">
    5.Â Rules for version mixing
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/modules.html#modules">
    6.Â Modules
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE">
      6.1.Â Device Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE__DEPRECATED.html#group__CUDART__DEVICE__DEPRECATED">
      6.2.Â Device Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__THREAD__DEPRECATED.html#group__CUDART__THREAD__DEPRECATED">
      6.3.Â Thread Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html#group__CUDART__ERROR">
      6.4.Â Error Handling
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM">
      6.5.Â Stream Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT">
      6.6.Â Event Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP">
      6.7.Â External Resource Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION">
      6.8.Â Execution Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html#group__CUDART__EXECUTION__DEPRECATED">
      6.9.Â Execution Control [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY">
      6.10.Â Occupancy
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY">
      6.11.Â Memory Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__DEPRECATED.html#group__CUDART__MEMORY__DEPRECATED">
      6.12.Â Memory Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS">
      6.13.Â Stream Ordered Memory Allocator
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__UNIFIED.html#group__CUDART__UNIFIED">
      6.14.Â Unified Addressing
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER">
      6.15.Â Peer Device Memory Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL.html#group__CUDART__OPENGL">
      6.16.Â OpenGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL__DEPRECATED.html#group__CUDART__OPENGL__DEPRECATED">
      6.17.Â OpenGL Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9.html#group__CUDART__D3D9">
      6.18.Â Direct3D 9 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9__DEPRECATED.html#group__CUDART__D3D9__DEPRECATED">
      6.19.Â Direct3D 9 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10.html#group__CUDART__D3D10">
      6.20.Â Direct3D 10 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10__DEPRECATED.html#group__CUDART__D3D10__DEPRECATED">
      6.21.Â Direct3D 10 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11.html#group__CUDART__D3D11">
      6.22.Â Direct3D 11 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11__DEPRECATED.html#group__CUDART__D3D11__DEPRECATED">
      6.23.Â Direct3D 11 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__VDPAU.html#group__CUDART__VDPAU">
      6.24.Â VDPAU Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EGL.html#group__CUDART__EGL">
      6.25.Â EGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__INTEROP.html#group__CUDART__INTEROP">
      6.26.Â Graphics Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TEXTURE__OBJECT.html#group__CUDART__TEXTURE__OBJECT">
      6.27.Â Texture Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__SURFACE__OBJECT.html#group__CUDART__SURFACE__OBJECT">
      6.28.Â Surface Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART____VERSION.html#group__CUDART____VERSION">
      6.29.Â Version Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">
      6.30.Â Graph Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER__ENTRY__POINT.html#group__CUDART__DRIVER__ENTRY__POINT">
      6.31.Â Driver Entry Point Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL">
      6.32.Â C++ API Routines
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER.html#group__CUDART__DRIVER">
      6.33.Â Interactions with the CUDA Driver API
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER">
      6.34.Â Profiler Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES">
      6.35.Â Data types used by CUDA Runtime
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/annotated.html#annotated">
    7.Â Data Structures
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/class____cudaOccupancyB2DHelper.html#class____cudaOccupancyB2DHelper">
      7.1.Â __cudaOccupancyB2DHelper
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html#structcudaAccessPolicyWindow">
      7.2.Â cudaAccessPolicyWindow
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements">
      7.3.Â cudaArrayMemoryRequirements
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties">
      7.4.Â cudaArraySparseProperties
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAsyncNotificationInfo__t.html#structcudaAsyncNotificationInfo__t">
      7.5.Â cudaAsyncNotificationInfo_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc">
      7.6.Â cudaChannelFormatDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChildGraphNodeParams.html#structcudaChildGraphNodeParams">
      7.7.Â cudaChildGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaConditionalNodeParams.html#structcudaConditionalNodeParams">
      7.8.Â cudaConditionalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp">
      7.9.Â cudaDeviceProp
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglFrame.html#structcudaEglFrame">
      7.10.Â cudaEglFrame
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglPlaneDesc.html#structcudaEglPlaneDesc">
      7.11.Â cudaEglPlaneDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventRecordNodeParams.html#structcudaEventRecordNodeParams">
      7.12.Â cudaEventRecordNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventWaitNodeParams.html#structcudaEventWaitNodeParams">
      7.13.Â cudaEventWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent">
      7.14.Â cudaExtent
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryBufferDesc.html#structcudaExternalMemoryBufferDesc">
      7.15.Â cudaExternalMemoryBufferDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryHandleDesc.html#structcudaExternalMemoryHandleDesc">
      7.16.Â cudaExternalMemoryHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryMipmappedArrayDesc.html#structcudaExternalMemoryMipmappedArrayDesc">
      7.17.Â cudaExternalMemoryMipmappedArrayDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreHandleDesc.html#structcudaExternalSemaphoreHandleDesc">
      7.18.Â cudaExternalSemaphoreHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParams.html#structcudaExternalSemaphoreSignalNodeParams">
      7.19.Â cudaExternalSemaphoreSignalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParamsV2.html#structcudaExternalSemaphoreSignalNodeParamsV2">
      7.20.Â cudaExternalSemaphoreSignalNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams.html#structcudaExternalSemaphoreSignalParams">
      7.21.Â cudaExternalSemaphoreSignalParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams__v1.html#structcudaExternalSemaphoreSignalParams__v1">
      7.22.Â cudaExternalSemaphoreSignalParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParams.html#structcudaExternalSemaphoreWaitNodeParams">
      7.23.Â cudaExternalSemaphoreWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParamsV2.html#structcudaExternalSemaphoreWaitNodeParamsV2">
      7.24.Â cudaExternalSemaphoreWaitNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams.html#structcudaExternalSemaphoreWaitParams">
      7.25.Â cudaExternalSemaphoreWaitParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams__v1.html#structcudaExternalSemaphoreWaitParams__v1">
      7.26.Â cudaExternalSemaphoreWaitParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaFuncAttributes.html#structcudaFuncAttributes">
      7.27.Â cudaFuncAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphEdgeData.html#structcudaGraphEdgeData">
      7.28.Â cudaGraphEdgeData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphExecUpdateResultInfo.html#structcudaGraphExecUpdateResultInfo">
      7.29.Â cudaGraphExecUpdateResultInfo
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphInstantiateParams.html#structcudaGraphInstantiateParams">
      7.30.Â cudaGraphInstantiateParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphKernelNodeUpdate.html#structcudaGraphKernelNodeUpdate">
      7.31.Â cudaGraphKernelNodeUpdate
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphNodeParams.html#structcudaGraphNodeParams">
      7.32.Â cudaGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParams.html#structcudaHostNodeParams">
      7.33.Â cudaHostNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParamsV2.html#structcudaHostNodeParamsV2">
      7.34.Â cudaHostNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t">
      7.35.Â cudaIpcEventHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t">
      7.36.Â cudaIpcMemHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParams.html#structcudaKernelNodeParams">
      7.37.Â cudaKernelNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParamsV2.html#structcudaKernelNodeParamsV2">
      7.38.Â cudaKernelNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchAttribute.html#structcudaLaunchAttribute">
      7.39.Â cudaLaunchAttribute
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/unioncudaLaunchAttributeValue.html#unioncudaLaunchAttributeValue">
      7.40.Â cudaLaunchAttributeValue
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t">
      7.41.Â cudaLaunchConfig_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchMemSyncDomainMap.html#structcudaLaunchMemSyncDomainMap">
      7.42.Â cudaLaunchMemSyncDomainMap
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchParams.html#structcudaLaunchParams">
      7.43.Â cudaLaunchParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAccessDesc.html#structcudaMemAccessDesc">
      7.44.Â cudaMemAccessDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParams.html#structcudaMemAllocNodeParams">
      7.45.Â cudaMemAllocNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParamsV2.html#structcudaMemAllocNodeParamsV2">
      7.46.Â cudaMemAllocNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms">
      7.47.Â cudaMemcpy3DParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms">
      7.48.Â cudaMemcpy3DPeerParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpyNodeParams.html#structcudaMemcpyNodeParams">
      7.49.Â cudaMemcpyNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemFreeNodeParams.html#structcudaMemFreeNodeParams">
      7.50.Â cudaMemFreeNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation">
      7.51.Â cudaMemLocation
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps">
      7.52.Â cudaMemPoolProps
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData">
      7.53.Â cudaMemPoolPtrExportData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParams.html#structcudaMemsetParams">
      7.54.Â cudaMemsetParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParamsV2.html#structcudaMemsetParamsV2">
      7.55.Â cudaMemsetParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr">
      7.56.Â cudaPitchedPtr
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPointerAttributes.html#structcudaPointerAttributes">
      7.57.Â cudaPointerAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos">
      7.58.Â cudaPos
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceDesc.html#structcudaResourceDesc">
      7.59.Â cudaResourceDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceViewDesc.html#structcudaResourceViewDesc">
      7.60.Â cudaResourceViewDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaTextureDesc.html#structcudaTextureDesc">
      7.61.Â cudaTextureDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structCUuuid__st.html#structCUuuid__st">
      7.62.Â CUuuid_st
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/functions.html#functions">
    8.Â Data Fields
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated">
    9.Â Deprecated List
   </a>
  </li>
 </ul>
 <h2>
  Search Results
 </h2>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html" shape="rect">
  &lt; Previous
 </a>
 |
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html" shape="rect">
  Next &gt;
 </a>
 CUDA Runtime API
                  (
 <a href="https://docs.nvidia.com/cuda/pdf/CUDA_Runtime_API.pdf">
  PDF
 </a>
 )
                  -
                   
                  
                  
                  v12.5.1
                  (
 <a href="https://developer.nvidia.com/cuda-toolkit-archive">
  older
 </a>
 )
                  -
                  Last updated July 1, 2024
                  -
 <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA%20Toolkit%20Documentation%20Feedback:%20CUDA%20Runtime%20API">
  Send Feedback
 </a>
 <a name="group__CUDART__OCCUPANCY" shape="rect">
  <!-- -->
 </a>
 <h2 class="topictitle2 cppModule">
  6.10.Â Occupancy
 </h2>
 <p>
  This section describes the occupancy calculation functions of the CUDA runtime application programming interface.
 </p>
 <p class="p">
  Besides the occupancy calculator functions (
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" shape="rect" title="Returns occupancy for a device function.">
   cudaOccupancyMaxActiveBlocksPerMultiprocessor
  </a>
  and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" shape="rect" title="Returns occupancy for a device function with the specified flags.">
   cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
  </a>
  ), there are also C++ only occupancy-based launch configuration functions documented in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL" shape="rect" title="C++-style interface built on top of CUDA runtime API.">
   C++ API Routines
  </a>
  module.
 </p>
 <p class="p">
  See
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSize ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" shape="rect" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags.">
   cudaOccupancyMaxPotentialBlockSize ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gc5896a36586821e8bb51d4e837b55bb6" shape="rect" title="Returns dynamic shared memory available per block when launching numBlocks blocks on SM.">
   cudaOccupancyAvailableDynamicSMemPerBlock ( C++ API)
  </a>
  ,
 </p>
 <h3 class="fake_sectiontitle member_header">
  Functions
 </h3>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY_1g3017bec8ddb4951e89f6ba4c259bb091" shape="rect">
   cudaOccupancyAvailableDynamicSMemPerBlock
  </a>
  (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dynamicSmemSize
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numBlocks
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   blockSize
  </span>
  )
 </span>
 <span class="desc">
  Returns dynamic shared memory available per block when launching
  numBlocks
  blocks on SM.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY_1ge99bee88c427b3f8ffa8ec3e43fd877d" shape="rect">
   cudaOccupancyMaxActiveBlocksPerMultiprocessor
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numBlocks
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   blockSize
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dynamicSMemSize
  </span>
  )
 </span>
 <span class="desc">
  Returns occupancy for a device function.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY_1ge2255f3637784624ea99a6d3c7885ca0" shape="rect">
   cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numBlocks
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   blockSize
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dynamicSMemSize
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Returns occupancy for a device function with the specified flags.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY_1gd4322b730e5b2c5a9a93f0a22c93ab03" shape="rect">
   cudaOccupancyMaxActiveClusters
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numClusters
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t" shape="rect" title="">
   cudaLaunchConfig_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   launchConfig
  </span>
  )
 </span>
 <span class="desc">
  Given the kernel function (
  func
  ) and launch configuration (
  config
  ), return the maximum number of clusters that could co-exist on the target device in
  *numClusters
  .
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY_1g6d65e4932b9ab03d6544e37f111d7ec9" shape="rect">
   cudaOccupancyMaxPotentialClusterSize
  </a>
  (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   clusterSize
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t" shape="rect" title="">
   cudaLaunchConfig_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   launchConfig
  </span>
  )
 </span>
 <span class="desc">
  Given the kernel function (
  func
  ) and launch configuration (
  config
  ), return the maximum cluster size in
  *clusterSize
  .
 </span>
 <h3 class="sectiontitle">
  Functions
 </h3>
 <a id="group__CUDART__OCCUPANCY_1g3017bec8ddb4951e89f6ba4c259bb091" name="group__CUDART__OCCUPANCY_1g3017bec8ddb4951e89f6ba4c259bb091" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaOccupancyAvailableDynamicSMemPerBlock (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dynamicSmemSize
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numBlocks
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   blockSize
  </span>
  )
 </span>
 Returns dynamic shared memory available per block when launching
 numBlocks
 blocks on SM.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dynamicSmemSize
 </span>
 - Returned maximum dynamic shared memory
 <span class="keyword keyword apiItemName">
  func
 </span>
 - Kernel function for which occupancy is calculated
 <span class="keyword keyword apiItemName">
  numBlocks
 </span>
 - Number of blocks to fit on SM
 <span class="keyword keyword apiItemName">
  blockSize
 </span>
 - Size of the block
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038b6af535e7e53d3f21e2437e8977b8c2e" shape="rect">
   cudaErrorInvalidDeviceFunction
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *dynamicSmemSize
  the maximum size of dynamic shared memory to allow
  numBlocks
  blocks per SM.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" shape="rect" title="Returns occupancy for a device function with the specified flags.">
   cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSize ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" shape="rect" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags.">
   cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gc5896a36586821e8bb51d4e837b55bb6" shape="rect" title="Returns dynamic shared memory available per block when launching numBlocks blocks on SM.">
   cudaOccupancyAvailableDynamicSMemPerBlock
  </a>
 </p>
 <a id="group__CUDART__OCCUPANCY_1ge99bee88c427b3f8ffa8ec3e43fd877d" name="group__CUDART__OCCUPANCY_1ge99bee88c427b3f8ffa8ec3e43fd877d" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaOccupancyMaxActiveBlocksPerMultiprocessor (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numBlocks
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   blockSize
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dynamicSMemSize
  </span>
  )
 </span>
 Returns occupancy for a device function.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  numBlocks
 </span>
 - Returned occupancy
 <span class="keyword keyword apiItemName">
  func
 </span>
 - Kernel function for which occupancy is calculated
 <span class="keyword keyword apiItemName">
  blockSize
 </span>
 - Block size the kernel is intended to be launched with
 <span class="keyword keyword apiItemName">
  dynamicSMemSize
 </span>
 - Per-block dynamic shared memory usage intended, in bytes
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038b6af535e7e53d3f21e2437e8977b8c2e" shape="rect">
   cudaErrorInvalidDeviceFunction
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *numBlocks
  the maximum number of active blocks per streaming multiprocessor for the device function.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g603b86b20b37823253ff89fe8688ba83" shape="rect" title="Returns occupancy for a device function with the specified flags.">
   cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSize ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" shape="rect" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags.">
   cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gc5896a36586821e8bb51d4e837b55bb6" shape="rect" title="Returns dynamic shared memory available per block when launching numBlocks blocks on SM.">
   cudaOccupancyAvailableDynamicSMemPerBlock ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gcc6e1094d05cba2cee17fe33ddd04a98" shape="rect" target="_blank">
   cuOccupancyMaxActiveBlocksPerMultiprocessor
  </a>
 </p>
 <a id="group__CUDART__OCCUPANCY_1ge2255f3637784624ea99a6d3c7885ca0" name="group__CUDART__OCCUPANCY_1ge2255f3637784624ea99a6d3c7885ca0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numBlocks
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   blockSize
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dynamicSMemSize
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Returns occupancy for a device function with the specified flags.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  numBlocks
 </span>
 - Returned occupancy
 <span class="keyword keyword apiItemName">
  func
 </span>
 - Kernel function for which occupancy is calculated
 <span class="keyword keyword apiItemName">
  blockSize
 </span>
 - Block size the kernel is intended to be launched with
 <span class="keyword keyword apiItemName">
  dynamicSMemSize
 </span>
 - Per-block dynamic shared memory usage intended, in bytes
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Requested behavior for the occupancy calculator
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038b6af535e7e53d3f21e2437e8977b8c2e" shape="rect">
   cudaErrorInvalidDeviceFunction
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *numBlocks
  the maximum number of active blocks per streaming multiprocessor for the device function.
 </p>
 <p class="p">
  The
  flags
  parameter controls how special cases are handled. Valid flags include:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g11570371f508845a9df47b17f85d90ac" shape="rect">
     cudaOccupancyDefault
    </a>
    : keeps the default behavior as
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" shape="rect" title="Returns occupancy for a device function.">
     cudaOccupancyMaxActiveBlocksPerMultiprocessor
    </a>
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g0a30e61b561f0678f1bf39eb051033bf" shape="rect">
     cudaOccupancyDisableCachingOverride
    </a>
    : This flag suppresses the default behavior on platform where global caching affects occupancy. On such platforms, if caching
                                          is enabled, but per-block SM resource usage would result in zero occupancy, the occupancy calculator will calculate the occupancy
                                          as if caching is disabled. Setting this flag makes the occupancy calculator to return 0 in such cases. More information can
                                          be found about this feature in the "Unified L1/Texture Cache" section of the Maxwell tuning guide.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g5a5d67a3c907371559ba692195e8a38c" shape="rect" title="Returns occupancy for a device function.">
   cudaOccupancyMaxActiveBlocksPerMultiprocessor
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gee5334618ed4bb0871e4559a77643fc1" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSize ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd0524825c5c01bbc9a5e29e890745800" shape="rect" title="Returns grid and block size that achived maximum potential occupancy for a device function with the specified flags.">
   cudaOccupancyMaxPotentialBlockSizeWithFlags ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g77b3bfb154b86e215a5bc01509ce8ea6" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMem ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g76975517a048cc199bc9e3ea6396ef26" shape="rect" title="Returns grid and block size that achieves maximum potential occupancy for a device function.">
   cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gc5896a36586821e8bb51d4e837b55bb6" shape="rect" title="Returns dynamic shared memory available per block when launching numBlocks blocks on SM.">
   cudaOccupancyAvailableDynamicSMemPerBlock ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1g8f1da4d4983e5c3025447665423ae2c2" shape="rect" target="_blank">
   cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
  </a>
 </p>
 <a id="group__CUDART__OCCUPANCY_1gd4322b730e5b2c5a9a93f0a22c93ab03" name="group__CUDART__OCCUPANCY_1gd4322b730e5b2c5a9a93f0a22c93ab03" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaOccupancyMaxActiveClusters (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numClusters
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t" shape="rect" title="">
   cudaLaunchConfig_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   launchConfig
  </span>
  )
 </span>
 Given the kernel function (
 func
 ) and launch configuration (
 config
 ), return the maximum number of clusters that could co-exist on the target device in
 *numClusters
 .
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  numClusters
 </span>
 - Returned maximum number of clusters that could co-exist on the target device
 <span class="keyword keyword apiItemName">
  func
 </span>
 - Kernel function for which maximum number of clusters are calculated
 <span class="keyword keyword apiItemName">
  launchConfig
 </span>
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038b6af535e7e53d3f21e2437e8977b8c2e" shape="rect">
   cudaErrorInvalidDeviceFunction
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003874b1d54ec922a8fffec403027a2dea9d" shape="rect">
   cudaErrorInvalidClusterSize
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  If the function has required cluster size already set (see
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g0e78e02c6d12ebddd4577ac6ebadf494" shape="rect" title="[C++ API] Find out attributes for a given function">
   cudaFuncGetAttributes
  </a>
  ), the cluster size from config must either be unspecified or match the required size. Without required sizes, the cluster
                                 size must be specified in config, else the function will return an error.
 </p>
 <p class="p">
  Note that various attributes of the kernel function may affect occupancy calculation. Runtime environment may affect how the
                                 hardware schedules the clusters, so the calculated occupancy is not guaranteed to be achievable.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g0e78e02c6d12ebddd4577ac6ebadf494" shape="rect" title="[C++ API] Find out attributes for a given function">
   cudaFuncGetAttributes
  </a>
  cudaOccupancyMaxActiveClusters (C++ API),
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1g4f52cbf144d74ed20351a594dc26386b" shape="rect" target="_blank">
   cuOccupancyMaxActiveClusters
  </a>
 </p>
 <a id="group__CUDART__OCCUPANCY_1g6d65e4932b9ab03d6544e37f111d7ec9" name="group__CUDART__OCCUPANCY_1g6d65e4932b9ab03d6544e37f111d7ec9" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaOccupancyMaxPotentialClusterSize (  int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   clusterSize
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   func
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t" shape="rect" title="">
   cudaLaunchConfig_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   launchConfig
  </span>
  )
 </span>
 Given the kernel function (
 func
 ) and launch configuration (
 config
 ), return the maximum cluster size in
 *clusterSize
 .
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  clusterSize
 </span>
 - Returned maximum cluster size that can be launched for the given kernel function and launch configuration
 <span class="keyword keyword apiItemName">
  func
 </span>
 - Kernel function for which maximum cluster size is calculated
 <span class="keyword keyword apiItemName">
  launchConfig
 </span>
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038b6af535e7e53d3f21e2437e8977b8c2e" shape="rect">
   cudaErrorInvalidDeviceFunction
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00382e491daacef266c7b3e3c1e140a6133c" shape="rect">
   cudaErrorUnknown
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  The cluster dimensions in
  config
  are ignored. If func has a required cluster size set (see
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g0e78e02c6d12ebddd4577ac6ebadf494" shape="rect" title="[C++ API] Find out attributes for a given function">
   cudaFuncGetAttributes
  </a>
  ),
  *clusterSize
  will reflect the required cluster size.
 </p>
 <p class="p">
  By default this function will always return a value that's portable on future hardware. A higher value may be returned if
                                 the kernel function allows non-portable cluster sizes.
 </p>
 <p class="p">
  This function will respect the compile time launch bounds.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g0e78e02c6d12ebddd4577ac6ebadf494" shape="rect" title="[C++ API] Find out attributes for a given function">
   cudaFuncGetAttributes
  </a>
  cudaOccupancyMaxPotentialClusterSize (C++ API),
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gd6f60814c1e3440145115ade3730365f" shape="rect" target="_blank">
   cuOccupancyMaxPotentialClusterSize
  </a>
 </p>
 <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
  Privacy Policy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
  Manage My Privacy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
  Do Not Sell or Share My Data
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
  Terms of Service
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
  Accessibility
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
  Corporate Policies
 </a>
 |
 <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
  Product Security
 </a>
 |
 <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
  Contact
 </a>
 Copyright Â© 2007-2024 NVIDIA Corporation
</body>
</body></html>