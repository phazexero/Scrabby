<html><head><title>Build and Run — nsight-visual-studio-edition 12.5 documentation</title></head><body><body class="wy-body-for-nav">
 <a href="https://docs.nvidia.com/nsight-visual-studio-edition/index.html">
 </a>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/introduction/index.html">
    Introduction
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/release-notes/index.html">
    Release Notes
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html">
    Installation and Setup
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   CUDA Debugger
  </span>
 </p>
 <ul class="current">
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-debugger/index.html">
    Getting Started with the CUDA Debugger
   </a>
  </li>
  <li class="toctree-l1 current">
   <a class="current reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html">
    Build and Run
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#id1">
      Build and Run
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#cuda-project-properties">
      CUDA Project Properties
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#common">
        Common
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#device">
        Device
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#host">
        Host
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#command-line">
        Command Line
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#launch-the-cuda-debugger">
      Launch the CUDA Debugger
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#local-debugging">
        Local Debugging
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#remote-debugging">
        Remote Debugging
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-to-a-running-cuda-process">
      Attach to a Running CUDA Process
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#one-time-setup">
        One Time Setup
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#when-launching-your-application">
        When Launching Your Application
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-to-a-cuda-application-in-visual-studio">
        Attach to a CUDA Application in Visual Studio
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-to-cuda-in-the-middle-of-a-kernel-launch">
        Attach to CUDA in the Middle of a Kernel Launch
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-control-gpu-execution/index.html">
    Control GPU Execution
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-inspect-state/index.html">
    Inspect State
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-advanced-topics/index.html">
    Advanced Topics
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Reference
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/reference/index.html">
    Reference
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Release Information
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/archives/index.html">
    Archives
   </a>
  </li>
 </ul>
 <p class="caption" role="heading">
  <span class="caption-text">
   Copyright and License Notices
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/nsight-visual-studio-edition/eula/index.html">
    EULA
   </a>
  </li>
 </ul>
 <a href="https://docs.nvidia.com/nsight-visual-studio-edition/index.html">
  nsight-visual-studio-edition
 </a>
 <ul class="wy-breadcrumbs">
  <li>
   <a class="icon icon-home" href="https://docs.nvidia.com/index.html">
   </a>
   »
  </li>
  <li>
   Build and Run
  </li>
  <li class="wy-breadcrumbs-aside">
   <a class="reference external" href="https://developer.nvidia.com/nsight-visual-studio-edition-2024_2-new-features">
    v2024.2.1 |
   </a>
   <a class="reference external" href="https://developer.nvidia.com/nsight-visual-studio-edition-archive">
    Archive
   </a>
  </li>
 </ul>
 <h1>
  Build and Run
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#build-and-run" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Build and run projects with the CUDA Debugger in NVIDIA Nsight VSE.
 </p>
 <h2>
  Build and Run
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#id1" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  In this section, learn more about how to configure the properties of a CUDA project, launching the CUDA Debugger, and how to attach debugging to a running CUDA Process.
 </p>
 <ul class="simple">
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#cuda-properties-config">
     CUDA Project Properties
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#launch-cuda-debugger">
     Launch the CUDA Debugger
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-cuda-to-process">
     Attach to a Running CUDA Process
    </a>
   </p>
  </li>
 </ul>
 <h2>
  CUDA Project Properties
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#cuda-project-properties" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  With NVIDIA Nsightâ¢ VSE, you can set parameters of your CUDA project in order to customize your debugging experience.
 </p>
 <p>
  To configure your projectâs CUDA properties page:
 </p>
 <ol class="arabic simple">
  <li>
   <p>
    In the Solution Explorer, click on the project name so that it is highlighted.
   </p>
  </li>
  <li>
   <p>
    From the Project menu, choose Properties. The Property Pages window opens.
   </p>
  </li>
  <li>
   <p>
    Select
    CUDA C/C++
    in the left pane.
   </p>
  </li>
 </ol>
 <h3>
  Common
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#common" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  On the
  Common
  page, you can configure the following options:
 </p>
 <ol class="arabic simple">
  <li>
   <p>
    CUDAÂ Toolkit Custom Dir
    â This option sets a custom path to the CUDAÂ toolkit. You can edit the path, select âBrowseâÂ to choose the path, or select âinherit from parent or project defaults.â
   </p>
  </li>
  <li>
   <p>
    Source Dependencies
    â This option allows you to add additional source file dependencies. If you have a dependency that has been set with an #include statement, it does not need to be explicitly specified in this.
   </p>
  </li>
  <li>
   <p>
    Compiler Output (obj/cubin)
    â This sets the output as an
    <span class="pre">
     .obj
    </span>
    or a
    <span class="pre">
     .cubin
    </span>
    file. The default setting is
    <span class="pre">
     $(IntDir)%(Filename)%(Extension).obj
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    Additional Include Directories
    â This option allows you to list at least one additional directory to add to the include path. If you have more than one, use a semicolon to separate them.
   </p>
  </li>
  <li>
   <p>
    Use Host Include Directories
    â This option specifies whether or not to use the additional include directories that are used by the host compiler for device code.
   </p>
  </li>
  <li>
   <p>
    Keep Preprocessed Files
    â This option allows you to choose whether or not the preprocessor files generated by the CUDA compiler (for example,
    <span class="pre">
     .ptx
    </span>
    ,
    <span class="pre">
     .cubin
    </span>
    ,
    <span class="pre">
     .cudafe1.c
    </span>
    , etc.) will be deleted.
   </p>
  </li>
  <li>
   <p>
    Keep Directory
    â This option sets the path the directory where the preprocessor files generated by the CUDA compiler will be kept.
   </p>
  </li>
  <li>
   <p>
    Generate Relocatable Device Code
    â This setting chooses whether or not to compile the input file into an object file that contains relocatable device code.
   </p>
  </li>
  <li>
   <p>
    NVCC Compilation Type
    â This option sets your desired output of NVCC compilation. Choices here include the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      Generate hybrid object file (
      <span class="pre">
       --compile
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Generate hybrid .c file (
      <span class="pre">
       -cuda
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Generate .gpu file (
      <span class="pre">
       -gpu
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Generate .cubin file (
      <span class="pre">
       -cubin
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Generate .ptx file (
      <span class="pre">
       -ptx
      </span>
      )
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    CUDAÂ Runtime
    â This option allows you to specify the type of CUDAÂ runtime library to be used. The choices here include the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      No CUDA runtime library (
      <span class="pre">
       -cudart
      </span>
      <span class="pre">
       none
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Shared/dynamic CUDA runtime library (
      <span class="pre">
       -cudart
      </span>
      <span class="pre">
       shared
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Static CUDA runtime library (
      <span class="pre">
       -cudart
      </span>
      <span class="pre">
       static
      </span>
      )
     </p>
    </li>
   </ul>
  </li>
 </ol>
 <h3>
  Device
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#device" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  On the
  Device
  page, you can configure the following options:
 </p>
 <ol class="arabic">
  <li>
   <p>
    CÂ interleaved in PTXASÂ Output
    â This setting chooses whether or not to insert source code into generated PTX.
   </p>
  </li>
  <li>
   <p>
    Code Generation
    â This option specifies the names of the NVIDIAÂ GPU architectures to generate code for. If you click
    Edit
    from the drop-down menu, the following pop-up appears:
   </p>
   <p>
    If you edit this field, the correct syntax to use is
    <span class="pre">
     [arch],[code]
    </span>
    (for example,
    <span class="pre">
     compute_80,sm_80
    </span>
    ). If the selected
    <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#cuda-properties-common">
     NVCC Compilation Type
    </a>
    is
    <span class="pre">
     compile
    </span>
    ,Â then multiple arch/code pairs may be listed, separated by a semicolon (for example,
    <span class="pre">
     compute_70,sm_70;compute_75,sm_75
    </span>
    ).
   </p>
  </li>
  <li>
   <p>
    Generate GPU Debug Information
    â This setting selects whether or not GPU debugging information is generated by the CUDA compiler.
   </p>
  </li>
  <li>
   <p>
    Generate Line Number Information
    â This option chooses whether or not to generate line number information for device code. If
    Generate GPU Debug Information
    is on (
    <span class="pre">
     -G
    </span>
    ), line information (
    <span class="pre">
     -lineinfo
    </span>
    ) is automatically generated as well.
   </p>
  </li>
  <li>
   <p>
    Max Used Register
    â This option specifies the maximum amount of registers that GPU functions can use.
   </p>
  </li>
  <li>
   <p>
    Verbose PTXAS Output
    â This option selects whether or not to use verbose PTXAS output.
   </p>
  </li>
  <li>
   <p>
    Split Compilation
    â The
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-altering-compiler-linker-behavior-split-compile">
     Split Compilation NVCC option
    </a>
    specifies the upper bound for the number of threads the compiler is allowed to use for parallel compilation. With split compilation, the compiler breaks up your code into groups of kernels that it compiles and optimizes in parallel to speed up compile time.
   </p>
   <p>
    Split-compilation can be set to:
   </p>
   <ul class="simple">
    <li>
     <p>
      Default
      : The
      <span class="pre">
       --split-compile
      </span>
      argument is not passed to the compiler and split compilation is disabled (equivalent to
      <span class="pre">
       --split-compile=1
      </span>
      ).
     </p>
    </li>
    <li>
     <p>
      Max threads (âsplit-compile=0)
      : The compiler automatically manages the maximum number of threads to use based on your software/hardware configuration.
     </p>
    </li>
    <li>
     <p>
      Max threads (extended) (âsplit-compile-extended=0)
      : The compiler automatically manages the maximum number of threads to use based on your software/hardware configuration.
     </p>
    </li>
    <li>
     <p>
      Custom (âsplit-compile=)
      : Uses the âNumber of split compilation threadsâ property field to specify a custom upper bound value for the number of compiler threads.
     </p>
    </li>
    <li>
     <p>
      Custom (extended) (âsplit-compile-extended=)
      : Uses the âNumber of split compilation threadsâ property field to specify a custom upper bound value for the number of compiler threads.
     </p>
    </li>
   </ul>
  </li>
 </ol>
 <p class="admonition-title">
  Note
 </p>
 <ul class="simple">
  <li>
   <p>
    The value specified in âNumber of split compilation threadsâ is ignored unless split compilation is set to âCustomâ or âCustom (extended)â.
   </p>
  </li>
  <li>
   <p>
    Setting split compilation to âCustomâ or âCustom (extended)â and not providing a value for âNumber of split compilation threadsâ results in a build error with the following text:
    <span class="pre">
     Invalid
    </span>
    <span class="pre">
     command
    </span>
    <span class="pre">
     line
    </span>
    <span class="pre">
     switch
    </span>
    <span class="pre">
     for
    </span>
    <span class="pre">
     "".
    </span>
    <span class="pre">
     The
    </span>
    <span class="pre">
     parameter
    </span>
    <span class="pre">
     "SplitCompile"
    </span>
    <span class="pre">
     requires
    </span>
    <span class="pre">
     missing
    </span>
    <span class="pre">
     parameter
    </span>
    <span class="pre">
     "SplitCompileCustomThreads"
    </span>
    <span class="pre">
     to
    </span>
    <span class="pre">
     be
    </span>
    <span class="pre">
     set.
    </span>
   </p>
  </li>
 </ul>
 <h3>
  Host
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#host" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  On the
  Host
  page, you can configure the following options:
 </p>
 <ol class="arabic simple">
  <li>
   <p>
    Additional Compiler Options
    â This setting lists additional host compiler options that are not supported by the hostâs project properties.
   </p>
  </li>
  <li>
   <p>
    Preprocessor Definitions
    â This option allows you to list preprocessor defines.
   </p>
  </li>
  <li>
   <p>
    Use Host Preprocessor Definitions
    â This option selects whether or not to use the defines that were used by the host compiler for device code.
   </p>
  </li>
  <li>
   <p>
    Emulation
    â This option specifies whether or not to generate emulated code.
   </p>
  </li>
  <li>
   <p>
    Generate Host Debug Information
    â This option specifies whether or not the host debugging information will be generated by the CUDA compiler.
   </p>
  </li>
  <li>
   <p>
    Use Fast Math
    â This option selects whether or not to make use of the fast math library.
   </p>
  </li>
  <li>
   <p>
    Optimization
    â This field selects the option for code optimization. Available choices include the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      &lt;inherit from host&gt;
     </p>
    </li>
    <li>
     <p>
      Disabled (
      <span class="pre">
       /Od
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Minimize Size (
      <span class="pre">
       /O1
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Maximize Speed (
      <span class="pre">
       /O2
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Full Optimization (
      <span class="pre">
       /Ox
      </span>
      )
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Runtime Library
    â This field selects the runtime library to use for linking. Available choices include the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      &lt;inherit from host&gt;
     </p>
    </li>
    <li>
     <p>
      Multi-Threaded (
      <span class="pre">
       /Mt
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Multi-Threaded Debug (
      <span class="pre">
       /Mtd
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Multi-Threaded DLL (
      <span class="pre">
       /MD
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Multi-Threaded Debug DLLÂ (
      <span class="pre">
       /MDd
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Single-Threaded (
      <span class="pre">
       /ML
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Single-Threaded Debug (
      <span class="pre">
       /MLd
      </span>
      )
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Basic Runtime Checks
    â This field performs basic runtime error checks, incompatible with any optimization type other than debug. Available choices include the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      &lt;inherit from host&gt;
     </p>
    </li>
    <li>
     <p>
      Default
     </p>
    </li>
    <li>
     <p>
      Stack Frames (
      <span class="pre">
       /RTCs
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Uninitialized Variables (
      <span class="pre">
       /RTCu
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Both (
      <span class="pre">
       /RTC1
      </span>
      )
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Enable Run-Time Type Info
    â This option chooses whether or not to add code for checking C++ object types at run time.
   </p>
  </li>
  <li>
   <p>
    Warning Level
    â This option selects how strictly you want the compiler to be when checking for potentially suspect constructs. Available choices here include:
   </p>
   <ul class="simple">
    <li>
     <p>
      &lt;inherit from host&gt;
     </p>
    </li>
    <li>
     <p>
      Off:Â Turn Off All Warnings (
      <span class="pre">
       /W0
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Level 1 (
      <span class="pre">
       /W1
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Level 2 (
      <span class="pre">
       /W2
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Level 3 (
      <span class="pre">
       /W3
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Level 4 (
      <span class="pre">
       /W4
      </span>
      )
     </p>
    </li>
    <li>
     <p>
      Enable All Warnings (
      <span class="pre">
       /Wall
      </span>
      )
     </p>
    </li>
   </ul>
  </li>
 </ol>
 <h3>
  Command Line
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#command-line" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  Command Line
  page shows the approximate command line parameters, given the settings youâve chosen.
 </p>
 <h2>
  Launch the CUDA Debugger
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#launch-the-cuda-debugger" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Make sure that the modules you intend to debug are built with the compiler generating debug symbols. If a module has no symbols, then debugging is disabled for all functions in that module.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  CPU/GPU Debugging Support
 </p>
 <p>
  The
  Legacy CUDA debugger
  only supports debugging GPU CUDA kernels.
 </p>
 <p>
  You cannot debug CUDA code in a target process while simultaneously debugging the x86 code of the same process. Use a separate Visual Studio instance to debug the host portion of a target application. If you wish to debug the host portion of your CUDA application while the CUDA Debugger is attached, you must attach using a different Visual Studio instance.
 </p>
 <p>
  Attaching the same instance of Visual Studio to debug both the host portion and the device portion of a target application will cause the debuggers to conflict. The result is that the target application and the CUDA Debugger hang while being blocked by operations of the native debugger.
 </p>
 <p>
  The
  Next-Gen CUDA debugger
  allows you to debug both CPU and GPU code simultaneously.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Remote Debugging Support
 </p>
 <p>
  The
  Legacy CUDA debugger
  supports local and remote debugging.
 </p>
 <p>
  The
  Next-Gen CUDA debugger
  only supports local debugging. Remote debugging is not currently supported.
 </p>
 <h3>
  Local Debugging
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#local-debugging" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The NVIDIA Nsightâ¢ VSE tools support launching and debugging a program on a single system. Please see
  <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#system-requirements">
   System Requirements for Nsight Software
  </a>
  for more information. Please also refer to the
  <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#setup-local-debugging">
   Setup Local Debugging
  </a>
  topic for configuring a debugging setup with multiple GPUs.
 </p>
 <p>
  To configure a project for local debugging:
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Note that this configuration only applies to the
  Legacy CUDA debugger
  .
 </p>
 <p>
  The
  Next-Gen CUDA debugger
  does not currently support remote debugging and will always run as a local debugger.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Start Visual Studio.
   </p>
  </li>
  <li>
   <p>
    Open a CUDA-based project.
   </p>
  </li>
  <li>
   <p>
    Right-click on the project name in the Solution Explorer, and choose
    Nsight User Properties
    . (As an alternative, you can also go to the
    Project
    menu &gt;
    Nsight User Properties
    .)
   </p>
  </li>
  <li>
   <p>
    In the Connection name text field, type:
    <span class="pre">
     localhost
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    Click OK.
   </p>
  </li>
 </ol>
 <p>
  To start the CUDA Debugger locally:
 </p>
 <ol class="arabic">
  <li>
   <p>
    On the host machine, go to the Nsight menu in Visual Studio.
   </p>
  </li>
  <li>
   <p>
    From the
    <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#using-vs-2019">
     Nsight menu
    </a>
    , select one of the following:
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      Start CUDA Debugging (Next-Gen)
     </p>
    </li>
    <li>
     <p>
      Start CUDA Debugging (Legacy)
     </p>
     <p>
      For information on choosing the correct debugger for your system configuration see the
      <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#system-requirements">
       System Requirements
      </a>
      page.
     </p>
     <p>
      Alternatively, you can also choose to:
     </p>
     <ul>
      <li>
       <p>
        Right-click on the project, and select
        Debug
        &gt;
        Start CUDA Debugging (Legacy)/(Next-Gen)
       </p>
      </li>
      <li>
       <p>
        Click on the
        Start CUDA Debugging (Legacy)/(Next-Gen)
        toolbar icon.
       </p>
       <p>
        Show/hide this icon group by right-clicking on the Visual Studio toolbar and toggling
        Nsight CUDA Debug
        .
       </p>
      </li>
      <li>
       <p>
        Click on the
        Start CUDA Debugging (Legacy)/(Next-Gen)
        toolbar menu item.
       </p>
       <p>
        Show/hide this icon group by right-clicking on the Visual Studio toolbar and toggling
        Nsight Connections
        .
       </p>
      </li>
     </ul>
    </li>
   </ol>
  </li>
  <li>
   <p>
    If you started Legacy CUDA debugging:
   </p>
   <ul class="simple">
    <li>
     <p>
      Youâll notice that on the host machine, a pop-up message indicates that a connection has been made.
     </p>
    </li>
    <li>
     <p>
      Note that with a remote debugging configuration, the Nsight Monitor must be started prior to debugging. However, in a local debugging setup, the Nsight Monitor will launch automatically when the CUDA Debugger is started.
     </p>
    </li>
    <li>
     <p>
      The CUDA Debugger launches the target application on the local machine. The CUDA Debugger communicates through port: 8000 by default, although this setting can be changed in the Nsight Monitor options. (See both
      <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#host">
       Host Basics
      </a>
      and
      <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#target">
       Target Basics
      </a>
      for more details on how to configure the default port settings.) You can use the CUDA Debugger to pause execution, step, and perform other debugger functions.
     </p>
    </li>
   </ul>
  </li>
 </ol>
 <h3>
  Remote Debugging
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#remote-debugging" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p class="admonition-title">
  Note
 </p>
 <p>
  If you are using the
  Next-Gen CUDA debugger
  :
 </p>
 <p>
  Remote debugging isnât currently supported. The target machine is assumed to be
  <span class="pre">
   localhost
  </span>
  . Please see
  <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#launch-cuda-local">
   Local Debugging
  </a>
  .
 </p>
 <p>
  You can launch and debug a program on any properly configured remote host. Please see
  <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#how-to-install-nsight">
   How To: Install the Nsight Monitor
  </a>
  and
  <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#setup-remote-debugging">
   Setup Remote Debugging
  </a>
  for more information on how to install and configure the NVIDIA Nsightâ¢ VSE tools on your remote machine.
 </p>
 <p>
  To configure a project for remote debugging:
 </p>
 <ol class="arabic">
  <li>
   <p>
    Start Visual Studio.
   </p>
  </li>
  <li>
   <p>
    Open a CUDA-based project.
   </p>
  </li>
  <li>
   <p>
    Right-click on the project name in the Solution Explorer, and choose
    Nsight User Properties
    . (As an alternative, you can also go to the
    Project
    menu &gt;
    Nsight User Properties
    .)
   </p>
  </li>
  <li>
   <p>
    In the Connection name field, replace
    <span class="pre">
     localhost
    </span>
    with the name of your target machine (the remote computer where the application to be debugged will run).
   </p>
   <p>
    This can be the IP address of the machine on your local network, or the machine name as recognized on your network.
   </p>
   <p>
    IMPORTANT: Do not use a mapped drive to specify the hostname. For example:
   </p>
   <p>
    WRONG:
    <span class="pre">
     M:\
    </span>
   </p>
   <p>
    CORRECT:
    <span class="pre">
     jsmith.mydomain.com
    </span>
   </p>
  </li>
  <li>
   <p>
    In the Working directory field, you can specify the directory you want the application to use. The default working directory is the project directory.
   </p>
  </li>
  <li>
   <p>
    Set any environment variables needed.
   </p>
  </li>
  <li>
   <p>
    Click OK button.
   </p>
  </li>
 </ol>
 <p>
  To start the CUDA Debugger remotely:
 </p>
 <ol class="arabic">
  <li>
   <p>
    Start the Nsight Monitor on the target machine (remote machine).
   </p>
   <ol class="loweralpha simple">
    <li>
     <p>
      From the Windows Start menu, select
      All Programs
      .
     </p>
    </li>
    <li>
     <p>
      Scroll down the through the installed programs and select: NVIDIA Corporation &gt; Nsight Monitor.
     </p>
    </li>
   </ol>
  </li>
  <li>
   <p>
    Optional: To abort the launch when a file fails to copy to the remote system, set the Abort on synchronize failure option to âTrue.â
   </p>
   <ol class="loweralpha simple">
    <li>
     <p>
      From the Nsight menu, select Nsight Options. The Nsight Options window opens.
     </p>
    </li>
    <li>
     <p>
      In the left hand pane, select Debugger.
     </p>
    </li>
    <li>
     <p>
      Under Launch section, set Abort on synchronize failure to True.
     </p>
    </li>
    <li>
     <p>
      Click OK button.
     </p>
    </li>
   </ol>
  </li>
  <li>
   <p>
    From the
    <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#using-vs-2019">
     Nsight menu
    </a>
    in Visual Studio:
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      Start CUDA Debugging (Legacy)
     </p>
    </li>
    <li>
     <p>
      Note that
      Start CUDA Debugging (Next-Gen)
      does not currently support remote debugging. If launched, it will attempt to debug locally.
     </p>
     <p>
      Alternatively, you can also choose to:
     </p>
     <ul>
      <li>
       <p>
        Right-click on the project, and select
        Debug
        &gt;
        Start CUDA Debugging (Legacy)/(Next-Gen)
       </p>
      </li>
      <li>
       <p>
        Click on the
        Start CUDA Debugging (Legacy)/(Next-Gen)
        toolbar icon.
       </p>
       <p>
        Show/hide this icon group by right-clicking on the Visual Studio toolbar and toggling
        Nsight CUDA Debug
        .
       </p>
      </li>
      <li>
       <p>
        Click on the
        Start CUDA Debugging (Legacy)/(Next-Gen)
        toolbar menu item.
       </p>
       <p>
        Show/hide this icon group by right-clicking on the Visual Studio toolbar and toggling
        Nsight Connections
        .
       </p>
      </li>
     </ul>
    </li>
   </ol>
  </li>
  <li>
   <p>
    Legacy CUDA debugging start up:
   </p>
   <ul class="simple">
    <li>
     <p>
      The host communicates with the Nsight Monitor on the remote machine, synchronizes the application files, and launches the application on the remote machine. The CUDA Debugger communicates through port: 8000 by default, although this setting can be changed in the Nsight Monitor options. (See both
      <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#host">
       Host Basics
      </a>
      and
      <a class="reference external" href="https://docs.nvidia.com/nsight-visual-studio-edition/install-setup/index.html#target">
       Target Basics
      </a>
      for more details on how to configure the default port settings.) You can use the CUDA Debugger to pause execution, step, and perform other debugger functions.
     </p>
    </li>
    <li>
     <p>
      To cancel the debugging sessions while files are synchronizing, select Nsight &gt; Cancel Debug Startup.
     </p>
    </li>
   </ul>
  </li>
 </ol>
 <p>
  NOTE: You cannot simultaneously perform CUDA debugging and x86 debugging of the same process when using the Legacy CUDAÂ Debugger.
 </p>
 <h2>
  Attach to a Running CUDA Process
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-to-a-running-cuda-process" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This feature is only supported by the Legacy CUDA Debugger. The Next-Gen CUDA Debugger will support this in a future release.
 </p>
 <p>
  With NVIDIA Nsightâ¢ VSE, it is possible to attach the Visual Studio debugger to a free-running CUDA application. This feature requires some one-time setup and setting additional environment variables when you launch programs that you wish to debug. The required steps are outlined below.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Note that if you are using NVIDIA Nsightâ¢ VSE on a Windows 10 x64 machine, you will not be able to attach to a win32/x86 CUDA application. Only 64-bit CUDA applications are supported.
 </p>
 <h3>
  One Time Setup
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#one-time-setup" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    On the target machine (either local or remote, depending on your configuration), right-click on the Nsight Monitor icon on the taskbar and select
    Options
    .
   </p>
  </li>
  <li>
   <p>
    Select the
    CUDA (Legacy)
    tab. Note that Attach does not work with the Next-Gen Debugger.
   </p>
  </li>
  <li>
   <p>
    For the option
    Use this Monitor for CUDA attach
    , click the drop-down menu and select
    True
    . If this setting is not enabled, you will get a warning message in the attach dialog on the host machine.
   </p>
   <p>
    This setting is required to allow the Nsight Monitor to attach to free-running CUDA applications. It only needs to be configured one time after installing NVIDIA Nsightâ¢ VSE.
   </p>
  </li>
 </ol>
 <h3>
  When Launching Your Application
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#when-launching-your-application" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  To make a process CUDA-attachable, you must set the environment variable
  <span class="pre">
   NSIGHT_CUDA_DEBUGGER=1
  </span>
  . The strict requirement is that the environment variable must be set before the application calls
  <span class="pre">
   cuInit()
  </span>
  . If the application uses the CUDA Runtime API, the environment variable must be set before the first CUDA Runtime API call is made.
 </p>
 <p>
  Since environment variables are typically inherited by child processes, setting
  <span class="pre">
   NSIGHT_CUDA_DEBUGGER=1
  </span>
  in a parent process that launches child processes will usually make the child processes CUDA-debuggable as well. Launcher processes and cluster nodes can benefit from this.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Setting
  <span class="pre">
   NSIGHT_CUDA_DEBUGGER=1
  </span>
  can degrade the performance of an application, since the debugger is made resident. The effect is minimal on Teslaâ¢ devices and headless devices; it is most severe on display devices with a desktop, where the debugger by necessity may need to serialize launches that would otherwise have been asynchronous. Therefore, itâs not always desirable to set
  <span class="pre">
   NSIGHT_CUDA_DEBUGGER=1
  </span>
  at a system-wide or user-wide level.
 </p>
 <p>
  It is not recommended that you set
  <span class="pre">
   NSIGHT_CUDA_DEBUGGER
  </span>
  as a system environment variable, as it could adversely affect performance of other applications that use the CUDA Debugger.
 </p>
 <h3>
  Attach to a CUDA Application in Visual Studio
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-to-a-cuda-application-in-visual-studio" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    On the host machine, open your project in Visual Studio.
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      This process will also work without a project. However, in that case, Visual Studio will not remember any breakpoints that are set.
     </p>
    </li>
    <li>
     <p>
      To resolve and hit source breakpoints, the debugger requires the absolute paths of source files to match those in the debug symbols built into the application.
     </p>
     <p>
      Note that if the project hits breakpoints when it is launched via the
      Nsight
      &gt;
      Start CUDA Debugging (Legacy)
      command, then it will also work with attach.
     </p>
     <p>
      Note that Attach does not work with the CUDA Next-Gen Debugger.
     </p>
    </li>
   </ol>
  </li>
  <li>
   <p>
    Go to
    Debug
    &gt;
    Attach to Process
    . (Or as an alternative, go to the Tools menu, and select Attach to Process.)
   </p>
   <p>
    This will open the Attach to Process dialog box.
   </p>
  </li>
  <li>
   <p>
    Click the drop-down menu next to the
    Transport
    field, and choose
    Nsight GPU Debugger
    .
   </p>
  </li>
  <li>
   <p>
    Ensure that your host machine name is listed in the
    Connection target
    field.
   </p>
   <p>
    Note that this field is blank by default; you will have to manually select your machine name the first time this dialog is opened.
   </p>
  </li>
  <li>
   <p>
    When you enter your computerâs hostname in the Connection target field, a list of available processes will appear in the dialog box.
   </p>
   <ol class="loweralpha simple">
    <li>
     <p>
      If a process is grayed out and CUDA
      is not
      listed in the Type column, then it cannot be debugged with the CUDA Debugger. Usually this occurs because the
      <span class="pre">
       NSIGHT_CUDA_DEBUGGER
      </span>
      environment variable is not set in that process.
     </p>
    </li>
    <li>
     <p>
      If a process is grayed out and CUDA
      is
      listed in the
      Type
      column, then a CUDA Debugger is already attached. In this case, it cannot be attached to again.
     </p>
    </li>
    <li>
     <p>
      Processes that may be attached will appear normally, and the
      Attach
      button will be enabled.
     </p>
    </li>
   </ol>
  </li>
  <li>
   <p>
    When you select the desired process and click
    Attach
    , a debug session will begin, exactly as if you had used the NVIDIA Nsightâ¢ VSE menu in Visual Studio (
    Nsight
    &gt;
    Start CUDA Debugging (Legacy)
    ).
   </p>
  </li>
 </ol>
 <p>
  To end, choose
  Debug
  &gt;
  Stop Debugging
  . Note that this will terminate the application.
 </p>
 <h3>
  Attach to CUDA in the Middle of a Kernel Launch
  <a class="headerlink" href="https://docs.nvidia.com/nsight-visual-studio-edition/cuda-build-run/index.html#attach-to-cuda-in-the-middle-of-a-kernel-launch" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The following dialog is shown when an attachable process hits a GPU exception. A GPU exception can be an MMU fault, inline breakpoint (
  <span class="pre">
   asm("brkpt;");
  </span>
  in CUDA C), or other abnormal condition.
 </p>
 <p>
  For safety reasons, the dialog will not be shown if any desktop GPUs are currently debugging in hardware mode, and the GPU will automatically resume. While detailed GPU inspection requires an attached Visual Studio instance, the dialog displays the faulting device name,
  <span class="pre">
   CUcontext
  </span>
  , kernel (mangled name), and the reason for the exception:
 </p>
 <p>
  The following options are available:
 </p>
 <ul>
  <li>
   <p>
    Continue execution
    â This closes the dialog and resumes the GPU and application execution. This operation is equivalent to the
    Debug
    &gt;
    Continue
    command in Visual Studio. The dialog will reappear upon the next GPU exception. If the âDonât ask me againâ box is checked, the program will instead automatically continue instead of showing this dialog again. This setting is not saved across program runs.
   </p>
  </li>
  <li>
   <p>
    Debug the application
    â This pauses the program while the user attaches the CUDA debugger:
   </p>
   <p>
    Canceling or closing this new dialog returns to the original dialog. The dialog automatically closes and reports the exception when the CUDA debugger attaches.
   </p>
  </li>
  <li>
   <p>
    Exit the application
    â Terminates the program. Closing the dialog is equivalent to selecting âExit the application.â
   </p>
  </li>
 </ul>
 <p class="rubric-h1 rubric">
  Notices
 </p>
 <p class="rubric-h2 rubric">
  Notice
 </p>
 <p>
  ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, âMATERIALSâ) ARE BEING PROVIDED âAS IS.â NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.
 </p>
 <p>
  Information furnished is believed to be accurate and reliable. However, NVIDIA Corporation assumes no responsibility for the consequences of use of such information or for any infringement of patents or other rights of third parties that may result from its use. No license is granted by implication of otherwise under any patent rights of NVIDIA Corporation. Specifications mentioned in this publication are subject to change without notice. This publication supersedes and replaces all other information previously supplied. NVIDIA Corporation products are not authorized as critical components in life support devices or systems without express written approval of NVIDIA Corporation.
 </p>
 <p class="rubric-h2 rubric">
  Trademarks
 </p>
 <p>
  NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.
 </p>
 <p>
  © Copyright 2018-2024, NVIDIA Corporation &amp; Affiliates. All rights reserved.
  <span class="lastupdated">
   Last updated on Jun 03, 2024.
  </span>
 </p>
</body>
</body></html>