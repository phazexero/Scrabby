<html><head><title><no title> â npp 12.5 documentation</title></head><body><body class="wy-body-for-nav">
 <a href="https://docs.nvidia.com/cuda/npp/index.html">
 </a>
 <p class="caption" role="heading">
  <span class="caption-text">
   Contents:
  </span>
 </p>
 <ul>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/introduction.html">
    What is NPP ?
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/introduction.html#general-conventions">
    General Conventions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/introduction.html#image-processing-conventions">
    Image Processing Conventions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/introduction.html#signal-processing-conventions">
    Signal Processing Conventions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/nppdefs.html">
    Data Types, Structs, Enums, and Constants
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_arithmetic_and_logical_operations.html">
    Image Arithmetic And Logical Operations
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_color_conversion.html">
    Image Color Conversion Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_data_exchange_and_initialization.html">
    Image Data Exchange And Initialization Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_filtering_functions.html">
    Image Filtering Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_geometry_transforms.html">
    Image Geometry Transforms Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_linear_transforms.html">
    Image Linear Transforms Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_morphological_operations.html">
    Image Morphological Operations
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_statistics_functions.html">
    Image Statistics Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_threshold_and_compare_operations.html">
    Image Threshold And Compare Operations
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/image_memory_management.html">
    Image Memory Management Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/signal_arithmetic_and_logical_operations.html">
    Signal Arithmetic And Logical Operations
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/signal_conversion_functions.html">
    Signal Conversion Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/signal_filtering_functions.html">
    Signal Filtering Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/signal_initialization.html">
    Signal Initialization Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/signal_statistical_functions.html">
    Signal Statistical Functions
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/signal_memory_management.html">
    Signal Memory Management Functions
   </a>
  </li>
 </ul>
 <a href="https://docs.nvidia.com/cuda/npp/index.html">
  npp
 </a>
 <ul class="wy-breadcrumbs">
  <li>
   <a class="icon icon-home" href="https://docs.nvidia.com/cuda/index.html">
   </a>
   Â»
  </li>
  <li>
   &lt;no title&gt;
  </li>
  <li class="wy-breadcrumbs-aside">
   <span>
    v23.05 |
   </span>
   <a class="reference external" href="https://docs.nvidia.com/cuda/pdf/NPP_Library.pdf">
    PDF
   </a>
   <span>
    |
   </span>
   <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit-archive">
    Archive
   </a>
   <span>
    Â
   </span>
  </li>
 </ul>
 <p id="group__core__npp">
  Basic functions for library management, in particular library version and device property query functions.
 </p>
 <p class="breathe-sectiondef-title rubric-h3 rubric" id="breathe-section-title-functions">
  Functions
 </p>
 <span class="k">
  <span class="pre">
   const
  </span>
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/nppdefs.html#c.NppLibraryVersion" title="NppLibraryVersion">
  <span class="n">
   <span class="pre">
    NppLibraryVersion
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetLibVersion
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetLibVersion" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the NPP library version.
 </p>
 Returns
 <p>
  A struct containing separate values for major and minor revision and build number.
 </p>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetGpuNumSMs
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetGpuNumSMs" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the number of Streaming Multiprocessors (SM) on the active CUDA device.
 </p>
 Returns
 <p>
  Number of SMs of the default CUDA device.
 </p>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetMaxThreadsPerBlock
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetMaxThreadsPerBlock" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the maximum number of threads per block on the active CUDA device.
 </p>
 Returns
 <p>
  Maximum number of threads per block on the active CUDA device.
 </p>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetMaxThreadsPerSM
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetMaxThreadsPerSM" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the maximum number of threads per SM for the active GPU.
 </p>
 Returns
 <p>
  Maximum number of threads per SM for the active GPU
 </p>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetGpuDeviceProperties
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   pMaxThreadsPerSM
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   pMaxThreadsPerBlock
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   pNumberOfSMs
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetGpuDeviceProperties" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the maximum number of threads per SM, maximum threads per block, and number of SMs for the active GPU.
 </p>
 Returns
 <p>
  cudaSuccess for success, -1 for failure
 </p>
 <span class="k">
  <span class="pre">
   const
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   char
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetGpuName
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetGpuName" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the name of the active CUDA device.
 </p>
 Returns
 <p>
  Name string of the active graphics-card/compute device in a system.
 </p>
 <span class="n">
  <span class="pre">
   cudaStream_t
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetStream
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetStream" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the NPP CUDA stream.
 </p>
 <p>
  NPP enables concurrent device tasks via a global stream state varible. The NPP stream by default is set to stream 0, i.e. non-concurrent mode. A user can set the NPP stream to any valid CUDA stream. All CUDA commands issued by NPP (e.g. kernels launched by the NPP library) are then issed to that NPP stream.
 </p>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/nppdefs.html#c.NppStatus" title="NppStatus">
  <span class="n">
   <span class="pre">
    NppStatus
   </span>
  </span>
 </a>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetStreamContext
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/nppdefs.html#c.NppStreamContext" title="NppStreamContext">
  <span class="n">
   <span class="pre">
    NppStreamContext
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   pNppStreamContext
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetStreamContext" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the current NPP managed CUDA stream context as set by calls to
  <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/core_npp.html#group__core__npp_1ga155122a2138b944949b0920e2bb1120f">
   <span class="std std-ref">
    nppSetStream()
   </span>
  </a>
  .
 </p>
 <p>
  NPP enables concurrent device tasks via an NPP maintained global stream state context. The NPP stream by default is set to stream 0, i.e. non-concurrent mode. A user can set the NPP stream to any valid CUDA stream which will update the current NPP managed stream state context or supply application initialized stream contexts to NPP calls. All CUDA commands issued by NPP (e.g. kernels launched by the NPP library) are then issed to the current NPP managed stream or to application supplied stream contexts depending on whether the stream context is passed to the NPP function or not. NPP managed stream context calls (those without stream context parameters) can be intermixed with application managed stream context calls but any NPP managed stream context calls will always use the most recent stream set by
  <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/core_npp.html#group__core__npp_1ga155122a2138b944949b0920e2bb1120f">
   <span class="std std-ref">
    nppSetStream()
   </span>
  </a>
  or the NULL stream if
  <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/core_npp.html#group__core__npp_1ga155122a2138b944949b0920e2bb1120f">
   <span class="std std-ref">
    nppSetStream()
   </span>
  </a>
  has never been called.
 </p>
 <span class="kt">
  <span class="pre">
   unsigned
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetStreamNumSMs
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetStreamNumSMs" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the number of SMs on the device associated with the current NPP CUDA stream.
 </p>
 <p>
  NPP enables concurrent device tasks via a global stream state varible. The NPP stream by default is set to stream 0, i.e. non-concurrent mode. A user can set the NPP stream to any valid CUDA stream. All CUDA commands issued by NPP (e.g. kernels launched by the NPP library) are then issed to that NPP stream. This call avoids a cudaGetDeviceProperties() call.
 </p>
 <span class="kt">
  <span class="pre">
   unsigned
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppGetStreamMaxThreadsPerSM
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppGetStreamMaxThreadsPerSM" title="Permalink to this definition">
  ï
 </a>
 <p>
  Get the maximum number of threads per SM on the device associated with the current NPP CUDA stream.
 </p>
 <p>
  NPP enables concurrent device tasks via a global stream state varible. The NPP stream by default is set to stream 0, i.e. non-concurrent mode. A user can set the NPP stream to any valid CUDA stream. All CUDA commands issued by NPP (e.g. kernels launched by the NPP library) are then issed to that NPP stream. This call avoids a cudaGetDeviceProperties() call.
 </p>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/nppdefs.html#c.NppStatus" title="NppStatus">
  <span class="n">
   <span class="pre">
    NppStatus
   </span>
  </span>
 </a>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    nppSetStream
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="n">
  <span class="pre">
   cudaStream_t
  </span>
 </span>
 <span class="n">
  <span class="pre">
   hStream
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/npp/core_npp.html#c.nppSetStream" title="Permalink to this definition">
  ï
 </a>
 <p>
  Set the NPP CUDA stream.
 </p>
 <p>
  This function now returns an error if a problem occurs with Cuda stream management. This function should only be called if a call to
  <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/core_npp.html#group__core__npp_1ga7b5dd1c9dc541b35137b0635e3150c07">
   <span class="std std-ref">
    nppGetStream()
   </span>
  </a>
  returns a stream number which is different from the desired stream since unnecessarily flushing the current stream can significantly affect performance.
 </p>
 <p class="admonition-title">
  See also
 </p>
 <p>
  <a class="reference internal" href="https://docs.nvidia.com/cuda/npp/core_npp.html#group__core__npp_1ga7b5dd1c9dc541b35137b0635e3150c07">
   <span class="std std-ref">
    nppGetStream()
   </span>
  </a>
 </p>
 <p class="notices">
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
   Privacy Policy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">
   Manage My Privacy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">
   Do Not Sell or Share My Data
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
   Terms of Service
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
   Accessibility
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
   Corporate Policies
  </a>
  |
  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
   Product Security
  </a>
  |
  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
   Contact
  </a>
 </p>
 <p>
  Copyright Â© 2009-2024, NVIDIA Corporation &amp; affiliates. All rights reserved.
 </p>
 <p>
  <span class="lastupdated">
   Last updated on Jul 1, 2024.
  </span>
 </p>
</body>
</body></html>