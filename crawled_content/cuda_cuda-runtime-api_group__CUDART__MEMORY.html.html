<html><head><title>CUDA Runtime API :: CUDA Toolkit Documentation</title></head><body><body>
 <span id="company">
  NVIDIA
 </span>
 <span id="site-title">
  CUDA Toolkit Documentation
 </span>
 Search In:
 Entire Site
 Just This Document
 clear search
 search
 <a href="https://docs.nvidia.com/cuda/index.html" title="The root of the site.">
  CUDA Toolkit 
                  
                  
                  v12.5.1
 </a>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html" title="CUDA Runtime API">
  CUDA Runtime API
 </a>
 <ul>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/driver-vs-runtime-api.html#driver-vs-runtime-api">
    1.Â Difference between the driver and runtime APIs
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior">
    2.Â API synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior">
    3.Â Stream synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/graphs-thread-safety.html#graphs-thread-safety">
    4.Â Graph object thread safety
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/version-mixing-rules.html#version-mixing-rules">
    5.Â Rules for version mixing
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/modules.html#modules">
    6.Â Modules
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE">
      6.1.Â Device Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE__DEPRECATED.html#group__CUDART__DEVICE__DEPRECATED">
      6.2.Â Device Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__THREAD__DEPRECATED.html#group__CUDART__THREAD__DEPRECATED">
      6.3.Â Thread Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html#group__CUDART__ERROR">
      6.4.Â Error Handling
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM">
      6.5.Â Stream Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EVENT.html#group__CUDART__EVENT">
      6.6.Â Event Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXTRES__INTEROP.html#group__CUDART__EXTRES__INTEROP">
      6.7.Â External Resource Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION">
      6.8.Â Execution Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION__DEPRECATED.html#group__CUDART__EXECUTION__DEPRECATED">
      6.9.Â Execution Control [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html#group__CUDART__OCCUPANCY">
      6.10.Â Occupancy
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY">
      6.11.Â Memory Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__DEPRECATED.html#group__CUDART__MEMORY__DEPRECATED">
      6.12.Â Memory Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS">
      6.13.Â Stream Ordered Memory Allocator
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__UNIFIED.html#group__CUDART__UNIFIED">
      6.14.Â Unified Addressing
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PEER.html#group__CUDART__PEER">
      6.15.Â Peer Device Memory Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL.html#group__CUDART__OPENGL">
      6.16.Â OpenGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OPENGL__DEPRECATED.html#group__CUDART__OPENGL__DEPRECATED">
      6.17.Â OpenGL Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9.html#group__CUDART__D3D9">
      6.18.Â Direct3D 9 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D9__DEPRECATED.html#group__CUDART__D3D9__DEPRECATED">
      6.19.Â Direct3D 9 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10.html#group__CUDART__D3D10">
      6.20.Â Direct3D 10 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D10__DEPRECATED.html#group__CUDART__D3D10__DEPRECATED">
      6.21.Â Direct3D 10 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11.html#group__CUDART__D3D11">
      6.22.Â Direct3D 11 Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__D3D11__DEPRECATED.html#group__CUDART__D3D11__DEPRECATED">
      6.23.Â Direct3D 11 Interoperability [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__VDPAU.html#group__CUDART__VDPAU">
      6.24.Â VDPAU Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EGL.html#group__CUDART__EGL">
      6.25.Â EGL Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__INTEROP.html#group__CUDART__INTEROP">
      6.26.Â Graphics Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TEXTURE__OBJECT.html#group__CUDART__TEXTURE__OBJECT">
      6.27.Â Texture Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__SURFACE__OBJECT.html#group__CUDART__SURFACE__OBJECT">
      6.28.Â Surface Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART____VERSION.html#group__CUDART____VERSION">
      6.29.Â Version Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__GRAPH.html#group__CUDART__GRAPH">
      6.30.Â Graph Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER__ENTRY__POINT.html#group__CUDART__DRIVER__ENTRY__POINT">
      6.31.Â Driver Entry Point Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL">
      6.32.Â C++ API Routines
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DRIVER.html#group__CUDART__DRIVER">
      6.33.Â Interactions with the CUDA Driver API
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__PROFILER.html#group__CUDART__PROFILER">
      6.34.Â Profiler Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES">
      6.35.Â Data types used by CUDA Runtime
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/annotated.html#annotated">
    7.Â Data Structures
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/class____cudaOccupancyB2DHelper.html#class____cudaOccupancyB2DHelper">
      7.1.Â __cudaOccupancyB2DHelper
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAccessPolicyWindow.html#structcudaAccessPolicyWindow">
      7.2.Â cudaAccessPolicyWindow
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements">
      7.3.Â cudaArrayMemoryRequirements
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties">
      7.4.Â cudaArraySparseProperties
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaAsyncNotificationInfo__t.html#structcudaAsyncNotificationInfo__t">
      7.5.Â cudaAsyncNotificationInfo_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc">
      7.6.Â cudaChannelFormatDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChildGraphNodeParams.html#structcudaChildGraphNodeParams">
      7.7.Â cudaChildGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaConditionalNodeParams.html#structcudaConditionalNodeParams">
      7.8.Â cudaConditionalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp">
      7.9.Â cudaDeviceProp
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglFrame.html#structcudaEglFrame">
      7.10.Â cudaEglFrame
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEglPlaneDesc.html#structcudaEglPlaneDesc">
      7.11.Â cudaEglPlaneDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventRecordNodeParams.html#structcudaEventRecordNodeParams">
      7.12.Â cudaEventRecordNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaEventWaitNodeParams.html#structcudaEventWaitNodeParams">
      7.13.Â cudaEventWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent">
      7.14.Â cudaExtent
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryBufferDesc.html#structcudaExternalMemoryBufferDesc">
      7.15.Â cudaExternalMemoryBufferDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryHandleDesc.html#structcudaExternalMemoryHandleDesc">
      7.16.Â cudaExternalMemoryHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalMemoryMipmappedArrayDesc.html#structcudaExternalMemoryMipmappedArrayDesc">
      7.17.Â cudaExternalMemoryMipmappedArrayDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreHandleDesc.html#structcudaExternalSemaphoreHandleDesc">
      7.18.Â cudaExternalSemaphoreHandleDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParams.html#structcudaExternalSemaphoreSignalNodeParams">
      7.19.Â cudaExternalSemaphoreSignalNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalNodeParamsV2.html#structcudaExternalSemaphoreSignalNodeParamsV2">
      7.20.Â cudaExternalSemaphoreSignalNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams.html#structcudaExternalSemaphoreSignalParams">
      7.21.Â cudaExternalSemaphoreSignalParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreSignalParams__v1.html#structcudaExternalSemaphoreSignalParams__v1">
      7.22.Â cudaExternalSemaphoreSignalParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParams.html#structcudaExternalSemaphoreWaitNodeParams">
      7.23.Â cudaExternalSemaphoreWaitNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitNodeParamsV2.html#structcudaExternalSemaphoreWaitNodeParamsV2">
      7.24.Â cudaExternalSemaphoreWaitNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams.html#structcudaExternalSemaphoreWaitParams">
      7.25.Â cudaExternalSemaphoreWaitParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExternalSemaphoreWaitParams__v1.html#structcudaExternalSemaphoreWaitParams__v1">
      7.26.Â cudaExternalSemaphoreWaitParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaFuncAttributes.html#structcudaFuncAttributes">
      7.27.Â cudaFuncAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphEdgeData.html#structcudaGraphEdgeData">
      7.28.Â cudaGraphEdgeData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphExecUpdateResultInfo.html#structcudaGraphExecUpdateResultInfo">
      7.29.Â cudaGraphExecUpdateResultInfo
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphInstantiateParams.html#structcudaGraphInstantiateParams">
      7.30.Â cudaGraphInstantiateParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphKernelNodeUpdate.html#structcudaGraphKernelNodeUpdate">
      7.31.Â cudaGraphKernelNodeUpdate
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaGraphNodeParams.html#structcudaGraphNodeParams">
      7.32.Â cudaGraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParams.html#structcudaHostNodeParams">
      7.33.Â cudaHostNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaHostNodeParamsV2.html#structcudaHostNodeParamsV2">
      7.34.Â cudaHostNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcEventHandle__t.html#structcudaIpcEventHandle__t">
      7.35.Â cudaIpcEventHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaIpcMemHandle__t.html#structcudaIpcMemHandle__t">
      7.36.Â cudaIpcMemHandle_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParams.html#structcudaKernelNodeParams">
      7.37.Â cudaKernelNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaKernelNodeParamsV2.html#structcudaKernelNodeParamsV2">
      7.38.Â cudaKernelNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchAttribute.html#structcudaLaunchAttribute">
      7.39.Â cudaLaunchAttribute
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/unioncudaLaunchAttributeValue.html#unioncudaLaunchAttributeValue">
      7.40.Â cudaLaunchAttributeValue
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchConfig__t.html#structcudaLaunchConfig__t">
      7.41.Â cudaLaunchConfig_t
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchMemSyncDomainMap.html#structcudaLaunchMemSyncDomainMap">
      7.42.Â cudaLaunchMemSyncDomainMap
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaLaunchParams.html#structcudaLaunchParams">
      7.43.Â cudaLaunchParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAccessDesc.html#structcudaMemAccessDesc">
      7.44.Â cudaMemAccessDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParams.html#structcudaMemAllocNodeParams">
      7.45.Â cudaMemAllocNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemAllocNodeParamsV2.html#structcudaMemAllocNodeParamsV2">
      7.46.Â cudaMemAllocNodeParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms">
      7.47.Â cudaMemcpy3DParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms">
      7.48.Â cudaMemcpy3DPeerParms
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpyNodeParams.html#structcudaMemcpyNodeParams">
      7.49.Â cudaMemcpyNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemFreeNodeParams.html#structcudaMemFreeNodeParams">
      7.50.Â cudaMemFreeNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation">
      7.51.Â cudaMemLocation
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolProps.html#structcudaMemPoolProps">
      7.52.Â cudaMemPoolProps
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemPoolPtrExportData.html#structcudaMemPoolPtrExportData">
      7.53.Â cudaMemPoolPtrExportData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParams.html#structcudaMemsetParams">
      7.54.Â cudaMemsetParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemsetParamsV2.html#structcudaMemsetParamsV2">
      7.55.Â cudaMemsetParamsV2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr">
      7.56.Â cudaPitchedPtr
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPointerAttributes.html#structcudaPointerAttributes">
      7.57.Â cudaPointerAttributes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos">
      7.58.Â cudaPos
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceDesc.html#structcudaResourceDesc">
      7.59.Â cudaResourceDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaResourceViewDesc.html#structcudaResourceViewDesc">
      7.60.Â cudaResourceViewDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaTextureDesc.html#structcudaTextureDesc">
      7.61.Â cudaTextureDesc
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structCUuuid__st.html#structCUuuid__st">
      7.62.Â CUuuid_st
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/functions.html#functions">
    8.Â Data Fields
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/deprecated.html#deprecated">
    9.Â Deprecated List
   </a>
  </li>
 </ul>
 <h2>
  Search Results
 </h2>
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__OCCUPANCY.html" shape="rect">
  &lt; Previous
 </a>
 |
 <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__DEPRECATED.html" shape="rect">
  Next &gt;
 </a>
 CUDA Runtime API
                  (
 <a href="https://docs.nvidia.com/cuda/pdf/CUDA_Runtime_API.pdf">
  PDF
 </a>
 )
                  -
                   
                  
                  
                  v12.5.1
                  (
 <a href="https://developer.nvidia.com/cuda-toolkit-archive">
  older
 </a>
 )
                  -
                  Last updated July 1, 2024
                  -
 <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA%20Toolkit%20Documentation%20Feedback:%20CUDA%20Runtime%20API">
  Send Feedback
 </a>
 <a name="group__CUDART__MEMORY" shape="rect">
  <!-- -->
 </a>
 <h2 class="topictitle2 cppModule">
  6.11.Â Memory Management
 </h2>
 <p>
  This section describes the memory management functions of the CUDA runtime application programming interface.
 </p>
 <p class="p">
  Some functions have overloaded C++ API template versions documented separately in the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL" shape="rect" title="C++-style interface built on top of CUDA runtime API.">
   C++ API Routines
  </a>
  module.
 </p>
 <h3 class="fake_sectiontitle member_header">
  Functions
 </h3>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g373dacf191566b0bf5e5b807517b6bf9" shape="rect">
   cudaArrayGetInfo
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  , unsigned int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  )
 </span>
 <span class="desc">
  Gets info about the specified cudaArray.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g809cc7ad6dbb23f84121f28136c6eace" shape="rect">
   cudaArrayGetMemoryRequirements
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements" shape="rect" title="">
   cudaArrayMemoryRequirements
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memoryRequirements
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns the memory requirements of a CUDA array.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9a851663a2b9f222b549c727adc0e079" shape="rect">
   cudaArrayGetPlane
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pPlaneArray
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hArray
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   planeIdx
  </span>
  )
 </span>
 <span class="desc">
  Gets a CUDA array plane from a CUDA array.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0bfd1422d4647443bab85ebcf2157185" shape="rect">
   cudaArrayGetSparseProperties
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties" shape="rect" title="">
   cudaArraySparseProperties
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   sparseProperties
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  )
 </span>
 <span class="desc">
  Returns the layout properties of a sparse CUDA array.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect">
   cudaFree
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  )
 </span>
 <span class="desc">
  Frees memory on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect">
   cudaFreeArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  )
 </span>
 <span class="desc">
  Frees an array on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect">
   cudaFreeHost
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  )
 </span>
 <span class="desc">
  Frees page-locked memory.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g904669241eac5bdbfb410eb4124e4924" shape="rect">
   cudaFreeMipmappedArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmappedArray
  </span>
  )
 </span>
 <span class="desc">
  Frees a mipmapped array on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7086e6f81e6dda1ddf4cdb6c1764094a" shape="rect">
   cudaGetMipmappedArrayLevel
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   levelArray
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g99f602628e1c5159da2dc2cefb5bdc04" shape="rect" title="">
   cudaMipmappedArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmappedArray
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   level
  </span>
  )
 </span>
 <span class="desc">
  Gets a mipmap level of a CUDA mipmapped array.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g4f513be54d3794667c2017146b3d6a2b" shape="rect">
   cudaGetSymbolAddress
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  )
 </span>
 <span class="desc">
  Finds the address associated with a CUDA symbol.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1d150bde14df4e291b520226fe475466" shape="rect">
   cudaGetSymbolSize
  </a>
  (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  )
 </span>
 <span class="desc">
  Finds the size of the object associated with a CUDA symbol.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect">
   cudaHostAlloc
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pHost
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Allocates page-locked memory on the host.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect">
   cudaHostGetDevicePointer
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pDevice
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pHost
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc470e9220559109f5088d9a01c0aeeda" shape="rect">
   cudaHostGetFlags
  </a>
  (  unsigned int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pFlags
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pHost
  </span>
  )
 </span>
 <span class="desc">
  Passes back flags used to allocate pinned host memory allocated by cudaHostAlloc.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect">
   cudaHostRegister
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 <span class="desc">
  Registers an existing host memory range for use by CUDA.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g81fd4101862bbefdb42a62d60e515eea" shape="rect">
   cudaHostUnregister
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  )
 </span>
 <span class="desc">
  Unregisters a memory range that was registered with cudaHostRegister.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect">
   cudaMalloc
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 <span class="desc">
  Allocate memory on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect">
   cudaMalloc3D
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitchedDevPtr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  )
 </span>
 <span class="desc">
  Allocates logical 1D, 2D, or 3D memory objects on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect">
   cudaMalloc3DArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Allocate an array on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect">
   cudaMallocArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Allocate an array on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect">
   cudaMallocHost
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 <span class="desc">
  Allocates page-locked memory on the host.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gd228014f19cc0975ebe3e0dd2af6dd1b" shape="rect">
   cudaMallocManaged
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   cudaMemAttachGlobal
  </span>
  )
 </span>
 <span class="desc">
  Allocates memory that will be automatically managed by the Unified Memory system.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9abd550dd3f655473d2640dc85be9774" shape="rect">
   cudaMallocMipmappedArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmappedArray
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numLevels
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Allocate a mipmapped array on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect">
   cudaMallocPitch
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  )
 </span>
 <span class="desc">
  Allocates pitched memory on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge37112fc1ac88d0f6bab7a945e48760a" shape="rect">
   cudaMemAdvise
  </a>
  (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gc314a8b14091f7e02a7ad15dcb36c857" shape="rect" title="">
   cudaMemoryAdvise
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   advice
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Advise about the usage of a given memory range.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3e95883b161c343f4b7ea881cf8e3a09" shape="rect">
   cudaMemAdvise_v2
  </a>
  (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gc314a8b14091f7e02a7ad15dcb36c857" shape="rect" title="">
   cudaMemoryAdvise
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   advice
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation" shape="rect" title="">
   cudaMemLocation
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   location
  </span>
  )
 </span>
 <span class="desc">
  Advise about the usage of a given memory range.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g376b97f5ab20321ca46f7cfa9511b978" shape="rect">
   cudaMemGetInfo
  </a>
  (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   free
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   total
  </span>
  )
 </span>
 <span class="desc">
  Gets free and total device memory.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect">
   cudaMemPrefetchAsync
  </a>
  (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Prefetches memory to the specified destination device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8048f6ea5ad77917444567656c140c5a" shape="rect">
   cudaMemRangeGetAttribute
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   data
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dataSize
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gdfcc848da2b9f49661333f861ad1a379" shape="rect" title="">
   cudaMemRangeAttribute
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attribute
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 <span class="desc">
  Query an attribute of a given memory range.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1a9199e7709c7817d1c715cfbe174d05" shape="rect">
   cudaMemRangeGetAttributes
  </a>
  (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   data
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dataSizes
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gdfcc848da2b9f49661333f861ad1a379" shape="rect" title="">
   cudaMemRangeAttribute
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attributes
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numAttributes
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 <span class="desc">
  Query attributes of a given memory range.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect">
   cudaMemcpy
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect">
   cudaMemcpy2D
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect">
   cudaMemcpy2DArrayToArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffsetDst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffsetDst
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1259f0b7bcff80ba46267c9117f9bb21" shape="rect" title="">
   cudaArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffsetSrc
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffsetSrc
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  =
  <span class="ph ph apiData">
   cudaMemcpyDeviceToDevice
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect">
   cudaMemcpy2DAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect">
   cudaMemcpy2DFromArray
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1259f0b7bcff80ba46267c9117f9bb21" shape="rect" title="">
   cudaArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect">
   cudaMemcpy2DFromArrayAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1259f0b7bcff80ba46267c9117f9bb21" shape="rect" title="">
   cudaArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect">
   cudaMemcpy2DToArray
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect">
   cudaMemcpy2DToArrayAsync
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect">
   cudaMemcpy3D
  </a>
  (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect" title="">
   cudaMemcpy3DParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  )
 </span>
 <span class="desc">
  Copies data between 3D objects.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect">
   cudaMemcpy3DAsync
  </a>
  (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect" title="">
   cudaMemcpy3DParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data between 3D objects.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1geeab4601354962a5968eefc8b79ec2dd" shape="rect">
   cudaMemcpy3DPeer
  </a>
  (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms" shape="rect" title="">
   cudaMemcpy3DPeerParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  )
 </span>
 <span class="desc">
  Copies memory between devices.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect">
   cudaMemcpy3DPeerAsync
  </a>
  (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms" shape="rect" title="">
   cudaMemcpy3DPeerParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies memory between devices asynchronously.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect">
   cudaMemcpyAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data between host and device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g17ce3365ef7b6687a7d16c5b29de1f82" shape="rect">
   cudaMemcpyFromSymbol
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  =
  <span class="ph ph apiData">
   cudaMemcpyDeviceToHost
  </span>
  )
 </span>
 <span class="desc">
  Copies data from the given symbol on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9445b750013829f03d0bb5ad5fa7a0fb" shape="rect">
   cudaMemcpyFromSymbolAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data from the given symbol on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect">
   cudaMemcpyPeer
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   srcDevice
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 <span class="desc">
  Copies memory between two devices.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" shape="rect">
   cudaMemcpyPeerAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   srcDevice
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies memory between two devices asynchronously.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9bcf02b53644eee2bef9983d807084c7" shape="rect">
   cudaMemcpyToSymbol
  </a>
  (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  =
  <span class="ph ph apiData">
   cudaMemcpyHostToDevice
  </span>
  )
 </span>
 <span class="desc">
  Copies data to the given symbol on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3551568f691baad5fb776b7656ecc05" shape="rect">
   cudaMemcpyToSymbolAsync
  </a>
  (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Copies data to the given symbol on the device.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect">
   cudaMemset
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 <span class="desc">
  Initializes or sets device memory to a value.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" shape="rect">
   cudaMemset2D
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitch
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  )
 </span>
 <span class="desc">
  Initializes or sets device memory to a value.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect">
   cudaMemset2DAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitch
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Initializes or sets device memory to a value.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect">
   cudaMemset3D
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitchedDevPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  )
 </span>
 <span class="desc">
  Initializes or sets device memory to a value.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect">
   cudaMemset3DAsync
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitchedDevPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Initializes or sets device memory to a value.
 </span>
 <span class="member_long_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name_long_type">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect">
   cudaMemsetAsync
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 <span class="desc">
  Initializes or sets device memory to a value.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g5585c79ccabe9cd9f882810b0ae2f382" shape="rect">
   cudaMipmappedArrayGetMemoryRequirements
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements" shape="rect" title="">
   cudaArrayMemoryRequirements
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memoryRequirements
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmap
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 <span class="desc">
  Returns the memory requirements of a CUDA mipmapped array.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g96d65849f80adb87d239f68756ed5b14" shape="rect">
   cudaMipmappedArrayGetSparseProperties
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties" shape="rect" title="">
   cudaArraySparseProperties
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   sparseProperties
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmap
  </span>
  )
 </span>
 <span class="desc">
  Returns the layout properties of a sparse CUDA mipmapped array.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect">
   make_cudaExtent
  </a>
  (  size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   w
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   h
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   d
  </span>
  )
 </span>
 <span class="desc">
  Returns a cudaExtent based on input parameters.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect">
   make_cudaPitchedPtr
  </a>
  (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   d
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   xsz
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ysz
  </span>
  )
 </span>
 <span class="desc">
  Returns a cudaPitchedPtr based on input parameters.
 </span>
 <span class="member_type">
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect" title="">
   cudaPos
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect">
   make_cudaPos
  </a>
  (  size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   x
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   y
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   z
  </span>
  )
 </span>
 <span class="desc">
  Returns a cudaPos based on input parameters.
 </span>
 <h3 class="sectiontitle">
  Functions
 </h3>
 <a id="group__CUDART__MEMORY_1g373dacf191566b0bf5e5b807517b6bf9" name="group__CUDART__MEMORY_1g373dacf191566b0bf5e5b807517b6bf9" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaArrayGetInfo (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  , unsigned int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  )
 </span>
 Gets info about the specified cudaArray.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  desc
 </span>
 - Returned array type
 <span class="keyword keyword apiItemName">
  extent
 </span>
 - Returned array shape. 2D arrays will have depth of zero
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Returned array flags
 <span class="keyword keyword apiItemName">
  array
 </span>
 - The cudaArray to get info for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *desc
  ,
  *extent
  and
  *flags
  respectively, the type, shape and flags of
  array
  .
 </p>
 <p class="p">
  Any of
  *desc
  ,
  *extent
  and
  *flags
  may be specified as NULL.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g661fe823dbd37bf11f82a71bd4762acf" shape="rect" target="_blank">
   cuArrayGetDescriptor
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gb58549f2f3f390b9e0e7c8f3acd53857" shape="rect" target="_blank">
   cuArray3DGetDescriptor
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g809cc7ad6dbb23f84121f28136c6eace" name="group__CUDART__MEMORY_1g809cc7ad6dbb23f84121f28136c6eace" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaArrayGetMemoryRequirements (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements" shape="rect" title="">
   cudaArrayMemoryRequirements
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memoryRequirements
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns the memory requirements of a CUDA array.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memoryRequirements
 </span>
 - Pointer to
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements" shape="rect">
  cudaArrayMemoryRequirements
 </a>
 <span class="keyword keyword apiItemName">
  array
 </span>
 - CUDA array to get the memory requirements of
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device to get the memory requirements for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns the memory requirements of a CUDA array in
  memoryRequirements
  If the CUDA array is not allocated with flag
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g91a50795515848406a89c2e6cef2fb02" shape="rect">
   cudaArrayDeferredMapping
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  will be returned.
 </p>
 <p class="p">
  The returned value in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements_1cff0bc12daa05c6c40892a2187befd87" shape="rect">
   cudaArrayMemoryRequirements::size
  </a>
  represents the total size of the CUDA array. The returned value in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements_137898b13b500d39e4a43d0ee04cf0ef3" shape="rect">
   cudaArrayMemoryRequirements::alignment
  </a>
  represents the alignment necessary for mapping the CUDA array.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g5585c79ccabe9cd9f882810b0ae2f382" shape="rect" title="Returns the memory requirements of a CUDA mipmapped array.">
   cudaMipmappedArrayGetMemoryRequirements
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g9a851663a2b9f222b549c727adc0e079" name="group__CUDART__MEMORY_1g9a851663a2b9f222b549c727adc0e079" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaArrayGetPlane (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pPlaneArray
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hArray
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   planeIdx
  </span>
  )
 </span>
 Gets a CUDA array plane from a CUDA array.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pPlaneArray
 </span>
 - Returned CUDA array referenced by the
 planeIdx
 <span class="keyword keyword apiItemName">
  hArray
 </span>
 - CUDA array
 <span class="keyword keyword apiItemName">
  planeIdx
 </span>
 - Plane index
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c4673247aee4d1ab8d07871f376e0273" shape="rect">
   cudaErrorInvalidResourceHandle
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  pPlaneArray
  a CUDA array that represents a single format plane of the CUDA array
  hArray
  .
 </p>
 <p class="p">
  If
  planeIdx
  is greater than the maximum number of planes in this array or if the array does not have a multi-planar format e.g:
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119c89d051aff61fb1bd60a69fdd82a97c2" shape="rect">
   cudaChannelFormatKindNV12
  </a>
  , then
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  is returned.
 </p>
 <p class="p">
  Note that if the
  hArray
  has format
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119c89d051aff61fb1bd60a69fdd82a97c2" shape="rect">
   cudaChannelFormatKindNV12
  </a>
  , then passing in 0 for
  planeIdx
  returns a CUDA array of the same size as
  hArray
  but with one 8-bit channel and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119240d73fa2dc05cbaa58f093f169ab3d4" shape="rect">
   cudaChannelFormatKindUnsigned
  </a>
  as its format kind. If 1 is passed for
  planeIdx
  , then the returned CUDA array has half the height and width of
  hArray
  with two 8-bit channels and
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119240d73fa2dc05cbaa58f093f169ab3d4" shape="rect">
   cudaChannelFormatKindUnsigned
  </a>
  as its format kind.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Note that this function may also return error codes from previous, asynchronous launches.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ge66ce245a1e3802f9ccc3583cec6b71f" shape="rect" target="_blank">
   cuArrayGetPlane
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g0bfd1422d4647443bab85ebcf2157185" name="group__CUDART__MEMORY_1g0bfd1422d4647443bab85ebcf2157185" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaArrayGetSparseProperties (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties" shape="rect" title="">
   cudaArraySparseProperties
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   sparseProperties
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  )
 </span>
 Returns the layout properties of a sparse CUDA array.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  sparseProperties
 </span>
 - Pointer to return the
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties" shape="rect">
  cudaArraySparseProperties
 </a>
 <span class="keyword keyword apiItemName">
  array
 </span>
 - The CUDA array to get the sparse properties of
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns the layout properties of a sparse CUDA array in
  sparseProperties
  . If the CUDA array is not allocated with flag
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g42c353686a15da063dc7722594ae4bff" shape="rect">
   cudaArraySparse
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  will be returned.
 </p>
 <p class="p">
  If the returned value in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_144c8728469d60e511aceb4ba7086c164" shape="rect">
   cudaArraySparseProperties::flags
  </a>
  contains
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6820071ffa1300699897eab8d319e4d9" shape="rect">
   cudaArraySparsePropertiesSingleMipTail
  </a>
  , then
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_122cfa4ad83195f0e9585303c988bb886" shape="rect">
   cudaArraySparseProperties::miptailSize
  </a>
  represents the total size of the array. Otherwise, it will be zero. Also, the returned value in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_1b6909e5db55b866477b6cc16fb02f9d3" shape="rect">
   cudaArraySparseProperties::miptailFirstLevel
  </a>
  is always zero. Note that the
  array
  must have been allocated using
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  . For CUDA arrays obtained using cudaMipmappedArrayGetLevel,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  will be returned. Instead,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g96d65849f80adb87d239f68756ed5b14" shape="rect" title="Returns the layout properties of a sparse CUDA mipmapped array.">
   cudaMipmappedArrayGetSparseProperties
  </a>
  must be used to obtain the sparse properties of the entire CUDA mipmapped array to which
  array
  belongs to.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g96d65849f80adb87d239f68756ed5b14" shape="rect" title="Returns the layout properties of a sparse CUDA mipmapped array.">
   cudaMipmappedArrayGetSparseProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
   cuMemMapArrayAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" name="group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaFree (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  )
 </span>
 Frees memory on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Device pointer to memory to free
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Frees the memory space pointed to by
  devPtr
  , which must have been returned by a previous call to one of the following memory allocation APIs -
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc()
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gd228014f19cc0975ebe3e0dd2af6dd1b" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged()
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1gbbf70065888d61853c047513baa14081" shape="rect" title="Allocates memory with stream ordered semantics.">
   cudaMallocAsync()
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync()
  </a>
  .
 </p>
 <p class="p">
  Note - This API will not perform any implicit synchronization when the pointer was allocated with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
  . Callers must ensure that all accesses to the pointer have completed before invoking
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  . For best performance and memory reuse, users should use
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  to free memory allocated via the stream ordered memory allocator.
 </p>
 <p class="p">
  If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  (
  devPtr
  ) has already been called before, an error is returned. If
  devPtr
  is 0, no operation is performed.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree()
  </a>
  returns cudaErrorValue in case of failure.
 </p>
 <p class="p">
  The device version of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  cannot be used with a
  *devPtr
  allocated using the host API, and vice versa.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1ga31efcffc48981621feddd98d71a0feb" shape="rect" title="Allocate from a pool.">
   cudaMallocAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g871003f518e27ec92f7b331307fa32d4" shape="rect" title="Allocates memory from a specified pool with stream ordered semantics.">
   cudaMallocFromPoolAsync
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html#group__CUDART__MEMORY__POOLS_1g3398a689c75448c1bf99368e490ac878" shape="rect" title="Frees memory with stream ordered semantics.">
   cudaFreeAsync
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g89b3f154e17cc89b6eea277dbdf5c93a" shape="rect" target="_blank">
   cuMemFree
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" name="group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaFreeArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  )
 </span>
 Frees an array on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  array
 </span>
 - Pointer to array to free
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Frees the CUDA array
  array
  , which must have been returned by a previous call to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray()
  </a>
  . If
  devPtr
  is 0, no operation is performed.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g982878affbbc023de84874faac838b0b" shape="rect" target="_blank">
   cuArrayDestroy
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" name="group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaFreeHost (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  )
 </span>
 Frees page-locked memory.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  ptr
 </span>
 - Pointer to memory to free
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Frees the memory space pointed to by
  hostPtr
  , which must have been returned by a previous call to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost()
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc()
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g62e0fdbe181dab6b1c90fa1a51c7b92c" shape="rect" target="_blank">
   cuMemFreeHost
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g904669241eac5bdbfb410eb4124e4924" name="group__CUDART__MEMORY_1g904669241eac5bdbfb410eb4124e4924" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaFreeMipmappedArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmappedArray
  </span>
  )
 </span>
 Frees a mipmapped array on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  mipmappedArray
 </span>
 - Pointer to mipmapped array to free
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Frees the CUDA mipmapped array
  mipmappedArray
  , which must have been returned by a previous call to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9abd550dd3f655473d2640dc85be9774" shape="rect" title="Allocate a mipmapped array on the device.">
   cudaMallocMipmappedArray()
  </a>
  . If
  devPtr
  is 0, no operation is performed.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ge0d7c768b6a6963c4d4bde5bbc74f0ad" shape="rect" target="_blank">
   cuMipmappedArrayDestroy
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g7086e6f81e6dda1ddf4cdb6c1764094a" name="group__CUDART__MEMORY_1g7086e6f81e6dda1ddf4cdb6c1764094a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetMipmappedArrayLevel (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   levelArray
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g99f602628e1c5159da2dc2cefb5bdc04" shape="rect" title="">
   cudaMipmappedArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmappedArray
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   level
  </span>
  )
 </span>
 Gets a mipmap level of a CUDA mipmapped array.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  levelArray
 </span>
 - Returned mipmap level CUDA array
 <span class="keyword keyword apiItemName">
  mipmappedArray
 </span>
 - CUDA mipmapped array
 <span class="keyword keyword apiItemName">
  level
 </span>
 - Mipmap level
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c4673247aee4d1ab8d07871f376e0273" shape="rect">
   cudaErrorInvalidResourceHandle
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *levelArray
  a CUDA array that represents a single mipmap level of the CUDA mipmapped array
  mipmappedArray
  .
 </p>
 <p class="p">
  If
  level
  is greater than the maximum number of levels in this mipmapped array,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  is returned.
 </p>
 <p class="p">
  If
  mipmappedArray
  is NULL,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038c4673247aee4d1ab8d07871f376e0273" shape="rect">
   cudaErrorInvalidResourceHandle
  </a>
  is returned.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g82f276659f05be14820e99346b0f86b7" shape="rect" target="_blank">
   cuMipmappedArrayGetLevel
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g4f513be54d3794667c2017146b3d6a2b" name="group__CUDART__MEMORY_1g4f513be54d3794667c2017146b3d6a2b" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetSymbolAddress (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  )
 </span>
 Finds the address associated with a CUDA symbol.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Return device pointer associated with symbol
 <span class="keyword keyword apiItemName">
  symbol
 </span>
 - Device symbol address
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388db0eb1b77feecee97b09d43dd876122" shape="rect">
   cudaErrorNoKernelImageForDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *devPtr
  the address of symbol
  symbol
  on the device.
  symbol
  is a variable that resides in global or constant memory space. If
  symbol
  cannot be found, or if
  symbol
  is not declared in the global or constant memory space,
  *devPtr
  is unchanged and the error
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  is returned.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Use of a string naming a variable as the
    symbol
    parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g3a0f010e70a3343db18227cec9615177" shape="rect" title="[C++ API] Finds the address associated with a CUDA symbol">
   cudaGetSymbolAddress ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1d150bde14df4e291b520226fe475466" shape="rect" title="Finds the size of the object associated with a CUDA symbol.">
   cudaGetSymbolSize ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE_1gf3e43672e26073b1081476dbf47a86ab" shape="rect" target="_blank">
   cuModuleGetGlobal
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g1d150bde14df4e291b520226fe475466" name="group__CUDART__MEMORY_1g1d150bde14df4e291b520226fe475466" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaGetSymbolSize (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  )
 </span>
 Finds the size of the object associated with a CUDA symbol.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Size of object associated with symbol
 <span class="keyword keyword apiItemName">
  symbol
 </span>
 - Device symbol address
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388db0eb1b77feecee97b09d43dd876122" shape="rect">
   cudaErrorNoKernelImageForDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *size
  the size of symbol
  symbol
  .
  symbol
  is a variable that resides in global or constant memory space. If
  symbol
  cannot be found, or if
  symbol
  is not declared in global or constant memory space,
  *size
  is unchanged and the error
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  is returned.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Use of a string naming a variable as the
    symbol
    parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g4f513be54d3794667c2017146b3d6a2b" shape="rect" title="Finds the address associated with a CUDA symbol.">
   cudaGetSymbolAddress ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g0561c8ffee270bff0bbb7deb81ad865c" shape="rect" title="[C++ API] Finds the size of the object associated with a CUDA symbol">
   cudaGetSymbolSize ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE_1gf3e43672e26073b1081476dbf47a86ab" shape="rect" target="_blank">
   cuModuleGetGlobal
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" name="group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaHostAlloc (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pHost
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Allocates page-locked memory on the host.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pHost
 </span>
 - Device pointer to allocated memory
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Requested allocation size in bytes
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Requested properties of allocated memory
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates
  size
  bytes of host memory that is page-locked and accessible to the device. The driver tracks the virtual memory ranges allocated
                                 with this function and automatically accelerates calls to functions such as
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy()
  </a>
  . Since the memory can be accessed directly by the device, it can be read or written with much higher bandwidth than pageable
                                 memory obtained with functions such as malloc(). Allocating excessive amounts of pinned memory may degrade system performance,
                                 since it reduces the amount of memory available to the system for paging. As a result, this function is best used sparingly
                                 to allocate staging areas for data exchange between host and device.
 </p>
 <p class="p">
  The
  flags
  parameter enables different options to be specified that affect the allocation, as follows.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1e00f7734325eb38d75f3ffeae6acac8" shape="rect">
     cudaHostAllocDefault
    </a>
    : This flag's value is defined to be 0 and causes
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
     cudaHostAlloc()
    </a>
    to emulate
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
     cudaMallocHost()
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gc46ce76be41cf79774331cc8cfceb52b" shape="rect">
     cudaHostAllocPortable
    </a>
    : The memory returned by this call will be considered as pinned memory by all CUDA contexts, not just the one that performed
                                          the allocation.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g01e600c738b962c8f973dda7708f7a70" shape="rect">
     cudaHostAllocMapped
    </a>
    : Maps the allocation into the CUDA address space. The device pointer to the memory may be obtained by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
     cudaHostGetDevicePointer()
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3a7db37d02ce0b2350067ab639ef321c" shape="rect">
     cudaHostAllocWriteCombined
    </a>
    : Allocates the memory as write-combined (WC). WC memory can be transferred across the PCI Express bus more quickly on some
                                          system configurations, but cannot be read efficiently by most CPUs. WC memory is a good option for buffers that will be written
                                          by the CPU and read by the device via mapped pinned memory or host-&gt;device transfers.
   </p>
  </li>
 </ul>
 <p class="p">
  All of these flags are orthogonal to one another: a developer may allocate memory that is portable, mapped and/or write-combined
                                 with no restrictions.
 </p>
 <p class="p">
  In order for the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g01e600c738b962c8f973dda7708f7a70" shape="rect">
   cudaHostAllocMapped
  </a>
  flag to have any effect, the CUDA context must support the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3762be9cccdd809a4ca128354fd134b0" shape="rect">
   cudaDeviceMapHost
  </a>
  flag, which can be checked via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" shape="rect" title="Gets the flags for the current device.">
   cudaGetDeviceFlags()
  </a>
  . The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3762be9cccdd809a4ca128354fd134b0" shape="rect">
   cudaDeviceMapHost
  </a>
  flag is implicitly set for contexts created via the runtime API.
 </p>
 <p class="p">
  The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g01e600c738b962c8f973dda7708f7a70" shape="rect">
   cudaHostAllocMapped
  </a>
  flag may be specified on CUDA contexts for devices that do not support mapped pinned memory. The failure is deferred to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  because the memory may be mapped into other CUDA contexts via the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gc46ce76be41cf79774331cc8cfceb52b" shape="rect">
   cudaHostAllocPortable
  </a>
  flag.
 </p>
 <p class="p">
  Memory allocated by this function must be freed with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost()
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gf830794caf068b71638c6182bba8f77a" shape="rect" title="Gets the flags for the current device.">
   cudaGetDeviceFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g572ca4011bfcb25034888a14d4e035b9" shape="rect" target="_blank">
   cuMemHostAlloc
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" name="group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaHostGetDevicePointer (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pDevice
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pHost
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pDevice
 </span>
 - Returned device pointer for mapped memory
 <span class="keyword keyword apiItemName">
  pHost
 </span>
 - Requested host pointer mapping
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Flags for extensions (must be 0 for now)
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Passes back the device pointer corresponding to the mapped, pinned host buffer allocated by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc()
  </a>
  or registered by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
   cudaHostRegister()
  </a>
  .
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  will fail if the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3762be9cccdd809a4ca128354fd134b0" shape="rect">
   cudaDeviceMapHost
  </a>
  flag was not specified before deferred context creation occurred, or if called on a device that does not support mapped,
                                 pinned memory.
 </p>
 <p class="p">
  For devices that have a non-zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb08e379a7a038dc8134914702c223f69" shape="rect">
   cudaDevAttrCanUseHostPointerForRegisteredMem
  </a>
  , the memory can also be accessed from the device using the host pointer
  pHost
  . The device pointer returned by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  may or may not match the original host pointer
  pHost
  and depends on the devices visible to the application. If all devices visible to the application have a non-zero value for
                                 the device attribute, the device pointer returned by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  will match the original pointer
  pHost
  . If any device visible to the application has a zero value for the device attribute, the device pointer returned by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  will not match the original host pointer
  pHost
  , but it will be suitable for use on all devices provided Unified Virtual Addressing is enabled. In such systems, it is valid
                                 to access the memory using either pointer on devices that have a non-zero value for the device attribute. Note however that
                                 such devices should access the memory using only of the two pointers and not both.
 </p>
 <p class="p">
  flags
  provides for future releases. For now, it must be set to 0.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g69e73c7dda3fc05306ae7c811a690fac" shape="rect" title="Sets flags to be used for device executions.">
   cudaSetDeviceFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g57a39e5cba26af4d06be67fc77cc62f0" shape="rect" target="_blank">
   cuMemHostGetDevicePointer
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gc470e9220559109f5088d9a01c0aeeda" name="group__CUDART__MEMORY_1gc470e9220559109f5088d9a01c0aeeda" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaHostGetFlags (  unsigned int*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pFlags
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pHost
  </span>
  )
 </span>
 Passes back flags used to allocate pinned host memory allocated by cudaHostAlloc.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pFlags
 </span>
 - Returned flags word
 <span class="keyword keyword apiItemName">
  pHost
 </span>
 - Host pointer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc470e9220559109f5088d9a01c0aeeda" shape="rect" title="Passes back flags used to allocate pinned host memory allocated by cudaHostAlloc.">
   cudaHostGetFlags()
  </a>
  will fail if the input pointer does not reside in an address range allocated by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc()
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g42066246915fcb0400df2a17a851b35f" shape="rect" target="_blank">
   cuMemHostGetFlags
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" name="group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaHostRegister (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  )
 </span>
 Registers an existing host memory range for use by CUDA.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  ptr
 </span>
 - Host pointer to memory to page-lock
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Size in bytes of the address range to page-lock in bytes
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Flags for allocation request
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388525f51f037b92383d29ae0e5db1e7a0" shape="rect">
   cudaErrorHostMemoryAlreadyRegistered
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Page-locks the memory range specified by
  ptr
  and
  size
  and maps it for the device(s) as specified by
  flags
  . This memory range also is added to the same tracking mechanism as
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc()
  </a>
  to automatically accelerate calls to functions such as
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy()
  </a>
  . Since the memory can be accessed directly by the device, it can be read or written with much higher bandwidth than pageable
                                 memory that has not been registered. Page-locking excessive amounts of memory may degrade system performance, since it reduces
                                 the amount of memory available to the system for paging. As a result, this function is best used sparingly to register staging
                                 areas for data exchange between host and device.
 </p>
 <p class="p">
  On systems where pageableMemoryAccessUsesHostPageTables is true,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
   cudaHostRegister
  </a>
  will not page-lock the memory range specified by
  ptr
  but only populate unpopulated pages.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
   cudaHostRegister
  </a>
  is supported only on I/O coherent devices that have a non-zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd6ea4a004a336c3c95b6ff06ec6269e29" shape="rect">
   cudaDevAttrHostRegisterSupported
  </a>
  .
 </p>
 <p class="p">
  The
  flags
  parameter enables different options to be specified that affect the allocation, as follows.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g91ca01bef4ecb16ca98b8e129ff6427f" shape="rect">
     cudaHostRegisterDefault
    </a>
    : On a system with unified virtual addressing, the memory will be both mapped and portable. On a system with no unified virtual
                                          addressing, the memory will be neither mapped nor portable.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g36977255e5c778f7e4362d32d6b1cecd" shape="rect">
     cudaHostRegisterPortable
    </a>
    : The memory returned by this call will be considered as pinned memory by all CUDA contexts, not just the one that performed
                                          the allocation.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g838b73458521c60f502efd19db0e365d" shape="rect">
     cudaHostRegisterMapped
    </a>
    : Maps the allocation into the CUDA address space. The device pointer to the memory may be obtained by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
     cudaHostGetDevicePointer()
    </a>
    .
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g27d1406f2a35d23fd8f70cb25c408d8a" shape="rect">
     cudaHostRegisterIoMemory
    </a>
    : The passed memory pointer is treated as pointing to some memory-mapped I/O space, e.g. belonging to a third-party PCIe device,
                                          and it will marked as non cache-coherent and contiguous.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g564c32d0e6032a9383494b6e63de7bd0" shape="rect">
     cudaHostRegisterReadOnly
    </a>
    : The passed memory pointer is treated as pointing to memory that is considered read-only by the device. On platforms without
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , this flag is required in order to register memory mapped to the CPU as read-only. Support for the use of this flag can be
                                          queried from the device attribute cudaDeviceAttrReadOnlyHostRegisterSupported. Using this flag with a current context associated
                                          with a device that does not have this attribute set will cause
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
     cudaHostRegister
    </a>
    to error with cudaErrorNotSupported.
   </p>
  </li>
 </ul>
 <p class="p">
  All of these flags are orthogonal to one another: a developer may page-lock memory that is portable or mapped with no restrictions.
 </p>
 <p class="p">
  The CUDA context must have been created with the cudaMapHost flag in order for the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g838b73458521c60f502efd19db0e365d" shape="rect">
   cudaHostRegisterMapped
  </a>
  flag to have any effect.
 </p>
 <p class="p">
  The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g838b73458521c60f502efd19db0e365d" shape="rect">
   cudaHostRegisterMapped
  </a>
  flag may be specified on CUDA contexts for devices that do not support mapped pinned memory. The failure is deferred to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  because the memory may be mapped into other CUDA contexts via the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g36977255e5c778f7e4362d32d6b1cecd" shape="rect">
   cudaHostRegisterPortable
  </a>
  flag.
 </p>
 <p class="p">
  For devices that have a non-zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdb08e379a7a038dc8134914702c223f69" shape="rect">
   cudaDevAttrCanUseHostPointerForRegisteredMem
  </a>
  , the memory can also be accessed from the device using the host pointer
  ptr
  . The device pointer returned by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  may or may not match the original host pointer
  ptr
  and depends on the devices visible to the application. If all devices visible to the application have a non-zero value for
                                 the device attribute, the device pointer returned by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  will match the original pointer
  ptr
  . If any device visible to the application has a zero value for the device attribute, the device pointer returned by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer()
  </a>
  will not match the original host pointer
  ptr
  , but it will be suitable for use on all devices provided Unified Virtual Addressing is enabled. In such systems, it is valid
                                 to access the memory using either pointer on devices that have a non-zero value for the device attribute. Note however that
                                 such devices should access the memory using only of the two pointers and not both.
 </p>
 <p class="p">
  The memory page-locked by this function must be unregistered with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g81fd4101862bbefdb42a62d60e515eea" shape="rect" title="Unregisters a memory range that was registered with cudaHostRegister.">
   cudaHostUnregister()
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g81fd4101862bbefdb42a62d60e515eea" shape="rect" title="Unregisters a memory range that was registered with cudaHostRegister.">
   cudaHostUnregister
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc470e9220559109f5088d9a01c0aeeda" shape="rect" title="Passes back flags used to allocate pinned host memory allocated by cudaHostAlloc.">
   cudaHostGetFlags
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0" shape="rect" title="Passes back device pointer of mapped host memory allocated by cudaHostAlloc or registered by cudaHostRegister.">
   cudaHostGetDevicePointer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gf0a9fe11544326dabd743b7aa6b54223" shape="rect" target="_blank">
   cuMemHostRegister
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g81fd4101862bbefdb42a62d60e515eea" name="group__CUDART__MEMORY_1g81fd4101862bbefdb42a62d60e515eea" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaHostUnregister (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  )
 </span>
 Unregisters a memory range that was registered with cudaHostRegister.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  ptr
 </span>
 - Host pointer to memory to unregister
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038bea52f6004752a4494e3c82fb38a16d9" shape="rect">
   cudaErrorHostMemoryNotRegistered
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Unmaps the memory range whose base address is specified by
  ptr
  , and makes it pageable again.
 </p>
 <p class="p">
  The base address must be the same one specified to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8d5c17670f16ac4fc8fcb4181cb490c" shape="rect" title="Registers an existing host memory range for use by CUDA.">
   cudaHostRegister()
  </a>
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g81fd4101862bbefdb42a62d60e515eea" shape="rect" title="Unregisters a memory range that was registered with cudaHostRegister.">
   cudaHostUnregister
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g63f450c8125359be87b7623b1c0b2a14" shape="rect" target="_blank">
   cuMemHostUnregister
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" name="group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMalloc (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 Allocate memory on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to allocated device memory
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Requested allocation size in bytes
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates
  size
  bytes of linear memory on the device and returns in
  *devPtr
  a pointer to the allocated memory. The allocated memory is suitably aligned for any kind of variable. The memory is not cleared.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc()
  </a>
  returns
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
  in case of failure.
 </p>
 <p class="p">
  The device version of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  cannot be used with a
  *devPtr
  allocated using the host API, and vice versa.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gb82d2a09844a58dd9e744dc31e8aa467" shape="rect" target="_blank">
   cuMemAlloc
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" name="group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMalloc3D (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitchedDevPtr
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  )
 </span>
 Allocates logical 1D, 2D, or 3D memory objects on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pitchedDevPtr
 </span>
 - Pointer to allocated pitched device memory
 <span class="keyword keyword apiItemName">
  extent
 </span>
 - Requested allocation size (
 width
 field in bytes)
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates at least
  width
  *
  height
  *
  depth
  bytes of linear memory on the device and returns a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  in which
  ptr
  is a pointer to the allocated memory. The function may pad the allocation to ensure hardware alignment requirements are met.
                                 The pitch returned in the
  pitch
  field of
  pitchedDevPtr
  is the width in bytes of the allocation.
 </p>
 <p class="p">
  The returned
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  contains additional fields
  xsize
  and
  ysize
  , the logical width and height of the allocation, which are equivalent to the
  width
  and
  height
  extent
  parameters provided by the programmer during allocation.
 </p>
 <p class="p">
  For allocations of 2D and 3D objects, it is highly recommended that programmers perform allocations using
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D()
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  . Due to alignment restrictions in the hardware, this is especially true if the application will be performing memory copies
                                 involving 2D or 3D objects (whether linear memory or CUDA arrays).
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect" title="Returns a cudaPitchedPtr based on input parameters.">
   make_cudaPitchedPtr
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gcbe9b033f6c4de80f63cc6e58ed9a45a" shape="rect" target="_blank">
   cuMemAllocPitch
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" name="group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMalloc3DArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Allocate an array on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  array
 </span>
 - Pointer to allocated array in device memory
 <span class="keyword keyword apiItemName">
  desc
 </span>
 - Requested channel format
 <span class="keyword keyword apiItemName">
  extent
 </span>
 - Requested allocation size (
 width
 field in elements)
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Flags for extensions
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates a CUDA array according to the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">
   cudaChannelFormatDesc
  </a>
  structure
  desc
  and returns a handle to the new CUDA array in
  *array
  .
 </p>
 <p class="p">
  The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">
   cudaChannelFormatDesc
  </a>
  is defined as:
 </p>
 <pre xml:space="preserve">â    struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">cudaChannelFormatDesc</a> {
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_170dede802100e2acd9f334326e9d7926" shape="rect">x</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_16570793c6567d0c704e8e8943ccaec43" shape="rect">y</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_1e371d37d940d2397139b0a3b7302f51a" shape="rect">z</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_106089c5a407a2cbd6ea05e5a39b19d69" shape="rect">w</a>;
              enum <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119" shape="rect">cudaChannelFormatKind</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_17d561d361936688eeae79c3184698278" shape="rect">f</a>;
          };</pre>
 where
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119" shape="rect">
  cudaChannelFormatKind
 </a>
 is one of
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119943e8b95cd113175ac55c56d90b40ae0" shape="rect">
  cudaChannelFormatKindSigned
 </a>
 ,
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119240d73fa2dc05cbaa58f093f169ab3d4" shape="rect">
  cudaChannelFormatKindUnsigned
 </a>
 , or
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f2351191107be31913affb6b3b49d8a6e795ee0" shape="rect">
  cudaChannelFormatKindFloat
 </a>
 .
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray()
  </a>
  can allocate the following:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    A 1D array is allocated if the height and depth extents are both zero.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 2D array is allocated if only the depth extent is zero.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 3D array is allocated if all three extents are non-zero.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 1D layered CUDA array is allocated if only the height extent is zero and the cudaArrayLayered flag is set. Each layer is
                                          a 1D array. The number of layers is determined by the depth extent.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 2D layered CUDA array is allocated if all three extents are non-zero and the cudaArrayLayered flag is set. Each layer is
                                          a 2D array. The number of layers is determined by the depth extent.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A cubemap CUDA array is allocated if all three extents are non-zero and the cudaArrayCubemap flag is set. Width must be equal
                                          to height, and depth must be six. A cubemap is a special type of 2D layered CUDA array, where the six layers represent the
                                          six faces of a cube. The order of the six layers in memory is the same as that listed in
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gbf3ce16a621826a09263b8a58902fee8" shape="rect">
     cudaGraphicsCubeFace
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    A cubemap layered CUDA array is allocated if all three extents are non-zero, and both, cudaArrayCubemap and cudaArrayLayered
                                          flags are set. Width must be equal to height, and depth must be a multiple of six. A cubemap layered CUDA array is a special
                                          type of 2D layered CUDA array that consists of a collection of cubemaps. The first six layers represent the first cubemap,
                                          the next six layers form the second cubemap, and so on.
   </p>
  </li>
 </ul>
 <p class="p">
  The
  flags
  parameter enables different options to be specified that affect the allocation, as follows.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6c47e87081bfd4f6030937f99ef12412" shape="rect">
     cudaArrayDefault
    </a>
    : This flag's value is defined to be 0 and provides default array allocation
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6d9a27dfb1207df13de0e822f75f4ab8" shape="rect">
     cudaArrayLayered
    </a>
    : Allocates a layered CUDA array, with the depth extent indicating the number of layers
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g802843d69ca8be35ee050ff66782179e" shape="rect">
     cudaArrayCubemap
    </a>
    : Allocates a cubemap CUDA array. Width must be equal to height, and depth must be six. If the cudaArrayLayered flag is also
                                          set, depth must be a multiple of six.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8cb5bdac32ad53c423992a125b3f9a66" shape="rect">
     cudaArraySurfaceLoadStore
    </a>
    : Allocates a CUDA array that could be read from or written to using a surface reference.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g142b19a14d56a03b1e410430aa5202d1" shape="rect">
     cudaArrayTextureGather
    </a>
    : This flag indicates that texture gather operations will be performed on the CUDA array. Texture gather can only be performed
                                          on 2D CUDA arrays.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g42c353686a15da063dc7722594ae4bff" shape="rect">
     cudaArraySparse
    </a>
    : Allocates a CUDA array without physical backing memory. The subregions within this sparse array can later be mapped onto
                                          a physical memory allocation by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
     cuMemMapArrayAsync
    </a>
    . This flag can only be used for creating 2D, 3D or 2D layered sparse CUDA arrays. The physical backing memory must be allocated
                                          via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g899d69a862bba36449789c64b430dc7c" shape="rect" target="_blank">
     cuMemCreate
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g91a50795515848406a89c2e6cef2fb02" shape="rect">
     cudaArrayDeferredMapping
    </a>
    : Allocates a CUDA array without physical backing memory. The entire array can later be mapped onto a physical memory allocation
                                          by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
     cuMemMapArrayAsync
    </a>
    . The physical backing memory must be allocated via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g899d69a862bba36449789c64b430dc7c" shape="rect" target="_blank">
     cuMemCreate
    </a>
    .
   </p>
  </li>
 </ul>
 <p class="p">
  The width, height and depth extents must meet certain size requirements as listed in the following table. All values are specified
                                 in elements.
 </p>
 <p class="p">
  Note that 2D CUDA arrays have different size requirements if the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g142b19a14d56a03b1e410430aa5202d1" shape="rect">
   cudaArrayTextureGather
  </a>
  flag is set. In that case, the valid range for (width, height, depth) is ((1,maxTexture2DGather[0]), (1,maxTexture2DGather[1]),
                                 0).
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table xmlonly" frame="border" rules="all" summary="">
  <tr class="row">
   <th class="entry" colspan="1" id="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    CUDA array type
   </th>
   <th class="entry" colspan="1" id="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    Valid extents that must always be met {(width range in elements),
                                                (height range), (depth range)}
   </th>
   <th class="entry" colspan="1" id="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    Valid extents with cudaArraySurfaceLoadStore set {(width range in
                                                elements), (height range), (depth range)}
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    1D
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture1D), 0, 0 }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface1D), 0, 0 }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    2D
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture2D[0]), (1,maxTexture2D[1]), 0 }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface2D[0]), (1,maxSurface2D[1]), 0 }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    3D
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture3D[0]), (1,maxTexture3D[1]), (1,maxTexture3D[2]) }
                                                OR { (1,maxTexture3DAlt[0]), (1,maxTexture3DAlt[1]),
                                                (1,maxTexture3DAlt[2]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface3D[0]), (1,maxSurface3D[1]), (1,maxSurface3D[2]) }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    1D Layered
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture1DLayered[0]), 0, (1,maxTexture1DLayered[1]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface1DLayered[0]), 0, (1,maxSurface1DLayered[1]) }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    2D Layered
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture2DLayered[0]), (1,maxTexture2DLayered[1]),
                                                (1,maxTexture2DLayered[2]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface2DLayered[0]), (1,maxSurface2DLayered[1]),
                                                (1,maxSurface2DLayered[2]) }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    Cubemap
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTextureCubemap), (1,maxTextureCubemap), 6 }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurfaceCubemap), (1,maxSurfaceCubemap), 6 }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e4562" rowspan="1" valign="top" width="14.285714285714285%">
    Cubemap Layered
   </td>
   <td class="entry" colspan="1" headers="d140665e4565" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTextureCubemapLayered[0]), (1,maxTextureCubemapLayered[0]),
                                                (1,maxTextureCubemapLayered[1]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e4568" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurfaceCubemapLayered[0]), (1,maxSurfaceCubemapLayered[0]),
                                                (1,maxSurfaceCubemapLayered[1]) }
   </td>
  </tr>
 </table>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gc2322c70b38c2984536c90ed118bb1d7" shape="rect" target="_blank">
   cuArray3DCreate
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" name="group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   array
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Allocate an array on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  array
 </span>
 - Pointer to allocated array in device memory
 <span class="keyword keyword apiItemName">
  desc
 </span>
 - Requested channel format
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Requested array allocation width
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Requested array allocation height
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Requested properties of allocated array
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates a CUDA array according to the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">
   cudaChannelFormatDesc
  </a>
  structure
  desc
  and returns a handle to the new CUDA array in
  *array
  .
 </p>
 <p class="p">
  The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">
   cudaChannelFormatDesc
  </a>
  is defined as:
 </p>
 <pre xml:space="preserve">â    struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">cudaChannelFormatDesc</a> {
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_170dede802100e2acd9f334326e9d7926" shape="rect">x</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_16570793c6567d0c704e8e8943ccaec43" shape="rect">y</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_1e371d37d940d2397139b0a3b7302f51a" shape="rect">z</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_106089c5a407a2cbd6ea05e5a39b19d69" shape="rect">w</a>;
          enum <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119" shape="rect">cudaChannelFormatKind</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_17d561d361936688eeae79c3184698278" shape="rect">f</a>;
          };</pre>
 where
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119" shape="rect">
  cudaChannelFormatKind
 </a>
 is one of
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119943e8b95cd113175ac55c56d90b40ae0" shape="rect">
  cudaChannelFormatKindSigned
 </a>
 ,
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119240d73fa2dc05cbaa58f093f169ab3d4" shape="rect">
  cudaChannelFormatKindUnsigned
 </a>
 , or
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f2351191107be31913affb6b3b49d8a6e795ee0" shape="rect">
  cudaChannelFormatKindFloat
 </a>
 .
 <p class="p">
  The
  flags
  parameter enables different options to be specified that affect the allocation, as follows.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6c47e87081bfd4f6030937f99ef12412" shape="rect">
     cudaArrayDefault
    </a>
    : This flag's value is defined to be 0 and provides default array allocation
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8cb5bdac32ad53c423992a125b3f9a66" shape="rect">
     cudaArraySurfaceLoadStore
    </a>
    : Allocates an array that can be read from or written to using a surface reference
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g142b19a14d56a03b1e410430aa5202d1" shape="rect">
     cudaArrayTextureGather
    </a>
    : This flag indicates that texture gather operations will be performed on the array.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g42c353686a15da063dc7722594ae4bff" shape="rect">
     cudaArraySparse
    </a>
    : Allocates a CUDA array without physical backing memory. The subregions within this sparse array can later be mapped onto
                                          a physical memory allocation by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
     cuMemMapArrayAsync
    </a>
    . The physical backing memory must be allocated via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g899d69a862bba36449789c64b430dc7c" shape="rect" target="_blank">
     cuMemCreate
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g91a50795515848406a89c2e6cef2fb02" shape="rect">
     cudaArrayDeferredMapping
    </a>
    : Allocates a CUDA array without physical backing memory. The entire array can later be mapped onto a physical memory allocation
                                          by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
     cuMemMapArrayAsync
    </a>
    . The physical backing memory must be allocated via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g899d69a862bba36449789c64b430dc7c" shape="rect" target="_blank">
     cuMemCreate
    </a>
    .
   </p>
  </li>
 </ul>
 <p class="p">
  width
  and
  height
  must meet certain size requirements. See
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray()
  </a>
  for more details.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4192ff387a81c3bd5ed8c391ed62ca24" shape="rect" target="_blank">
   cuArrayCreate
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" name="group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocHost (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ptr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 Allocates page-locked memory on the host.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  ptr
 </span>
 - Pointer to allocated host memory
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Requested allocation size in bytes
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates
  size
  bytes of host memory that is page-locked and accessible to the device. The driver tracks the virtual memory ranges allocated
                                 with this function and automatically accelerates calls to functions such as
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  *(). Since the memory can be accessed directly by the device, it can be read or written with much higher bandwidth than pageable
                                 memory obtained with functions such as malloc().
 </p>
 <p class="p">
  On systems where pageableMemoryAccessUsesHostPageTables is true,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd5c991beb38e2b8419f50285707ae87e" shape="rect" title="[C++ API] Allocates page-locked memory on the host">
   cudaMallocHost
  </a>
  may not page-lock the allocated memory.
 </p>
 <p class="p">
  Page-locking excessive amounts of memory with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost()
  </a>
  may degrade system performance, since it reduces the amount of memory available to the system for paging. As a result, this
                                 function is best used sparingly to allocate staging areas for data exchange between host and device.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd5c991beb38e2b8419f50285707ae87e" shape="rect" title="[C++ API] Allocates page-locked memory on the host">
   cudaMallocHost ( C++ API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gdd8311286d2c2691605362c689bc64e0" shape="rect" target="_blank">
   cuMemAllocHost
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gd228014f19cc0975ebe3e0dd2af6dd1b" name="group__CUDART__MEMORY_1gd228014f19cc0975ebe3e0dd2af6dd1b" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocManaged (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   cudaMemAttachGlobal
  </span>
  )
 </span>
 Allocates memory that will be automatically managed by the Unified Memory system.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to allocated device memory
 <span class="keyword keyword apiItemName">
  size
 </span>
 - Requested allocation size in bytes
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Must be either
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">
  cudaMemAttachGlobal
 </a>
 or
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">
  cudaMemAttachHost
 </a>
 (defaults to
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">
  cudaMemAttachGlobal
 </a>
 )
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates
  size
  bytes of managed memory on the device and returns in
  *devPtr
  a pointer to the allocated memory. If the device doesn't support allocating managed memory,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038d846fd9f2e8ba5e2fb4f1695b7ab6164" shape="rect">
   cudaErrorNotSupported
  </a>
  is returned. Support for managed memory can be queried using the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cd5467985f87821a03625ab62e72195ff8" shape="rect">
   cudaDevAttrManagedMemory
  </a>
  . The allocated memory is suitably aligned for any kind of variable. The memory is not cleared. If
  size
  is 0,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  returns
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  . The pointer is valid on the CPU and on all GPUs in the system that support managed memory. All accesses to this pointer
                                 must obey the Unified Memory programming model.
 </p>
 <p class="p">
  flags
  specifies the default stream association for this allocation.
  flags
  must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">
   cudaMemAttachGlobal
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">
   cudaMemAttachHost
  </a>
  . The default value for
  flags
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">
   cudaMemAttachGlobal
  </a>
  . If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">
   cudaMemAttachGlobal
  </a>
  is specified, then this memory is accessible from any stream on any device. If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4f9a428d18fdd89a99441d0dd27131c0" shape="rect">
   cudaMemAttachHost
  </a>
  is specified, then the allocation should not be accessed from devices that have a zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  ; an explicit call to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" shape="rect" title="Attach memory to a stream asynchronously.">
   cudaStreamAttachMemAsync
  </a>
  will be required to enable access on such devices.
 </p>
 <p class="p">
  If the association is later changed via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" shape="rect" title="Attach memory to a stream asynchronously.">
   cudaStreamAttachMemAsync
  </a>
  to a single stream, the default association, as specifed during
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  , is restored when that stream is destroyed. For __managed__ variables, the default association is always
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g4808e47eba73eb94622ec70a9f9b91ff" shape="rect">
   cudaMemAttachGlobal
  </a>
  . Note that destroying a stream is an asynchronous operation, and as a result, the change to default association won't happen
                                 until all work in the stream has completed.
 </p>
 <p class="p">
  Memory allocated with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  should be released with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  .
 </p>
 <p class="p">
  Device memory oversubscription is possible for GPUs that have a non-zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  . Managed memory on such GPUs may be evicted from device memory to host memory at any time by the Unified Memory driver in
                                 order to make room for other allocations.
 </p>
 <p class="p">
  In a system where all GPUs have a non-zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  , managed memory may not be populated when this API returns and instead may be populated on access. In such systems, managed
                                 memory can migrate to any processor's memory at any time. The Unified Memory driver will employ heuristics to maintain data
                                 locality and prevent excessive page faults to the extent possible. The application can also guide the driver about memory
                                 usage patterns via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g8ea5ecc5b50b0987119964dcccbb743c" shape="rect" title="Advise about the usage of a given memory range.">
   cudaMemAdvise
  </a>
  . The application can also explicitly migrate memory to a desired processor's memory via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
   cudaMemPrefetchAsync
  </a>
  .
 </p>
 <p class="p">
  In a multi-GPU system where all of the GPUs have a zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  and all the GPUs have peer-to-peer support with each other, the physical storage for managed memory is created on the GPU
                                 which is active at the time
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  is called. All other GPUs will reference the data at reduced bandwidth via peer mappings over the PCIe bus. The Unified Memory
                                 driver does not migrate memory among such GPUs.
 </p>
 <p class="p">
  In a multi-GPU system where not all GPUs have peer-to-peer support with each other and where the value of the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  is zero for at least one of those GPUs, the location chosen for physical storage of managed memory is system-dependent.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    On Linux, the location chosen will be device memory as long as the current set of active contexts are on devices that either
                                          have peer-to-peer support with each other or have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    . If there is an active context on a GPU that does not have a non-zero value for that device attribute and it does not have
                                          peer-to-peer support with the other devices that have active contexts on them, then the location for physical storage will
                                          be 'zero-copy' or host memory. Note that this means that managed memory that is located in device memory is migrated to host
                                          memory if a new context is created on a GPU that doesn't have a non-zero value for the device attribute and does not support
                                          peer-to-peer with at least one of the other devices that has an active context. This in turn implies that context creation
                                          may fail if there is insufficient host memory to migrate all managed allocations.
   </p>
  </li>
  <li class="li">
   <p class="p">
    On Windows, the physical storage is always created in 'zero-copy' or host memory. All GPUs will reference the data at reduced
                                          bandwidth over the PCIe bus. In these circumstances, use of the environment variable CUDA_VISIBLE_DEVICES is recommended to
                                          restrict CUDA to only use those GPUs that have peer-to-peer support. Alternatively, users can also set CUDA_MANAGED_FORCE_DEVICE_ALLOC
                                          to a non-zero value to force the driver to always use device memory for physical storage. When this environment variable is
                                          set to a non-zero value, all devices used in that process that support managed memory have to be peer-to-peer compatible with
                                          each other. The error
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
     cudaErrorInvalidDevice
    </a>
    will be returned if a device that supports managed memory is used and it is not peer-to-peer compatible with any of the other
                                          managed memory supporting devices that were previously used in that process, even if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217" shape="rect" title="Destroy all allocations and reset all state on the current device in the current process.">
     cudaDeviceReset
    </a>
    has been called on those devices. These environment variables are described in the CUDA programming guide under the "CUDA
                                          environment variables" section.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gb22e8256592b836df9a9cc36c9db7151" shape="rect" title="Returns information about the device.">
   cudaDeviceGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g496353d630c29c44a2e33f531a3944d1" shape="rect" title="Attach memory to a stream asynchronously.">
   cudaStreamAttachMemAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gb347ded34dc326af404aa02af5388a32" shape="rect" target="_blank">
   cuMemAllocManaged
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g9abd550dd3f655473d2640dc85be9774" name="group__CUDART__MEMORY_1g9abd550dd3f655473d2640dc85be9774" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocMipmappedArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmappedArray
  </span>
  , const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect" title="">
   cudaChannelFormatDesc
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   desc
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numLevels
  </span>
  , unsigned int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   flags
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Allocate a mipmapped array on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  mipmappedArray
 </span>
 - Pointer to allocated mipmapped array in device memory
 <span class="keyword keyword apiItemName">
  desc
 </span>
 - Requested channel format
 <span class="keyword keyword apiItemName">
  extent
 </span>
 - Requested allocation size (
 width
 field in elements)
 <span class="keyword keyword apiItemName">
  numLevels
 </span>
 - Number of mipmap levels to allocate
 <span class="keyword keyword apiItemName">
  flags
 </span>
 - Flags for extensions
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates a CUDA mipmapped array according to the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">
   cudaChannelFormatDesc
  </a>
  structure
  desc
  and returns a handle to the new CUDA mipmapped array in
  *mipmappedArray
  .
  numLevels
  specifies the number of mipmap levels to be allocated. This value is clamped to the range [1, 1 + floor(log2(max(width, height,
                                 depth)))].
 </p>
 <p class="p">
  The
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">
   cudaChannelFormatDesc
  </a>
  is defined as:
 </p>
 <pre xml:space="preserve">â    struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc" shape="rect">cudaChannelFormatDesc</a> {
              int <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_170dede802100e2acd9f334326e9d7926" shape="rect">x</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_16570793c6567d0c704e8e8943ccaec43" shape="rect">y</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_1e371d37d940d2397139b0a3b7302f51a" shape="rect">z</a>, <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_106089c5a407a2cbd6ea05e5a39b19d69" shape="rect">w</a>;
              enum <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119" shape="rect">cudaChannelFormatKind</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaChannelFormatDesc.html#structcudaChannelFormatDesc_17d561d361936688eeae79c3184698278" shape="rect">f</a>;
          };</pre>
 where
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8085eac5cb54b4228f3619a60f235119" shape="rect">
  cudaChannelFormatKind
 </a>
 is one of
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119943e8b95cd113175ac55c56d90b40ae0" shape="rect">
  cudaChannelFormatKindSigned
 </a>
 ,
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f235119240d73fa2dc05cbaa58f093f169ab3d4" shape="rect">
  cudaChannelFormatKindUnsigned
 </a>
 , or
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg8085eac5cb54b4228f3619a60f2351191107be31913affb6b3b49d8a6e795ee0" shape="rect">
  cudaChannelFormatKindFloat
 </a>
 .
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9abd550dd3f655473d2640dc85be9774" shape="rect" title="Allocate a mipmapped array on the device.">
   cudaMallocMipmappedArray()
  </a>
  can allocate the following:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    A 1D mipmapped array is allocated if the height and depth extents are both zero.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 2D mipmapped array is allocated if only the depth extent is zero.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 3D mipmapped array is allocated if all three extents are non-zero.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 1D layered CUDA mipmapped array is allocated if only the height extent is zero and the cudaArrayLayered flag is set. Each
                                          layer is a 1D mipmapped array. The number of layers is determined by the depth extent.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A 2D layered CUDA mipmapped array is allocated if all three extents are non-zero and the cudaArrayLayered flag is set. Each
                                          layer is a 2D mipmapped array. The number of layers is determined by the depth extent.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A cubemap CUDA mipmapped array is allocated if all three extents are non-zero and the cudaArrayCubemap flag is set. Width
                                          must be equal to height, and depth must be six. The order of the six layers in memory is the same as that listed in
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gbf3ce16a621826a09263b8a58902fee8" shape="rect">
     cudaGraphicsCubeFace
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    A cubemap layered CUDA mipmapped array is allocated if all three extents are non-zero, and both, cudaArrayCubemap and cudaArrayLayered
                                          flags are set. Width must be equal to height, and depth must be a multiple of six. A cubemap layered CUDA mipmapped array
                                          is a special type of 2D layered CUDA mipmapped array that consists of a collection of cubemap mipmapped arrays. The first
                                          six layers represent the first cubemap mipmapped array, the next six layers form the second cubemap mipmapped array, and so
                                          on.
   </p>
  </li>
 </ul>
 <p class="p">
  The
  flags
  parameter enables different options to be specified that affect the allocation, as follows.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6c47e87081bfd4f6030937f99ef12412" shape="rect">
     cudaArrayDefault
    </a>
    : This flag's value is defined to be 0 and provides default mipmapped array allocation
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6d9a27dfb1207df13de0e822f75f4ab8" shape="rect">
     cudaArrayLayered
    </a>
    : Allocates a layered CUDA mipmapped array, with the depth extent indicating the number of layers
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g802843d69ca8be35ee050ff66782179e" shape="rect">
     cudaArrayCubemap
    </a>
    : Allocates a cubemap CUDA mipmapped array. Width must be equal to height, and depth must be six. If the cudaArrayLayered
                                          flag is also set, depth must be a multiple of six.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g8cb5bdac32ad53c423992a125b3f9a66" shape="rect">
     cudaArraySurfaceLoadStore
    </a>
    : This flag indicates that individual mipmap levels of the CUDA mipmapped array will be read from or written to using a surface
                                          reference.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g142b19a14d56a03b1e410430aa5202d1" shape="rect">
     cudaArrayTextureGather
    </a>
    : This flag indicates that texture gather operations will be performed on the CUDA array. Texture gather can only be performed
                                          on 2D CUDA mipmapped arrays, and the gather operations are performed only on the most detailed mipmap level.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g42c353686a15da063dc7722594ae4bff" shape="rect">
     cudaArraySparse
    </a>
    : Allocates a CUDA mipmapped array without physical backing memory. The subregions within this sparse array can later be mapped
                                          onto a physical memory allocation by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
     cuMemMapArrayAsync
    </a>
    . This flag can only be used for creating 2D, 3D or 2D layered sparse CUDA mipmapped arrays. The physical backing memory must
                                          be allocated via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g899d69a862bba36449789c64b430dc7c" shape="rect" target="_blank">
     cuMemCreate
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g91a50795515848406a89c2e6cef2fb02" shape="rect">
     cudaArrayDeferredMapping
    </a>
    : Allocates a CUDA mipmapped array without physical backing memory. The entire array can later be mapped onto a physical memory
                                          allocation by calling
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
     cuMemMapArrayAsync
    </a>
    . The physical backing memory must be allocated via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g899d69a862bba36449789c64b430dc7c" shape="rect" target="_blank">
     cuMemCreate
    </a>
    .
   </p>
  </li>
 </ul>
 <p class="p">
  The width, height and depth extents must meet certain size requirements as listed in the following table. All values are specified
                                 in elements.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table xmlonly" frame="border" rules="all" summary="">
  <tr class="row">
   <th class="entry" colspan="1" id="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    CUDA array type
   </th>
   <th class="entry" colspan="1" id="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    Valid extents that must always be met {(width range in elements),
                                                (height range), (depth range)}
   </th>
   <th class="entry" colspan="1" id="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    Valid extents with cudaArraySurfaceLoadStore set {(width range in
                                                elements), (height range), (depth range)}
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    1D
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture1DMipmap), 0, 0 }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface1D), 0, 0 }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    2D
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture2DMipmap[0]), (1,maxTexture2DMipmap[1]), 0 }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface2D[0]), (1,maxSurface2D[1]), 0 }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    3D
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture3D[0]), (1,maxTexture3D[1]), (1,maxTexture3D[2]) }
                                                OR { (1,maxTexture3DAlt[0]), (1,maxTexture3DAlt[1]),
                                                (1,maxTexture3DAlt[2]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface3D[0]), (1,maxSurface3D[1]), (1,maxSurface3D[2]) }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    1D Layered
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture1DLayered[0]), 0, (1,maxTexture1DLayered[1]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface1DLayered[0]), 0, (1,maxSurface1DLayered[1]) }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    2D Layered
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTexture2DLayered[0]), (1,maxTexture2DLayered[1]),
                                                (1,maxTexture2DLayered[2]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurface2DLayered[0]), (1,maxSurface2DLayered[1]),
                                                (1,maxSurface2DLayered[2]) }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    Cubemap
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTextureCubemap), (1,maxTextureCubemap), 6 }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurfaceCubemap), (1,maxSurfaceCubemap), 6 }
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d140665e6308" rowspan="1" valign="top" width="14.285714285714285%">
    Cubemap Layered
   </td>
   <td class="entry" colspan="1" headers="d140665e6311" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxTextureCubemapLayered[0]), (1,maxTextureCubemapLayered[0]),
                                                (1,maxTextureCubemapLayered[1]) }
   </td>
   <td class="entry" colspan="1" headers="d140665e6314" rowspan="1" valign="top" width="42.857142857142854%">
    { (1,maxSurfaceCubemapLayered[0]), (1,maxSurfaceCubemapLayered[0]),
                                                (1,maxSurfaceCubemapLayered[1]) }
   </td>
  </tr>
 </table>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ga5d2e311c7f9b0bc6d130af824a40bd3" shape="rect" target="_blank">
   cuMipmappedArrayCreate
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" name="group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMallocPitch (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  )
 </span>
 Allocates pitched memory on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to allocated pitched device memory
 <span class="keyword keyword apiItemName">
  pitch
 </span>
 - Pitch for allocation
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Requested pitched allocation width (in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Requested pitched allocation height
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f210f50ae7f17f655e0504929606add9" shape="rect">
   cudaErrorMemoryAllocation
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Allocates at least
  width
  (in bytes) *
  height
  bytes of linear memory on the device and returns in
  *devPtr
  a pointer to the allocated memory. The function may pad the allocation to ensure that corresponding pointers in any given
                                 row will continue to meet the alignment requirements for coalescing as the address is updated from row to row. The pitch returned
                                 in
  *pitch
  by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  is the width in bytes of the allocation. The intended usage of
  pitch
  is as a separate parameter of the allocation, used to compute addresses within the 2D array. Given the row and column of
                                 an array element of type
  T
  , the address is computed as:
 </p>
 <pre xml:space="preserve">â    T* pElement = (T*)((char*)BaseAddress + Row * pitch) + Column;</pre>
 <p class="p">
  For allocations of 2D arrays, it is recommended that programmers consider performing pitch allocations using
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  . Due to pitch alignment restrictions in the hardware, this is especially true if the application will be performing 2D memory
                                 copies between different regions of device memory (whether linear memory or CUDA arrays).
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094" shape="rect" title="Frees memory on the device.">
   cudaFree
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1b553f5f4806d67525230ac305d50900" shape="rect" title="Frees an array on the device.">
   cudaFreeArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b" shape="rect" title="Allocates page-locked memory on the host.">
   cudaMallocHost ( C API)
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g71c078689c17627566b2a91989184969" shape="rect" title="Frees page-locked memory.">
   cudaFreeHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902" shape="rect" title="Allocates page-locked memory on the host.">
   cudaHostAlloc
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gcbe9b033f6c4de80f63cc6e58ed9a45a" shape="rect" target="_blank">
   cuMemAllocPitch
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1ge37112fc1ac88d0f6bab7a945e48760a" name="group__CUDART__MEMORY_1ge37112fc1ac88d0f6bab7a945e48760a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemAdvise (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gc314a8b14091f7e02a7ad15dcb36c857" shape="rect" title="">
   cudaMemoryAdvise
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   advice
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Advise about the usage of a given memory range.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to memory to set the advice for
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes of the memory range
 <span class="keyword keyword apiItemName">
  advice
 </span>
 - Advice to be applied for the specified memory range
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device to apply the advice for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Advise the Unified Memory subsystem about the usage pattern for the memory range starting at
  devPtr
  with a size of
  count
  bytes. The start address and end address of the memory range will be rounded down and rounded up respectively to be aligned
                                 to CPU page size before the advice is applied. The memory range must refer to managed memory allocated via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  or declared via __managed__ variables. The memory range could also refer to system-allocated pageable memory provided it
                                 represents a valid, host-accessible region of memory and all additional constraints imposed by
  advice
  as outlined below are also satisfied. Specifying an invalid system-allocated pageable memory range results in an error being
                                 returned.
 </p>
 <p class="p">
  The
  advice
  parameter can take the following values:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    : This implies that the data is mostly going to be read from and only occasionally written to. Any read accesses from any
                                          processor to this region will create a read-only copy of at least the accessed pages in that processor's memory. Additionally,
                                          if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
     cudaMemPrefetchAsync
    </a>
    is called on this region, it will create a read-only copy of the data on the destination processor. If any processor writes
                                          to this region, all copies of the corresponding page will be invalidated except for the one where the write occurred. The
    device
    argument is ignored for this advice. Note that for a page to be read-duplicated, the accessing processor must either be the
                                          CPU or a GPU that has a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    . Also, if a context is created on a device that does not have the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    set, then read-duplication will not occur until all such contexts are destroyed. If the memory region refers to valid system-allocated
                                          pageable memory, then the accessing device must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    for a read-only copy to be created on that device. Note however that if the accessing device also has a non-zero value for
                                          the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , then setting this advice will not create a read-only copy when that device accesses this memory region.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    cudaMemAdviceUnsetReadMostly: Undoes the effect of cudaMemAdviceReadMostly and also prevents the Unified Memory driver from
                                          attempting heuristic read-duplication on the memory range. Any read-duplicated copies of the data will be collapsed into a
                                          single copy. The location for the collapsed copy will be the preferred location if the page has a preferred location and one
                                          of the read-duplicated copies was resident at that location. Otherwise, the location chosen is arbitrary.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb" shape="rect">
     cudaMemAdviseSetPreferredLocation
    </a>
    : This advice sets the preferred location for the data to be the memory belonging to
    device
    . Passing in cudaCpuDeviceId for
    device
    sets the preferred location as host memory. If
    device
    is a GPU, then it must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    . Setting the preferred location does not cause data to migrate to that location immediately. Instead, it guides the migration
                                          policy when a fault occurs on that memory region. If the data is already in its preferred location and the faulting processor
                                          can establish a mapping without requiring the data to be migrated, then data migration will be avoided. On the other hand,
                                          if the data is not in its preferred location or if a direct mapping cannot be established, then it will be migrated to the
                                          processor accessing it. It is important to note that setting the preferred location does not prevent data prefetching done
                                          using
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
     cudaMemPrefetchAsync
    </a>
    . Having a preferred location can override the page thrash detection and resolution logic in the Unified Memory driver. Normally,
                                          if a page is detected to be constantly thrashing between for example host and device memory, the page may eventually be pinned
                                          to host memory by the Unified Memory driver. But if the preferred location is set as device memory, then the page will continue
                                          to thrash indefinitely. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    is also set on this memory region or any subset of it, then the policies associated with that advice will override the policies
                                          of this advice, unless read accesses from
    device
    will not result in a read-only copy being created on that device as outlined in description for the advice
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    . If the memory region refers to valid system-allocated pageable memory, then
    device
    must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    .
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857537caa36d8dddd3cedee0b2de7b74322" shape="rect">
     cudaMemAdviseUnsetPreferredLocation
    </a>
    : Undoes the effect of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb" shape="rect">
     cudaMemAdviseSetPreferredLocation
    </a>
    and changes the preferred location to none.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623" shape="rect">
     cudaMemAdviseSetAccessedBy
    </a>
    : This advice implies that the data will be accessed by
    device
    . Passing in
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gb3de5e703b559507c39a6a02127e2967" shape="rect">
     cudaCpuDeviceId
    </a>
    for
    device
    will set the advice for the CPU. If
    device
    is a GPU, then the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    must be non-zero. This advice does not cause data migration and has no impact on the location of the data per se. Instead,
                                          it causes the data to always be mapped in the specified processor's page tables, as long as the location of the data permits
                                          a mapping to be established. If the data gets migrated for any reason, the mappings are updated accordingly. This advice is
                                          recommended in scenarios where data locality is not important, but avoiding faults is. Consider for example a system containing
                                          multiple GPUs with peer-to-peer access enabled, where the data located on one GPU is occasionally accessed by peer GPUs. In
                                          such scenarios, migrating data over to the other GPUs is not as important because the accesses are infrequent and the overhead
                                          of migration may be too high. But preventing faults can still help improve performance, and so having a mapping set up in
                                          advance is useful. Note that on CPU access of this data, the data may be migrated to host memory because the CPU typically
                                          cannot access device memory directly. Any GPU that had the cudaMemAdviceSetAccessedBy flag set for this data will now have
                                          its mapping updated to point to the page in host memory. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    is also set on this memory region or any subset of it, then the policies associated with that advice will override the policies
                                          of this advice. Additionally, if the preferred location of this memory region or any subset of it is also
    device
    , then the policies associated with
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb" shape="rect">
     cudaMemAdviseSetPreferredLocation
    </a>
    will override the policies of this advice. If the memory region refers to valid system-allocated pageable memory, then
    device
    must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    . Additionally, if
    device
    has a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , then this call has no effect.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857187be2a2843cf4e7976bd359a64794bf" shape="rect">
     cudaMemAdviseUnsetAccessedBy
    </a>
    : Undoes the effect of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623" shape="rect">
     cudaMemAdviseSetAccessedBy
    </a>
    . Any mappings to the data from
    device
    may be removed at any time causing accesses to result in non-fatal page faults. If the memory region refers to valid system-allocated
                                          pageable memory, then
    device
    must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    . Additionally, if
    device
    has a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , then this call has no effect.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect" title="Copies memory between two devices.">
   cudaMemcpyPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
   cudaMemPrefetchAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1g27608c857a9254789c13f3e3b72029e2" shape="rect" target="_blank">
   cuMemAdvise
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g3e95883b161c343f4b7ea881cf8e3a09" name="group__CUDART__MEMORY_1g3e95883b161c343f4b7ea881cf8e3a09" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemAdvise_v2 (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gc314a8b14091f7e02a7ad15dcb36c857" shape="rect" title="">
   cudaMemoryAdvise
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   advice
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation" shape="rect" title="">
   cudaMemLocation
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   location
  </span>
  )
 </span>
 Advise about the usage of a given memory range.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to memory to set the advice for
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes of the memory range
 <span class="keyword keyword apiItemName">
  advice
 </span>
 - Advice to be applied for the specified memory range
 <span class="keyword keyword apiItemName">
  location
 </span>
 - location to apply the advice for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Advise the Unified Memory subsystem about the usage pattern for the memory range starting at
  devPtr
  with a size of
  count
  bytes. The start address and end address of the memory range will be rounded down and rounded up respectively to be aligned
                                 to CPU page size before the advice is applied. The memory range must refer to managed memory allocated via cudaMemAllocManaged
                                 or declared via __managed__ variables. The memory range could also refer to system-allocated pageable memory provided it represents
                                 a valid, host-accessible region of memory and all additional constraints imposed by
  advice
  as outlined below are also satisfied. Specifying an invalid system-allocated pageable memory range results in an error being
                                 returned.
 </p>
 <p class="p">
  The
  advice
  parameter can take the following values:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    : This implies that the data is mostly going to be read from and only occasionally written to. Any read accesses from any
                                          processor to this region will create a read-only copy of at least the accessed pages in that processor's memory. Additionally,
                                          if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
     cudaMemPrefetchAsync
    </a>
    or cudaMemPrefetchAsync_v2 is called on this region, it will create a read-only copy of the data on the destination processor.
                                          If the target location for cudaMemPrefetchAsync_v2 is a host NUMA node and a read-only copy already exists on another host
                                          NUMA node, that copy will be migrated to the targeted host NUMA node. If any processor writes to this region, all copies of
                                          the corresponding page will be invalidated except for the one where the write occurred. If the writing processor is the CPU
                                          and the preferred location of the page is a host NUMA node, then the page will also be migrated to that host NUMA node. The
    location
    argument is ignored for this advice. Note that for a page to be read-duplicated, the accessing processor must either be the
                                          CPU or a GPU that has a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    . Also, if a context is created on a device that does not have the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    set, then read-duplication will not occur until all such contexts are destroyed. If the memory region refers to valid system-allocated
                                          pageable memory, then the accessing device must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    for a read-only copy to be created on that device. Note however that if the accessing device also has a non-zero value for
                                          the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , then setting this advice will not create a read-only copy when that device accesses this memory region.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    cudaMemAdviceUnsetReadMostly: Undoes the effect of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    and also prevents the Unified Memory driver from attempting heuristic read-duplication on the memory range. Any read-duplicated
                                          copies of the data will be collapsed into a single copy. The location for the collapsed copy will be the preferred location
                                          if the page has a preferred location and one of the read-duplicated copies was resident at that location. Otherwise, the location
                                          chosen is arbitrary. Note: The
    location
    argument is ignored for this advice.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb" shape="rect">
     cudaMemAdviseSetPreferredLocation
    </a>
    : This advice sets the preferred location for the data to be the memory belonging to
    location
    . When
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    is
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f01ec97ff5f3c715e4b18e39dabf9e31c5" shape="rect">
     cudaMemLocationTypeHost
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    is ignored and the preferred location is set to be host memory. To set the preferred location to a specific host NUMA node,
                                          applications must set
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    to
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
     cudaMemLocationTypeHostNuma
    </a>
    and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    must specify the NUMA ID of the host NUMA node. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    is set to
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0a3925690e32332c940cb726ef56a4258" shape="rect">
     cudaMemLocationTypeHostNumaCurrent
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    will be ignored and the host NUMA node closest to the calling thread's CPU will be used as the preferred location. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    is a
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
     cudaMemLocationTypeDevice
    </a>
    , then
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    must be a valid device ordinal and the device must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    . Setting the preferred location does not cause data to migrate to that location immediately. Instead, it guides the migration
                                          policy when a fault occurs on that memory region. If the data is already in its preferred location and the faulting processor
                                          can establish a mapping without requiring the data to be migrated, then data migration will be avoided. On the other hand,
                                          if the data is not in its preferred location or if a direct mapping cannot be established, then it will be migrated to the
                                          processor accessing it. It is important to note that setting the preferred location does not prevent data prefetching done
                                          using
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
     cudaMemPrefetchAsync
    </a>
    . Having a preferred location can override the page thrash detection and resolution logic in the Unified Memory driver. Normally,
                                          if a page is detected to be constantly thrashing between for example host and device memory, the page may eventually be pinned
                                          to host memory by the Unified Memory driver. But if the preferred location is set as device memory, then the page will continue
                                          to thrash indefinitely. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    is also set on this memory region or any subset of it, then the policies associated with that advice will override the policies
                                          of this advice, unless read accesses from
    location
    will not result in a read-only copy being created on that procesor as outlined in description for the advice
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    . If the memory region refers to valid system-allocated pageable memory, and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    is
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
     cudaMemLocationTypeDevice
    </a>
    then
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    must be a valid device that has a non-zero alue for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    .
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857537caa36d8dddd3cedee0b2de7b74322" shape="rect">
     cudaMemAdviseUnsetPreferredLocation
    </a>
    : Undoes the effect of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb" shape="rect">
     cudaMemAdviseSetPreferredLocation
    </a>
    and changes the preferred location to none. The
    location
    argument is ignored for this advice.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623" shape="rect">
     cudaMemAdviseSetAccessedBy
    </a>
    : This advice implies that the data will be accessed by processor
    location
    . The
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    must be either
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
     cudaMemLocationTypeDevice
    </a>
    with
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    representing a valid device ordinal or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f01ec97ff5f3c715e4b18e39dabf9e31c5" shape="rect">
     cudaMemLocationTypeHost
    </a>
    and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    will be ignored. All other location types are invalid. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    is a GPU, then the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
     cudaDevAttrConcurrentManagedAccess
    </a>
    must be non-zero. This advice does not cause data migration and has no impact on the location of the data per se. Instead,
                                          it causes the data to always be mapped in the specified processor's page tables, as long as the location of the data permits
                                          a mapping to be established. If the data gets migrated for any reason, the mappings are updated accordingly. This advice is
                                          recommended in scenarios where data locality is not important, but avoiding faults is. Consider for example a system containing
                                          multiple GPUs with peer-to-peer access enabled, where the data located on one GPU is occasionally accessed by peer GPUs. In
                                          such scenarios, migrating data over to the other GPUs is not as important because the accesses are infrequent and the overhead
                                          of migration may be too high. But preventing faults can still help improve performance, and so having a mapping set up in
                                          advance is useful. Note that on CPU access of this data, the data may be migrated to host memory because the CPU typically
                                          cannot access device memory directly. Any GPU that had the
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623" shape="rect">
     cudaMemAdviseSetAccessedBy
    </a>
    flag set for this data will now have its mapping updated to point to the page in host memory. If
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
     cudaMemAdviseSetReadMostly
    </a>
    is also set on this memory region or any subset of it, then the policies associated with that advice will override the policies
                                          of this advice. Additionally, if the preferred location of this memory region or any subset of it is also
    location
    , then the policies associated with
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggcfe2ed2d4567745dd4ad41034136fff3ddee285dc5e0e7d26469009ffd583cea" shape="rect" target="_blank">
     CU_MEM_ADVISE_SET_PREFERRED_LOCATION
    </a>
    will override the policies of this advice. If the memory region refers to valid system-allocated pageable memory, and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    is
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
     cudaMemLocationTypeDevice
    </a>
    then device in
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    . Additionally, if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    has a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , then this call has no effect.
   </p>
  </li>
 </ul>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggcfe2ed2d4567745dd4ad41034136fff3f8118635c5f39d76432654ec13a726a5" shape="rect" target="_blank">
     CU_MEM_ADVISE_UNSET_ACCESSED_BY
    </a>
    : Undoes the effect of
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623" shape="rect">
     cudaMemAdviseSetAccessedBy
    </a>
    . Any mappings to the data from
    location
    may be removed at any time causing accesses to result in non-fatal page faults. If the memory region refers to valid system-allocated
                                          pageable memory, and
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_16df2243c9f48e48ad92306df676b2fe0" shape="rect">
     cudaMemLocation::type
    </a>
    is
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
     cudaMemLocationTypeDevice
    </a>
    then device in
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    must have a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cddc80992427a92713e699953a6d249d6f" shape="rect">
     cudaDevAttrPageableMemoryAccess
    </a>
    . Additionally, if
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemLocation.html#structcudaMemLocation_11c914cd5c3cc7323b4fde9756458efb0" shape="rect">
     cudaMemLocation::id
    </a>
    has a non-zero value for the device attribute
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc228cf8983c97d0e035da72a71494eaa" shape="rect">
     cudaDevAttrPageableMemoryAccessUsesHostPageTables
    </a>
    , then this call has no effect.
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect" title="Copies memory between two devices.">
   cudaMemcpyPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
   cudaMemPrefetchAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1g27608c857a9254789c13f3e3b72029e2" shape="rect" target="_blank">
   cuMemAdvise
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1g1ee1ef51ac4f44b4cf5d54711f227584" shape="rect" target="_blank">
   cuMemAdvise_v2
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g376b97f5ab20321ca46f7cfa9511b978" name="group__CUDART__MEMORY_1g376b97f5ab20321ca46f7cfa9511b978" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemGetInfo (  size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   free
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   total
  </span>
  )
 </span>
 Gets free and total device memory.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  free
 </span>
 - Returned free memory in bytes
 <span class="keyword keyword apiItemName">
  total
 </span>
 - Returned total memory in bytes
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038099def426efea2b2366d8d7ad09f974a" shape="rect">
   cudaErrorLaunchFailure
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *total
  the total amount of memory available to the the current context. Returns in
  *free
  the amount of memory on the device that is free according to the OS. CUDA is not guaranteed to be able to allocate all of
                                 the memory that the OS reports as free. In a multi-tenet situation, free estimate returned is prone to race condition where
                                 a new allocation/free done by a different process or a different thread in the same process between the time when free memory
                                 was estimated and reported, will result in deviation in free value reported and actual free memory.
 </p>
 <p class="p">
  The integrated GPU on Tegra shares memory with CPU and other component of the SoC. The free and total values returned by the
                                 API excludes the SWAP memory space maintained by the OS on some platforms. The OS may move some of the memory pages into swap
                                 area as the GPU or CPU allocate or access memory. See Tegra app note on how to calculate total and free memory on Tegra.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g808f555540d0143a331cc42aa98835c0" shape="rect" target="_blank">
   cuMemGetInfo
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" name="group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemPrefetchAsync (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Prefetches memory to the specified destination device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to be prefetched
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes
 <span class="keyword keyword apiItemName">
  dstDevice
 </span>
 - Destination device to prefetch to
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream to enqueue prefetch operation
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Prefetches memory to the specified destination device.
  devPtr
  is the base device pointer of the memory to be prefetched and
  dstDevice
  is the destination device.
  count
  specifies the number of bytes to copy.
  stream
  is the stream in which the operation is enqueued. The memory range must refer to managed memory allocated via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  or declared via __managed__ variables.
 </p>
 <p class="p">
  Passing in cudaCpuDeviceId for
  dstDevice
  will prefetch the data to host memory. If
  dstDevice
  is a GPU, then the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  must be non-zero. Additionally,
  stream
  must be associated with a device that has a non-zero value for the device attribute
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg49e2f8c2c0bd6fe264f2fc970912e5cdc88178f29891f2c18fe67361cc80de09" shape="rect">
   cudaDevAttrConcurrentManagedAccess
  </a>
  .
 </p>
 <p class="p">
  The start address and end address of the memory range will be rounded down and rounded up respectively to be aligned to CPU
                                 page size before the prefetch operation is enqueued in the stream.
 </p>
 <p class="p">
  If no physical memory has been allocated for this region, then this memory region will be populated and mapped on the destination
                                 device. If there's insufficient memory to prefetch the desired region, the Unified Memory driver may evict pages from other
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  allocations to host memory in order to make room. Device memory allocated using
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356" shape="rect" title="Allocate memory on the device.">
   cudaMalloc
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g6728eb7dc25f332f50bdb16a19620d3d" shape="rect" title="Allocate an array on the device.">
   cudaMallocArray
  </a>
  will not be evicted.
 </p>
 <p class="p">
  By default, any mappings to the previous location of the migrated pages are removed and mappings for the new location are
                                 only setup on
  dstDevice
  . The exact behavior however also depends on the settings applied to this memory range via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g8ea5ecc5b50b0987119964dcccbb743c" shape="rect" title="Advise about the usage of a given memory range.">
   cudaMemAdvise
  </a>
  as described below:
 </p>
 <p class="p">
  If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857441d911811beda174627f403142d5ff0" shape="rect">
   cudaMemAdviseSetReadMostly
  </a>
  was set on any subset of this memory range, then that subset will create a read-only copy of the pages on
  dstDevice
  .
 </p>
 <p class="p">
  If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c857a4a2bc3c7d218dcd9a1b425b432759eb" shape="rect">
   cudaMemAdviseSetPreferredLocation
  </a>
  was called on any subset of this memory range, then the pages will be migrated to
  dstDevice
  even if
  dstDevice
  is not the preferred location of any pages in the memory range.
 </p>
 <p class="p">
  If
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggc314a8b14091f7e02a7ad15dcb36c85750a22279bce0dc29956ad4f257084623" shape="rect">
   cudaMemAdviseSetAccessedBy
  </a>
  was called on any subset of this memory range, then mappings to those pages from all the appropriate processors are updated
                                 to refer to the new location if establishing such a mapping is possible. Otherwise, those mappings are cleared.
 </p>
 <p class="p">
  Note that this API is not required for functionality and only serves to improve performance by allowing the application to
                                 migrate data to a suitable location before it is accessed. Memory accesses to this range are always coherent and are allowed
                                 even when the data is actively being migrated.
 </p>
 <p class="p">
  Note that this function is asynchronous with respect to the host and all work on other devices.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect" title="Copies memory between two devices.">
   cudaMemcpyPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g8ea5ecc5b50b0987119964dcccbb743c" shape="rect" title="Advise about the usage of a given memory range.">
   cudaMemAdvise
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3e95883b161c343f4b7ea881cf8e3a09" shape="rect" title="Advise about the usage of a given memory range.">
   cudaMemAdvise_v2
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1gfe94f8b7fb56291ebcea44261aa4cb84" shape="rect" target="_blank">
   cuMemPrefetchAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g8048f6ea5ad77917444567656c140c5a" name="group__CUDART__MEMORY_1g8048f6ea5ad77917444567656c140c5a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemRangeGetAttribute (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   data
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dataSize
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gdfcc848da2b9f49661333f861ad1a379" shape="rect" title="">
   cudaMemRangeAttribute
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attribute
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 Query an attribute of a given memory range.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  data
 </span>
 - A pointers to a memory location where the result of each attribute query will be written to.
 <span class="keyword keyword apiItemName">
  dataSize
 </span>
 - Array containing the size of data
 <span class="keyword keyword apiItemName">
  attribute
 </span>
 - The attribute to query
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Start of the range to query
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size of the range to query
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Query an attribute about the memory range starting at
  devPtr
  with a size of
  count
  bytes. The memory range must refer to managed memory allocated via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  or declared via __managed__ variables.
 </p>
 <p class="p">
  The
  attribute
  parameter can take the following values:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3794afd2109d3b8be3e1dd0fdfeed1275ee" shape="rect">
     cudaMemRangeAttributeReadMostly
    </a>
    : If this attribute is specified,
    data
    will be interpreted as a 32-bit integer, and
    dataSize
    must be 4. The result returned will be 1 if all pages in the given memory range have read-duplication enabled, or 0 otherwise.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a37946c596738ff234fa4c82859349e698f7" shape="rect">
     cudaMemRangeAttributePreferredLocation
    </a>
    : If this attribute is specified,
    data
    will be interpreted as a 32-bit integer, and
    dataSize
    must be 4. The result returned will be a GPU device id if all pages in the memory range have that GPU as their preferred
                                          location, or it will be cudaCpuDeviceId if all pages in the memory range have the CPU as their preferred location, or it will
                                          be cudaInvalidDeviceId if either all the pages don't have the same preferred location or some of the pages don't have a preferred
                                          location at all. Note that the actual location of the pages in the memory range at the time of the query may be different
                                          from the preferred location.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3790cbc6164d35671ca02e1b0813a8b7b20" shape="rect">
     cudaMemRangeAttributeAccessedBy
    </a>
    : If this attribute is specified,
    data
    will be interpreted as an array of 32-bit integers, and
    dataSize
    must be a non-zero multiple of 4. The result returned will be a list of device ids that had cudaMemAdviceSetAccessedBy set
                                          for that entire memory range. If any device does not have that advice set for the entire memory range, that device will not
                                          be included. If
    data
    is larger than the number of devices that have that advice set for that memory range, cudaInvalidDeviceId will be returned
                                          in all the extra space provided. For ex., if
    dataSize
    is 12 (i.e.
    data
    has 3 elements) and only device 0 has the advice set, then the result returned will be { 0, cudaInvalidDeviceId, cudaInvalidDeviceId
                                          }. If
    data
    is smaller than the number of devices that have that advice set, then only as many devices will be returned as can fit in
                                          the array. There is no guarantee on which specific devices will be returned, however.
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3794e9e1521833d7ff0a4dcfbd2f6304592" shape="rect">
     cudaMemRangeAttributeLastPrefetchLocation
    </a>
    : If this attribute is specified,
    data
    will be interpreted as a 32-bit integer, and
    dataSize
    must be 4. The result returned will be the last location to which all pages in the memory range were prefetched explicitly
                                          via
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
     cudaMemPrefetchAsync
    </a>
    . This will either be a GPU id or cudaCpuDeviceId depending on whether the last location for prefetch was a GPU or the CPU
                                          respectively. If any page in the memory range was never explicitly prefetched or if all pages were not prefetched to the same
                                          location, cudaInvalidDeviceId will be returned. Note that this simply returns the last location that the applicaton requested
                                          to prefetch the memory range to. It gives no indication as to whether the prefetch operation to that location has completed
                                          or even begun.
   </p>
  </li>
  <li class="li">
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a379f2a7a75f029a9066e3cfea932c4870da" shape="rect">
    cudaMemRangeAttributePreferredLocationType
   </a>
   : If this attribute is specified,
   data
   will be interpreted as a
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2279aa08666f329f3ba4afe397fa60f0" shape="rect">
    cudaMemLocationType
   </a>
   , and
   dataSize
   must be sizeof(cudaMemLocationType). The
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2279aa08666f329f3ba4afe397fa60f0" shape="rect">
    cudaMemLocationType
   </a>
   returned will be
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
    cudaMemLocationTypeDevice
   </a>
   if all pages in the memory range have the same GPU as their preferred location, or
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2279aa08666f329f3ba4afe397fa60f0" shape="rect">
    cudaMemLocationType
   </a>
   will be
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f01ec97ff5f3c715e4b18e39dabf9e31c5" shape="rect">
    cudaMemLocationTypeHost
   </a>
   if all pages in the memory range have the CPU as their preferred location, or or it will be
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
    cudaMemLocationTypeHostNuma
   </a>
   if all the pages in the memory range have the same host NUMA node ID as their preferred location or it will be cudaMemLocationTypeInvalid
                                          if either all the pages don't have the same preferred location or some of the pages don't have a preferred location at all.
                                          Note that the actual location type of the pages in the memory range at the time of the query may be different from the preferred
                                          location type.
   <ul class="ul">
    <li class="li">
     <p class="p">
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3794b4222e06b1067f90ffd9e1b250ce184" shape="rect">
       cudaMemRangeAttributePreferredLocationId
      </a>
      : If this attribute is specified,
      data
      will be interpreted as a 32-bit integer, and
      dataSize
      must be 4. If the
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a379f2a7a75f029a9066e3cfea932c4870da" shape="rect">
       cudaMemRangeAttributePreferredLocationType
      </a>
      query for the same address range returns
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
       cudaMemLocationTypeDevice
      </a>
      , it will be a valid device ordinal or if it returns
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
       cudaMemLocationTypeHostNuma
      </a>
      , it will be a valid host NUMA node ID or if it returns any other location type, the id should be ignored.
     </p>
    </li>
   </ul>
  </li>
  <li class="li">
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a379f68f9fab3cfdeb75d08e8b129bdd6762" shape="rect">
    cudaMemRangeAttributeLastPrefetchLocationType
   </a>
   : If this attribute is specified,
   data
   will be interpreted as a
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2279aa08666f329f3ba4afe397fa60f0" shape="rect">
    cudaMemLocationType
   </a>
   , and
   dataSize
   must be sizeof(cudaMemLocationType). The result returned will be the last location type to which all pages in the memory
                                          range were prefetched explicitly via
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1gfe94f8b7fb56291ebcea44261aa4cb84" shape="rect" target="_blank">
    cuMemPrefetchAsync
   </a>
   . The
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g2279aa08666f329f3ba4afe397fa60f0" shape="rect">
    cudaMemLocationType
   </a>
   returned will be
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
    cudaMemLocationTypeDevice
   </a>
   if the last prefetch location was the GPU or
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f01ec97ff5f3c715e4b18e39dabf9e31c5" shape="rect">
    cudaMemLocationTypeHost
   </a>
   if it was the CPU or
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
    cudaMemLocationTypeHostNuma
   </a>
   if the last prefetch location was a specific host NUMA node. If any page in the memory range was never explicitly prefetched
                                          or if all pages were not prefetched to the same location,
   <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1g75cfd5b9fa5c1c6ee2be2547bfbe882e" shape="rect" target="_blank">
    CUmemLocationType
   </a>
   will be cudaMemLocationTypeInvalid. Note that this simply returns the last location type that the application requested to
                                          prefetch the memory range to. It gives no indication as to whether the prefetch operation to that location has completed or
                                          even begun.
   <ul class="ul">
    <li class="li">
     <p class="p">
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a37919d650ef233ba3b126447b0b21cc6a96" shape="rect">
       cudaMemRangeAttributeLastPrefetchLocationId
      </a>
      : If this attribute is specified,
      data
      will be interpreted as a 32-bit integer, and
      dataSize
      must be 4. If the
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a379f68f9fab3cfdeb75d08e8b129bdd6762" shape="rect">
       cudaMemRangeAttributeLastPrefetchLocationType
      </a>
      query for the same address range returns
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f0e479b8710f3c5270117ee9d8cf5868d4" shape="rect">
       cudaMemLocationTypeDevice
      </a>
      , it will be a valid device ordinal or if it returns
      <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg2279aa08666f329f3ba4afe397fa60f024dc63fb938dee27b41e3842da35d2d0" shape="rect">
       cudaMemLocationTypeHostNuma
      </a>
      , it will be a valid host NUMA node ID or if it returns any other location type, the id should be ignored.
     </p>
    </li>
   </ul>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1a9199e7709c7817d1c715cfbe174d05" shape="rect" title="Query attributes of a given memory range.">
   cudaMemRangeGetAttributes
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
   cudaMemPrefetchAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g8ea5ecc5b50b0987119964dcccbb743c" shape="rect" title="Advise about the usage of a given memory range.">
   cudaMemAdvise
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1g1c92408a7d0d8875e19b1a58af56f67d" shape="rect" target="_blank">
   cuMemRangeGetAttribute
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g1a9199e7709c7817d1c715cfbe174d05" name="group__CUDART__MEMORY_1g1a9199e7709c7817d1c715cfbe174d05" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemRangeGetAttributes (  void**
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   data
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dataSizes
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gdfcc848da2b9f49661333f861ad1a379" shape="rect" title="">
   cudaMemRangeAttribute
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attributes
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   numAttributes
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 Query attributes of a given memory range.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  data
 </span>
 - A two-dimensional array containing pointers to memory locations where the result of each attribute query will be written
                                    to.
 <span class="keyword keyword apiItemName">
  dataSizes
 </span>
 - Array containing the sizes of each result
 <span class="keyword keyword apiItemName">
  attributes
 </span>
 - An array of attributes to query (numAttributes and the number of attributes in this array should match)
 <span class="keyword keyword apiItemName">
  numAttributes
 </span>
 - Number of attributes to query
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Start of the range to query
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size of the range to query
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Query attributes of the memory range starting at
  devPtr
  with a size of
  count
  bytes. The memory range must refer to managed memory allocated via
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e" shape="rect" title="Allocates memory that will be automatically managed by the Unified Memory system.">
   cudaMallocManaged
  </a>
  or declared via __managed__ variables. The
  attributes
  array will be interpreted to have
  numAttributes
  entries. The
  dataSizes
  array will also be interpreted to have
  numAttributes
  entries. The results of the query will be stored in
  data
  .
 </p>
 <p class="p">
  The list of supported attributes are given below. Please refer to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8048f6ea5ad77917444567656c140c5a" shape="rect" title="Query an attribute of a given memory range.">
   cudaMemRangeGetAttribute
  </a>
  for attribute descriptions and restrictions.
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3794afd2109d3b8be3e1dd0fdfeed1275ee" shape="rect">
     cudaMemRangeAttributeReadMostly
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a37946c596738ff234fa4c82859349e698f7" shape="rect">
     cudaMemRangeAttributePreferredLocation
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3790cbc6164d35671ca02e1b0813a8b7b20" shape="rect">
     cudaMemRangeAttributeAccessedBy
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ggdfcc848da2b9f49661333f861ad1a3794e9e1521833d7ff0a4dcfbd2f6304592" shape="rect">
     cudaMemRangeAttributeLastPrefetchLocation
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    :: cudaMemRangeAttributePreferredLocationType
   </p>
  </li>
  <li class="li">
   <p class="p">
    :: cudaMemRangeAttributePreferredLocationId
   </p>
  </li>
  <li class="li">
   <p class="p">
    :: cudaMemRangeAttributeLastPrefetchLocationType
   </p>
  </li>
  <li class="li">
   <p class="p">
    :: cudaMemRangeAttributeLastPrefetchLocationId
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8048f6ea5ad77917444567656c140c5a" shape="rect" title="Query an attribute of a given memory range.">
   cudaMemRangeGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g8ea5ecc5b50b0987119964dcccbb743c" shape="rect" title="Advise about the usage of a given memory range.">
   cudaMemAdvise
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge8dc9199943d421bc8bc7f473df12e42" shape="rect" title="Prefetches memory to the specified destination device.">
   cudaMemPrefetchAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1gc7ce142e60f8613cfb7d722b87dc9d12" shape="rect" target="_blank">
   cuMemRangeGetAttributes
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" name="group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to copy
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies
  count
  bytes from the memory area pointed to by
  src
  to the memory area pointed to by
  dst
  , where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing. Calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy()
  </a>
  with dst and src pointers that do not match the direction of the copy results in an undefined behavior.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g3480368ee0208a98f75019c9a8450893" shape="rect" target="_blank">
   cuMemcpyDtoH
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4d32266788c440b0220b1a9ba5795169" shape="rect" target="_blank">
   cuMemcpyHtoD
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g1725774abf8b51b91945f3336b778c8b" shape="rect" target="_blank">
   cuMemcpyDtoD
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g8d0ff510f26d4b87bd3a51e731e7f698" shape="rect" target="_blank">
   cuMemcpy
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" name="group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2D (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  dpitch
 </span>
 - Pitch of destination memory
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  spitch
 </span>
 - Pitch of source memory
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the memory area pointed to by
  src
  to the memory area pointed to by
  dst
  , where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  dpitch
  and
  spitch
  are the widths in memory in bytes of the 2D arrays pointed to by
  dst
  and
  src
  , including any padding added to the end of each row. The memory areas may not overlap.
  width
  must not exceed either
  dpitch
  or
  spitch
  . Calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D()
  </a>
  with
  dst
  and
  src
  pointers that do not match the direction of the copy results in an undefined behavior.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D()
  </a>
  returns an error if
  dpitch
  or
  spitch
  exceeds the maximum allowed.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g27f885b30c34cc20a663a671dbf6fc27" shape="rect" target="_blank">
   cuMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g2fa285d47fd7020e596bfeab3deb651b" shape="rect" target="_blank">
   cuMemcpy2DUnaligned
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" name="group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2DArrayToArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffsetDst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffsetDst
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1259f0b7bcff80ba46267c9117f9bb21" shape="rect" title="">
   cudaArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffsetSrc
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffsetSrc
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  =
  <span class="ph ph apiData">
   cudaMemcpyDeviceToDevice
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  wOffsetDst
 </span>
 - Destination starting X offset (columns in bytes)
 <span class="keyword keyword apiItemName">
  hOffsetDst
 </span>
 - Destination starting Y offset (rows)
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  wOffsetSrc
 </span>
 - Source starting X offset (columns in bytes)
 <span class="keyword keyword apiItemName">
  hOffsetSrc
 </span>
 - Source starting Y offset (rows)
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the CUDA array
  src
  starting at
  hOffsetSrc
  rows and
  wOffsetSrc
  bytes from the upper left corner to the CUDA array
  dst
  starting at
  hOffsetDst
  rows and
  wOffsetDst
  bytes from the upper left corner, where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  wOffsetDst
  +
  width
  must not exceed the width of the CUDA array
  dst
  .
  wOffsetSrc
  +
  width
  must not exceed the width of the CUDA array
  src
  .
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g27f885b30c34cc20a663a671dbf6fc27" shape="rect" target="_blank">
   cuMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g2fa285d47fd7020e596bfeab3deb651b" shape="rect" target="_blank">
   cuMemcpy2DUnaligned
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" name="group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2DAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  dpitch
 </span>
 - Pitch of destination memory
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  spitch
 </span>
 - Pitch of source memory
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the memory area pointed to by
  src
  to the memory area pointed to by
  dst
  , where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  dpitch
  and
  spitch
  are the widths in memory in bytes of the 2D arrays pointed to by
  dst
  and
  src
  , including any padding added to the end of each row. The memory areas may not overlap.
  width
  must not exceed either
  dpitch
  or
  spitch
  .
 </p>
 <p class="p">
  Calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync()
  </a>
  with
  dst
  and
  src
  pointers that do not match the direction of the copy results in an undefined behavior.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync()
  </a>
  returns an error if
  dpitch
  or
  spitch
  is greater than the maximum allowed.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  and
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <p class="p">
  The device version of this function only handles device to device copies and cannot be given local or shared pointers.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4acf155faeb969d9d21f5433d3d0f274" shape="rect" target="_blank">
   cuMemcpy2DAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" name="group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2DFromArray (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1259f0b7bcff80ba46267c9117f9bb21" shape="rect" title="">
   cudaArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  dpitch
 </span>
 - Pitch of destination memory
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  wOffset
 </span>
 - Source starting X offset (columns in bytes)
 <span class="keyword keyword apiItemName">
  hOffset
 </span>
 - Source starting Y offset (rows)
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the CUDA array
  src
  starting at
  hOffset
  rows and
  wOffset
  bytes from the upper left corner to the memory area pointed to by
  dst
  , where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  dpitch
  is the width in memory in bytes of the 2D array pointed to by
  dst
  , including any padding added to the end of each row.
  wOffset
  +
  width
  must not exceed the width of the CUDA array
  src
  .
  width
  must not exceed
  dpitch
  .
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray()
  </a>
  returns an error if
  dpitch
  exceeds the maximum allowed.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g27f885b30c34cc20a663a671dbf6fc27" shape="rect" target="_blank">
   cuMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g2fa285d47fd7020e596bfeab3deb651b" shape="rect" target="_blank">
   cuMemcpy2DUnaligned
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" name="group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2DFromArrayAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dpitch
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1259f0b7bcff80ba46267c9117f9bb21" shape="rect" title="">
   cudaArray_const_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  dpitch
 </span>
 - Pitch of destination memory
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  wOffset
 </span>
 - Source starting X offset (columns in bytes)
 <span class="keyword keyword apiItemName">
  hOffset
 </span>
 - Source starting Y offset (rows)
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the CUDA array
  src
  starting at
  hOffset
  rows and
  wOffset
  bytes from the upper left corner to the memory area pointed to by
  dst
  , where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  dpitch
  is the width in memory in bytes of the 2D array pointed to by
  dst
  , including any padding added to the end of each row.
  wOffset
  +
  width
  must not exceed the width of the CUDA array
  src
  .
  width
  must not exceed
  dpitch
  .
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync()
  </a>
  returns an error if
  dpitch
  exceeds the maximum allowed.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  and
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4acf155faeb969d9d21f5433d3d0f274" shape="rect" target="_blank">
   cuMemcpy2DAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" name="group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2DToArray (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  wOffset
 </span>
 - Destination starting X offset (columns in bytes)
 <span class="keyword keyword apiItemName">
  hOffset
 </span>
 - Destination starting Y offset (rows)
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  spitch
 </span>
 - Pitch of source memory
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the memory area pointed to by
  src
  to the CUDA array
  dst
  starting at
  hOffset
  rows and
  wOffset
  bytes from the upper left corner, where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  spitch
  is the width in memory in bytes of the 2D array pointed to by
  src
  , including any padding added to the end of each row.
  wOffset
  +
  width
  must not exceed the width of the CUDA array
  dst
  .
  width
  must not exceed
  spitch
  .
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray()
  </a>
  returns an error if
  spitch
  exceeds the maximum allowed.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g27f885b30c34cc20a663a671dbf6fc27" shape="rect" target="_blank">
   cuMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g2fa285d47fd7020e596bfeab3deb651b" shape="rect" target="_blank">
   cuMemcpy2DUnaligned
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" name="group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy2DToArrayAsync (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect" title="">
   cudaArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   wOffset
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   hOffset
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   spitch
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  wOffset
 </span>
 - Destination starting X offset (columns in bytes)
 <span class="keyword keyword apiItemName">
  hOffset
 </span>
 - Destination starting Y offset (rows)
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  spitch
 </span>
 - Pitch of source memory
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix transfer (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix transfer (rows)
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies a matrix (
  height
  rows of
  width
  bytes each) from the memory area pointed to by
  src
  to the CUDA array
  dst
  starting at
  hOffset
  rows and
  wOffset
  bytes from the upper left corner, where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
  spitch
  is the width in memory in bytes of the 2D array pointed to by
  src
  , including any padding added to the end of each row.
  wOffset
  +
  width
  must not exceed the width of the CUDA array
  dst
  .
  width
  must not exceed
  spitch
  .
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync()
  </a>
  returns an error if
  spitch
  exceeds the maximum allowed.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  and
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4acf155faeb969d9d21f5433d3d0f274" shape="rect" target="_blank">
   cuMemcpy2DAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" name="group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy3D (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect" title="">
   cudaMemcpy3DParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  )
 </span>
 Copies data between 3D objects.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  p
 </span>
 - 3D memory copy parameters
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <pre xml:space="preserve">âstruct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">cudaExtent</a> {
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent_1774b7b99b827dbd9f5456041b20ab319" shape="rect">width</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent_152b01e552a3d6b36e2b17fae948414f7" shape="rect">height</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent_1ba8ba71ca34c3875ec3f8f7e064af750" shape="rect">depth</a>;
      };
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">cudaExtent</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">make_cudaExtent</a>(size_t w, size_t h, size_t d);
      
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a> {
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1ee81d58a0ea213f0136b9f25cbfade0d" shape="rect">x</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1211bae4c3bc936237f34237d04d98088" shape="rect">y</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_142abb5eb62901902e70965a2ddf860b0" shape="rect">z</a>;
      };
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect" title="Returns a cudaPos based on input parameters.">make_cudaPos</a>(size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1ee81d58a0ea213f0136b9f25cbfade0d" shape="rect">x</a>, size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1211bae4c3bc936237f34237d04d98088" shape="rect">y</a>, size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_142abb5eb62901902e70965a2ddf860b0" shape="rect">z</a>);
      
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> {
        <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect">cudaArray_t</a>           
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_122fb6a1c28fe0d6d96772c994a963f1f" shape="rect">srcArray</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a>        
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_136e02256b567dca1b3099d7a6a3b6d4b" shape="rect">srcPos</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">cudaPitchedPtr</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_12c0214914f84710757a07cc679b01397" shape="rect">srcPtr</a>;
        <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect">cudaArray_t</a>           
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_17d77d9ecb416b7f4ba4ee8d354b9d6fd" shape="rect">dstArray</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a>        
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_162d0ce8f8030683a365c9fc58b0b4d45" shape="rect">dstPos</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">cudaPitchedPtr</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_15541621b6b654ecae4d5cab526ddd70e" shape="rect">dstPtr</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">cudaExtent</a>     
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_11a54c24021add984df530442dd65ec1c" shape="rect">extent</a>;
        enum <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect">cudaMemcpyKind</a>   
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_10caa37ba0134b351170924565d07be20" shape="rect">kind</a>;
      };</pre>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D()
  </a>
  copies data betwen two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA
                                 array. The source, destination, extent, and kind of copy performed is specified by the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">
   cudaMemcpy3DParms
  </a>
  struct which should be initialized to zero before use:
 </p>
 <pre xml:space="preserve">â<a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> myParms = {0};</pre>
 <p class="p">
  The struct passed to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D()
  </a>
  must specify one of
  srcArray
  or
  srcPtr
  and one of
  dstArray
  or
  dstPtr
  . Passing more than one non-zero source or destination will cause
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D()
  </a>
  to return an error.
 </p>
 <p class="p">
  The
  srcPos
  and
  dstPos
  fields are optional offsets into the source and destination objects and are defined in units of each object's elements. The
                                 element for a host or device pointer is assumed to be
  unsigned char
  .
 </p>
 <p class="p">
  The
  extent
  field defines the dimensions of the transferred area in elements. If a CUDA array is participating in the copy, the extent
                                 is defined in terms of that array's elements. If no CUDA array is participating in the copy then the extents are defined in
                                 elements of
  unsigned char
  .
 </p>
 <p class="p">
  The
  kind
  field defines the direction of the copy. It must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing. For
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  passed as kind and cudaArray type passed as source or destination, if the kind implies cudaArray type to be present on the
                                 host,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D()
  </a>
  will disregard that implication and silently correct the kind based on the fact that cudaArray type can only be present on
                                 the device.
 </p>
 <p class="p">
  If the source and destination are both arrays,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D()
  </a>
  will return an error if they do not have the same element size.
 </p>
 <p class="p">
  The source and destination object may not overlap. If overlapping source and destination objects are specified, undefined
                                 behavior will result.
 </p>
 <p class="p">
  The source object must entirely contain the region defined by
  srcPos
  and
  extent
  . The destination object must entirely contain the region defined by
  dstPos
  and
  extent
  .
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D()
  </a>
  returns an error if the pitch of
  srcPtr
  or
  dstPtr
  exceeds the maximum allowed. The pitch of a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  allocated with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D()
  </a>
  will always be valid.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect" title="Returns a cudaPos based on input parameters.">
   make_cudaPos
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4b5238975579f002c0199a3800ca44df" shape="rect" target="_blank">
   cuMemcpy3D
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" name="group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy3DAsync (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect" title="">
   cudaMemcpy3DParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data between 3D objects.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  p
 </span>
 - 3D memory copy parameters
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <pre xml:space="preserve">âstruct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">cudaExtent</a> {
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent_1774b7b99b827dbd9f5456041b20ab319" shape="rect">width</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent_152b01e552a3d6b36e2b17fae948414f7" shape="rect">height</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent_1ba8ba71ca34c3875ec3f8f7e064af750" shape="rect">depth</a>;
      };
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">cudaExtent</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">make_cudaExtent</a>(size_t w, size_t h, size_t d);
      
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a> {
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1ee81d58a0ea213f0136b9f25cbfade0d" shape="rect">x</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1211bae4c3bc936237f34237d04d98088" shape="rect">y</a>;
        size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_142abb5eb62901902e70965a2ddf860b0" shape="rect">z</a>;
      };
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect" title="Returns a cudaPos based on input parameters.">make_cudaPos</a>(size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1ee81d58a0ea213f0136b9f25cbfade0d" shape="rect">x</a>, size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_1211bae4c3bc936237f34237d04d98088" shape="rect">y</a>, size_t <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos_142abb5eb62901902e70965a2ddf860b0" shape="rect">z</a>);
      
      struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> {
        <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect">cudaArray_t</a>           
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_122fb6a1c28fe0d6d96772c994a963f1f" shape="rect">srcArray</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a>        
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_136e02256b567dca1b3099d7a6a3b6d4b" shape="rect">srcPos</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">cudaPitchedPtr</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_12c0214914f84710757a07cc679b01397" shape="rect">srcPtr</a>;
        <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gaf8b3ba752727d996074a71ee997ce68" shape="rect">cudaArray_t</a>           
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_17d77d9ecb416b7f4ba4ee8d354b9d6fd" shape="rect">dstArray</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">cudaPos</a>        
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_162d0ce8f8030683a365c9fc58b0b4d45" shape="rect">dstPos</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">cudaPitchedPtr</a> 
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_15541621b6b654ecae4d5cab526ddd70e" shape="rect">dstPtr</a>;
        struct <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">cudaExtent</a>     
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_11a54c24021add984df530442dd65ec1c" shape="rect">extent</a>;
        enum <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect">cudaMemcpyKind</a>   
                  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms_10caa37ba0134b351170924565d07be20" shape="rect">kind</a>;
      };</pre>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  copies data betwen two 3D objects. The source and destination objects may be in either host memory, device memory, or a CUDA
                                 array. The source, destination, extent, and kind of copy performed is specified by the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">
   cudaMemcpy3DParms
  </a>
  struct which should be initialized to zero before use:
 </p>
 <pre xml:space="preserve">â<a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DParms.html#structcudaMemcpy3DParms" shape="rect">cudaMemcpy3DParms</a> myParms = {0};</pre>
 <p class="p">
  The struct passed to
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  must specify one of
  srcArray
  or
  srcPtr
  and one of
  dstArray
  or
  dstPtr
  . Passing more than one non-zero source or destination will cause
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  to return an error.
 </p>
 <p class="p">
  The
  srcPos
  and
  dstPos
  fields are optional offsets into the source and destination objects and are defined in units of each object's elements. The
                                 element for a host or device pointer is assumed to be
  unsigned char
  . For CUDA arrays, positions must be in the range [0, 2048) for any dimension.
 </p>
 <p class="p">
  The
  extent
  field defines the dimensions of the transferred area in elements. If a CUDA array is participating in the copy, the extent
                                 is defined in terms of that array's elements. If no CUDA array is participating in the copy then the extents are defined in
                                 elements of
  unsigned char
  .
 </p>
 <p class="p">
  The
  kind
  field defines the direction of the copy. It must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing. For
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  passed as kind and cudaArray type passed as source or destination, if the kind implies cudaArray type to be present on the
                                 host,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  will disregard that implication and silently correct the kind based on the fact that cudaArray type can only be present on
                                 the device.
 </p>
 <p class="p">
  If the source and destination are both arrays,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  will return an error if they do not have the same element size.
 </p>
 <p class="p">
  The source and destination object may not overlap. If overlapping source and destination objects are specified, undefined
                                 behavior will result.
 </p>
 <p class="p">
  The source object must lie entirely within the region defined by
  srcPos
  and
  extent
  . The destination object must lie entirely within the region defined by
  dstPos
  and
  extent
  .
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  returns an error if the pitch of
  srcPtr
  or
  dstPtr
  exceeds the maximum allowed. The pitch of a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  allocated with
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D()
  </a>
  will always be valid.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g785bd0963e476a740533382a67674641" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3DAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  and
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <p class="p">
  The device version of this function only handles device to device copies and cannot be given local or shared pointers.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g948143cf2423a072ac6a31fb635efd88" shape="rect" title="Allocate an array on the device.">
   cudaMalloc3DArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfec7ee5257d48c8528a709ffad48d208" shape="rect" title="Copies data between 3D objects.">
   cudaMemcpy3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  , :
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect" title="Returns a cudaPos based on input parameters.">
   make_cudaPos
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g79f4f3fde6ae0f529568d881d9e11987" shape="rect" target="_blank">
   cuMemcpy3DAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1geeab4601354962a5968eefc8b79ec2dd" name="group__CUDART__MEMORY_1geeab4601354962a5968eefc8b79ec2dd" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy3DPeer (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms" shape="rect" title="">
   cudaMemcpy3DPeerParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  )
 </span>
 Copies memory between devices.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  p
 </span>
 - Parameters for the memory copy
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Perform a 3D memory copy according to the parameters specified in
  p
  . See the definition of the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms" shape="rect">
   cudaMemcpy3DPeerParms
  </a>
  structure for documentation of its parameters.
 </p>
 <p class="p">
  Note that this function is synchronous with respect to the host only if the source or destination of the transfer is host
                                 memory. Note also that this copy is serialized with respect to all pending and future asynchronous work in to the current
                                 device, the copy's source device, and the copy's destination device (use
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  to avoid this synchronization).
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect" title="Copies memory between two devices.">
   cudaMemcpyPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" shape="rect" title="Copies memory between two devices asynchronously.">
   cudaMemcpyPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g11466fd70cde9329a4e16eb1f258c433" shape="rect" target="_blank">
   cuMemcpy3DPeer
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" name="group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpy3DPeerAsync (  const
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms" shape="rect" title="">
   cudaMemcpy3DPeerParms
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies memory between devices asynchronously.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  p
 </span>
 - Parameters for the memory copy
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038225c65c0348cced651d5dd87ccc22f48" shape="rect">
   cudaErrorInvalidPitchValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Perform a 3D memory copy according to the parameters specified in
  p
  . See the definition of the
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaMemcpy3DPeerParms.html#structcudaMemcpy3DPeerParms" shape="rect">
   cudaMemcpy3DPeerParms
  </a>
  structure for documentation of its parameters.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect" title="Copies memory between two devices.">
   cudaMemcpyPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" shape="rect" title="Copies memory between two devices asynchronously.">
   cudaMemcpyPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gc4e4bfd9f627d3aa3695979e058f1bb8" shape="rect" target="_blank">
   cuMemcpy3DPeerAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" name="group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data between host and device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to copy
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies
  count
  bytes from the memory area pointed to by
  src
  to the memory area pointed to by
  dst
  , where
  kind
  specifies the direction of the copy, and must be one of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95bdeec295de8a74ac2a74f98ffb6c5d7c7" shape="rect">
   cudaMemcpyHostToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
 </p>
 <p class="p">
  The memory areas may not overlap. Calling
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync()
  </a>
  with
  dst
  and
  src
  pointers that do not match the direction of the copy results in an undefined behavior.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  and the
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <p class="p">
  The device version of this function only handles device to device copies and cannot be given local or shared pointers.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Memory regions requested must be either entirely registered with CUDA, or in the case of host pageable transfers, not registered
                                             at all. Memory regions spanning over allocations that are both registered and not registered with CUDA are not supported and
                                             will return CUDA_ERROR_INVALID_VALUE.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g5f26aaf5582ade791e5688727a178d78" shape="rect" target="_blank">
   cuMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g56f30236c7c5247f8e061b59d3268362" shape="rect" target="_blank">
   cuMemcpyDtoHAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g1572263fe2597d7ba4f6964597a354a3" shape="rect" target="_blank">
   cuMemcpyHtoDAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g39ea09ba682b8eccc9c3e0c04319b5c8" shape="rect" target="_blank">
   cuMemcpyDtoDAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g17ce3365ef7b6687a7d16c5b29de1f82" name="group__CUDART__MEMORY_1g17ce3365ef7b6687a7d16c5b29de1f82" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyFromSymbol (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  =
  <span class="ph ph apiData">
   cudaMemcpyDeviceToHost
  </span>
  )
 </span>
 Copies data from the given symbol on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  symbol
 </span>
 - Device symbol address
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to copy
 <span class="keyword keyword apiItemName">
  offset
 </span>
 - Offset from start of symbol in bytes
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388db0eb1b77feecee97b09d43dd876122" shape="rect">
   cudaErrorNoKernelImageForDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies
  count
  bytes from the memory area pointed to by
  offset
  bytes from the start of symbol
  symbol
  to the memory area pointed to by
  dst
  . The memory areas may not overlap.
  symbol
  is a variable that resides in global or constant memory space.
  kind
  can be either
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Use of a string naming a variable as the
    symbol
    parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g8d0ff510f26d4b87bd3a51e731e7f698" shape="rect" target="_blank">
   cuMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g3480368ee0208a98f75019c9a8450893" shape="rect" target="_blank">
   cuMemcpyDtoH
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g1725774abf8b51b91945f3336b778c8b" shape="rect" target="_blank">
   cuMemcpyDtoD
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g9445b750013829f03d0bb5ad5fa7a0fb" name="group__CUDART__MEMORY_1g9445b750013829f03d0bb5ad5fa7a0fb" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyFromSymbolAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data from the given symbol on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination memory address
 <span class="keyword keyword apiItemName">
  symbol
 </span>
 - Device symbol address
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to copy
 <span class="keyword keyword apiItemName">
  offset
 </span>
 - Offset from start of symbol in bytes
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388db0eb1b77feecee97b09d43dd876122" shape="rect">
   cudaErrorNoKernelImageForDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies
  count
  bytes from the memory area pointed to by
  offset
  bytes from the start of symbol
  symbol
  to the memory area pointed to by
  dst
  . The memory areas may not overlap.
  symbol
  is a variable that resides in global or constant memory space.
  kind
  can be either
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9445b750013829f03d0bb5ad5fa7a0fb" shape="rect" title="Copies data from the given symbol on the device.">
   cudaMemcpyFromSymbolAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b5653197602d3455a530db5a7edb1a253" shape="rect">
   cudaMemcpyDeviceToHost
  </a>
  and
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Use of a string naming a variable as the
    symbol
    parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g5f26aaf5582ade791e5688727a178d78" shape="rect" target="_blank">
   cuMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g56f30236c7c5247f8e061b59d3268362" shape="rect" target="_blank">
   cuMemcpyDtoHAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g39ea09ba682b8eccc9c3e0c04319b5c8" shape="rect" target="_blank">
   cuMemcpyDtoDAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" name="group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyPeer (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   srcDevice
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 Copies memory between two devices.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination device pointer
 <span class="keyword keyword apiItemName">
  dstDevice
 </span>
 - Destination device
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source device pointer
 <span class="keyword keyword apiItemName">
  srcDevice
 </span>
 - Source device
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size of memory copy in bytes
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies memory from one device to memory on another device.
  dst
  is the base device pointer of the destination memory and
  dstDevice
  is the destination device.
  src
  is the base device pointer of the source memory and
  srcDevice
  is the source device.
  count
  specifies the number of bytes to copy.
 </p>
 <p class="p">
  Note that this function is asynchronous with respect to the host, but serialized with respect all pending and future asynchronous
                                 work in to the current device,
  srcDevice
  , and
  dstDevice
  (use
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" shape="rect" title="Copies memory between two devices asynchronously.">
   cudaMemcpyPeerAsync
  </a>
  to avoid this synchronization).
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" shape="rect" title="Copies memory between two devices asynchronously.">
   cudaMemcpyPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ge1f5c7771544fee150ada8853c7cbf4a" shape="rect" target="_blank">
   cuMemcpyPeer
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" name="group__CUDART__MEMORY_1gbfde4ace9ff4823f4ac45e5c6bdcd2ee" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyPeerAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dst
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   dstDevice
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   srcDevice
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies memory between two devices asynchronously.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  dst
 </span>
 - Destination device pointer
 <span class="keyword keyword apiItemName">
  dstDevice
 </span>
 - Destination device
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source device pointer
 <span class="keyword keyword apiItemName">
  srcDevice
 </span>
 - Source device
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size of memory copy in bytes
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038938c6e8b96ecde62e3ab5137156f739a" shape="rect">
   cudaErrorInvalidDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies memory from one device to memory on another device.
  dst
  is the base device pointer of the destination memory and
  dstDevice
  is the destination device.
  src
  is the base device pointer of the source memory and
  srcDevice
  is the source device.
  count
  specifies the number of bytes to copy.
 </p>
 <p class="p">
  Note that this function is asynchronous with respect to the host and all work on other devices.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g88fd1245b2cb10d2d30c74900b7dfb9c" shape="rect" title="Copies memory between two devices.">
   cudaMemcpyPeer
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7386b2845149b48c87f82ea017690aa8" shape="rect" title="Copies memory between devices asynchronously.">
   cudaMemcpy3DPeerAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g82fcecb38018e64b98616a8ac30112f2" shape="rect" target="_blank">
   cuMemcpyPeerAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g9bcf02b53644eee2bef9983d807084c7" name="group__CUDART__MEMORY_1g9bcf02b53644eee2bef9983d807084c7" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyToSymbol (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  =
  <span class="ph ph apiData">
   cudaMemcpyHostToDevice
  </span>
  )
 </span>
 Copies data to the given symbol on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  symbol
 </span>
 - Device symbol address
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to copy
 <span class="keyword keyword apiItemName">
  offset
 </span>
 - Offset from start of symbol in bytes
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388db0eb1b77feecee97b09d43dd876122" shape="rect">
   cudaErrorNoKernelImageForDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies
  count
  bytes from the memory area pointed to by
  src
  to the memory area pointed to by
  offset
  bytes from the start of symbol
  symbol
  . The memory areas may not overlap.
  symbol
  is a variable that resides in global or constant memory space.
  kind
  can be either
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync" shape="rect">
     synchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Use of a string naming a variable as the
    symbol
    parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gd00b41ade29161aafbf6ff8aee3d6eb5" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g8d0ff510f26d4b87bd3a51e731e7f698" shape="rect" target="_blank">
   cuMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4d32266788c440b0220b1a9ba5795169" shape="rect" target="_blank">
   cuMemcpyHtoD
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g1725774abf8b51b91945f3336b778c8b" shape="rect" target="_blank">
   cuMemcpyDtoD
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gc3551568f691baad5fb776b7656ecc05" name="group__CUDART__MEMORY_1gc3551568f691baad5fb776b7656ecc05" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemcpyToSymbolAsync (  const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   symbol
  </span>
  , const void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   src
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   offset
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g18fa99055ee694244a270e4d5101e95b" shape="rect" title="">
   cudaMemcpyKind
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   kind
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Copies data to the given symbol on the device.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  symbol
 </span>
 - Device symbol address
 <span class="keyword keyword apiItemName">
  src
 </span>
 - Source memory address
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to copy
 <span class="keyword keyword apiItemName">
  offset
 </span>
 - Offset from start of symbol in bytes
 <span class="keyword keyword apiItemName">
  kind
 </span>
 - Type of transfer
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003801a4a97f3060ec714ffa9dd650b9213a" shape="rect">
   cudaErrorInvalidSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003872ce39cee8ef48a83b0191b2e33d2630" shape="rect">
   cudaErrorInvalidMemcpyDirection
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00388db0eb1b77feecee97b09d43dd876122" shape="rect">
   cudaErrorNoKernelImageForDevice
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Copies
  count
  bytes from the memory area pointed to by
  src
  to the memory area pointed to by
  offset
  bytes from the start of symbol
  symbol
  . The memory areas may not overlap.
  symbol
  is a variable that resides in global or constant memory space.
  kind
  can be either
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b783338534304281650c6cb1363f5a00a" shape="rect">
   cudaMemcpyDeviceToDevice
  </a>
  , or
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  . Passing
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is recommended, in which case the type of transfer is inferred from the pointer values. However,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b715aff8fb2b8f4f1bb553fee802db57a" shape="rect">
   cudaMemcpyDefault
  </a>
  is only allowed on systems that support unified virtual addressing.
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3551568f691baad5fb776b7656ecc05" shape="rect" title="Copies data to the given symbol on the device.">
   cudaMemcpyToSymbolAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the copy is complete. The copy can optionally be
                                 associated to a stream by passing a non-zero
  stream
  argument. If
  kind
  is
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg18fa99055ee694244a270e4d5101e95b1a03d03a676ea8ec51b9b1e193617568" shape="rect">
   cudaMemcpyHostToDevice
  </a>
  and
  stream
  is non-zero, the copy may overlap with operations in other streams.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function exhibits
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async" shape="rect">
     asynchronous
    </a>
    behavior for most use cases.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Use of a string naming a variable as the
    symbol
    parameter was deprecated in CUDA 4.1 and removed in CUDA 5.0.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8" shape="rect" title="Copies data between host and device.">
   cudaMemcpy
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g3a58270f6775efe56c65ac47843e7cee" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g9509226164aaa58baf0c5b8ed165df58" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0f944b3fd3c81edad0a352cf22de24f0" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf111724f090f2a73d5302e03d6f82488" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DArrayToArray
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g4561bf9c99d91c92684a91a0bd356bfe" shape="rect" title="[C++ API] Copies data to the given symbol on the device">
   cudaMemcpyToSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g99db510d18d37fbb0f5c075a8caf3b5f" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbol
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g85073372f776b4c4d5f89f7124b7bf79" shape="rect" title="Copies data between host and device.">
   cudaMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ge529b926e8fb574c2666a9a1d58b0dc1" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g217af4b9e2de79d9252418fc661e6a6a" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DToArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g1c81de45e9ed5e72008a8f28e706b599" shape="rect" title="Copies data between host and device.">
   cudaMemcpy2DFromArrayAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1g2d9f7a440f1e522555dfe994245a5946" shape="rect" title="[C++ API] Copies data from the given symbol on the device">
   cudaMemcpyFromSymbolAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g5f26aaf5582ade791e5688727a178d78" shape="rect" target="_blank">
   cuMemcpyAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g1572263fe2597d7ba4f6964597a354a3" shape="rect" target="_blank">
   cuMemcpyHtoDAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g39ea09ba682b8eccc9c3e0c04319b5c8" shape="rect" target="_blank">
   cuMemcpyDtoDAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" name="group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemset (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  )
 </span>
 Initializes or sets device memory to a value.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to device memory
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Value to set for each byte of specified memory
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to set
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Fills the first
  count
  bytes of the memory area pointed to by
  devPtr
  with the constant byte value
  value
  .
 </p>
 <p class="p">
  Note that this function is asynchronous with respect to the host unless
  devPtr
  refers to pinned host memory.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    See also
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memset" shape="rect">
     memset synchronization details
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g6e582bf866e9e2fb014297bfaf354d7b" shape="rect" target="_blank">
   cuMemsetD8
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g7d805e610054392a4d11e8a8bf5eb35c" shape="rect" target="_blank">
   cuMemsetD16
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g983e8d8759acd1b64326317481fbf132" shape="rect" target="_blank">
   cuMemsetD32
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" name="group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemset2D (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitch
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  )
 </span>
 Initializes or sets device memory to a value.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to 2D device memory
 <span class="keyword keyword apiItemName">
  pitch
 </span>
 - Pitch in bytes of 2D device memory(Unused if
 height
 is 1)
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Value to set for each byte of specified memory
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix set (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix set (rows)
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Sets to the specified value
  value
  a matrix (
  height
  rows of
  width
  bytes each) pointed to by
  dstPtr
  .
  pitch
  is the width in bytes of the 2D array pointed to by
  dstPtr
  , including any padding added to the end of each row. This function performs fastest when the pitch is one that has been passed
                                 back by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  .
 </p>
 <p class="p">
  Note that this function is asynchronous with respect to the host unless
  devPtr
  refers to pinned host memory.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    See also
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memset" shape="rect">
     memset synchronization details
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemsetAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1ge88b13e646e2be6ba0e0475ef5205974" shape="rect" target="_blank">
   cuMemsetD2D8
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g7f561a15a66144fa9f6ab5350edc8a30" shape="rect" target="_blank">
   cuMemsetD2D16
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g74b359b2d026bfeb7c795b5038d07523" shape="rect" target="_blank">
   cuMemsetD2D32
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" name="group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemset2DAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitch
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   width
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   height
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Initializes or sets device memory to a value.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to 2D device memory
 <span class="keyword keyword apiItemName">
  pitch
 </span>
 - Pitch in bytes of 2D device memory(Unused if
 height
 is 1)
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Value to set for each byte of specified memory
 <span class="keyword keyword apiItemName">
  width
 </span>
 - Width of matrix set (columns in bytes)
 <span class="keyword keyword apiItemName">
  height
 </span>
 - Height of matrix set (rows)
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Sets to the specified value
  value
  a matrix (
  height
  rows of
  width
  bytes each) pointed to by
  dstPtr
  .
  pitch
  is the width in bytes of the 2D array pointed to by
  dstPtr
  , including any padding added to the end of each row. This function performs fastest when the pitch is one that has been passed
                                 back by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g32bd7a39135594788a542ae72217775c" shape="rect" title="Allocates pitched memory on the device.">
   cudaMallocPitch()
  </a>
  .
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2DAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the memset is complete. The operation can optionally
                                 be associated to a stream by passing a non-zero
  stream
  argument. If
  stream
  is non-zero, the operation may overlap with operations in other streams.
 </p>
 <p class="p">
  The device version of this function only handles device to device copies and cannot be given local or shared pointers.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    See also
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memset" shape="rect">
     memset synchronization details
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemsetAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g3f7b6924a3e49c3265b328f534102e97" shape="rect" target="_blank">
   cuMemsetD2D8Async
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g64ee197befac3d74d9fefedcf6ef6b10" shape="rect" target="_blank">
   cuMemsetD2D16Async
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g8a78d3147ac93fac955052c815d9ea3c" shape="rect" target="_blank">
   cuMemsetD2D32Async
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" name="group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemset3D (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitchedDevPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  )
 </span>
 Initializes or sets device memory to a value.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pitchedDevPtr
 </span>
 - Pointer to pitched device memory
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Value to set for each byte of specified memory
 <span class="keyword keyword apiItemName">
  extent
 </span>
 - Size parameters for where to set device memory (
 width
 field in bytes)
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Initializes each element of a 3D array to the specified value
  value
  . The object to initialize is defined by
  pitchedDevPtr
  . The
  pitch
  field of
  pitchedDevPtr
  is the width in memory in bytes of the 3D array pointed to by
  pitchedDevPtr
  , including any padding added to the end of each row. The
  xsize
  field specifies the logical width of each row in bytes, while the
  ysize
  field specifies the height of each 2D slice in rows. The
  pitch
  field of
  pitchedDevPtr
  is ignored when
  height
  and
  depth
  are both equal to 1.
 </p>
 <p class="p">
  The extents of the initialized region are specified as a
  width
  in bytes, a
  height
  in rows, and a
  depth
  in slices.
 </p>
 <p class="p">
  Extents with
  width
  greater than or equal to the
  xsize
  of
  pitchedDevPtr
  may perform significantly faster than extents narrower than the
  xsize
  . Secondarily, extents with
  height
  equal to the
  ysize
  of
  pitchedDevPtr
  will perform faster than when the
  height
  is shorter than the
  ysize
  .
 </p>
 <p class="p">
  This function performs fastest when the
  pitchedDevPtr
  has been allocated by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D()
  </a>
  .
 </p>
 <p class="p">
  Note that this function is asynchronous with respect to the host unless
  pitchedDevPtr
  refers to pinned host memory.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    See also
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memset" shape="rect">
     memset synchronization details
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemsetAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect" title="Returns a cudaPitchedPtr based on input parameters.">
   make_cudaPitchedPtr
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" name="group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemset3DAsync (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   pitchedDevPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   extent
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Initializes or sets device memory to a value.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  pitchedDevPtr
 </span>
 - Pointer to pitched device memory
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Value to set for each byte of specified memory
 <span class="keyword keyword apiItemName">
  extent
 </span>
 - Size parameters for where to set device memory (
 width
 field in bytes)
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Initializes each element of a 3D array to the specified value
  value
  . The object to initialize is defined by
  pitchedDevPtr
  . The
  pitch
  field of
  pitchedDevPtr
  is the width in memory in bytes of the 3D array pointed to by
  pitchedDevPtr
  , including any padding added to the end of each row. The
  xsize
  field specifies the logical width of each row in bytes, while the
  ysize
  field specifies the height of each 2D slice in rows. The
  pitch
  field of
  pitchedDevPtr
  is ignored when
  height
  and
  depth
  are both equal to 1.
 </p>
 <p class="p">
  The extents of the initialized region are specified as a
  width
  in bytes, a
  height
  in rows, and a
  depth
  in slices.
 </p>
 <p class="p">
  Extents with
  width
  greater than or equal to the
  xsize
  of
  pitchedDevPtr
  may perform significantly faster than extents narrower than the
  xsize
  . Secondarily, extents with
  height
  equal to the
  ysize
  of
  pitchedDevPtr
  will perform faster than when the
  height
  is shorter than the
  ysize
  .
 </p>
 <p class="p">
  This function performs fastest when the
  pitchedDevPtr
  has been allocated by
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D()
  </a>
  .
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3DAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the memset is complete. The operation can optionally
                                 be associated to a stream by passing a non-zero
  stream
  argument. If
  stream
  is non-zero, the operation may overlap with operations in other streams.
 </p>
 <p class="p">
  The device version of this function only handles device to device copies and cannot be given local or shared pointers.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    See also
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memset" shape="rect">
     memset synchronization details
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemsetAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g188300e599ded65c925e79eab2a57347" shape="rect" title="Allocates logical 1D, 2D, or 3D memory objects on the device.">
   cudaMalloc3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect" title="Returns a cudaPitchedPtr based on input parameters.">
   make_cudaPitchedPtr
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" name="group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <span class="keyword keyword apiItemName">
   __device__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMemsetAsync (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   devPtr
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   count
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1ge15d9c8b7a240312b533d6122558085a" shape="rect" title="">
   cudaStream_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   stream
  </span>
  =
  <span class="ph ph apiData">
   0
  </span>
  )
 </span>
 Initializes or sets device memory to a value.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  devPtr
 </span>
 - Pointer to device memory
 <span class="keyword keyword apiItemName">
  value
 </span>
 - Value to set for each byte of specified memory
 <span class="keyword keyword apiItemName">
  count
 </span>
 - Size in bytes to set
 <span class="keyword keyword apiItemName">
  stream
 </span>
 - Stream identifier
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  ,
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Fills the first
  count
  bytes of the memory area pointed to by
  devPtr
  with the constant byte value
  value
  .
 </p>
 <p class="p">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g7c9761e21d9f0999fd136c51e7b9b2a0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemsetAsync()
  </a>
  is asynchronous with respect to the host, so the call may return before the memset is complete. The operation can optionally
                                 be associated to a stream by passing a non-zero
  stream
  argument. If
  stream
  is non-zero, the operation may overlap with operations in other streams.
 </p>
 <p class="p">
  The device version of this function only handles device to device copies and cannot be given local or shared pointers.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <ul class="ul">
  <li class="li">
   <p class="p">
    Note that this function may also return error codes from previous, asynchronous launches.
   </p>
  </li>
  <li class="li">
   <p class="p">
    See also
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memset" shape="rect">
     memset synchronization details
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    This function uses standard
    <a class="xref xmlonly" href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html#stream-sync-behavior__default-stream" shape="rect">
     default stream
    </a>
    semantics.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that this function may also return
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038ce7993a88ecf2c57b8102d55d997a18c" shape="rect">
     cudaErrorInitializationError
    </a>
    ,
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038f5e52d1774934b77ba55d2aa2c063067" shape="rect">
     cudaErrorInsufficientDriver
    </a>
    or
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e942e4cbbd2bef6e92e293253f055613" shape="rect">
     cudaErrorNoDevice
    </a>
    if this call tries to initialize internal CUDA RT state.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Note that as specified by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g74aa9f4b1c2f12d994bf13876a5a2498" shape="rect" title="Add a callback to a compute stream.">
     cudaStreamAddCallback
    </a>
    no CUDA function may be called from callback.
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e003867b6095ab719b21659a400b553963eb3" shape="rect">
     cudaErrorNotPermitted
    </a>
    may, but is not guaranteed to, be returned as a diagnostic in such case.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gf7338650f7683c51ee26aadc6973c63a" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g120112b2bd627c7a896390efadc4d2c1" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g87688e6e9ce6a19c3405bb2bc8e49f93" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3D
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g8fdcc53996ff49c570f4b5ead0256ef0" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset2DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga0fe471e6538e11e6e8ad9895833cc71" shape="rect" title="Initializes or sets device memory to a value.">
   cudaMemset3DAsync
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gaef08a7ccd61112f94e82f2b30d43627" shape="rect" target="_blank">
   cuMemsetD8Async
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gf731438877dd8ec875e4c43d848c878c" shape="rect" target="_blank">
   cuMemsetD16Async
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g58229da5d30f1c0cdf667b320ec2c0f5" shape="rect" target="_blank">
   cuMemsetD32Async
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g5585c79ccabe9cd9f882810b0ae2f382" name="group__CUDART__MEMORY_1g5585c79ccabe9cd9f882810b0ae2f382" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMipmappedArrayGetMemoryRequirements (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements" shape="rect" title="">
   cudaArrayMemoryRequirements
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   memoryRequirements
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmap
  </span>
  , int
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   device
  </span>
  )
 </span>
 Returns the memory requirements of a CUDA mipmapped array.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  memoryRequirements
 </span>
 - Pointer to
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements" shape="rect">
  cudaArrayMemoryRequirements
 </a>
 <span class="keyword keyword apiItemName">
  mipmap
 </span>
 - CUDA mipmapped array to get the memory requirements of
 <span class="keyword keyword apiItemName">
  device
 </span>
 - Device to get the memory requirements for
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns the memory requirements of a CUDA mipmapped array in
  memoryRequirements
  If the CUDA mipmapped array is not allocated with flag
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g91a50795515848406a89c2e6cef2fb02" shape="rect">
   cudaArrayDeferredMapping
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  will be returned.
 </p>
 <p class="p">
  The returned value in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements_1cff0bc12daa05c6c40892a2187befd87" shape="rect">
   cudaArrayMemoryRequirements::size
  </a>
  represents the total size of the CUDA mipmapped array. The returned value in
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArrayMemoryRequirements.html#structcudaArrayMemoryRequirements_137898b13b500d39e4a43d0ee04cf0ef3" shape="rect">
   cudaArrayMemoryRequirements::alignment
  </a>
  represents the alignment necessary for mapping the CUDA mipmapped array.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g809cc7ad6dbb23f84121f28136c6eace" shape="rect" title="Returns the memory requirements of a CUDA array.">
   cudaArrayGetMemoryRequirements
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g96d65849f80adb87d239f68756ed5b14" name="group__CUDART__MEMORY_1g96d65849f80adb87d239f68756ed5b14" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gf599e5b8b829ce7db0f5216928f6ecb6" shape="rect" title="">
   cudaError_t
  </a>
  cudaMipmappedArrayGetSparseProperties (
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties" shape="rect" title="">
   cudaArraySparseProperties
  </a>
  *
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   sparseProperties
  </span>
  ,
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g1b03ad14fc0ab86f8b033837f5562d8a" shape="rect" title="">
   cudaMipmappedArray_t
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   mipmap
  </span>
  )
 </span>
 Returns the layout properties of a sparse CUDA mipmapped array.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  sparseProperties
 </span>
 - Pointer to return
 <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties" shape="rect">
  cudaArraySparseProperties
 </a>
 <span class="keyword keyword apiItemName">
  mipmap
 </span>
 - The CUDA mipmapped array to get the sparse properties of
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e0038e355f04607d824883b4a50662830d591" shape="rect">
   cudaSuccess
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns the sparse array layout properties in
  sparseProperties
  . If the CUDA mipmapped array is not allocated with flag
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g42c353686a15da063dc7722594ae4bff" shape="rect">
   cudaArraySparse
  </a>
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1gg3f51e3575c2178246db0a94a430e00383e8aef5398ee38e28ed41e357b48917c" shape="rect">
   cudaErrorInvalidValue
  </a>
  will be returned.
 </p>
 <p class="p">
  For non-layered CUDA mipmapped arrays,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_122cfa4ad83195f0e9585303c988bb886" shape="rect">
   cudaArraySparseProperties::miptailSize
  </a>
  returns the size of the mip tail region. The mip tail region includes all mip levels whose width, height or depth is less
                                 than that of the tile. For layered CUDA mipmapped arrays, if
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_144c8728469d60e511aceb4ba7086c164" shape="rect">
   cudaArraySparseProperties::flags
  </a>
  contains
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g6820071ffa1300699897eab8d319e4d9" shape="rect">
   cudaArraySparsePropertiesSingleMipTail
  </a>
  , then
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_122cfa4ad83195f0e9585303c988bb886" shape="rect">
   cudaArraySparseProperties::miptailSize
  </a>
  specifies the size of the mip tail of all layers combined. Otherwise,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_122cfa4ad83195f0e9585303c988bb886" shape="rect">
   cudaArraySparseProperties::miptailSize
  </a>
  specifies mip tail size per layer. The returned value of
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_1b6909e5db55b866477b6cc16fb02f9d3" shape="rect">
   cudaArraySparseProperties::miptailFirstLevel
  </a>
  is valid only if
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaArraySparseProperties.html#structcudaArraySparseProperties_122cfa4ad83195f0e9585303c988bb886" shape="rect">
   cudaArraySparseProperties::miptailSize
  </a>
  is non-zero.
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g0bfd1422d4647443bab85ebcf2157185" shape="rect" title="Returns the layout properties of a sparse CUDA array.">
   cudaArrayGetSparseProperties
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA_1g5dc41a62a9feb68f2e943b438c83e5ab" shape="rect" target="_blank">
   cuMemMapArrayAsync
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" name="group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect" title="">
   cudaExtent
  </a>
  make_cudaExtent (  size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   w
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   h
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   d
  </span>
  )
 </span>
 Returns a cudaExtent based on input parameters.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  w
 </span>
 - Width in elements when referring to array memory, in bytes when referring to linear memory
 <span class="keyword keyword apiItemName">
  h
 </span>
 - Height in elements
 <span class="keyword keyword apiItemName">
  d
 </span>
 - Depth in elements
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">
   cudaExtent
  </a>
  specified by
  w
  ,
  h
  , and
  d
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaExtent.html#structcudaExtent" shape="rect">
   cudaExtent
  </a>
  based on the specified input parameters
  w
  ,
  h
  , and
  d
  .
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect" title="Returns a cudaPitchedPtr based on input parameters.">
   make_cudaPitchedPtr
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect" title="Returns a cudaPos based on input parameters.">
   make_cudaPos
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" name="group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect" title="">
   cudaPitchedPtr
  </a>
  make_cudaPitchedPtr (  void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   d
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   p
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   xsz
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   ysz
  </span>
  )
 </span>
 Returns a cudaPitchedPtr based on input parameters.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  d
 </span>
 - Pointer to allocated memory
 <span class="keyword keyword apiItemName">
  p
 </span>
 - Pitch of allocated memory in bytes
 <span class="keyword keyword apiItemName">
  xsz
 </span>
 - Logical width of allocation in elements
 <span class="keyword keyword apiItemName">
  ysz
 </span>
 - Logical height of allocation in elements
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  specified by
  d
  ,
  p
  ,
  xsz
  , and
  ysz
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPitchedPtr.html#structcudaPitchedPtr" shape="rect">
   cudaPitchedPtr
  </a>
  based on the specified input parameters
  d
  ,
  p
  ,
  xsz
  , and
  ysz
  .
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect" title="Returns a cudaPos based on input parameters.">
   make_cudaPos
  </a>
 </p>
 <a id="group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" name="group__CUDART__MEMORY_1gfdde5695fcf95a6ec8899c3943f7dd8c" shape="rect">
  <!-- -->
 </a>
 <span>
  <span class="keyword keyword apiItemName">
   __host__
  </span>
  â
  <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect" title="">
   cudaPos
  </a>
  make_cudaPos (  size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   x
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   y
  </span>
  , size_t
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   z
  </span>
  )
 </span>
 Returns a cudaPos based on input parameters.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  x
 </span>
 - X position
 <span class="keyword keyword apiItemName">
  y
 </span>
 - Y position
 <span class="keyword keyword apiItemName">
  z
 </span>
 - Z position
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">
   cudaPos
  </a>
  specified by
  x
  ,
  y
  , and
  z
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns a
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaPos.html#structcudaPos" shape="rect">
   cudaPos
  </a>
  based on the specified input parameters
  x
  ,
  y
  , and
  z
  .
 </p>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g66d2e640656aa155d4ed6650fc7a2a5e" shape="rect" title="Returns a cudaExtent based on input parameters.">
   make_cudaExtent
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc3f66f8f11f9949768ae8d10cad5a1a0" shape="rect" title="Returns a cudaPitchedPtr based on input parameters.">
   make_cudaPitchedPtr
  </a>
 </p>
 <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
  Privacy Policy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
  Manage My Privacy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
  Do Not Sell or Share My Data
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
  Terms of Service
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
  Accessibility
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
  Corporate Policies
 </a>
 |
 <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
  Product Security
 </a>
 |
 <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
  Contact
 </a>
 Copyright Â© 2007-2024 NVIDIA Corporation
</body>
</body></html>