<html>

<head>
    <title>cuBLAS</title>
</head>

<body>

    <body class="wy-body-for-nav">
        <a href="https://docs.nvidia.com/cuda/cublas/contents.html">
        </a>
        <ul class="current">
            <li class="toctree-l1 current">
                <a class="current reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html">
                    1. Introduction
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#data-layout">
                            1.1. Data Layout
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#new-and-legacy-cublas-api">
                            1.2. New and Legacy cuBLAS API
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#example-code">
                            1.3. Example Code
                        </a>
                    </li>
                </ul>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublas-api">
                    2. Using the cuBLAS API
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#general-description">
                            2.1. General Description
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#error-status">
                                    2.1.1. Error Status
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-context">
                                    2.1.2. cuBLAS Context
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#thread-safety">
                                    2.1.3. Thread Safety
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility">
                                    2.1.4. Results Reproducibility
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#scalar-parameters">
                                    2.1.5. Scalar Parameters
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#parallelism-with-streams">
                                    2.1.6. Parallelism with Streams
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#batching-kernels">
                                    2.1.7. Batching Kernels
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cache-configuration">
                                    2.1.8. Cache Configuration
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#static-library-support">
                                    2.1.9. Static Library Support
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#gemm-algorithms-numerical-behavior">
                                    2.1.10. GEMM Algorithms Numerical Behavior
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#tensor-core-usage">
                                    2.1.11. Tensor Core Usage
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cuda-graphs-support">
                                    2.1.12. CUDA Graphs Support
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                                    2.1.13. 64-bit Integer Interface
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-datatypes-reference">
                            2.2. cuBLAS Datatypes Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t">
                                    2.2.1. cublasHandle_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                                    2.2.2. cublasStatus_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                                    2.2.3. cublasOperation_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasfillmode-t">
                                    2.2.4. cublasFillMode_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdiagtype-t">
                                    2.2.5. cublasDiagType_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassidemode-t">
                                    2.2.6. cublasSideMode_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublaspointermode-t">
                                    2.2.7. cublasPointerMode_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasatomicsmode-t">
                                    2.2.8. cublasAtomicsMode_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmalgo-t">
                                    2.2.9. cublasGemmAlgo_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasmath-t">
                                    2.2.10. cublasMath_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                                    2.2.11. cublasComputeType_t
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cuda-datatypes-reference">
                            2.3. CUDA Datatypes Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t">
                                    2.3.1. cudaDataType_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#librarypropertytype-t">
                                    2.3.2. libraryPropertyType_t
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-helper-function-reference">
                            2.4. cuBLAS Helper Function Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                                    2.4.1. cublasCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                                    2.4.2. cublasDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetversion">
                                    2.4.3. cublasGetVersion()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetproperty">
                                    2.4.4. cublasGetProperty()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetstatusname">
                                    2.4.5. cublasGetStatusName()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetstatusstring">
                                    2.4.6. cublasGetStatusString()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                                    2.4.7. cublasSetStream()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                                    2.4.8. cublasSetWorkspace()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetstream">
                                    2.4.9. cublasGetStream()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetpointermode">
                                    2.4.10. cublasGetPointerMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetpointermode">
                                    2.4.11. cublasSetPointerMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetvector">
                                    2.4.12. cublasSetVector()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetvector">
                                    2.4.13. cublasGetVector()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmatrix">
                                    2.4.14. cublasSetMatrix()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmatrix">
                                    2.4.15. cublasGetMatrix()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetvectorasync">
                                    2.4.16. cublasSetVectorAsync()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetvectorasync">
                                    2.4.17. cublasGetVectorAsync()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmatrixasync">
                                    2.4.18. cublasSetMatrixAsync()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmatrixasync">
                                    2.4.19. cublasGetMatrixAsync()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetatomicsmode">
                                    2.4.20. cublasSetAtomicsMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetatomicsmode">
                                    2.4.21. cublasGetAtomicsMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode">
                                    2.4.22. cublasSetMathMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmathmode">
                                    2.4.23. cublasGetMathMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetsmcounttarget">
                                    2.4.24. cublasSetSmCountTarget()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetsmcounttarget">
                                    2.4.25. cublasGetSmCountTarget()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasloggerconfigure">
                                    2.4.26. cublasLoggerConfigure()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetloggercallback">
                                    2.4.27. cublasGetLoggerCallback()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetloggercallback">
                                    2.4.28. cublasSetLoggerCallback()
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-1-function-reference">
                            2.5. cuBLAS Level-1 Function Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasi-t-amax">
                                    2.5.1. cublasI&lt;t&gt;amax()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasi-t-amin">
                                    2.5.2. cublasI&lt;t&gt;amin()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-asum">
                                    2.5.3. cublas&lt;t&gt;asum()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-axpy">
                                    2.5.4. cublas&lt;t&gt;axpy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-copy">
                                    2.5.5. cublas&lt;t&gt;copy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dot">
                                    2.5.6. cublas&lt;t&gt;dot()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-nrm2">
                                    2.5.7. cublas&lt;t&gt;nrm2()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rot">
                                    2.5.8. cublas&lt;t&gt;rot()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rotg">
                                    2.5.9. cublas&lt;t&gt;rotg()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rotm">
                                    2.5.10. cublas&lt;t&gt;rotm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rotmg">
                                    2.5.11. cublas&lt;t&gt;rotmg()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-scal">
                                    2.5.12. cublas&lt;t&gt;scal()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-swap">
                                    2.5.13. cublas&lt;t&gt;swap()
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference">
                            2.6. cuBLAS Level-2 Function Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gbmv">
                                    2.6.1. cublas&lt;t&gt;gbmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemv">
                                    2.6.2. cublas&lt;t&gt;gemv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-ger">
                                    2.6.3. cublas&lt;t&gt;ger()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-sbmv">
                                    2.6.4. cublas&lt;t&gt;sbmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-spmv">
                                    2.6.5. cublas&lt;t&gt;spmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-spr">
                                    2.6.6. cublas&lt;t&gt;spr()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-spr2">
                                    2.6.7. cublas&lt;t&gt;spr2()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id2">
                                    2.6.8. cublas&lt;t&gt;symv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syr">
                                    2.6.9. cublas&lt;t&gt;syr()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syr2">
                                    2.6.10. cublas&lt;t&gt;syr2()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tbmv">
                                    2.6.11. cublas&lt;t&gt;tbmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tbsv">
                                    2.6.12. cublas&lt;t&gt;tbsv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tpmv">
                                    2.6.13. cublas&lt;t&gt;tpmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tpsv">
                                    2.6.14. cublas&lt;t&gt;tpsv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trmv">
                                    2.6.15. cublas&lt;t&gt;trmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsv">
                                    2.6.16. cublas&lt;t&gt;trsv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id3">
                                    2.6.17. cublas&lt;t&gt;hemv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hbmv">
                                    2.6.18. cublas&lt;t&gt;hbmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hpmv">
                                    2.6.19. cublas&lt;t&gt;hpmv()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-her">
                                    2.6.20. cublas&lt;t&gt;her()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-her2">
                                    2.6.21. cublas&lt;t&gt;her2()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hpr">
                                    2.6.22. cublas&lt;t&gt;hpr()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hpr2">
                                    2.6.23. cublas&lt;t&gt;hpr2()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemvbatched">
                                    2.6.24. cublas&lt;t&gt;gemvBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemvstridedbatched">
                                    2.6.25. cublas&lt;t&gt;gemvStridedBatched()
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-3-function-reference">
                            2.7. cuBLAS Level-3 Function Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                                    2.7.1. cublas&lt;t&gt;gemm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm3m">
                                    2.7.2. cublas&lt;t&gt;gemm3m()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched">
                                    2.7.3. cublas&lt;t&gt;gemmBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmstridedbatched">
                                    2.7.4. cublas&lt;t&gt;gemmStridedBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmgroupedbatched">
                                    2.7.5. cublas&lt;t&gt;gemmGroupedBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-symm">
                                    2.7.6. cublas&lt;t&gt;symm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syrk">
                                    2.7.7. cublas&lt;t&gt;syrk()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syr2k">
                                    2.7.8. cublas&lt;t&gt;syr2k()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syrkx">
                                    2.7.9. cublas&lt;t&gt;syrkx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trmm">
                                    2.7.10. cublas&lt;t&gt;trmm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsm">
                                    2.7.11. cublas&lt;t&gt;trsm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsmbatched">
                                    2.7.12. cublas&lt;t&gt;trsmBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hemm">
                                    2.7.13. cublas&lt;t&gt;hemm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-herk">
                                    2.7.14. cublas&lt;t&gt;herk()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-her2k">
                                    2.7.15. cublas&lt;t&gt;her2k()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-herkx">
                                    2.7.16. cublas&lt;t&gt;herkx()
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#blas-like-extension">
                            2.8. BLAS-like Extension
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-geam">
                                    2.8.1. cublas&lt;t&gt;geam()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#id10">
                                    2.8.2. cublas&lt;t&gt;dgmm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrfbatched">
                                    2.8.3. cublas&lt;t&gt;getrfBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrsbatched">
                                    2.8.4. cublas&lt;t&gt;getrsBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getribatched">
                                    2.8.5. cublas&lt;t&gt;getriBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-matinvbatched">
                                    2.8.6. cublas&lt;t&gt;matinvBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-geqrfbatched">
                                    2.8.7. cublas&lt;t&gt;geqrfBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gelsbatched">
                                    2.8.8. cublas&lt;t&gt;gelsBatched()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tpttr">
                                    2.8.9. cublas&lt;t&gt;tpttr()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trttp">
                                    2.8.10. cublas&lt;t&gt;trttp()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                                    2.8.11. cublas&lt;t&gt;gemmEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                                    2.8.12. cublasGemmEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                                    2.8.13. cublasGemmBatchedEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmstridedbatchedex">
                                    2.8.14. cublasGemmStridedBatchedEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmgroupedbatchedex">
                                    2.8.15. cublasGemmGroupedBatchedEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublascsyrkex">
                                    2.8.16. cublasCsyrkEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublascsyrk3mex">
                                    2.8.17. cublasCsyrk3mEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublascherkex">
                                    2.8.18. cublasCherkEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublascherk3mex">
                                    2.8.19. cublasCherk3mEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasnrm2ex">
                                    2.8.20. cublasNrm2Ex()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasaxpyex">
                                    2.8.21. cublasAxpyEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdotex">
                                    2.8.22. cublasDotEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasrotex">
                                    2.8.23. cublasRotEx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasscalex">
                                    2.8.24. cublasScalEx()
                                </a>
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublaslt-api">
                    3. Using the cuBLASLt API
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id41">
                            3.1. General Description
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#problem-size-limitations">
                                    3.1.1. Problem Size Limitations
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#heuristics-cache">
                                    3.1.2. Heuristics Cache
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-logging">
                                    3.1.3. cuBLASLt Logging
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#bit-floating-point-data-types-fp8-usage">
                                    3.1.4. 8-bit Floating Point Data Types (FP8) Usage
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#disabling-cpu-instructions">
                                    3.1.5. Disabling CPU Instructions
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization">
                                    3.1.6. Atomics Synchronization
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-code-examples">
                            3.2. cuBLASLt Code Examples
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-datatypes-reference">
                            3.3. cuBLASLt Datatypes Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltclustershape-t">
                                    3.3.1. cublasLtClusterShape_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltepilogue-t">
                                    3.3.2. cublasLtEpilogue_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                                    3.3.3. cublasLtHandle_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggercallback-t">
                                    3.3.4. cublasLtLoggerCallback_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                                    3.3.5. cublasLtMatmulAlgo_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t">
                                    3.3.6. cublasLtMatmulAlgoCapAttributes_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                                    3.3.7. cublasLtMatmulAlgoConfigAttributes_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                                    3.3.8. cublasLtMatmulDesc_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                                    3.3.9. cublasLtMatmulDescAttributes_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulheuristicresult-t">
                                    3.3.10. cublasLtMatmulHeuristicResult_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulinnershape-t">
                                    3.3.11. cublasLtMatmulInnerShape_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t">
                                    3.3.12. cublasLtMatmulPreference_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceattributes-t">
                                    3.3.13. cublasLtMatmulPreferenceAttributes_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulsearch-t">
                                    3.3.14. cublasLtMatmulSearch_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmultile-t">
                                    3.3.15. cublasLtMatmulTile_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulstages-t">
                                    3.3.16. cublasLtMatmulStages_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltnumericalimplflags-t">
                                    3.3.17. cublasLtNumericalImplFlags_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                                    3.3.18. cublasLtMatrixLayout_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutattribute-t">
                                    3.3.19. cublasLtMatrixLayoutAttribute_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                                    3.3.20. cublasLtMatrixTransformDesc_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescattributes-t">
                                    3.3.21. cublasLtMatrixTransformDescAttributes_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                                    3.3.22. cublasLtOrder_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                                    3.3.23. cublasLtPointerMode_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermodemask-t">
                                    3.3.24. cublasLtPointerModeMask_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltreductionscheme-t">
                                    3.3.25. cublasLtReductionScheme_t
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-api-reference">
                            3.4. cuBLASLt API Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltcreate">
                                    3.4.1. cublasLtCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdestroy">
                                    3.4.2. cublasLtDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdisablecpuinstructionssetmask">
                                    3.4.3. cublasLtDisableCpuInstructionsSetMask()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetcudartversion">
                                    3.4.4. cublasLtGetCudartVersion()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetproperty">
                                    3.4.5. cublasLtGetProperty()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetstatusname">
                                    3.4.6. cublasLtGetStatusName()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetstatusstring">
                                    3.4.7. cublasLtGetStatusString()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachegetcapacity">
                                    3.4.8. cublasLtHeuristicsCacheGetCapacity()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachesetcapacity">
                                    3.4.9. cublasLtHeuristicsCacheSetCapacity()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetversion">
                                    3.4.10. cublasLtGetVersion()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetcallback">
                                    3.4.11. cublasLtLoggerSetCallback()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetfile">
                                    3.4.12. cublasLtLoggerSetFile()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggeropenfile">
                                    3.4.13. cublasLtLoggerOpenFile()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetlevel">
                                    3.4.14. cublasLtLoggerSetLevel()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetmask">
                                    3.4.15. cublasLtLoggerSetMask()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggerforcedisable">
                                    3.4.16. cublasLtLoggerForceDisable()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                                    3.4.17. cublasLtMatmul()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapgetattribute">
                                    3.4.18. cublasLtMatmulAlgoCapGetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocheck">
                                    3.4.19. cublasLtMatmulAlgoCheck()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfiggetattribute">
                                    3.4.20. cublasLtMatmulAlgoConfigGetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigsetattribute">
                                    3.4.21. cublasLtMatmulAlgoConfigSetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic">
                                    3.4.22. cublasLtMatmulAlgoGetHeuristic()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetids">
                                    3.4.23. cublasLtMatmulAlgoGetIds()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoinit">
                                    3.4.24. cublasLtMatmulAlgoInit()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesccreate">
                                    3.4.25. cublasLtMatmulDescCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescinit">
                                    3.4.26. cublasLtMatmulDescInit()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescdestroy">
                                    3.4.27. cublasLtMatmulDescDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescgetattribute">
                                    3.4.28. cublasLtMatmulDescGetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescsetattribute">
                                    3.4.29. cublasLtMatmulDescSetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencecreate">
                                    3.4.30. cublasLtMatmulPreferenceCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceinit">
                                    3.4.31. cublasLtMatmulPreferenceInit()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencedestroy">
                                    3.4.32. cublasLtMatmulPreferenceDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencegetattribute">
                                    3.4.33. cublasLtMatmulPreferenceGetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencesetattribute">
                                    3.4.34. cublasLtMatmulPreferenceSetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutcreate">
                                    3.4.35. cublasLtMatrixLayoutCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutinit">
                                    3.4.36. cublasLtMatrixLayoutInit()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutdestroy">
                                    3.4.37. cublasLtMatrixLayoutDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutgetattribute">
                                    3.4.38. cublasLtMatrixLayoutGetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutsetattribute">
                                    3.4.39. cublasLtMatrixLayoutSetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransform">
                                    3.4.40. cublasLtMatrixTransform()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesccreate">
                                    3.4.41. cublasLtMatrixTransformDescCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescinit">
                                    3.4.42. cublasLtMatrixTransformDescInit()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescdestroy">
                                    3.4.43. cublasLtMatrixTransformDescDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescgetattribute">
                                    3.4.44. cublasLtMatrixTransformDescGetAttribute()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescsetattribute">
                                    3.4.45. cublasLtMatrixTransformDescSetAttribute()
                                </a>
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublasxt-api">
                    4. Using the cuBLASXt API
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id93">
                            4.1. General description
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#tiling-design-approach">
                                    4.1.1. Tiling design approach
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#hybrid-cpu-gpu-computation">
                                    4.1.2. Hybrid CPU-GPU computation
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#id95">
                                    4.1.3. Results reproducibility
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-api-datatypes-reference">
                            4.2. cuBLASXt API Datatypes Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxthandle-t">
                                    4.2.1. cublasXtHandle_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtoptype-t">
                                    4.2.2. cublasXtOpType_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtblasop-t">
                                    4.2.3. cublasXtBlasOp_t
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtpinningmemmode-t">
                                    4.2.4. cublasXtPinningMemMode_t
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-api-helper-function-reference">
                            4.3. cuBLASXt API Helper Function Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtcreate">
                                    4.3.1. cublasXtCreate()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtdestroy">
                                    4.3.2. cublasXtDestroy()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtdeviceselect">
                                    4.3.3. cublasXtDeviceSelect()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetblockdim">
                                    4.3.4. cublasXtSetBlockDim()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtgetblockdim">
                                    4.3.5. cublasXtGetBlockDim()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuroutine">
                                    4.3.6. cublasXtSetCpuRoutine()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuratio">
                                    4.3.7. cublasXtSetCpuRatio()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetpinningmemmode">
                                    4.3.8. cublasXtSetPinningMemMode()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtgetpinningmemmode">
                                    4.3.9. cublasXtGetPinningMemMode()
                                </a>
                            </li>
                        </ul>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-api-math-functions-reference">
                            4.4. cuBLASXt API Math Functions Reference
                        </a>
                        <ul>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#id96">
                                    4.4.1. cublasXt&lt;t&gt;gemm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-hemm">
                                    4.4.2. cublasXt&lt;t&gt;hemm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-symm">
                                    4.4.3. cublasXt&lt;t&gt;symm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-syrk">
                                    4.4.4. cublasXt&lt;t&gt;syrk()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-syr2k">
                                    4.4.5. cublasXt&lt;t&gt;syr2k()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-syrkx">
                                    4.4.6. cublasXt&lt;t&gt;syrkx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-herk">
                                    4.4.7. cublasXt&lt;t&gt;herk()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-her2k">
                                    4.4.8. cublasXt&lt;t&gt;her2k()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-herkx">
                                    4.4.9. cublasXt&lt;t&gt;herkx()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-trsm">
                                    4.4.10. cublasXt&lt;t&gt;trsm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-trmm">
                                    4.4.11. cublasXt&lt;t&gt;trmm()
                                </a>
                            </li>
                            <li class="toctree-l3">
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-spmm">
                                    4.4.12. cublasXt&lt;t&gt;spmm()
                                </a>
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublasdx-api">
                    5. Using the cuBLASDx API
                </a>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublas-legacy-api">
                    6. Using the cuBLAS Legacy API
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id99">
                            6.1. Error Status
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#initialization-and-shutdown">
                            6.2. Initialization and Shutdown
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id100">
                            6.3. Thread Safety
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#memory-management">
                            6.4. Memory Management
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id101">
                            6.5. Scalar Parameters
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#helper-functions">
                            6.6. Helper Functions
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#level-1-2-3-functions">
                            6.7. Level-1,2,3 Functions
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#converting-legacy-to-the-cublas-api">
                            6.8. Converting Legacy to the cuBLAS API
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#examples">
                            6.9. Examples
                        </a>
                    </li>
                </ul>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-fortran-bindings">
                    7. cuBLAS Fortran Bindings
                </a>
            </li>
            <li class="toctree-l1">
                <a class="reference internal"
                    href="https://docs.nvidia.com/cuda/cublas/index.html#interaction-with-other-libraries-and-tools">
                    8. Interaction with Other Libraries and Tools
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#nvprune">
                            8.1. nvprune
                        </a>
                    </li>
                </ul>
            </li>
            <li class="toctree-l1">
                <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#acknowledgements">
                    9. Acknowledgements
                </a>
            </li>
            <li class="toctree-l1">
                <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#notices">
                    10. Notices
                </a>
                <ul>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#notice">
                            10.1. Notice
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#opencl">
                            10.2. OpenCL
                        </a>
                    </li>
                    <li class="toctree-l2">
                        <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#trademarks">
                            10.3. Trademarks
                        </a>
                    </li>
                </ul>
            </li>
        </ul>
        <a href="https://docs.nvidia.com/cuda/cublas/contents.html">
            cuBLAS
        </a>
        <ul class="wy-breadcrumbs">
            <li>
                <a class="icon icon-home" href="https://docs.nvidia.com/cuda/index.html">
                </a>
                
            </li>
            <li>
                <span class="section-number">
                    1.
                </span>
                Introduction
            </li>
            <li class="wy-breadcrumbs-aside">
                <span>
                    v12.5 |
                </span>
                <a class="reference external" href="https://docs.nvidia.com/cuda/pdf/CUBLAS_Library.pdf">
                    PDF
                </a>
                <span>
                    |
                </span>
                <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit-archive">
                    Archive
                </a>
                <span>
                    
                </span>
            </li>
        </ul>
        <p class="rubric-h1 rubric">
            cuBLAS
        </p>
        <p>
            The API Reference guide for cuBLAS, the CUDA Basic Linear Algebra Subroutine library.
        </p>
        <h1>
            <span class="section-number">
                1.
            </span>
            Introduction
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#introduction"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <p>
            The cuBLAS library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the
            NVIDIACUDA runtime. It allows the user to access the computational resources of NVIDIA Graphics
            Processing Unit (GPU).
        </p>
        <p>
            The cuBLAS Library exposes four sets of APIs:
        </p>
        <ul class="simple">
            <li>
                <p>
                    The
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublas-api">
                        <span class="std std-ref">
                            cuBLAS API
                        </span>
                    </a>
                    , which is simply called cuBLAS API in this document (starting with CUDA 6.0),
                </p>
            </li>
            <li>
                <p>
                    The
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublasxt-api">
                        <span class="std std-ref">
                            cuBLASXt API
                        </span>
                    </a>
                    (starting with CUDA 6.0), and
                </p>
            </li>
            <li>
                <p>
                    The
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublaslt-api">
                        <span class="std std-ref">
                            cuBLASLt API
                        </span>
                    </a>
                    (starting with CUDA 10.1)
                </p>
            </li>
            <li>
                <p>
                    The
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublasdx-api">
                        <span class="std std-ref">
                            cuBLASDx API
                        </span>
                    </a>
                    (not shipped with the CUDA Toolkit)
                </p>
            </li>
        </ul>
        <p>
            To use the cuBLAS API, the application must allocate the required matrices and vectors in the GPU memory
            space, fill them with data, call the sequence of desired cuBLAS functions, and then upload the results from
            the GPU memory space back to the host. The cuBLAS API also provides helper functions for writing and
            retrieving data from the GPU.
        </p>
        <p>
            To use the cuBLASXt API, the application may have the data on the Host or any of the devices involved in the
            computation, and the Library will take care of dispatching the operation to, and transferring the data to,
            one or multiple GPUs present in the system, depending on the user request.
        </p>
        <p>
            The cuBLASLt is a lightweight library dedicated to GEneral Matrix-to-matrix Multiply (GEMM) operations with
            a new flexible API. This library adds flexibility in matrix data layouts, input types, compute types, and
            also in choosing the algorithmic implementations and heuristics through parameter programmability. After a
            set of options for the intended GEMM operation are identified by the user, these options can be used
            repeatedly for different inputs. This is analogous to how cuFFT and FFTW first create a plan and reuse for
            same size and type FFTs with different input data.
        </p>
        <h2>
            <span class="section-number">
                1.1.
            </span>
            Data Layout
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#data-layout"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            For maximum compatibility with existing Fortran environments, the cuBLAS library uses column-major storage,
            and 1-based indexing. Since C and C++ use row-major storage, applications written in these languages can not
            use the native array semantics for two-dimensional arrays. Instead, macros or inline functions should be
            defined to implement matrices on top of one-dimensional arrays. For Fortran code ported to C in mechanical
            fashion, one may chose to retain 1-based indexing to avoid the need to transform loops. In this case, the
            array index of a matrix element in row i and column j can be computed via the following macro
        </p>
        <pre><span class="cp">#define IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))</span>
</pre>
        <p>
            Here, ld refers to the leading dimension of the matrix, which in the case of column-major storage is the
            number of rows of the allocated matrix (even if only a submatrix of it is being used). For natively written
            C and C++ code, one would most likely choose 0-based indexing, in which case the array index of a matrix
            element in row i and column j can be computed via the following macro
        </p>
        <pre><span class="cp">#define IDX2C(i,j,ld) (((j)*(ld))+(i))</span>
</pre>
        <h2>
            <span class="section-number">
                1.2.
            </span>
            New and Legacy cuBLAS API
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#new-and-legacy-cublas-api"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            Starting with version 4.0, the cuBLAS Library provides a new API, in addition to the existing legacy API.
            This section discusses why a new API is provided, the advantages of using it, and the differences with the
            existing legacy API.
        </p>
        <p class="admonition-title">
            Warning
        </p>
        <p>
            The legacy cuBLAS API is deprecated and will be removed in future release.
        </p>
        <p>
            The new cuBLAS library API can be used by including the header file
            <span class="pre">
                cublas_v2.h
            </span>
            . It has the following features that the legacy cuBLAS API does not have:
        </p>
        <ul class="simple">
            <li>
                <p>
                    The
                    <span class="pre">
                        handle
                    </span>
                    to the cuBLAS library context is initialized using the function and is explicitly passed to every
                    subsequent library function call. This allows the user to have more control over the library setup
                    when using multiple host threads and multiple GPUs. This also allows the cuBLAS APIs to be
                    reentrant.
                </p>
            </li>
            <li>
                <p>
                    The scalars
                    <span class="math notranslate nohighlight">
                        \(\alpha\)
                    </span>
                    and
                    <span class="math notranslate nohighlight">
                        \(\beta\)
                    </span>
                    can be passed by reference on the host or the device, instead of only being allowed to be passed by
                    value on the host. This change allows library functions to execute asynchronously using streams even
                    when
                    <span class="math notranslate nohighlight">
                        \(\alpha\)
                    </span>
                    and
                    <span class="math notranslate nohighlight">
                        \(\beta\)
                    </span>
                    are generated by a previous kernel.
                </p>
            </li>
            <li>
                <p>
                    When a library routine returns a scalar result, it can be returned by reference on the host or the
                    device, instead of only being allowed to be returned by value only on the host. This change allows
                    library routines to be called asynchronously when the scalar result is generated and returned by
                    reference on the device resulting in maximum parallelism.
                </p>
            </li>
            <li>
                <p>
                    The error status
                    <span class="pre">
                        cublasStatus_t
                    </span>
                    is returned by all cuBLAS library function calls. This change facilitates debugging and simplifies
                    software development. Note that
                    <span class="pre">
                        cublasStatus
                    </span>
                    was renamed
                    <span class="pre">
                        cublasStatus_t
                    </span>
                    to be more consistent with other types in the cuBLAS library.
                </p>
            </li>
            <li>
                <p>
                    The
                    <span class="pre">
                        cublasAlloc()
                    </span>
                    and
                    <span class="pre">
                        cublasFree()
                    </span>
                    functions have been deprecated. This change removes these unnecessary wrappers around
                    <span class="pre">
                        cudaMalloc()
                    </span>
                    and
                    <span class="pre">
                        cudaFree()
                    </span>
                    , respectively.
                </p>
            </li>
            <li>
                <p>
                    The function
                    <span class="pre">
                        cublasSetKernelStream()
                    </span>
                    was renamed
                    <span class="pre">
                        cublasSetStream()
                    </span>
                    to be more consistent with the other CUDA libraries.
                </p>
            </li>
        </ul>
        <p>
            The legacy cuBLAS API, explained in more detail in
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#id98">
                Using the cuBLAS Legacy API
            </a>
            , can be used by including the header file
            <span class="pre">
                cublas.h
            </span>
            . Since the legacy API is identical to the previously released cuBLAS library API, existing applications
            will work out of the box and automatically use this legacy API without any source code changes.
        </p>
        <p>
            The current and the legacy cuBLAS APIs cannot be used simultaneously in a single translation unit: including
            both
            <span class="pre">
                cublas.h
            </span>
            and
            <span class="pre">
                cublas_v2.h
            </span>
            header files will lead to compilation errors due to incompatible symbol redeclarations.
        </p>
        <p>
            In general, new applications should not use the legacy cuBLAS API, and existing applications should convert
            to using the new API if it requires sophisticated and optimal stream parallelism, or if it calls cuBLAS
            routines concurrently from multiple threads.
        </p>
        <p>
            For the rest of the document, the new cuBLAS Library API will simply be referred to as the cuBLAS Library
            API.
        </p>
        <p>
            As mentioned earlier the interfaces to the legacy and the cuBLAS library APIs are the header file
            <span class="pre">
                cublas.h
            </span>
            and
            <span class="pre">
                cublas_v2.h
            </span>
            , respectively. In addition, applications using the cuBLAS library need to link against:
        </p>
        <ul class="simple">
            <li>
                <p>
                    The DSO
                    <span class="pre">
                        cublas.so
                    </span>
                    for Linux,
                </p>
            </li>
            <li>
                <p>
                    The DLL
                    <span class="pre">
                        cublas.dll
                    </span>
                    for Windows, or
                </p>
            </li>
            <li>
                <p>
                    The dynamic library
                    <span class="pre">
                        cublas.dylib
                    </span>
                    for Mac OS X.
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The same dynamic library implements both the new and legacy cuBLAS APIs.
        </p>
        <h2>
            <span class="section-number">
                1.3.
            </span>
            Example Code
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#example-code"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            For sample code references please see the two examples below. They show an application written in C using
            the cuBLAS library API with two indexing styles (Example 1. Application Using C and cuBLAS: 1-based
            indexing and Example 2. Application Using C and cuBLAS: 0-based Indexing).
        </p>
        <pre><span class="c1">//Example 1. Application Using C and cuBLAS: 1-based indexing</span>
<span class="c1">//-----------------------------------------------------------</span>
<span class="cp">#include</span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="cpf">"cublas_v2.h"</span>
<span class="cp">#define M 6</span>
<span class="cp">#define N 5</span>
<span class="cp">#define IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))</span>

<span class="k">static</span><span class="n">__inline__</span><span class="kt">void</span><span class="n">modify</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">ldm</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">p</span><span class="p">,</span><span class="kt">int</span><span class="n">q</span><span class="p">,</span><span class="kt">float</span><span class="n">alpha</span><span class="p">,</span><span class="kt">float</span><span class="n">beta</span><span class="p">){</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="n">q</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="o">&amp;</span><span class="n">alpha</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="n">ldm</span><span class="p">);</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">ldm</span><span class="o">-</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="o">&amp;</span><span class="n">beta</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="n">cudaError_t</span><span class="n">cudaStat</span><span class="p">;</span>
<span class="n">cublasStatus_t</span><span class="n">stat</span><span class="p">;</span>
<span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">;</span>
<span class="kt">int</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">devPtrA</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="n">a</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">));</span>
<span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">a</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"host memory allocation failed"</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;=</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">a</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="p">)((</span><span class="n">i</span><span class="mi">-1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="o">+</span><span class="n">j</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
<span class="n">cudaStat</span><span class="o">=</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">));</span>
<span class="k">if</span><span class="p">(</span><span class="n">cudaStat</span><span class="o">!=</span><span class="n">cudaSuccess</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"device memory allocation failed"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"CUBLAS initialization failed</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasSetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data download failed"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">modify</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mf">16.0f</span><span class="p">,</span><span class="mf">12.0f</span><span class="p">);</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasGetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data upload failed"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;=</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"%7.0f"</span><span class="p">,</span><span class="n">a</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]);</span>
<span class="p">}</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre>
        <pre><span class="c1">//Example 2. Application Using C and cuBLAS: 0-based indexing</span>
<span class="c1">//-----------------------------------------------------------</span>
<span class="cp">#include</span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="cp">#include</span><span class="cpf">"cublas_v2.h"</span>
<span class="cp">#define M 6</span>
<span class="cp">#define N 5</span>
<span class="cp">#define IDX2C(i,j,ld) (((j)*(ld))+(i))</span>

<span class="k">static</span><span class="n">__inline__</span><span class="kt">void</span><span class="n">modify</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">ldm</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">p</span><span class="p">,</span><span class="kt">int</span><span class="n">q</span><span class="p">,</span><span class="kt">float</span><span class="n">alpha</span><span class="p">,</span><span class="kt">float</span><span class="n">beta</span><span class="p">){</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="n">q</span><span class="p">,</span><span class="o">&amp;</span><span class="n">alpha</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="n">ldm</span><span class="p">);</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">ldm</span><span class="o">-</span><span class="n">p</span><span class="p">,</span><span class="o">&amp;</span><span class="n">beta</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="n">cudaError_t</span><span class="n">cudaStat</span><span class="p">;</span>
<span class="n">cublasStatus_t</span><span class="n">stat</span><span class="p">;</span>
<span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">;</span>
<span class="kt">int</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">devPtrA</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="n">a</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">));</span>
<span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">a</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"host memory allocation failed"</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">a</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="p">)(</span><span class="n">i</span><span class="o">*</span><span class="n">N</span><span class="o">+</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
<span class="n">cudaStat</span><span class="o">=</span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">));</span>
<span class="k">if</span><span class="p">(</span><span class="n">cudaStat</span><span class="o">!=</span><span class="n">cudaSuccess</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"device memory allocation failed"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"CUBLAS initialization failed</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasSetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data download failed"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">modify</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">16.0f</span><span class="p">,</span><span class="mf">12.0f</span><span class="p">);</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasGetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data upload failed"</span><span class="p">);</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"%7.0f"</span><span class="p">,</span><span class="n">a</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]);</span>
<span class="p">}</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre>
        <h1>
            <span class="section-number">
                2.
            </span>
            Using the cuBLAS API
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublas-api"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <h2>
            <span class="section-number">
                2.1.
            </span>
            General Description
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#general-description"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            This section describes how to use the cuBLAS library API.
        </p>
        <h3>
            <span class="section-number">
                2.1.1.
            </span>
            Error Status
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#error-status"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            All cuBLAS library function calls return the error status
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                2.1.2.
            </span>
            cuBLAS Context
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-context"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The application must initialize a handle to the cuBLAS library context by calling the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            function. Then, the handle is explicitly passed to every subsequent library function call. Once the
            application finishes using the library, it must call the function
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                cublasDestroy()
            </a>
            to release the resources associated with the cuBLAS library context.
        </p>
        <p>
            This approach allows the user to explicitly control the library setup when using multiple host threads and
            multiple GPUs. For example, the application can use
            <span class="pre">
                cudaSetDevice()
            </span>
            to associate different devices with different host threads and in each of those host threads it can
            initialize a unique handle to the cuBLAS library context, which will use the particular device associated
            with that host thread. Then, the cuBLAS library function calls made with different handles will
            automatically dispatch the computation to different devices.
        </p>
        <p>
            The device associated with a particular cuBLAS context is assumed to remain unchanged between the
            corresponding
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                cublasDestroy()
            </a>
            calls. In order for the cuBLAS library to use a different device in the same host thread, the application
            must set the new device to be used by calling
            <span class="pre">
                cudaSetDevice()
            </span>
            and then create another cuBLAS context, which will be associated with the new device, by calling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            .
        </p>
        <p>
            A cuBLAS library context is tightly coupled with the CUDA context that is current at the time of the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            call. An application that uses multiple CUDA contexts is required to create a cuBLAS context per CUDA
            context and make sure the former never outlives the latter.
        </p>
        <h3>
            <span class="section-number">
                2.1.3.
            </span>
            Thread Safety
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#thread-safety"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The library is thread safe and its functions can be called from multiple host threads, even with the same
            handle. When multiple threads share the same handle, extreme care needs to be taken when the handle
            configuration is changed because that change will affect potentially subsequent cuBLAS calls in all threads.
            It is even more true for the destruction of the handle. So it is not recommended that multiple thread share
            the same cuBLAS handle.
        </p>
        <h3>
            <span class="section-number">
                2.1.4.
            </span>
            Results Reproducibility
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            By design, all cuBLAS API routines from a given toolkit version, generate the same bit-wise results at every
            run when executed on GPUs with the same architecture and the same number of SMs. However, bit-wise
            reproducibility is not guaranteed across toolkit versions because the implementation might differ due to
            some implementation changes.
        </p>
        <p>
            This guarantee holds when a single CUDA stream is active only. If multiple concurrent streams are active,
            the library may optimize total performance by picking different internal implementations.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The non-deterministic behavior of multi-stream execution is due to library optimizations in selecting
            internal workspace for the routines running in parallel streams. To avoid this effect user can either:
        </p>
        <ul class="simple">
            <li>
                <p>
                    provide a separate workspace for each used stream using the
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                        cublasSetWorkspace()
                    </a>
                    function, or
                </p>
            </li>
            <li>
                <p>
                    have one cuBLAS handle per stream, or
                </p>
            </li>
            <li>
                <p>
                    use
                    <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                        cublasLtMatmul()
                    </a>
                    instead of GEMM-family of functions and provide user owned workspace, or
                </p>
            </li>
            <li>
                <p>
                    set a debug environment variable
                    <span class="pre">
                        CUBLAS_WORKSPACE_CONFIG
                    </span>
                    to
                    <span class="pre">
                        :16:8
                    </span>
                    (may limit overall performance) or
                    <span class="pre">
                        :4096:8
                    </span>
                    (will increase library footprint in GPU memory by approximately 24MiB).
                </p>
            </li>
        </ul>
        <p>
            Any of those settings will allow for deterministic behavior even with multiple concurrent streams sharing a
            single cuBLAS handle.
        </p>
        <p>
            This behavior is expected to change in a future release.
        </p>
        <p>
            For some routines such as
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-symv">
                cublas&lt;t&gt;symv
            </a>
            and
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hemv">
                cublas&lt;t&gt;hemv
            </a>
            , an alternate significantly faster routine can be chosen using the routine
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetatomicsmode">
                cublasSetAtomicsMode()
            </a>
            . In that case, the results are not guaranteed to be bit-wise reproducible because atomics are used for the
            computation.
        </p>
        <h3>
            <span class="section-number">
                2.1.5.
            </span>
            Scalar Parameters
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#scalar-parameters"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            There are two categories of the functions that use scalar parameters :
        </p>
        <ul class="simple">
            <li>
                <p>
                    Functions that take
                    <span class="pre">
                        alpha
                    </span>
                    and/or
                    <span class="pre">
                        beta
                    </span>
                    parameters by reference on the host or the device as scaling factors, such as
                    <span class="pre">
                        gemm
                    </span>
                    .
                </p>
            </li>
            <li>
                <p>
                    Functions that return a scalar result on the host or the device such as
                    <span class="pre">
                        amax()
                    </span>
                    ,
                    <span class="pre">
                        amin
                    </span>
                    ,
                    <span class="pre">
                        asum()
                    </span>
                    ,
                    <span class="pre">
                        rotg()
                    </span>
                    ,
                    <span class="pre">
                        rotmg()
                    </span>
                    ,
                    <span class="pre">
                        dot()
                    </span>
                    and
                    <span class="pre">
                        nrm2()
                    </span>
                    .
                </p>
            </li>
        </ul>
        <p>
            For the functions of the first category, when the pointer mode is set to
            <span class="pre">
                CUBLAS_POINTER_MODE_HOST
            </span>
            , the scalar parameters
            <span class="pre">
                alpha
            </span>
            and/or
            <span class="pre">
                beta
            </span>
            can be on the stack or allocated on the heap, shouldnt be placed in managed memory. Underneath, the CUDA
            kernels related to those functions will be launched with the value of
            <span class="pre">
                alpha
            </span>
            and/or
            <span class="pre">
                beta
            </span>
            . Therefore if they were allocated on the heap, they can be freed just after the return of the call even
            though the kernel launch is asynchronous. When the pointer mode is set to
            <span class="pre">
                CUBLAS_POINTER_MODE_DEVICE
            </span>
            ,
            <span class="pre">
                alpha
            </span>
            and/or
            <span class="pre">
                beta
            </span>
            must be accessible on the device and their values should not be modified until the kernel is done. Note that
            since
            <span class="pre">
                cudaFree()
            </span>
            does an implicit
            <span class="pre">
                cudaDeviceSynchronize()
            </span>
            ,
            <span class="pre">
                cudaFree()
            </span>
            can still be called on
            <span class="pre">
                alpha
            </span>
            and/or
            <span class="pre">
                beta
            </span>
            just after the call but it would defeat the purpose of using this pointer mode in that case.
        </p>
        <p>
            For the functions of the second category, when the pointer mode is set to
            <span class="pre">
                CUBLAS_POINTER_MODE_HOST
            </span>
            , these functions block the CPU, until the GPU has completed its computation and the results have been
            copied back to the Host. When the pointer mode is set to
            <span class="pre">
                CUBLAS_POINTER_MODE_DEVICE
            </span>
            , these functions return immediately. In this case, similar to matrix and vector results, the scalar result
            is ready only when execution of the routine on the GPU has completed. This requires proper synchronization
            in order to read the result from the host.
        </p>
        <p>
            In either case, the pointer mode
            <span class="pre">
                CUBLAS_POINTER_MODE_DEVICE
            </span>
            allows the library functions to execute completely asynchronously from the Host even when
            <span class="pre">
                alpha
            </span>
            and/or
            <span class="pre">
                beta
            </span>
            are generated by a previous kernel. For example, this situation can arise when iterative methods for
            solution of linear systems and eigenvalue problems are implemented using the cuBLAS library.
        </p>
        <h3>
            <span class="section-number">
                2.1.6.
            </span>
            Parallelism with Streams
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#parallelism-with-streams"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            If the application uses the results computed by multiple independent tasks, CUDA streams can be used to
            overlap the computation performed in these tasks.
        </p>
        <p>
            The application can conceptually associate each stream with each task. In order to achieve the overlap of
            computation between the tasks, the user should create CUDA streams using the function
            <span class="pre">
                cudaStreamCreate()
            </span>
            and set the stream to be used by each individual cuBLAS library routine by calling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            just before calling the actual cuBLAS routine. Note that
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            resets the user-provided workspace to the default workspace pool; see
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                cublasSetWorkspace()
            </a>
            . Then, the computation performed in separate streams would be overlapped automatically when possible on the
            GPU. This approach is especially useful when the computation performed by a single task is relatively small
            and is not enough to fill the GPU with work.
        </p>
        <p>
            We recommend using the new cuBLAS API with scalar parameters and results passed by reference in the device
            memory to achieve maximum overlap of the computation when using streams.
        </p>
        <p>
            A particular application of streams, batching of multiple small kernels, is described in the following
            section.
        </p>
        <h3>
            <span class="section-number">
                2.1.7.
            </span>
            Batching Kernels
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#batching-kernels"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            In this section, we explain how to use streams to batch the execution of small kernels. For instance,
            suppose that we have an application where we need to make many small independent matrix-matrix
            multiplications with dense matrices.
        </p>
        <p>
            It is clear that even with millions of small independent matrices we will not be able to achieve the same
            GFLOPS
            rate as with a one large matrix. For example, a single
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            large matrix-matrix multiplication performs
            <span class="math notranslate nohighlight">
                \(n^{3}\)
            </span>
            operations for
            <span class="math notranslate nohighlight">
                \(n^{2}\)
            </span>
            input size, while 1024
            <span class="math notranslate nohighlight">
                \(\frac{n}{32} \times \frac{n}{32}\)
            </span>
            small matrix-matrix multiplications perform
            <span class="math notranslate nohighlight">
                \(1024\left( \frac{n}{32} \right)^{3} = \frac{n^{3}}{32}\)
            </span>
            operations for the same input size. However, it is also clear that we can achieve a significantly better
            performance with many small independent matrices compared with a single small matrix.
        </p>
        <p>
            The architecture family of GPUs allows us to execute multiple kernels simultaneously. Hence, in order to
            batch the execution of independent kernels, we can run each of them in a separate stream. In particular, in
            the above example we could create 1024 CUDA streams using the function
            <span class="pre">
                cudaStreamCreate()
            </span>
            , then preface each call to
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm()
            </a>
            with a call to
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            with a different stream for each of the matrix-matrix multiplications (note that
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            resets user-provided workspace to the default workspace pool, see
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                cublasSetWorkspace()
            </a>
            ). This will ensure that when possible the different computations will be executed concurrently. Although
            the user can create many streams, in practice it is not possible to have more than 32 concurrent kernels
            executing at the same time.
        </p>
        <h3>
            <span class="section-number">
                2.1.8.
            </span>
            Cache Configuration
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cache-configuration"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            On some devices, L1 cache and shared memory use the same hardware resources. The cache configuration can be
            set directly with the CUDA Runtime function cudaDeviceSetCacheConfig. The cache configuration can also be
            set specifically for some functions using the routine cudaFuncSetCacheConfig. Please refer to the CUDA
            Runtime API documentation for details about the cache configuration settings.
        </p>
        <p>
            Because switching from one configuration to another can affect kernels concurrency, the cuBLAS Library does
            not set any cache configuration preference and relies on the current setting. However, some cuBLAS routines,
            especially Level-3 routines, rely heavily on shared memory. Thus the cache preference setting might affect
            adversely their performance.
        </p>
        <h3>
            <span class="section-number">
                2.1.9.
            </span>
            Static Library Support
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#static-library-support"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The cuBLAS Library is also delivered in a static form as
            <span class="pre">
                libcublas_static.a
            </span>
            on Linux. The static cuBLAS library and all other static math libraries depend on a common thread
            abstraction layer library called
            <span class="pre">
                libculibos.a
            </span>
            .
        </p>
        <p>
            For example, on Linux, to compile a small application using cuBLAS, against the dynamic library, the
            following command can be used:
        </p>
        <pre><span class="n">nvcc</span><span class="n">myCublasApp</span><span class="p">.</span><span class="n">c</span><span class="o">-</span><span class="n">lcublas</span><span class="o">-</span><span class="n">o</span><span class="n">myCublasApp</span>
</pre>
        <p>
            Whereas to compile against the static cuBLAS library, the following command must be used:
        </p>
        <pre><span class="n">nvcc</span><span class="n">myCublasApp</span><span class="p">.</span><span class="n">c</span><span class="o">-</span><span class="n">lcublas_static</span><span class="o">-</span><span class="n">lculibos</span><span class="o">-</span><span class="n">o</span><span class="n">myCublasApp</span>
</pre>
        <p>
            It is also possible to use the native Host C++ compiler. Depending on the Host operating system, some
            additional libraries like
            <span class="pre">
                pthread
            </span>
            or
            <span class="pre">
                dl
            </span>
            might be needed on the linking line. The following command on Linux is suggested :
        </p>
        <pre><span class="n">g</span><span class="o">++</span><span class="n">myCublasApp</span><span class="p">.</span><span class="n">c</span><span class="o">-</span><span class="n">lcublas_static</span><span class="o">-</span><span class="n">lculibos</span><span class="o">-</span><span class="n">lcudart_static</span><span class="o">-</span><span class="n">lpthread</span><span class="o">-</span><span class="n">ldl</span><span class="o">-</span><span class="n">I</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">-</span><span class="n">toolkit</span><span class="o">-</span><span class="n">path</span><span class="o">&gt;/</span><span class="n">include</span><span class="o">-</span><span class="n">L</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">-</span><span class="n">toolkit</span><span class="o">-</span><span class="n">path</span><span class="o">&gt;/</span><span class="n">lib64</span><span class="o">-</span><span class="n">o</span><span class="n">myCublasApp</span>
</pre>
        <p>
            Note that in the latter case, the library
            <span class="pre">
                cuda
            </span>
            is not needed. The CUDA Runtime will try to open explicitly the
            <span class="pre">
                cuda
            </span>
            library if needed. In the case of a system which does not have the CUDA driver installed, this allows the
            application to gracefully manage this issue and potentially run if a CPU-only path is available.
        </p>
        <p>
            Starting with release 11.2, using the typed functions instead of the extension functions (cublas**Ex())
            helps in reducing the binary size when linking to static cuBLAS Library.
        </p>
        <h3>
            <span class="section-number">
                2.1.10.
            </span>
            GEMM Algorithms Numerical Behavior
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#gemm-algorithms-numerical-behavior"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            Some GEMM algorithms split the computation along the dimension K to increase the GPU occupancy, especially
            when the dimension K is large compared to dimensions M and N. When this type of algorithm is chosen by the
            cuBLAS heuristics or explicitly by the user, the results of each split is summed deterministically into the
            resulting matrix to get the final result.
        </p>
        <p>
            For the routines
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                cublas&lt;t&gt;gemmEx
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                cublasGemmEx()
            </a>
            , when the compute type is greater than the output type, the sum of the split chunks can potentially lead to
            some intermediate overflows thus producing a final resulting matrix with some overflows. Those overflows
            might not have occurred if all the dot products had been accumulated in the compute type before being
            converted at the end in the output type. This computation side-effect can be easily exposed when the
            computeType is CUDA_R_32F and Atype, Btype and Ctype are in CUDA_R_16F. This behavior can be controlled
            using the compute precision mode
            <span class="pre">
                CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION
            </span>
            with
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode">
                cublasSetMathMode()
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.1.11.
            </span>
            Tensor Core Usage
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#tensor-core-usage"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            Tensor cores were first introduced with Volta GPUs (compute capability 7.0 and above) and significantly
            accelerate matrix multiplications. Starting with cuBLAS version 11.0.0, the library may automatically make
            use of Tensor Core capabilities wherever possible, unless they are explicitly disabled by selecting pedantic
            compute modes in cuBLAS (see
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode">
                cublasSetMathMode()
            </a>
            ,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasmath-t">
                cublasMath_t
            </a>
            ).
        </p>
        <p>
            It should be noted that the library will pick a Tensor Core enabled implementation wherever it determines
            that it would provide the best performance.
        </p>
        <p>
            The best performance when using Tensor Cores can be achieved when the matrix dimensions and pointers meet
            certain memory alignment requirements. Specifically, all of the following conditions must be satisfied to
            get the most performance out of Tensor Cores:
        </p>
        <ul class="simple">
            <li>
                <p>
                    <span class="pre">
                        ((op_A
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        CUBLAS_OP_N
                    </span>
                    <span class="pre">
                        ?
                    </span>
                    <span class="pre">
                        m
                    </span>
                    <span class="pre">
                        :
                    </span>
                    <span class="pre">
                        k)
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        AtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        ((op_B
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        CUBLAS_OP_N
                    </span>
                    <span class="pre">
                        ?
                    </span>
                    <span class="pre">
                        k
                    </span>
                    <span class="pre">
                        :
                    </span>
                    <span class="pre">
                        n)
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        BtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        (m
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        CtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        (lda
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        AtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        (ldb
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        BtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        (ldc
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        CtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        intptr_t(A)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        intptr_t(B)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        intptr_t(C)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                </p>
            </li>
        </ul>
        <p>
            To conduct matrix multiplication with FP8 types (see
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#bit-floating-point-data-types-fp8-usage">
                8-bit Floating Point Data Types (FP8) Usage
            </a>
            ), you must ensure that your matrix dimensions and pointers meet the optimal requirements listed above.
            Aside from FP8, there are no longer any restrictions on matrix dimensions and memory alignments to use
            Tensor Cores (starting with cuBLAS version 11.0.0).
        </p>
        <h3>
            <span class="section-number">
                2.1.12.
            </span>
            CUDA Graphs Support
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cuda-graphs-support"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            cuBLAS routines can be captured in CUDA Graph stream capture without restrictions in most situations.
        </p>
        <p>
            The exception are routines that output results into host buffers (e.g.
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dot">
                cublas&lt;t&gt;dot
            </a>
            while pointer mode
            <span class="pre">
                CUBLAS_POINTER_MODE_HOST
            </span>
            is configured), as it enforces synchronization.
        </p>
        <p>
            For input coefficients (such as
            <span class="pre">
                alpha
            </span>
            ,
            <span class="pre">
                beta
            </span>
            ) behavior depends on the pointer mode setting:
        </p>
        <ul class="simple">
            <li>
                <p>
                    In the case of
                    <span class="pre">
                        CUBLAS(LT)_POINTER_MODE_HOST
                    </span>
                    , coefficient values are captured in the graph.
                </p>
            </li>
            <li>
                <p>
                    In the case of pointer modes with device pointers, coefficient value is accessed using the device
                    pointer at the time of graph execution.
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            When captured in CUDA Graph stream capture, cuBLAS routines can create
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#graph-memory-nodes">
                memory nodes
            </a>
            through the use of stream-ordered allocation APIs,
            <span class="pre">
                cudaMallocAsync
            </span>
            and
            <span class="pre">
                cudaFreeAsync
            </span>
            . However, as there is currently no support for memory nodes in
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#node-types">
                child graphs
            </a>
            or graphs launched
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-graph-launch">
                from the device
            </a>
            , attempts to capture cuBLAS routines in such scenarios may fail. To avoid this issue, use the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                cublasSetWorkspace()
            </a>
            function to provide user-owned workspace memory.
        </p>
        <h3>
            <span class="section-number">
                2.1.13.
            </span>
            64-bit Integer Interface
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            cuBLAS version 12 introduced 64-bit integer capable functions. Each 64-bit integer function is equivalent to
            a 32-bit integer function with the following changes:
        </p>
        <ul class="simple">
            <li>
                <p>
                    The function name has
                    <span class="pre">
                        _64
                    </span>
                    suffix.
                </p>
            </li>
            <li>
                <p>
                    The dimension (problem size) data type changed from
                    <span class="pre">
                        int
                    </span>
                    to
                    <span class="pre">
                        int64_t
                    </span>
                    . Examples of dimension:
                    <span class="pre">
                        m
                    </span>
                    ,
                    <span class="pre">
                        n
                    </span>
                    , and
                    <span class="pre">
                        k
                    </span>
                    .
                </p>
            </li>
            <li>
                <p>
                    The leading dimension data type changed from
                    <span class="pre">
                        int
                    </span>
                    to
                    <span class="pre">
                        int64_t
                    </span>
                    . Examples of leading dimension:
                    <span class="pre">
                        lda
                    </span>
                    ,
                    <span class="pre">
                        ldb
                    </span>
                    , and
                    <span class="pre">
                        ldc
                    </span>
                    .
                </p>
            </li>
            <li>
                <p>
                    The vector increment data type changed from
                    <span class="pre">
                        int
                    </span>
                    to
                    <span class="pre">
                        int64_t
                    </span>
                    . Examples of vector increment:
                    <span class="pre">
                        incx
                    </span>
                    and
                    <span class="pre">
                        incy
                    </span>
                    .
                </p>
            </li>
        </ul>
        <p>
            For example, consider the following 32-bit integer functions:
        </p>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSetMatrix</span><span class="p">(</span><span class="kt">int</span><span class="n">rows</span><span class="p">,</span><span class="kt">int</span><span class="n">cols</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span><span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasIsamax</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasSsyr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">);</span>
</pre>
        <p>
            The equivalent 64-bit integer functions are:
        </p>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSetMatrix_64</span><span class="p">(</span><span class="kt">int64_t</span><span class="n">rows</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">cols</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">elemSize</span><span class="p">,</span><span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">lda</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">ldb</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasIsamax_64</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">incx</span><span class="p">,</span><span class="kt">int64_t</span><span class="o">*</span><span class="n">result</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasSsyr_64</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int64_t</span><span class="n">lda</span><span class="p">);</span>
</pre>
        <p>
            Not every function has a 64-bit integer equivalent. For instance,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode">
                cublasSetMathMode()
            </a>
            doesnt have any arguments that could meaningfully be
            <span class="pre">
                int64_t
            </span>
            . For documentation brevity, the 64-bit integer APIs are not explicitly listed, but only mentioned that they
            exist for the relevant functions.
        </p>
        <h2>
            <span class="section-number">
                2.2.
            </span>
            cuBLAS Datatypes Reference
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-datatypes-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <h3>
            <span class="section-number">
                2.2.1.
            </span>
            cublasHandle_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t">
                cublasHandle_t
            </a>
            type is a pointer type to an opaque structure holding the cuBLAS library context. The cuBLAS library context
            must be initialized using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            and the returned handle must be passed to all subsequent library function calls. The context should be
            destroyed at the end using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                cublasDestroy()
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                2.2.2.
            </span>
            cublasStatus_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The type is used for function status returns. All cuBLAS library functions return their status, which can
            have the following values.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The cuBLAS library was not initialized. This is usually caused by the lack of a prior
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                            cublasCreate()
                        </a>
                        call, an error in the CUDA Runtime API called by the cuBLAS routine, or an error in the hardware
                        setup.
                    </p>
                    <p>
                        To correct: call
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                            cublasCreate()
                        </a>
                        before the function call; and check that the hardware, an appropriate version of the driver, and
                        the cuBLAS library are correctly installed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Resource allocation failed inside the cuBLAS library. This is usually caused by a
                        <span class="pre">
                            cudaMalloc()
                        </span>
                        failure.
                    </p>
                    <p>
                        To correct: prior to the function call, deallocate previously allocated memory as much as
                        possible.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        An unsupported value or parameter was passed to the function (a negative vector size, for
                        example).
                    </p>
                    <p>
                        To correct: ensure that all the parameters being passed have valid values.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function requires a feature absent from the device architecture; usually caused by compute
                        capability lower than 5.0.
                    </p>
                    <p>
                        To correct: compile and run the application on a device with appropriate compute capability.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        An access to GPU memory space failed, which is usually caused by a failure to bind a texture.
                    </p>
                    <p>
                        To correct: before the function call, unbind any previously bound textures.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The GPU program failed to execute. This is often caused by a launch failure of the kernel on the
                        GPU, which can be caused by multiple reasons.
                    </p>
                    <p>
                        To correct: check that the hardware, an appropriate version of the driver, and the cuBLAS
                        library are correctly installed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INTERNAL_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        An internal cuBLAS operation failed. This error is usually caused by a
                        <span class="pre">
                            cudaMemcpyAsync()
                        </span>
                        failure.
                    </p>
                    <p>
                        To correct: check that the hardware, an appropriate version of the driver, and the cuBLAS
                        library are correctly installed. Also, check that the memory passed as a parameter to the
                        routine is not being deallocated prior to the routines completion.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The functionality requested is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_LICENSE_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The functionality requested requires some license and an error was detected when trying to check
                        the current licensing. This error can happen if the license is not present or is expired or if
                        the environment variable NVIDIA_LICENSE_FILE is not set properly.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.3.
            </span>
            cublasOperation_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                cublasOperation_t
            </a>
            type indicates which operation needs to be performed with the dense matrix. Its values correspond to Fortran
            characters
            <span class="pre">
                N
            </span>
            or
            <span class="pre">
                n
            </span>
            (non-transpose),
            <span class="pre">
                T
            </span>
            or
            <span class="pre">
                t
            </span>
            (transpose) and
            <span class="pre">
                C
            </span>
            or
            <span class="pre">
                c
            </span>
            (conjugate transpose) that are often used as parameters to legacy BLAS implementations.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The non-transpose operation is selected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_OP_T
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The transpose operation is selected.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_OP_C
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The conjugate transpose operation is selected.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.4.
            </span>
            cublasFillMode_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasfillmode-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The type indicates which part (lower or upper) of the dense matrix was filled and consequently should be
            used by the function. Its values correspond to Fortran characters
            <span class="pre">
                L
            </span>
            or
            <span class="pre">
                l
            </span>
            (lower) and
            <span class="pre">
                U
            </span>
            or
            <span class="pre">
                u
            </span>
            (upper) that are often used as parameters to legacy BLAS implementations.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_FILL_MODE_LOWER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The lower part of the matrix is filled.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_FILL_MODE_UPPER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The upper part of the matrix is filled.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_FILL_MODE_FULL
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The full matrix is filled.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.5.
            </span>
            cublasDiagType_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdiagtype-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The type indicates whether the main diagonal of the dense matrix is unity and consequently should not be
            touched or modified by the function. Its values correspond to Fortran characters
            <span class="pre">
                N
            </span>
            or
            <span class="pre">
                n
            </span>
            (non-unit) and
            <span class="pre">
                U
            </span>
            or
            <span class="pre">
                u
            </span>
            (unit) that are often used as parameters to legacy BLAS implementations.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_DIAG_NON_UNIT
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The matrix diagonal has non-unit elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_DIAG_UNIT
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The matrix diagonal has unit elements.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.6.
            </span>
            cublasSideMode_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassidemode-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The type indicates whether the dense matrix is on the left or right side in the matrix equation solved by a
            particular function. Its values correspond to Fortran characters
            <span class="pre">
                L
            </span>
            or
            <span class="pre">
                l
            </span>
            (left) and
            <span class="pre">
                R
            </span>
            or
            <span class="pre">
                r
            </span>
            (right) that are often used as parameters to legacy BLAS implementations.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The matrix is on the left side in the equation.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_SIDE_RIGHT
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The matrix is on the right side in the equation.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.7.
            </span>
            cublasPointerMode_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaspointermode-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaspointermode-t">
                cublasPointerMode_t
            </a>
            type indicates whether the scalar values are passed by reference on the host or device. It is important to
            point out that if several scalar values are present in the function call, all of them must conform to the
            same single pointer mode. The pointer mode can be set and retrieved using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetpointermode">
                cublasSetPointerMode()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetpointermode">
                cublasGetPointerMode()
            </a>
            routines, respectively.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_POINTER_MODE_HOST
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The scalars are passed by reference on the host.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_POINTER_MODE_DEVICE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The scalars are passed by reference on the device.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.8.
            </span>
            cublasAtomicsMode_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasatomicsmode-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The type indicates whether cuBLAS routines which has an alternate implementation using atomics can be used.
            The atomics mode can be set and queried using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetatomicsmode">
                cublasSetAtomicsMode()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetatomicsmode">
                cublasGetAtomicsMode()
            </a>
            and routines, respectively.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_ATOMICS_NOT_ALLOWED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The usage of atomics is not allowed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_ATOMICS_ALLOWED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The usage of atomics is allowed.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.9.
            </span>
            cublasGemmAlgo_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmalgo-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            cublasGemmAlgo_t type is an enumerant to specify the algorithm for matrix-matrix multiplication on GPU
            architectures up to
            <span class="pre">
                sm_75
            </span>
            . On
            <span class="pre">
                sm_80
            </span>
            and newer GPU architectures, this enumarant has no effect. cuBLAS has the following algorithm options:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_GEMM_DEFAULT
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Apply Heuristics to select the GEMM algorithm
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_GEMM_ALGO0
                        </span>
                        to
                        <span class="pre">
                            CUBLAS_GEMM_ALGO23
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Explicitly choose an Algorithm [0,23]. Note: Doesnt have effect on NVIDIA Ampere architecture
                        GPUs and newer.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_GEMM_DEFAULT_TENSOR_OP
                        </span>
                        [DEPRECATED]
                    </p>
                </td>
                <td>
                    <p>
                        This mode is deprecated and will be removed in a future release. Apply Heuristics to select the
                        GEMM algorithm, while allowing use of reduced precision CUBLAS_COMPUTE_32F_FAST_16F kernels (for
                        backward compatibility).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_GEMM_ALGO0_TENSOR_OP
                        </span>
                        to
                        <span class="pre">
                            CUBLAS_GEMM_ALGO15_TENSOR_OP
                        </span>
                        [DEPRECATED]
                    </p>
                </td>
                <td>
                    <p>
                        Those values are deprecated and will be removed in a future release. Explicitly choose a Tensor
                        core GEMM Algorithm [0,15]. Allows use of reduced precision CUBLAS_COMPUTE_32F_FAST_16F kernels
                        (for backward compatibility). Note: Doesnt have effect on NVIDIA Ampere architecture GPUs and
                        newer.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.10.
            </span>
            cublasMath_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasmath-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasmath-t">
                cublasMath_t
            </a>
            enumerate type is used in
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode">
                cublasSetMathMode()
            </a>
            to choose compute precision modes as defined in the following table. Since this setting does not directly
            control the use of Tensor Cores, the mode
            <span class="pre">
                CUBLAS_TENSOR_OP_MATH
            </span>
            is being deprecated, and will be removed in a future release.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_DEFAULT_MATH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This is the default and highest-performance mode that uses compute and intermediate storage
                        precisions with at least the same number of mantissa and exponent bits as requested. Tensor
                        Cores will be used whenever possible.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_PEDANTIC_MATH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This mode uses the prescribed precision and standardized arithmetic for all phases of
                        calculations and is primarily intended for numerical robustness studies, testing, and debugging.
                        This mode might not be as performant as the other modes.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_TF32_TENSOR_OP_MATH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Enable acceleration of single-precision routines using TF32 tensor cores.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Forces any reductions during matrix multiplications to use the accumulator type (that is,
                        compute type) and not the output type in case of mixed precision routines where output type
                        precision is less than the compute type precision. This is a flag that can be set (using a
                        bitwise or operation) alongside any of the other values.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_TENSOR_OP_MATH
                        </span>
                        [DEPRECATED]
                    </p>
                </td>
                <td>
                    <p>
                        This mode is deprecated and will be removed in a future release. Allows the library to use
                        Tensor Core operations whenever possible. For single precision GEMM routines cuBLAS will use the
                        CUBLAS_COMPUTE_32F_FAST_16F compute type.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.2.11.
            </span>
            cublasComputeType_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                cublasComputeType_t
            </a>
            enumerate type is used in
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                cublasGemmEx()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            (including all batched and strided batched variants) to choose compute precision modes as defined below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This is the default and highest-performance mode for 16-bit half precision floating point and
                        all compute and intermediate storage precisions with at least 16-bit half precision. Tensor
                        Cores will be used whenever possible.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This mode uses 16-bit half precision floating point standardized arithmetic for all phases of
                        calculations and is primarily intended for numerical robustness studies, testing, and debugging.
                        This mode might not be as performant as the other modes since it disables use of tensor cores.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This is the default 32-bit single precision floating point and uses compute and intermediate
                        storage precisions of at least 32-bits.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Uses 32-bit single precision floatin point arithmetic for all phases of calculations and also
                        disables algorithmic optimizations such as Gaussian complexity reduction (3M).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Allows the library to use Tensor Cores with automatic down-conversion and 16-bit half-precision
                        compute for 32-bit input and output matrices.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Allows the library to use Tensor Cores with automatic down-convesion and bfloat16 compute for
                        32-bit input and output matrices. See
                        <a class="reference external"
                            href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#wmma-altfp">
                            Alternate Floating Point
                        </a>
                        section for more details on bfloat16.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_TF32
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Allows the library to use Tensor Cores with TF32 compute for 32-bit input and output matrices.
                        See
                        <a class="reference external"
                            href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#wmma-altfp">
                            Alternate Floating Point
                        </a>
                        section for more details on TF32 compute.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This is the default 64-bit double precision floating point and uses compute and intermediate
                        storage precisions of at least 64-bits.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Uses 64-bit double precision floatin point arithmetic for all phases of calculations and also
                        disables algorithmic optimizations such as Gaussian complexity reduction (3M).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        This is the default 32-bit integer mode and uses compute and intermediate storage precisions of
                        at least 32-bits.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Uses 32-bit integer arithmetic for all phases of calculations.
                    </p>
                </td>
            </tr>
        </table>
        <p class="admonition-title">
            Note
        </p>
        <p>
            Setting the environment variable
            <span class="pre">
                NVIDIA_TF32_OVERRIDE
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                0
            </span>
            will override any defaults or programmatic configuration of NVIDIA libraries, and consequently, cuBLAS will
            not accelerate FP32 computations with TF32 tensor cores.
        </p>
        <h2>
            <span class="section-number">
                2.3.
            </span>
            CUDA Datatypes Reference
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cuda-datatypes-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The chapter describes types shared by multiple CUDA Libraries and defined in the header file
            <span class="pre">
                library_types.h
            </span>
            .
        </p>
        <h3>
            <span class="section-number">
                2.3.1.
            </span>
            cudaDataType_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <span class="pre">
                cudaDataType_t
            </span>
            type is an enumerant to specify the data precision. It is used when the data reference does not carry the
            type itself (e.g void *)
        </p>
        <p>
            For example, it is used in the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                cublasSgemmEx()
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 16-bit real half precision floating-point
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 32-bit structure comprised of two half precision floating-points representing
                        a complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 16-bit real bfloat16 floating-point
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 32-bit structure comprised of two bfloat16 floating-points representing a
                        complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 32-bit real single precision floating-point
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 64-bit structure comprised of two single precision floating-points
                        representing a complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 64-bit real double precision floating-point
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 128-bit structure comprised of two double precision floating-points
                        representing a complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 8-bit real signed integer
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 16-bit structure comprised of two 8-bit signed integers representing a
                        complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8U
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 8-bit real unsigned integer
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8U
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 16-bit structure comprised of two 8-bit unsigned integers representing a
                        complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 32-bit real signed integer
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is a 64-bit structure comprised of two 32-bit signed integers representing a
                        complex number.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8F_E4M3
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is an 8-bit real floating point in E4M3 format
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8F_E5M2
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the data type is an 8-bit real floating point in E5M2 format
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.3.2.
            </span>
            libraryPropertyType_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#librarypropertytype-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <span class="pre">
                libraryPropertyType_t
            </span>
            is used as a parameter to specify which property is requested when using the routine
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetproperty">
                cublasGetProperty()
            </a>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            MAJOR_VERSION
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        enumerant to query the major version
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            MINOR_VERSION
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        enumerant to query the minor version
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            PATCH_LEVEL
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        number to identify the patch level
                    </p>
                </td>
            </tr>
        </table>
        <h2>
            <span class="section-number">
                2.4.
            </span>
            cuBLAS Helper Function Reference
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-helper-function-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <h3>
            <span class="section-number">
                2.4.1.
            </span>
            cublasCreate()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasCreate</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="o">*</span><span class="n">handle</span><span class="p">)</span>
</pre>
        <p>
            This function initializes the cuBLAS library and creates a handle to an opaque structure holding the cuBLAS
            library context. It allocates hardware resources on the host and device and must be called prior to making
            any other cuBLAS library calls. The cuBLAS library context is tied to the current CUDA device. To use the
            library on multiple devices, one cuBLAS handle needs to be created for each device. Furthermore, for a given
            device, multiple cuBLAS handles with different configurations can be created. Because
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            allocates some internal resources and the release of those resources by calling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                cublasDestroy()
            </a>
            will implicitly call
            <span class="pre">
                cudaDeviceSynchronize()
            </span>
            , it is recommended to minimize the number of times these functions are called. For multi-threaded
            applications that use the same device from different threads, the recommended programming model is to create
            one cuBLAS handle per thread and use that cuBLAS handle for the entire life of the thread.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the initialization succeeded
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the CUDA Runtime initialization failed
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the resources could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            handle
                        </span>
                        == NULL
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.2.
            </span>
            cublasDestroy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasDestroy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">)</span>
</pre>
        <p>
            This function releases hardware resources used by the cuBLAS library. This function is usually the last call
            with a particular handle to the cuBLAS library. Because
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            allocates some internal resources and the release of those resources by calling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                cublasDestroy()
            </a>
            will implicitly call
            <span class="pre">
                cudaDeviceSynchronize()
            </span>
            , it is recommended to minimize the number of times these functions are called.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the shut down succeeded
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.3.
            </span>
            cublasGetVersion()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetversion"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetVersion</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">version</span><span class="p">)</span>
</pre>
        <p>
            This function returns the version number of the cuBLAS library.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the provided storage for library version number is not initialized (NULL)
                    </p>
                </td>
            </tr>
        </table>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This function can be safely called with the handle set to NULL. This allows users to get the version of the
            library without a handle. Another way to do this is with
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetproperty">
                cublasGetProperty()
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                2.4.4.
            </span>
            cublasGetProperty()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetproperty"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetProperty</span><span class="p">(</span><span class="n">libraryPropertyType</span><span class="n">type</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">value</span><span class="p">)</span>
</pre>
        <p>
            This function returns the value of the requested property in memory pointed to by value. Refer to
            <span class="pre">
                libraryPropertyType
            </span>
            for supported types.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Invalid type value
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                If invalid
                                <span class="pre">
                                    type
                                </span>
                                value or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    value
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.5.
            </span>
            cublasGetStatusName()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetstatusname"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="k">const</span><span class="kt">char</span><span class="o">*</span><span class="n">cublasGetStatusName</span><span class="p">(</span><span class="n">cublasStatus_t</span><span class="n">status</span><span class="p">)</span>
</pre>
        <p>
            This function returns the string representation of a given status.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        NULL-terminated string
                    </p>
                </td>
                <td>
                    <p>
                        The string representation of the
                        <span class="pre">
                            status
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.6.
            </span>
            cublasGetStatusString()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetstatusstring"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="k">const</span><span class="kt">char</span><span class="o">*</span><span class="n">cublasGetStatusString</span><span class="p">(</span><span class="n">cublasStatus_t</span><span class="n">status</span><span class="p">)</span>
</pre>
        <p>
            This function returns the description string for a given status.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        NULL-terminated string
                    </p>
                </td>
                <td>
                    <p>
                        The description of the
                        <span class="pre">
                            status
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.7.
            </span>
            cublasSetStream()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetStream</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cudaStream_t</span><span class="n">streamId</span><span class="p">)</span>
</pre>
        <p>
            This function sets the cuBLAS library stream, which will be used to execute all subsequent calls to the
            cuBLAS library functions. If the cuBLAS library stream is not set, all kernels use the
            default
            <span class="pre">
                NULL
            </span>
            stream. In particular, this routine can be used to change the stream between kernel launches and then to
            reset the cuBLAS library stream back to
            <span class="pre">
                NULL
            </span>
            . Additionally this function unconditionally resets the cuBLAS library workspace back to the default
            workspace pool (see
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                cublasSetWorkspace()
            </a>
            ).
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the stream was set successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.8.
            </span>
            cublasSetWorkspace()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetWorkspace</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">workspace</span><span class="p">,</span><span class="kt">size_t</span><span class="n">workspaceSizeInBytes</span><span class="p">)</span>
</pre>
        <p>
            This function sets the cuBLAS library workspace to a user-owned device buffer, which will be used to execute
            all subsequent calls to the cuBLAS library functions (on the currently set stream). If the cuBLAS library
            workspace is not set, all kernels will use the default workspace pool allocated during the cuBLAS context
            creation. In particular, this routine can be used to change the workspace between kernel launches. The
            workspace pointer has to be aligned to at least 256 bytes, otherwise
            <span class="pre">
                CUBLAS_STATUS_INVALID_VALUE
            </span>
            error is returned. The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            function unconditionally resets the cuBLAS library workspace back to the default workspace pool. Calling
            this function, including with
            <span class="pre">
                workspaceSizeInBytes
            </span>
            equal to 0, will prevent the cuBLAS library from utilizing the default workspace. Too small
            <span class="pre">
                workspaceSizeInBytes
            </span>
            may cause some routines to fail with
            <span class="pre">
                CUBLAS_STATUS_ALLOC_FAILED
            </span>
            error returned or cause large regressions in performance. Workspace size equal to or larger than 16KiB is
            enough to prevent
            <span class="pre">
                CUBLAS_STATUS_ALLOC_FAILED
            </span>
            error, while a larger workspace can provide performance benefits for some routines.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            If the stream set by
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            is
            <span class="pre">
                cudaStreamPerThread
            </span>
            and there are multiple threads using the same cuBLAS library handle, then users must manually manage
            synchronization to avoid possible race conditions in the user provided workspace. Alternatively, users may
            rely on the default workspace pool which safely guards against race conditions.
        </p>
        <p>
            The table below shows the recommended size of user-provided workspace.
            This is based on the cuBLAS default workspace pool size which is GPU architecture dependent.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        GPU Architecture
                    </p>
                </th>
                <th class="head">
                    <p>
                        Recommended workspace size
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        NVIDIA Hopper Architecture
                    </p>
                </td>
                <td>
                    <p>
                        32 MiB
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Other
                    </p>
                </td>
                <td>
                    <p>
                        4 MiB
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the stream was set successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the
                        <span class="pre">
                            workspace
                        </span>
                        pointer wasnt aligned to at least 256 bytes
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.9.
            </span>
            cublasGetStream()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetstream"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetStream</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cudaStream_t</span><span class="o">*</span><span class="n">streamId</span><span class="p">)</span>
</pre>
        <p>
            This function gets the cuBLAS library stream, which is being used to execute all calls to the cuBLAS library
            functions. If the cuBLAS library stream is not set, all kernels use the
            default
            <span class="pre">
                NULL
            </span>
            stream.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the stream was returned successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            streamId
                        </span>
                        == NULL
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.10.
            </span>
            cublasGetPointerMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetpointermode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetPointerMode</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasPointerMode_t</span><span class="o">*</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            This function obtains the pointer mode used by the cuBLAS library. Please see the section on the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaspointermode-t">
                cublasPointerMode_t
            </a>
            type for more details.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the pointer mode was obtained successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            mode
                        </span>
                        == NULL
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.11.
            </span>
            cublasSetPointerMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetpointermode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetPointerMode</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasPointerMode_t</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            This function sets the pointer mode used by the cuBLAS library. The
            default
            is for the values to be passed by reference on the host. Please see the section on the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaspointermode-t">
                cublasPointerMode_t
            </a>
            type for more details.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the pointer mode was set successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            mode
                        </span>
                        is not
                        <span class="pre">
                            CUBLAS_POINTER_MODE_HOST
                        </span>
                        or
                        <span class="pre">
                            CUBLAS_POINTER_MODE_DEVICE
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.12.
            </span>
            cublasSetVector()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetvector"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetVector</span><span class="p">(</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function copies
            <span class="pre">
                n
            </span>
            elements from a vector
            <span class="pre">
                x
            </span>
            in host memory space to a vector
            <span class="pre">
                y
            </span>
            in GPU memory space. Elements in both vectors are assumed to have a size of
            <span class="pre">
                elemSize
            </span>
            bytes. The storage spacing between consecutive elements is given by
            <span class="pre">
                incx
            </span>
            for the source vector
            <span class="pre">
                x
            </span>
            and by
            <span class="pre">
                incy
            </span>
            for the destination vector
            <span class="pre">
                y
            </span>
            .
        </p>
        <p>
            Since column-major format for two-dimensional matrices is assumed, if a vector is part of a matrix, a vector
            increment equal to
            <span class="pre">
                1
            </span>
            accesses a (partial) column of that matrix. Similarly, using an increment equal to the leading dimension of
            the matrix results in accesses to a (partial) row of that matrix.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            incx
                        </span>
                        ,
                        <span class="pre">
                            incy
                        </span>
                        ,
                        <span class="pre">
                            elemSize&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.13.
            </span>
            cublasGetVector()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetvector"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetVector</span><span class="p">(</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function copies
            <span class="pre">
                n
            </span>
            elements from a vector
            <span class="pre">
                x
            </span>
            in GPU memory space to a vector
            <span class="pre">
                y
            </span>
            in host memory space. Elements in both vectors are assumed to have a size of
            <span class="pre">
                elemSize
            </span>
            bytes. The storage spacing between consecutive elements is given by
            <span class="pre">
                incx
            </span>
            for the source vector and
            <span class="pre">
                incy
            </span>
            for the destination vector
            <span class="pre">
                y
            </span>
            .
        </p>
        <p>
            Since column-major format for two-dimensional matrices is assumed, if a vector is part of a matrix, a vector
            increment equal to
            <span class="pre">
                1
            </span>
            accesses a (partial) column of that matrix. Similarly, using an increment equal to the leading dimension of
            the matrix results in accesses to a (partial) row of that matrix.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            incx
                        </span>
                        ,
                        <span class="pre">
                            incy
                        </span>
                        ,
                        <span class="pre">
                            elemSize&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.14.
            </span>
            cublasSetMatrix()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmatrix"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetMatrix</span><span class="p">(</span><span class="kt">int</span><span class="n">rows</span><span class="p">,</span><span class="kt">int</span><span class="n">cols</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function copies a tile of
            <span class="pre">
                rows
            </span>
            <span class="pre">
                x
            </span>
            <span class="pre">
                cols
            </span>
            elements from a matrix
            <span class="pre">
                A
            </span>
            in host memory space to a matrix
            <span class="pre">
                B
            </span>
            in GPU memory space. It is assumed that each element requires storage of
            <span class="pre">
                elemSize
            </span>
            bytes and that both matrices are stored in column-major format, with the leading dimension of the source
            matrix
            <span class="pre">
                A
            </span>
            and destination matrix
            <span class="pre">
                B
            </span>
            given in
            <span class="pre">
                lda
            </span>
            and
            <span class="pre">
                ldb
            </span>
            , respectively. The leading dimension indicates the number of rows of the allocated matrix, even if only a
            submatrix of it is being used.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            rows,
                        </span>
                        <span class="pre">
                            cols&lt;0
                        </span>
                        or
                        <span class="pre">
                            elemSize,
                        </span>
                        <span class="pre">
                            lda,
                        </span>
                        <span class="pre">
                            ldb&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.15.
            </span>
            cublasGetMatrix()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmatrix"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetMatrix</span><span class="p">(</span><span class="kt">int</span><span class="n">rows</span><span class="p">,</span><span class="kt">int</span><span class="n">cols</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function copies a tile of
            <span class="pre">
                rows
            </span>
            <span class="pre">
                x
            </span>
            <span class="pre">
                cols
            </span>
            elements from a matrix
            <span class="pre">
                A
            </span>
            in GPU memory space to a matrix
            <span class="pre">
                B
            </span>
            in host memory space. It is assumed that each element requires storage of
            <span class="pre">
                elemSize
            </span>
            bytes and that both matrices are stored in column-major format, with the leading dimension of the source
            matrix
            <span class="pre">
                A
            </span>
            and destination matrix
            <span class="pre">
                B
            </span>
            given in
            <span class="pre">
                lda
            </span>
            and
            <span class="pre">
                ldb
            </span>
            , respectively. The leading dimension indicates the number of rows of the allocated matrix, even if only a
            submatrix of it is being used.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            rows,
                        </span>
                        <span class="pre">
                            cols&lt;0
                        </span>
                        or
                        <span class="pre">
                            elemSize,
                        </span>
                        <span class="pre">
                            lda,
                        </span>
                        <span class="pre">
                            ldb&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.16.
            </span>
            cublasSetVectorAsync()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetvectorasync"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetVectorAsync</span><span class="p">(</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span><span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">devicePtr</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="n">cudaStream_t</span><span class="n">stream</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function has the same functionality as
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetvector">
                cublasSetVector()
            </a>
            , with the exception that the data transfer is done asynchronously (with respect to the host) using the
            given CUDA stream parameter.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            incx
                        </span>
                        ,
                        <span class="pre">
                            incy
                        </span>
                        ,
                        <span class="pre">
                            elemSize&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.17.
            </span>
            cublasGetVectorAsync()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetvectorasync"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetVectorAsync</span><span class="p">(</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span><span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">devicePtr</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">hostPtr</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="n">cudaStream_t</span><span class="n">stream</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function has the same functionality as
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetvector">
                cublasGetVector()
            </a>
            , with the exception that the data transfer is done asynchronously (with respect to the host) using the
            given CUDA stream parameter.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            incx
                        </span>
                        ,
                        <span class="pre">
                            incy
                        </span>
                        ,
                        <span class="pre">
                            elemSize&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.18.
            </span>
            cublasSetMatrixAsync()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmatrixasync"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasSetMatrixAsync</span><span class="p">(</span><span class="kt">int</span><span class="n">rows</span><span class="p">,</span><span class="kt">int</span><span class="n">cols</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span><span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span><span class="n">cudaStream_t</span><span class="n">stream</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function has the same functionality as
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmatrix">
                cublasSetMatrix()
            </a>
            , with the exception that the data transfer is done asynchronously (with respect to the host) using the
            given CUDA stream parameter.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            rows,
                        </span>
                        <span class="pre">
                            cols&lt;0
                        </span>
                        or
                        <span class="pre">
                            elemSize,
                        </span>
                        <span class="pre">
                            lda,
                        </span>
                        <span class="pre">
                            ldb&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.19.
            </span>
            cublasGetMatrixAsync()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmatrixasync"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasGetMatrixAsync</span><span class="p">(</span><span class="kt">int</span><span class="n">rows</span><span class="p">,</span><span class="kt">int</span><span class="n">cols</span><span class="p">,</span><span class="kt">int</span><span class="n">elemSize</span><span class="p">,</span><span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span><span class="n">cudaStream_t</span><span class="n">stream</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function has the same functionality as
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmatrix">
                cublasGetMatrix()
            </a>
            , with the exception that the data transfer is done asynchronously (with respect to the host) using the
            given CUDA stream parameter.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            rows,
                        </span>
                        <span class="pre">
                            cols&lt;0
                        </span>
                        or
                        <span class="pre">
                            elemSize,
                        </span>
                        <span class="pre">
                            lda,
                        </span>
                        <span class="pre">
                            ldb&lt;=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        there was an error accessing GPU memory
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.20.
            </span>
            cublasSetAtomicsMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetatomicsmode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSetAtomicsMode</span><span class="p">(</span><span class="n">cublasHandlet</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasAtomicsMode_t</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            Some routines like
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-symv">
                cublas&lt;t&gt;symv
            </a>
            and
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hemv">
                cublas&lt;t&gt;hemv
            </a>
            have an alternate implementation that use atomics to cumulate results. This implementation is generally
            significantly faster but can generate results that are not strictly identical from one run to the others.
            Mathematically, those different results are not significant but when debugging those differences can be
            prejudicial.
        </p>
        <p>
            This function allows or disallows the usage of atomics in the cuBLAS library for all routines which have an
            alternate implementation. When not explicitly specified in the documentation of any cuBLAS routine, it means
            that this routine does not have an alternate implementation that use atomics. When atomics mode is disabled,
            each cuBLAS routine should produce the same results from one run to the other when called with identical
            parameters on the same Hardware.
        </p>
        <p>
            The default atomics mode of default initialized
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t">
                cublasHandle_t
            </a>
            object is
            <span class="pre">
                CUBLAS_ATOMICS_NOT_ALLOWED
            </span>
            . Please see the section on the type for more details.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the atomics mode was set successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.21.
            </span>
            cublasGetAtomicsMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetatomicsmode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGetAtomicsMode</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasAtomicsMode_t</span><span class="o">*</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            This function queries the atomic mode of a specific cuBLAS context.
        </p>
        <p>
            The default atomics mode of default initialized
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t">
                cublasHandle_t
            </a>
            object is
            <span class="pre">
                CUBLAS_ATOMICS_NOT_ALLOWED
            </span>
            . Please see the section on the type for more details.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the atomics mode was queried successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the argument
                        <span class="pre">
                            mode
                        </span>
                        is a NULL pointer
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.22.
            </span>
            cublasSetMathMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSetMathMode</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasMath_t</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode">
                cublasSetMathMode()
            </a>
            function enables you to choose the compute precision modes as defined by
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasmath-t">
                cublasMath_t
            </a>
            . Users are allowed to set the compute precision mode as a logical combination of them (except the
            deprecated
            <span class="pre">
                CUBLAS_TENSOR_OP_MATH
            </span>
            ). For example,
            <span class="pre">
                cublasSetMathMode(handle,
            </span>
            <span class="pre">
                CUBLAS_DEFAULT_MATH
            </span>
            <span class="pre">
                |
            </span>
            <span class="pre">
                CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION)
            </span>
            . Please note that the default math mode is
            <span class="pre">
                CUBLAS_DEFAULT_MATH
            </span>
            .
        </p>
        <p>
            For matrix and compute precisions allowed for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                cublasGemmEx()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            APIs and their strided variants please refer to:
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                cublasGemmEx()
            </a>
            ,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                cublasGemmBatchedEx()
            </a>
            ,
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmstridedbatchedex">
                cublasGemmStridedBatchedEx()
            </a>
            , and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the math mode was set successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        an invalid value for mode was specified.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.23.
            </span>
            cublasGetMathMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetmathmode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGetMathMode</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasMath_t</span><span class="o">*</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            This function returns the math mode used by the library routines.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the math type was returned successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        if mode is NULL.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.24.
            </span>
            cublasSetSmCountTarget()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetsmcounttarget"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSetSmCountTarget</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">smCountTarget</span><span class="p">)</span>
</pre>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetsmcounttarget">
                cublasSetSmCountTarget()
            </a>
            function allows overriding the number of multiprocessors available to the library during kernels execution.
        </p>
        <p>
            This option can be used to improve the library performance when cuBLAS routines are known to run
            concurrently with other work on different CUDA streams. E.g. a NVIDIA A100 GPU has 108 SM and there is a
            concurrent kenrel running with grid size of 8, one can use
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetsmcounttarget">
                cublasSetSmCountTarget()
            </a>
            with value
            <span class="pre">
                100
            </span>
            to override the library heuristics to optimize for running on 100 multiprocessors.
        </p>
        <p>
            When set to
            <span class="pre">
                0
            </span>
            the library returns to its default behavior. The input value should not exceed the devices multiprocessor
            count, which can be obtained using
            <span class="pre">
                cudaDeviceGetAttribute
            </span>
            . Negative values are not accepted.
        </p>
        <p>
            The user must ensure thread safety when modifying the library handle with this routine similar to when using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                cublasSetStream()
            </a>
            , etc.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SM count target was set successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the value of
                        <span class="pre">
                            smCountTarget
                        </span>
                        outside of the allowed range.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.25.
            </span>
            cublasGetSmCountTarget()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetsmcounttarget"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGetSmCountTarget</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">smCountTarget</span><span class="p">)</span>
</pre>
        <p>
            This function obtains the value previously programmed to the library handle.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SM count target was set successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        smCountTarget is NULL.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.26.
            </span>
            cublasLoggerConfigure()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasloggerconfigure"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasLoggerConfigure</span><span class="p">(</span>
<span class="kt">int</span><span class="n">logIsOn</span><span class="p">,</span>
<span class="kt">int</span><span class="n">logToStdOut</span><span class="p">,</span>
<span class="kt">int</span><span class="n">logToStdErr</span><span class="p">,</span>
<span class="k">const</span><span class="kt">char</span><span class="o">*</span><span class="n">logFileName</span><span class="p">)</span>
</pre>
        <p>
            This function configures logging during runtime. Besides this type of configuration, it is possible to
            configure logging with special environment variables which will be checked by libcublas:
        </p>
        <ul class="simple">
            <li>
                <p>
                    CUBLAS_LOGINFO_DBG - Setup env. variable to 1 means turn on logging (by default logging is
                    off).
                </p>
            </li>
            <li>
                <p>
                    CUBLAS_LOGDEST_DBG - Setup env. variable encodes how to log. stdout, stderr means to
                    output log messages to stdout or stderr, respectively. In the other case, its specifies
                    filename of file.
                </p>
            </li>
        </ul>
        <p>
            Parameters
        </p>
        logIsOn
        <p>
            Input
            . Turn on/off logging completely. By default is off, but is turned on by calling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetloggercallback">
                cublasSetLoggerCallback()
            </a>
            to user defined callback function.
        </p>
        logToStdOut
        <p>
            Input
            . Turn on/off logging to standard output I/O stream. By default is off.
        </p>
        logToStdErr
        <p>
            Input
            . Turn on/off logging to standard error I/O stream. By default is off.
        </p>
        logFileName
        <p>
            Input
            . Turn on/off logging to file in filesystem specified by its name.
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasloggerconfigure">
                cublasLoggerConfigure()
            </a>
            copies the content of
            <span class="pre">
                logFileName
            </span>
            . You should provide null pointer if you are not interested in this type of logging.
        </p>
        <p>
            Returns
        </p>
        <span class="pre">
            CUBLAS_STATUS_SUCCESS
        </span>
        <p>
            Success.
        </p>
        <h3>
            <span class="section-number">
                2.4.27.
            </span>
            cublasGetLoggerCallback()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgetloggercallback"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGetLoggerCallback</span><span class="p">(</span>
<span class="n">cublasLogCallback</span><span class="o">*</span><span class="n">userCallback</span><span class="p">)</span>
</pre>
        <p>
            This function retrieves function pointer to previously installed custom user defined callback function via
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetloggercallback">
                cublasSetLoggerCallback()
            </a>
            or zero otherwise.
        </p>
        <p>
            Parameters
        </p>
        userCallback
        <p>
            Output
            . Pointer to user defined callback function.
        </p>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            userCallback
                        </span>
                        is NULL
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.4.28.
            </span>
            cublasSetLoggerCallback()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetloggercallback"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSetLoggerCallback</span><span class="p">(</span>
<span class="n">cublasLogCallback</span><span class="n">userCallback</span><span class="p">)</span>
</pre>
        <p>
            This function installs a custom user defined callback function via cublas C public API.
        </p>
        <p>
            Parameters
        </p>
        userCallback
        <p>
            Input
            . Pointer to user defined callback function.
        </p>
        <p>
            Returns
        </p>
        <span class="pre">
            CUBLAS_STATUS_SUCCESS
        </span>
        <p>
            Success.
        </p>
        <h2>
            <span class="section-number">
                2.5.
            </span>
            cuBLAS Level-1 Function Reference
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-1-function-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            In this chapter we describe the Level-1 Basic Linear Algebra Subprograms (BLAS1) functions that perform
            scalar and vector based operations. We will use abbreviations &lt;
            type
            &gt; for type and &lt;
            t
            &gt; for the corresponding short type to make a more concise and clear presentation of the implemented
            functions. Unless otherwise specified &lt;
            type
            &gt; and &lt;
            t
            &gt; have the following meanings:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        &lt;type&gt;
                    </p>
                </th>
                <th class="head">
                    <p>
                        &lt;t&gt;
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            float
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        s or S
                    </p>
                </td>
                <td>
                    <p>
                        real single-precision
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            double
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        d or D
                    </p>
                </td>
                <td>
                    <p>
                        real double-precision
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cuComplex
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        c or C
                    </p>
                </td>
                <td>
                    <p>
                        complex single-precision
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cuDoubleComplex
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        z or Z
                    </p>
                </td>
                <td>
                    <p>
                        complex double-precision
                    </p>
                </td>
            </tr>
        </table>
        <p>
            When the parameters and returned values of the function differ, which sometimes happens for complex input,
            the
            <span class="pre">
                &lt;t&gt;
            </span>
            can also have the following meanings
            <span class="pre">
                Sc
            </span>
            ,
            <span class="pre">
                Cs
            </span>
            ,
            <span class="pre">
                Dz
            </span>
            and
            <span class="pre">
                Zd
            </span>
            .
        </p>
        <p>
            The abbreviation
            <span class="math notranslate nohighlight">
                \(\mathbf{Re}(\cdot)\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{Im}(\cdot)\)
            </span>
            will stand for the real and imaginary part of a number, respectively. Since imaginary part of a real number
            does not exist, we will consider it to be zero and can usually simply discard it from the equation where it
            is being used. Also, the
            <span class="math notranslate nohighlight">
                \(\bar{\alpha}\)
            </span>
            will denote the complex conjugate of
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            .
        </p>
        <p>
            In general throughout the documentation, the lower case Greek symbols
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            will denote scalars, lower case English letters in bold type
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            will denote vectors and capital English letters
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            will denote matrices.
        </p>
        <h3>
            <span class="section-number">
                2.5.1.
            </span>
            cublasI&lt;t&gt;amax()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasi-t-amax"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasIsamax</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasIdamax</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasIcamax</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasIzamax</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function finds the (smallest) index of the element of the maximum magnitude. Hence, the result is the
            first
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
            such that
            <span class="math notranslate nohighlight">
                \(\left| \mathbf{Im}\left( {x\lbrack j\rbrack} \right) \middle| + \middle| \mathbf{Re}\left( {x\lbrack
                j\rbrack} \right) \right|\)
            </span>
            is maximum for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{ incx}\)
            </span>
            . Notice that the last equation reflects 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        the resulting index, which is
                        <span class="pre">
                            0
                        </span>
                        if
                        <span class="pre">
                            n,incx&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the reduction buffer could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            result
                        </span>
                        is NULL
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/isamax.f">
                isamax
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/idamax.f">
                idamax
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/icamax.f">
                icamax
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/izamax.f">
                izamax
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.2.
            </span>
            cublasI&lt;t&gt;amin()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasi-t-amin"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasIsamin</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasIdamin</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasIcamin</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasIzamin</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function finds the (smallest) index of the element of the minimum magnitude. Hence, the result is the
            first
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
            such that
            <span class="math notranslate nohighlight">
                \(\left| \mathbf{Im}\left( {x\lbrack j\rbrack} \right) \middle| + \middle| \mathbf{Re}\left( {x\lbrack
                j\rbrack} \right) \right|\)
            </span>
            is minimum for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            Notice that the last equation reflects 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        the resulting index, which is
                        <span class="pre">
                            0
                        </span>
                        if
                        <span class="pre">
                            n,incx&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the reduction buffer could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            result
                        </span>
                        is NULL
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/scilib/blass.f">
                isamin
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.3.
            </span>
            cublas&lt;t&gt;asum()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-asum"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSasum</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDasum</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasScasum</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDzasum</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function computes the sum of the absolute values of the elements of vector
            <span class="pre">
                x
            </span>
            . Hence, the result is
            <span class="math notranslate nohighlight">
                \(\left. \sum_{i = 1}^{n} \middle| \mathbf{Im}\left( {x\lbrack j\rbrack} \right) \middle| + \middle|
                \mathbf{Re}\left( {x\lbrack j\rbrack} \right) \right|\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            . Notice that the last equation reflects 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        the resulting index, which is
                        <span class="pre">
                            0.0
                        </span>
                        if
                        <span class="pre">
                            n,incx&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the reduction buffer could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            result
                        </span>
                        is NULL
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sasum.f">
                sasum
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dasum.f">
                dasum
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/scasum.f">
                scasum
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dzasum.f">
                dzasum
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.4.
            </span>
            cublas&lt;t&gt;axpy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-axpy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSaxpy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDaxpy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCaxpy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZaxpy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function multiplies the vector
            <span class="pre">
                x
            </span>
            by the scalar
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and adds it to the vector
            <span class="pre">
                y
            </span>
            overwriting the latest vector with the result. Hence, the performed operation is
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\lbrack j\rbrack = \alpha \times \mathbf{x}\lbrack k\rbrack + \mathbf{y}\lbrack j\rbrack\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/saxpy.f">
                saxpy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/daxpy.f">
                daxpy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/caxpy.f">
                caxpy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zaxpy.f">
                zaxpy
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.5.
            </span>
            cublas&lt;t&gt;copy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-copy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasScopy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDcopy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCcopy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZcopy</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function copies the vector
            <span class="pre">
                x
            </span>
            into the vector
            <span class="pre">
                y
            </span>
            . Hence, the performed operation is
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\lbrack j\rbrack = \mathbf{x}\lbrack k\rbrack\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/scopy.f">
                scopy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dcopy.f">
                dcopy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ccopy.f">
                ccopy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zcopy.f">
                zcopy
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.6.
            </span>
            cublas&lt;t&gt;dot()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dot"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSdot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDdot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCdotu</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCdotc</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZdotu</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZdotc</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function computes the dot product of vectors
            <span class="pre">
                x
            </span>
            and
            <span class="pre">
                y
            </span>
            . Hence, the result is
            <span class="math notranslate nohighlight">
                \(\sum_{i = 1}^{n}\left( {\mathbf{x}\lbrack k\rbrack \times \mathbf{y}\lbrack j\rbrack} \right)\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that in the first equation the conjugate of the element of vector x should be used if the function
            name ends in character c and that the last two equations reflect 1-based indexing used for
            compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vectors
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        the resulting dot product, which is
                        <span class="pre">
                            0.0
                        </span>
                        if
                        <span class="pre">
                            n&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the reduction buffer could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sdot.f">
                sdot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ddot.f">
                ddot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cdotu.f">
                cdotu
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cdotc.f">
                cdotc
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdotu.f">
                zdotu
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdotc.f">
                zdotc
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.7.
            </span>
            cublas&lt;t&gt;nrm2()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-nrm2"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSnrm2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDnrm2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasScnrm2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDznrm2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">result</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function computes the Euclidean norm of the vector
            <span class="pre">
                x
            </span>
            . The code uses a multiphase model of accumulation to avoid intermediate underflow and overflow, with the
            result being equivalent to
            <span class="math notranslate nohighlight">
                \(\sqrt{\sum_{i = 1}^{n}\left( {\mathbf{x}\lbrack j\rbrack \times \mathbf{x}\lbrack j\rbrack} \right)}\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            in exact arithmetic. Notice that the last equation reflects 1-based indexing used for compatibility with
            Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        the resulting norm, which is
                        <span class="pre">
                            0.0
                        </span>
                        if
                        <span class="pre">
                            n,incx&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the reduction buffer could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            result
                        </span>
                        is NULL
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/snrm2.f90">
                snrm2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dnrm2.f90">
                dnrm2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/scnrm2.f90">
                scnrm2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dznrm2.f90">
                dznrm2
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.8.
            </span>
            cublas&lt;t&gt;rot()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rot"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSrot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDrot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCrot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsrot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZrot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZdrot</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function applies Givens rotation matrix (i.e., rotation in the x,y plane counter-clockwise by angle
            defined by cos(alpha)=c, sin(alpha)=s):
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(G = \begin{pmatrix}
                c &amp; s \\
                {- s} &amp; c \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            to vectors
            <span class="pre">
                x
            </span>
            and
            <span class="pre">
                y
            </span>
            .
        </p>
        <p>
            Hence, the result is
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\lbrack k\rbrack = c \times \mathbf{x}\lbrack k\rbrack + s \times \mathbf{y}\lbrack
                j\rbrack\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\lbrack j\rbrack = - s \times \mathbf{x}\lbrack k\rbrack + c \times \mathbf{y}\lbrack
                j\rbrack\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vectors
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        c
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        cosine element of the rotation matrix.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        s
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        sine element of the rotation matrix.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/srot.f">
                srot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/drot.f">
                drot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/lapack_routine/crot.f">
                crot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csrot.f">
                csrot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/lapack_routine/zrot.f">
                zrot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdrot.f">
                zdrot
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.9.
            </span>
            cublas&lt;t&gt;rotg()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rotg"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSrotg</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">b</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDrotg</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">b</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCrotg</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">b</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZrotg</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">a</span><span class="p">,</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">b</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">s</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function constructs the Givens rotation matrix
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(G = \begin{pmatrix}
                c &amp; s \\
                {- s} &amp; c \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            that zeros out the second entry of a
            <span class="math notranslate nohighlight">
                \(2 \times 1\)
            </span>
            vector
            <span class="math notranslate nohighlight">
                \(\left( {a,b} \right)^{T}\)
            </span>
            .
        </p>
        <p>
            Then, for real numbers we can write
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\begin{pmatrix}
                c &amp; s \\
                {- s} &amp; c \\
                \end{pmatrix}\begin{pmatrix}
                a \\
                b \\
                \end{pmatrix} = \begin{pmatrix}
                r \\
                0 \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(c^{2} + s^{2} = 1\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(r = a^{2} + b^{2}\)
            </span>
            . The parameters
            <span class="math notranslate nohighlight">
                \(a\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(b\)
            </span>
            are overwritten with
            <span class="math notranslate nohighlight">
                \(r\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(z\)
            </span>
            , respectively. The value of
            <span class="math notranslate nohighlight">
                \(z\)
            </span>
            is such that
            <span class="math notranslate nohighlight">
                \(c\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(s\)
            </span>
            may be recovered using the following rules:
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\left( {c,s} \right) = \begin{cases}
                \left( {\sqrt{1 - z^{2}},z} \right) &amp; {\text{ if }\left| z \middle| &lt; 1 \right.} \\
                \left( {0.0,1.0} \right) &amp; {\text{ if }\left| z \middle| = 1 \right.} \\
                \left( 1/z,\sqrt{1 - z^{2}} \right) &amp; {\text{ if }\left| z \middle| &gt; 1 \right.} \\
                \end{cases}\)
            </span>
        </p>
        <p>
            For complex numbers we can write
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\begin{pmatrix}
                c &amp; s \\
                {- \bar{s}} &amp; c \\
                \end{pmatrix}\begin{pmatrix}
                a \\
                b \\
                \end{pmatrix} = \begin{pmatrix}
                r \\
                0 \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(c^{2} + \left( {\bar{s} \times s} \right) = 1\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(r = \frac{a}{|a|} \times \parallel \left( {a,b} \right)^{T} \parallel_{2}\)
            </span>
            with
            <span class="math notranslate nohighlight">
                \(\parallel \left( {a,b} \right)^{T} \parallel_{2} = \sqrt{\left| a|^{2} + \middle| b|^{2} \right.}\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(a \neq 0\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(r = b\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(a = 0\)
            </span>
            . Finally, the parameter
            <span class="math notranslate nohighlight">
                \(a\)
            </span>
            is overwritten with
            <span class="math notranslate nohighlight">
                \(r\)
            </span>
            on exit.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        a
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar that is overwritten with
                        <span class="math notranslate nohighlight">
                            \(r\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        b
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar that is overwritten with
                        <span class="math notranslate nohighlight">
                            \(z\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        c
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        cosine element of the rotation matrix.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        s
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        sine element of the rotation matrix.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/srotg.f90">
                srotg
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/drotg.f90">
                drotg
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/crotg.f90">
                crotg
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zrotg.f90">
                zrotg
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.10.
            </span>
            cublas&lt;t&gt;rotm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rotm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSrotm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">param</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDrotm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">param</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function applies the modified Givens transformation
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(H = \begin{pmatrix}
                h_{11} &amp; h_{12} \\
                h_{21} &amp; h_{22} \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            to vectors
            <span class="pre">
                x
            </span>
            and
            <span class="pre">
                y
            </span>
            .
        </p>
        <p>
            Hence, the result is
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\lbrack k\rbrack = h_{11} \times \mathbf{x}\lbrack k\rbrack + h_{12} \times
                \mathbf{y}\lbrack j\rbrack\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\lbrack j\rbrack = h_{21} \times \mathbf{x}\lbrack k\rbrack + h_{22} \times
                \mathbf{y}\lbrack j\rbrack\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <p>
            The elements , , and of matrix
            <span class="math notranslate nohighlight">
                \(H\)
            </span>
            are stored in
            <span class="pre">
                param[1]
            </span>
            ,
            <span class="pre">
                param[2]
            </span>
            ,
            <span class="pre">
                param[3]
            </span>
            and
            <span class="pre">
                param[4]
            </span>
            , respectively. The
            <span class="pre">
                flag=param[0]
            </span>
            defines the following predefined values for the matrix
            <span class="math notranslate nohighlight">
                \(H\)
            </span>
            entries
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=-1.0
                        </span>
                    </p>
                </th>
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=
                        </span>
                        <span class="pre">
                            0.0
                        </span>
                    </p>
                </th>
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=
                        </span>
                        <span class="pre">
                            1.0
                        </span>
                    </p>
                </th>
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=-2.0
                        </span>
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            h_{11} &amp; h_{12} \\
                            h_{21} &amp; h_{22} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            {1.0} &amp; h_{12} \\
                            h_{21} &amp; {1.0} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            h_{11} &amp; {1.0} \\
                            {- 1.0} &amp; h_{22} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            {1.0} &amp; {0.0} \\
                            {0.0} &amp; {1.0} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Notice that the values -1.0, 0.0 and 1.0 implied by the flag are not stored in param.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vectors
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        param
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector of 5 elements, where
                        <span class="pre">
                            param[0]
                        </span>
                        and
                        <span class="pre">
                            param[1-4]
                        </span>
                        contain the flag and matrix
                        <span class="math notranslate nohighlight">
                            \(H\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/srotm.f">
                srotm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/drotm.f">
                drotm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.11.
            </span>
            cublas&lt;t&gt;rotmg()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rotmg"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSrotmg</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">d1</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">d2</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x1</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">y1</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">param</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDrotmg</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">d1</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">d2</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x1</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">y1</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">param</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function constructs the modified Givens transformation
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(H = \begin{pmatrix}
                h_{11} &amp; h_{12} \\
                h_{21} &amp; h_{22} \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            that zeros out the second entry of a
            <span class="math notranslate nohighlight">
                \(2 \times 1\)
            </span>
            vector
            <span class="math notranslate nohighlight">
                \(\left( {\sqrt{d1}*x1,\sqrt{d2}*y1} \right)^{T}\)
            </span>
            .
        </p>
        <p>
            The
            <span class="pre">
                flag=param[0]
            </span>
            defines the following predefined values for the matrix
            <span class="math notranslate nohighlight">
                \(H\)
            </span>
            entries
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=-1.0
                        </span>
                    </p>
                </th>
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=
                        </span>
                        <span class="pre">
                            0.0
                        </span>
                    </p>
                </th>
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=
                        </span>
                        <span class="pre">
                            1.0
                        </span>
                    </p>
                </th>
                <th class="head">
                    <p>
                        <span class="pre">
                            flag=-2.0
                        </span>
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            h_{11} &amp; h_{12} \\
                            h_{21} &amp; h_{22} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            {1.0} &amp; h_{12} \\
                            h_{21} &amp; {1.0} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            h_{11} &amp; {1.0} \\
                            {- 1.0} &amp; h_{22} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="math notranslate nohighlight">
                            \(\begin{pmatrix}
                            {1.0} &amp; {0.0} \\
                            {0.0} &amp; {1.0} \\
                            \end{pmatrix}\)
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Notice that the values -1.0, 0.0 and 1.0 implied by the flag are not stored in param.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        d1
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar that is overwritten on exit.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        d2
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar that is overwritten on exit.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x1
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar that is overwritten on exit.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y1
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        param
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector of 5 elements, where
                        <span class="pre">
                            param[0]
                        </span>
                        and
                        <span class="pre">
                            param[1-4]
                        </span>
                        contain the flag and matrix
                        <span class="math notranslate nohighlight">
                            \(H\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/srotmg.f">
                srotmg
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/drotmg.f">
                drotmg
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.12.
            </span>
            cublas&lt;t&gt;scal()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-scal"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSscal</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDscal</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCscal</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsscal</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZscal</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZdscal</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function scales the vector
            <span class="pre">
                x
            </span>
            by the scalar
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and overwrites it with the result. Hence, the performed operation is
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\lbrack j\rbrack = \alpha \times \mathbf{x}\lbrack j\rbrack\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="docutils align-default" id="id102">
            <span class="caption-text">
                :class: table-no-stripes
            </span>
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id102"
                title="Permalink to this table">
                
            </a>
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sscal.f">
                sscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dscal.f">
                dscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csscal.f">
                csscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cscal.f">
                cscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdscal.f">
                zdscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zscal.f">
                zscal
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.5.13.
            </span>
            cublas&lt;t&gt;swap()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-swap"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSswap</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDswap</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCswap</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZswap</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function interchanges the elements of vector
            <span class="pre">
                x
            </span>
            and
            <span class="pre">
                y
            </span>
            . Hence, the performed operation is
            <span class="math notranslate nohighlight">
                \(\left. \mathbf{y}\lbrack j\rbrack\Leftrightarrow\mathbf{x}\lbrack k\rbrack \right.\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sswap.f">
                sswap
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dswap.f">
                dswap
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cswap.f">
                cswap
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zswap.f">
                zswap
            </a>
        </p>
        <h2>
            <span class="section-number">
                2.6.
            </span>
            cuBLAS Level-2 Function Reference
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-2-function-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            In this chapter we describe the Level-2 Basic Linear Algebra Subprograms (BLAS2) functions that perform
            matrix-vector operations.
        </p>
        <h3>
            <span class="section-number">
                2.6.1.
            </span>
            cublas&lt;t&gt;gbmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gbmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">kl</span><span class="p">,</span><span class="kt">int</span><span class="n">ku</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">kl</span><span class="p">,</span><span class="kt">int</span><span class="n">ku</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">kl</span><span class="p">,</span><span class="kt">int</span><span class="n">ku</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">kl</span><span class="p">,</span><span class="kt">int</span><span class="n">ku</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the banded matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\mathbf{y} = \alpha\text{ op}(A)\mathbf{x} + \beta\mathbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a banded matrix with
            <span class="math notranslate nohighlight">
                \(kl\)
            </span>
            subdiagonals and
            <span class="math notranslate nohighlight">
                \(ku\)
            </span>
            superdiagonals,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{ op}(A) = \begin{cases}
                A &amp; \text{ if transa == $\mathrm{CUBLAS\_OP\_N}$} \\
                A^{T} &amp; \text{ if transa == $\mathrm{CUBLAS\_OP\_T}$} \\
                A^{H} &amp; \text{ if transa == $\mathrm{CUBLAS\_OP\_C}$} \\
                \end{cases}\)
            </span>
        </p>
        <p>
            The banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal stored in row
            <span class="math notranslate nohighlight">
                \(ku + 1\)
            </span>
            (starting in first position), the first superdiagonal stored in row
            <span class="math notranslate nohighlight">
                \(ku\)
            </span>
            (starting in second position), the first subdiagonal stored in row
            <span class="math notranslate nohighlight">
                \(ku + 2\)
            </span>
            (starting in first position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A\left( {i,j} \right)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(ku+1+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \left\lbrack {\max\left( {1,j - ku} \right),\min\left( {m,j + kl} \right)} \right\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the top left
            <span class="math notranslate nohighlight">
                \(ku \times ku\)
            </span>
            and bottom right
            <span class="math notranslate nohighlight">
                \(kl \times kl\)
            </span>
            triangles) are not referenced.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        kl
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of subdiagonals of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ku
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of superdiagonals of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=kl+ku+1
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            m
                        </span>
                        elements otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            m
                        </span>
                        elements if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            n
                        </span>
                        elements otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m,
                                </span>
                                <span class="pre">
                                    n,
                                </span>
                                <span class="pre">
                                    kl,
                                </span>
                                <span class="pre">
                                    ku
                                </span>
                                <span class="pre">
                                    &lt;
                                </span>
                                <span class="pre">
                                    0
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                <span class="pre">
                                    &lt;
                                </span>
                                <span class="pre">
                                    (kl+ku+1)
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx,
                                </span>
                                <span class="pre">
                                    incy
                                </span>
                                <span class="pre">
                                    ==
                                </span>
                                <span class="pre">
                                    0
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                != CUBLAS_OP_N, CUBLAS_OP_T, CUBLAS_OP_C or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha,
                                </span>
                                <span class="pre">
                                    beta
                                </span>
                                <span class="pre">
                                    ==
                                </span>
                                <span class="pre">
                                    NULL
                                </span>
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sgbmv.f">
                sgbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dgbmv.f">
                dgbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cgbmv.f">
                cgbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgbmv.f">
                zgbmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.2.
            </span>
            cublas&lt;t&gt;gemv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgemv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha\text{ op}(A)\textbf{x} + \beta\textbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrix stored in column-major format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{ op}(A) = \begin{cases}
                A &amp; \text{ if transa == $\mathrm{CUBLAS\_OP\_N}$} \\
                A^{T} &amp; \text{ if transa == $\mathrm{CUBLAS\_OP\_T}$} \\
                A^{H} &amp; \text{ if transa == $\mathrm{CUBLAS\_OP\_C}$} \\
                \end{cases}\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            &gt;=
                        </span>
                        <span class="pre">
                            max(1,m)
                        </span>
                        . Before entry, the leading
                        <span class="pre">
                            m
                        </span>
                        by
                        <span class="pre">
                            n
                        </span>
                        part of the array
                        <span class="pre">
                            A
                        </span>
                        must contain the matrix of coefficients. Unchanged on exit.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                        <span class="pre">
                            lda
                        </span>
                        must be at least
                        <span class="pre">
                            max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector at least
                        <span class="pre">
                            (1+(n-1)*abs(incx))
                        </span>
                        elements if
                        <span class="pre">
                            transa==CUBLAS_OP_N
                        </span>
                        and at least
                        <span class="pre">
                            (1+(m-1)*abs(incx))
                        </span>
                        elements otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector at least
                        <span class="pre">
                            (1+(m-1)*abs(incy))
                        </span>
                        elements if
                        <span class="pre">
                            transa==CUBLAS_OP_N
                        </span>
                        and at least
                        <span class="pre">
                            (1+(n-1)*abs(incy))
                        </span>
                        elements otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n&lt;0
                        </span>
                        or
                        <span class="pre">
                            incx,incy=0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sgemv.f">
                sgemv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dgemv.f">
                dgemv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cgemv.f">
                cgemv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgemv.f">
                zgemv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.3.
            </span>
            cublas&lt;t&gt;ger()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-ger"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSger</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDger</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgeru</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgerc</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgeru</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgerc</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the rank-1 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \begin{cases}
                {\alpha\mathbf{xy}^{T} + A} &amp; \text{if ger(),geru() is called} \\
                {\alpha\mathbf{xy}^{H} + A} &amp; \text{if gerc() is called} \\
                \end{cases}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrix stored in column-major format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            m
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            &gt;=
                        </span>
                        <span class="pre">
                            max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sger.f">
                sger
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dger.f">
                dger
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cgeru.f">
                cgeru
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cgerc.f">
                cgerc
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgeru.f">
                zgeru
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgerc.f">
                zgerc
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.4.
            </span>
            cublas&lt;t&gt;sbmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-sbmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric banded matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha A\textbf{x} + \beta\textbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric banded matrix with
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            subdiagonals and superdiagonals,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the symmetric banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row 1, the first subdiagonal in
            row 2 (starting at first position), the second subdiagonal in row 3 (starting at first position), etc. So
            that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack j,\min(m,j + k)\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the bottom right
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the symmetric banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                k+1
            </span>
            , the first superdiagonal in row
            <span class="pre">
                k
            </span>
            (starting at second position), the second superdiagonal in row
            <span class="pre">
                k-1
            </span>
            (starting at third position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+k+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack\max(1,j - k),j\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the top left
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of sub- and super-diagonals of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            &gt;=
                        </span>
                        <span class="pre">
                            k+1
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; (1 +
                                <span class="pre">
                                    k
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssbmv.f">
                ssbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsbmv.f">
                dsbmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.5.
            </span>
            cublas&lt;t&gt;spmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-spmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSspmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDspmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric packed matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha A\textbf{x} + \beta\textbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sspmv.f">
                sspmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dspmv.f">
                dspmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.6.
            </span>
            cublas&lt;t&gt;spr()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-spr"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSspr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDspr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the packed symmetric rank-1 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\textbf{x}\textbf{x}^{T} + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sspr.f">
                sspr
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dspr.f">
                dspr
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.7.
            </span>
            cublas&lt;t&gt;spr2()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-spr2"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSspr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDspr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the packed symmetric rank-2 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\left( {\textbf{x}\textbf{y}^{T} + \textbf{y}\textbf{x}^{T}} \right) + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sspr2.f">
                sspr2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dspr2.f">
                dspr2
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.8.
            </span>
            cublas&lt;t&gt;symv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id2"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsymv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsymv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsymv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="cm">/* host or device pointer */</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsymv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric matrix-vector multiplication.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha A\textbf{x} + \beta\textbf{y}\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in lower or upper mode,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            This function has an alternate faster implementation using atomics that can be enabled with
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetatomicsmode">
                cublasSetAtomicsMode()
            </a>
            .
        </p>
        <p>
            Please see the section on the function
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetatomicsmode">
                cublasSetAtomicsMode()
            </a>
            for more details about the usage of atomics.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix lower or upper part is stored, the other symmetric part is not referenced
                        and is inferred from the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt;
                                <span class="pre">
                                    n
                                </span>
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssymv.f">
                ssymv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsymv.f">
                dsymv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.9.
            </span>
            cublas&lt;t&gt;syr()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syr"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsyr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsyr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsyr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsyr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric rank-1 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\textbf{x}\textbf{x}^{T} + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in column-major format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyr.f">
                ssyr
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyr.f">
                dsyr
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.10.
            </span>
            cublas&lt;t&gt;syr2()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syr2"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsyr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsyr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsyr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsyr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric rank-2 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\left( {\textbf{x}\textbf{y}^{T} + \textbf{y}\textbf{x}^{T}} \right) + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in column-major format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/db/d99/ssyr2_8f_source.html">
                ssyr2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/de/d41/dsyr2_8f_source.html">
                dsyr2
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.11.
            </span>
            cublas&lt;t&gt;tbmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tbmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the triangular banded matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{x} = \text{op}(A)\textbf{x}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular banded matrix, and
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the triangular banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                1
            </span>
            , the first subdiagonal in row
            <span class="pre">
                2
            </span>
            (starting at first position), the second subdiagonal in row
            <span class="pre">
                3
            </span>
            (starting at first position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack j,\min(m,j + k)\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the bottom right
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the triangular banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                k+1
            </span>
            , the first superdiagonal in row
            <span class="pre">
                k
            </span>
            (starting at second position), the second superdiagonal in row
            <span class="pre">
                k-1
            </span>
            (starting at third position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+k+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack\max(1,j - k,j)\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the top left
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of sub- and super-diagonals of matrix .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=k+1
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; (1 +
                                <span class="pre">
                                    k
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the allocation of internal scratch memory failed
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/stbmv.f">
                stbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtbmv.f">
                dtbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctbmv.f">
                ctbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztbmv.f">
                ztbmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.12.
            </span>
            cublas&lt;t&gt;tbsv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tbsv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStbsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtbsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtbsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtbsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function solves the triangular banded linear system with a single right-hand-side
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\textbf{x} = \textbf{b}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular banded matrix, and
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{b}\)
            </span>
            are vectors. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            The solution
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            overwrites the right-hand-sides
            <span class="math notranslate nohighlight">
                \(\mathbf{b}\)
            </span>
            on exit.
        </p>
        <p>
            No test for singularity or near-singularity is included in this function.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the triangular banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                1
            </span>
            , the first subdiagonal in row
            <span class="pre">
                2
            </span>
            (starting at first position), the second subdiagonal in row
            <span class="pre">
                3
            </span>
            (starting at first position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack j,\min(m,j + k)\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the bottom right
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the triangular banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                k+1
            </span>
            , the first superdiagonal in row
            <span class="pre">
                k
            </span>
            (starting at second position), the second superdiagonal in row
            <span class="pre">
                k-1
            </span>
            (starting at third position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+k+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack\max(1,j - k,j)\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the top left
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of sub- and super-diagonals of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            &gt;=
                        </span>
                        <span class="pre">
                            k+1
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; (1 +
                                <span class="pre">
                                    k
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/stbsv.f">
                stbsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtbsv.f">
                dtbsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctbsv.f">
                ctbsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztbsv.f">
                ztbsv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.13.
            </span>
            cublas&lt;t&gt;tpmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tpmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStpmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtpmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtpmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtpmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the triangular packed matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{x} = \text{op}(A)\textbf{x}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in packed format, and
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the triangular matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the triangular matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                <span class="pre">
                                    &lt;
                                </span>
                                <span class="pre">
                                    0
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                <span class="pre">
                                    ==
                                </span>
                                <span class="pre">
                                    0
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                <span class="pre">
                                    !=
                                </span>
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER,
                                </span>
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                <span class="pre">
                                    !=
                                </span>
                                <span class="pre">
                                    CUBLAS_OP_N,
                                </span>
                                <span class="pre">
                                    CUBLAS_OP_T,
                                </span>
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    diag
                                </span>
                                <span class="pre">
                                    !=
                                </span>
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT,
                                </span>
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the allocation of internal scratch memory failed
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/stpmv.f">
                stpmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtpmv.f">
                dtpmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctpmv.f">
                ctpmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztpmv.f">
                ztpmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.14.
            </span>
            cublas&lt;t&gt;tpsv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tpsv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStpsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtpsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtpsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtpsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function solves the packed triangular linear system with a single right-hand-side
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\textbf{x} = \textbf{b}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in packed format, and
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{b}\)
            </span>
            are vectors. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            The solution
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            overwrites the right-hand-sides
            <span class="math notranslate nohighlight">
                \(\mathbf{b}\)
            </span>
            on exit.
        </p>
        <p>
            No test for singularity or near-singularity is included in this function.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the triangular matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the triangular matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="pre">
                            A
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/stpsv.f">
                stpsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtpsv.f">
                dtpsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctpsv.f">
                ctpsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztpsv.f">
                ztpsv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.15.
            </span>
            cublas&lt;t&gt;trmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStrmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtrmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtrmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtrmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the triangular matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{x} = \text{op}(A)\textbf{x}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal, and
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) (that is, non- or conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the allocation of internal scratch memory failed
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strmv.f">
                strmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrmv.f">
                dtrmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrmv.f">
                ctrmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrmv.f">
                ztrmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.16.
            </span>
            cublas&lt;t&gt;trsv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStrsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtrsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtrsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtrsv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function solves the triangular linear system with a single right-hand-side
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\textbf{x} = \textbf{b}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal, and
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{b}\)
            </span>
            are vectors. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            The solution
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            overwrites the right-hand-sides
            <span class="math notranslate nohighlight">
                \(\mathbf{b}\)
            </span>
            on exit.
        </p>
        <p>
            No test for singularity or near-singularity is included in this function.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strsv.f">
                strsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrsv.f">
                dtrsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrsv.f">
                ctrsv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrsv.f">
                ztrsv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.17.
            </span>
            cublas&lt;t&gt;hemv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id3"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasChemv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZhemv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha A\textbf{x} + \beta\textbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian matrix stored in lower or upper mode,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            This function has an alternate faster implementation using atomics that can be enabled with
        </p>
        <p>
            Please see the section on the for more details about the usage of atomics
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed to be zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt;
                                <span class="pre">
                                    n
                                </span>
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/chemv.f">
                chemv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zhemv.f">
                zhemv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.18.
            </span>
            cublas&lt;t&gt;hbmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hbmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasChbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZhbmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian banded matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha A\textbf{x} + \beta\textbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian banded matrix with
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            subdiagonals and superdiagonals,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the Hermitian banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                1
            </span>
            , the first subdiagonal in row
            <span class="pre">
                2
            </span>
            (starting at first position), the second subdiagonal in row
            <span class="pre">
                3
            </span>
            (starting at first position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack j,\min(m,j + k)\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the bottom right
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the Hermitian banded matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is stored column by column, with the main diagonal of the matrix stored in row
            <span class="pre">
                k+1
            </span>
            , the first superdiagonal in row
            <span class="pre">
                k
            </span>
            (starting at second position), the second superdiagonal in row
            <span class="pre">
                k-1
            </span>
            (starting at third position), etc. So that in general, the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                A(1+k+i-j,j)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \in \lbrack\max(1,j - k),j\rbrack\)
            </span>
            . Also, the elements in the array
            <span class="pre">
                A
            </span>
            that do not conceptually correspond to the elements in the banded matrix (the top left
            <span class="math notranslate nohighlight">
                \(k \times k\)
            </span>
            triangle) are not referenced.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of sub- and super-diagonals of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=k+1
                        </span>
                        . The imaginary parts of the diagonal elements are assumed to be zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                = 0 or
                                <span class="pre">
                                    incy
                                </span>
                                = 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; (
                                <span class="pre">
                                    k
                                </span>
                                + 1) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/chbmv.f">
                chbmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zhbmv.f">
                zhbmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.19.
            </span>
            cublas&lt;t&gt;hpmv()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hpmv"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasChpmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZhpmv</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian packed matrix-vector multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} = \alpha A\textbf{x} + \beta\textbf{y}\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the Hermitian matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the Hermitian matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="pre">
                            A
                        </span>
                        stored in packed format. The imaginary parts of the diagonal elements are assumed to be zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                == 0 or
                                <span class="pre">
                                    incy
                                </span>
                                == 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/chpmv.f">
                chpmv
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zhpmv.f">
                zhpmv
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.20.
            </span>
            cublas&lt;t&gt;her()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-her"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCher</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZher</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian rank-1 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\textbf{x}\textbf{x}^{H} + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian matrix stored in column-major format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                == 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cher.f">
                cher
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zher.f">
                zher
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.21.
            </span>
            cublas&lt;t&gt;her2()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-her2"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCher2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZher2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian rank-2 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\textbf{x}\textbf{y}^{H} + \overset{}{\alpha}\textbf{y}\textbf{x}^{H} + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian matrix stored in column-major format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                == 0 or
                                <span class="pre">
                                    incy
                                </span>
                                == 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            cher2, zher2
        </p>
        <h3>
            <span class="section-number">
                2.6.22.
            </span>
            cublas&lt;t&gt;hpr()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hpr"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasChpr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZhpr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the packed Hermitian rank-1 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\textbf{x}\textbf{x}^{H} + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            is a vector, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the Hermitian matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the Hermitian matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="pre">
                            A
                        </span>
                        stored in packed format. The imaginary parts of the diagonal elements are assumed and set to
                        zero.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                == 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/chpr.f">
                chpr
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zhpr.f">
                zhpr
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.6.23.
            </span>
            cublas&lt;t&gt;hpr2()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hpr2"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasChpr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZhpr2</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the packed Hermitian rank-2 update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(A = \alpha\textbf{x}\textbf{y}^{H} + \overset{}{\alpha}\textbf{y}\textbf{x}^{H} + A\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            Hermitian matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            are vectors, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the Hermitian matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the Hermitian matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="pre">
                            A
                        </span>
                        stored in packed format. The imaginary parts of the diagonal elements are assumed and set to
                        zero.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    incx
                                </span>
                                == 0 or
                                <span class="pre">
                                    incy
                                </span>
                                == 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            chpr2, zhpr2
        </p>
        <h3>
            <span class="section-number">
                2.6.24.
            </span>
            cublas&lt;t&gt;gemvBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemvbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>

<span class="cp">#if defined(__cplusplus)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasHSHgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasHSSgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasTSTgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__nv_bfloat16</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasTSSgemvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="k">const</span><span class="n">xarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">yarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="cp">#endif</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-vector multiplication of a batch of matrices and vectors. The batch is
            considered to be uniform, i.e. all instances have the same dimensions (m, n), leading dimension (lda),
            increments (incx, incy) and transposition (trans) for their respective A matrix, x and y vectors. The
            address of the input matrix and vector, and the output vector of each instance of the batch are read from
            arrays of pointers passed to the function by the caller.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y}\lbrack i\rbrack = \alpha\text{op}(A\lbrack i\rbrack)\textbf{x}\lbrack i\rbrack +
                \beta\textbf{y}\lbrack i\rbrack,\text{ for i} \in \lbrack 0,batchCount - 1\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is an array of pointers to matrice
            <span class="math notranslate nohighlight">
                \(A\lbrack i\rbrack\)
            </span>
            stored in column-major format with dimension
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , and
            <span class="math notranslate nohighlight">
                \(\textbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\textbf{y}\)
            </span>
            are arrays of pointers to vectors. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\lbrack i\rbrack\)
            </span>
            ,
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack) = \left\{ \begin{matrix}
                {A\lbrack i\rbrack} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A\lbrack i\rbrack}^{T} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                {A\lbrack i\rbrack}^{H} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y}\lbrack i\rbrack\)
            </span>
            vectors must not overlap, i.e. the individual gemv operations must be computable independently; otherwise,
            undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemv">
                cublas&lt;t&gt;gemv
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        .
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        xarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each dimension
                        <span class="pre">
                            n
                        </span>
                        if
                        <span class="pre">
                            trans==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            m
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride of each one-dimensional array x[i].
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        ,
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        yarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array. It has dimensions
                        <span class="pre">
                            m
                        </span>
                        if
                        <span class="pre">
                            trans==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            n
                        </span>
                        otherwise. Vectors
                        <span class="pre">
                            y[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride of each one-dimensional array y[i].
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in Aarray, xarray and yarray.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            If math mode enables fast math modes when using
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemvbatched">
                cublasSgemvBatched()
            </a>
            , pointers (not the pointer arrays) placed in the GPU memory must be properly aligned to avoid misaligned
            memory access errors. Ideally all pointers are aligned to at least 16 Bytes. Otherwise it is recommended
            that they meet the following rule:
        </p>
        <ul class="simple">
            <li>
                <p>
                    if
                    <span class="pre">
                        k
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        4==0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    ,
                </p>
            </li>
        </ul>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n,batchCount&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.6.25.
            </span>
            cublas&lt;t&gt;gemvStridedBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemvstridedbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasHSHgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__half</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasHSSgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasTSTgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__nv_bfloat16</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasTSSgemvStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">__nv_bfloat16</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridex</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">y</span><span class="p">,</span><span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">stridey</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-vector multiplication of a batch of matrices and vectors. The batch is
            considered to be uniform, i.e. all instances have the same dimensions (m, n), leading dimension (lda),
            increments (incx, incy) and transposition (trans) for their respective A matrix, x and y vectors. Input
            matrix A and vector x, and output vector y for each instance of the batch are located at fixed offsets in
            number of elements from their locations in the previous instance. Pointers to A matrix, x and y vectors for
            the first instance are passed to the function by the user along with offsets in number of elements -
            strideA, stridex and stridey that determine the locations of input matrices and vectors, and output vectors
            in future instances.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y} + i*{stridey} = \alpha\text{op}(A + i*{strideA})(\textbf{x} + i*{stridex}) +
                \beta(\textbf{y} + i*{stridey}),\text{ for i } \in \lbrack 0,batchCount - 1\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is an array of pointers to matrix stored in column-major format with dimension
            <span class="math notranslate nohighlight">
                \(A\lbrack i\rbrack\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , and
            <span class="math notranslate nohighlight">
                \(\textbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\textbf{y}\)
            </span>
            are arrays of pointers to vectors. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\lbrack i\rbrack\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack) = \left\{ \begin{matrix}
                {A\lbrack i\rbrack} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A\lbrack i\rbrack}^{T} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                {A\lbrack i\rbrack}^{H} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\textbf{y}\lbrack i\rbrack\)
            </span>
            matrices must not overlap, i.e. the individual gemv operations must be computable independently; otherwise,
            undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemv">
                cublas&lt;t&gt;gemv
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            In the table below, we use
            <span class="pre">
                A[i],
            </span>
            <span class="pre">
                x[i],
            </span>
            <span class="pre">
                y[i]
            </span>
            as notation for A matrix, and x and y vectors in the ith instance of the batch, implicitly assuming they are
            respectively offsets in number of elements
            <span class="pre">
                strideA,
            </span>
            <span class="pre">
                stridex,
            </span>
            <span class="pre">
                stridey
            </span>
            away from
            <span class="pre">
                A[i-1],
            </span>
            <span class="pre">
                x[i-1],
            </span>
            <span class="pre">
                y[i-1]
            </span>
            . The unit for the offset is number of elements and must not be zero .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt;* pointer to the A matrix corresponding to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        strideA
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            A[i]
                        </span>
                        and
                        <span class="pre">
                            A[i+1]
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt;* pointer to the x vector corresponding to the first instance of the batch, with
                        each dimension
                        <span class="pre">
                            n
                        </span>
                        if
                        <span class="pre">
                            trans==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            m
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride of each one-dimensional array x[i].
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        stridex
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            x[i]
                        </span>
                        and
                        <span class="pre">
                            x[i+1]
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        ,
                        <span class="pre">
                            y
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt;* pointer to the y vector corresponding to the first instance of the batch, with
                        each dimension
                        <span class="pre">
                            m
                        </span>
                        if
                        <span class="pre">
                            trans==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            n
                        </span>
                        otherwise. Vectors
                        <span class="pre">
                            y[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride of each one-dimensional array y[i].
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        stridey
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            y[i]
                        </span>
                        and
                        <span class="pre">
                            y[i+1]
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of GEMVs to perform in the batch.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n,batchCount&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <h2>
            <span class="section-number">
                2.7.
            </span>
            cuBLAS Level-3 Function Reference
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-level-3-function-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            In this chapter we describe the Level-3 Basic Linear Algebra Subprograms (BLAS3) functions that perform
            matrix-matrix operations.
        </p>
        <h3>
            <span class="section-number">
                2.7.1.
            </span>
            cublas&lt;t&gt;gemm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasHgemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__half</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            B
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            A
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                ,
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                ,
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                ,
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        in the case of
                        <a class="reference external"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                            cublasHgemm()
                        </a>
                        the device does not support math in half precision.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sgemm.f">
                sgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dgemm.f">
                dgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cgemm.f">
                cgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgemm.f">
                zgemm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.2.
            </span>
            cublas&lt;t&gt;gemm3m()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm3m"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCgemm3m</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemm3m</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the complex matrix-matrix multiplication, using Gauss complexity reduction algorithm.
            This can lead to an increase in performance up to 25%
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            These 2 routines are only supported on GPUs with architecture capabilities equal to or greater than 5.0
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            B
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of op(
                        <span class="pre">
                            A
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed in the following table:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                ,
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                ,
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                ,
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The device has a compute capabilites lower than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cgemm.f">
                cgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgemm.f">
                zgemm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.3.
            </span>
            cublas&lt;t&gt;gemmBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasHgemmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__half</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasSgemmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix multiplication of a batch of matrices. The batch is considered to
            be uniform, i.e. all instances have the same dimensions (m, n, k), leading dimensions (lda, ldb, ldc)
            and transpositions (transa, transb) for their respective A, B and C matrices. The address of the input
            matrices and the output matrix of each instance of the batch are read from arrays of pointers passed to the
            function by the caller.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack = \alpha\text{op}(A\lbrack i\rbrack)\text{op}(B\lbrack i\rbrack) + \beta C\lbrack
                i\rbrack,\text{ for i } \in \lbrack 0,batchCount - 1\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are arrays of pointers to matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            matrices must not overlap, that is, the individual gemm operations must be computable independently;
            otherwise, undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B[i]
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Barray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        max(1,) otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            B[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Carray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array. It has dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        . Matrices
                        <span class="pre">
                            C[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in Aarray, Barray and Carray.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            If math mode enables fast math modes when using
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched">
                cublasSgemmBatched()
            </a>
            , pointers (not the pointer arrays) placed in the GPU memory must be properly aligned to avoid misaligned
            memory access errors. Ideally all pointers are aligned to at least 16 Bytes. Otherwise it is recommended
            that they meet the following rule:
        </p>
        <ul class="simple">
            <li>
                <p>
                    if
                    <span class="pre">
                        k%4==0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    ,
                </p>
            </li>
        </ul>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                ,
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                ,
                                <span class="pre">
                                    batchCount
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                ,
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <a class="reference external"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched">
                            cublasHgemmBatched()
                        </a>
                        is only supported for GPU with architecture capabilities equal or greater than 5.3
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.7.4.
            </span>
            cublas&lt;t&gt;gemmStridedBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmstridedbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasHgemmStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="n">__half</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">__half</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasSgemmStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemmStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemmStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemm3mStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgemmStridedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix multiplication of a batch of matrices. The batch is considered to
            be uniform, i.e. all instances have the same dimensions (m, n, k), leading dimensions (lda, ldb, ldc)
            and transpositions (transa, transb) for their respective A, B and C matrices. Input matrices A, B and output
            matrix C for each instance of the batch are located at fixed offsets in number of elements from their
            locations in the previous instance. Pointers to A, B and C matrices for the first instance are passed to the
            function by the user along with offsets in number of elements - strideA, strideB and strideC that determine
            the locations of input and output matrices in future instances.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C + i*{strideC} = \alpha\text{op}(A + i*{strideA})\text{op}(B + i*{strideB}) + \beta(C +
                i*{strideC}),\text{ for i } \in \lbrack 0,batchCount - 1\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are arrays of pointers to matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            matrices must not overlap, i.e. the individual gemm operations must be computable independently; otherwise,
            undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            In the table below, we use
            <span class="pre">
                A[i],
            </span>
            <span class="pre">
                B[i],
            </span>
            <span class="pre">
                C[i]
            </span>
            as notation for A, B and C matrices in the ith instance of the batch, implicitly assuming they are
            respectively offsets in number of elements
            <span class="pre">
                strideA,
            </span>
            <span class="pre">
                strideB,
            </span>
            <span class="pre">
                strideC
            </span>
            away from
            <span class="pre">
                A[i-1],
            </span>
            <span class="pre">
                B[i-1],
            </span>
            <span class="pre">
                C[i-1]
            </span>
            . The unit for the offset is number of elements and must not be zero .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B[i]
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt;* pointer to the A matrix corresponding to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        strideA
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            A[i]
                        </span>
                        and
                        <span class="pre">
                            A[i+1]
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt;* pointer to the B matrix corresponding to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        max(1,) otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            B[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        strideB
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            B[i]
                        </span>
                        and
                        <span class="pre">
                            B[i+1]
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt;* pointer to the C matrix corresponding to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        . Matrices
                        <span class="pre">
                            C[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        strideC
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            C[i]
                        </span>
                        and
                        <span class="pre">
                            C[i+1]
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of GEMMs to perform in the batch.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                ,
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                ,
                                <span class="pre">
                                    batchCount
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                ,
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <a class="reference external"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmstridedbatched">
                            cublasHgemmStridedBatched()
                        </a>
                        is only supported for GPU with architecture capabilities equal or greater than 5.3
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.7.5.
            </span>
            cublas&lt;t&gt;gemmGroupedBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmgroupedbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgemmGroupedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="k">const</span><span class="n">cublasOperation_t</span><span class="n">transa_array</span><span class="p">[],</span>
<span class="k">const</span><span class="n">cublasOperation_t</span><span class="n">transb_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">m_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">n_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">k_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">float</span><span class="n">alpha_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">lda_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">ldb_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">float</span><span class="n">beta_array</span><span class="p">[],</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">ldc_array</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">group_count</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="n">group_size</span><span class="p">[])</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgemmGroupedBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="k">const</span><span class="n">cublasOperation_t</span><span class="n">transa_array</span><span class="p">[],</span>
<span class="k">const</span><span class="n">cublasOperation_t</span><span class="n">transb_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">m_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">n_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">k_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">double</span><span class="n">alpha_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">lda_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">ldb_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">double</span><span class="n">beta_array</span><span class="p">[],</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">ldc_array</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">group_count</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="n">group_size</span><span class="p">[])</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix multiplication on groups of matrices. A given group is considered
            to be uniform, i.e. all instances have the same dimensions (m, n, k), leading dimensions (lda, ldb,
            ldc) and transpositions (transa, transb) for their respective A, B and C matrices. However, the dimensions,
            leading dimensions, transpositions, and scaling factors (alpha, beta) may vary between groups. The address
            of the input matrices and the output matrix of each instance of the batch are read from arrays of pointers
            passed to the function by the caller. This is functionally equivalent to the following:
        </p>
        <pre><span class="n">idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="k">for</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span><span class="n">group_count</span><span class="o">-</span><span class="mi">1</span>
<span class="k">for</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span><span class="n">group_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>
<span class="n">gemm</span><span class="p">(</span><span class="n">transa_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">transb_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">m_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">n_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">k_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">alpha_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">Aarray</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">lda_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">Barray</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">ldb_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">beta_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">Carray</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">ldc_array</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="n">idx</span><span class="o">+=</span><span class="mi">1</span><span class="p">;</span>
<span class="n">end</span>
<span class="n">end</span>
</pre>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\text{$\mathrm{alpha\_array}$}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{$\mathrm{beta\_array}$}\)
            </span>
            are arrays of scaling factors, and
            <span class="math notranslate nohighlight">
                \(\text{Aarray}\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{Barray}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{Carray}\)
            </span>
            are arrays of pointers to matrices stored in column-major format. For a given index,
            <span class="math notranslate nohighlight">
                \(\text{idx}\)
            </span>
            , that is part of group
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
            , the dimensions are:
        </p>
        <ul class="simple">
            <li>
                <p>
                    <span class="math notranslate nohighlight">
                        \(\text{op}(\text{Aarray}\lbrack\text{idx}\rbrack)\)
                    </span>
                    :
                    <span class="math notranslate nohighlight">
                        \(\text{$\mathrm{m\_array}$}\lbrack i\rbrack \times \text{$\mathrm{k\_array}$}\lbrack i\rbrack\)
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="math notranslate nohighlight">
                        \(\text{op}(\text{Barray}\lbrack\text{idx}\rbrack)\)
                    </span>
                    :
                    <span class="math notranslate nohighlight">
                        \(\text{$\mathrm{k\_array}$}\lbrack i\rbrack \times \text{$\mathrm{n\_array}$}\lbrack i\rbrack\)
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="math notranslate nohighlight">
                        \(\text{Carray}\lbrack\text{idx}\rbrack\)
                    </span>
                    :
                    <span class="math notranslate nohighlight">
                        \(\text{$\mathrm{m\_array}$}\lbrack i\rbrack \times \text{$\mathrm{n\_array}$}\lbrack i\rbrack\)
                    </span>
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This API takes arrays of two different lengths. The arrays of dimensions, leading dimensions,
            transpositions, and scaling factors are of length
            <span class="pre">
                group_count
            </span>
            and the arrays of matrices are of length
            <span class="pre">
                problem_count
            </span>
            where
            <span class="math notranslate nohighlight">
                \(\text{$\mathrm{problem\_count}$} = \sum_{i = 0}^{\text{$\mathrm{group\_count}$} - 1}
                \text{$\mathrm{group\_size}$}\lbrack i\rbrack\)
            </span>
        </p>
        <p>
            For matrix
            <span class="math notranslate nohighlight">
                \(A[\text{idx}]\)
            </span>
            in group
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A[\text{idx}]) = \left\{ \begin{matrix}
                A[\text{idx}] &amp; {\text{if }\textsf{$\mathrm{transa\_array}\lbrack i\rbrack$ ==
                $\mathrm{CUBLAS\_OP\_N}$}} \\
                A[\text{idx}]^{T} &amp; {\text{if }\textsf{$\mathrm{transa\_array}\lbrack i\rbrack$ ==
                $\mathrm{CUBLAS\_OP\_T}$}} \\
                A[\text{idx}]^{H} &amp; {\text{if }\textsf{$\mathrm{transa\_array}\lbrack i\rbrack$ ==
                $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B[\text{idx}])\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B[\text{idx}]\)
            </span>
            in group
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack\text{idx}\rbrack\)
            </span>
            matrices must not overlap, that is, the individual gemm operations must be computable independently;
            otherwise, undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched">
                cublas&lt;t&gt;gemmBatched
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
                <th class="head">
                    <p>
                        Array Length
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the operations, op(
                        <span class="pre">
                            A[idx]
                        </span>
                        ), that is non- or (conj.) transpose for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the operations, op(
                        <span class="pre">
                            B[idx]
                        </span>
                        ), that is non- or (conj.) transpose for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the number of rows of matrix op(
                        <span class="pre">
                            A[idx]
                        </span>
                        ) and
                        <span class="pre">
                            C[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the number of columns of op(
                        <span class="pre">
                            B[idx]
                        </span>
                        ) and
                        <span class="pre">
                            C[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the number of columns of op(
                        <span class="pre">
                            A[idx]
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B[idx]
                        </span>
                        ) for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the &lt;type&gt; scalar used for multiplication for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            lda[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k[i]
                        </span>
                        with
                        <span class="pre">
                            lda[i]&gt;=max(1,m[i])
                        </span>
                        if
                        <span class="pre">
                            transa[i]==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m[i]
                        </span>
                        with
                        <span class="pre">
                            lda[i]&gt;=max(1,k[i])
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
                <td>
                    <p>
                        problem_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the leading dimensions of two-dimensional arrays used to store each matrix
                        <span class="pre">
                            A[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Barray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            ldb[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n[i]
                        </span>
                        with
                        <span class="pre">
                            ldb[i]&gt;=max(1,k[i])
                        </span>
                        if
                        <span class="pre">
                            transb[i]==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k[i]
                        </span>
                        with
                        <span class="pre">
                            ldb[i]&gt;=max(1,n[i])
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
                <td>
                    <p>
                        problem_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the leading dimensions of two-dimensional arrays used to store each matrix
                        <span class="pre">
                            B[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the &lt;type&gt; scalar used for multiplication for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Carray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array. It has dimensions
                        <span class="pre">
                            ldc[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n[i]
                        </span>
                        with
                        <span class="pre">
                            ldc[i]&gt;=max(1,m[i])
                        </span>
                        . Matrices
                        <span class="pre">
                            C[idx]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
                <td>
                    <p>
                        problem_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the leading dimensions of two-dimensional arrays used to store each matrix
                        <span class="pre">
                            C[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        group_count
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of groups
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        group_size
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containg the number of pointers contained in Aarray, Barray and Carray for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
        </table>
        <p>
            If math mode enables fast math modes when using
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmgroupedbatched">
                cublasSgemmGroupedBatched()
            </a>
            , pointers (not the pointer arrays) placed in the GPU memory must be properly aligned to avoid misaligned
            memory access errors. Ideally all pointers are aligned to at least 16 Bytes. Otherwise it is required that
            they meet the following rule:
        </p>
        <ul class="simple">
            <li>
                <p>
                    if
                    <span class="pre">
                        k%4==0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    ,
                </p>
            </li>
        </ul>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    transa_array
                                </span>
                                ,
                                <span class="pre">
                                    transb_array
                                </span>
                                ,
                                <span class="pre">
                                    m_array
                                </span>
                                ,
                                <span class="pre">
                                    n_array
                                </span>
                                ,
                                <span class="pre">
                                    k_array
                                </span>
                                ,
                                <span class="pre">
                                    alpha_array
                                </span>
                                ,
                                <span class="pre">
                                    lda_array
                                </span>
                                ,
                                <span class="pre">
                                    ldb_array
                                </span>
                                ,
                                <span class="pre">
                                    beta_array
                                </span>
                                ,
                                <span class="pre">
                                    ldc_array
                                </span>
                                , or
                                <span class="pre">
                                    group_size
                                </span>
                                are NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    group_count
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    m_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    n_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    k_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    group_size[i]
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    transb_array[i]
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m_array[i]
                                </span>
                                ) if
                                <span class="pre">
                                    transa_array[i]
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k_array[i]
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k_array[i]
                                </span>
                                ) if
                                <span class="pre">
                                    transb_array[i]
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n_array[i]
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m_array[i]
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the pointer mode is set to
                        <span class="pre">
                            CUBLAS_POINTER_MODE_DEVICE
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.7.6.
            </span>
            cublas&lt;t&gt;symm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-symm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsymm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsymm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsymm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsymm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha AB + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha BA + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a symmetric matrix stored in lower or upper mode,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                ,
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    side
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_SIDE_RIGHT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    side
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssymm.f">
                ssymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsymm.f">
                dsymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csymm.f">
                csymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsymm.f">
                zsymm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.7.
            </span>
            cublas&lt;t&gt;syrk()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syrk"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsyrk</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsyrk</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsyrk</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsyrk</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{T} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix A.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyrk.f">
                ssyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyrk.f">
                dsyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyrk.f">
                csyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyrk.f">
                zsyrk
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.8.
            </span>
            cublas&lt;t&gt;syr2k()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syr2k"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsyr2k</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsyr2k</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsyr2k</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsyr2k</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the symmetric rank-
            <span class="math notranslate nohighlight">
                \(2k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha(\text{op}(A)\text{op}(B)^{T} + \text{op}(B)\text{op}(A)^{T}) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{T}\text{ and }B^{T}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part, is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        , then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyr2k.f">
                ssyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyr2k.f">
                dsyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyr2k.f">
                csyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyr2k.f">
                zsyr2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.9.
            </span>
            cublas&lt;t&gt;syrkx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syrkx"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSsyrkx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDsyrkx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCsyrkx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZsyrkx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs a variation of the symmetric rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B)^{T} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrices
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{T}\text{ and }B^{T}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            This routine can be used when B is in such way that the result is guaranteed to be symmetric. A usual
            example is when the matrix B is a scaled form of the matrix A: this is equivalent to B being the product of
            the matrix A and a diagonal matrix. For an efficient computation of the product of a regular matrix with a
            diagonal matrix, refer to the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dgmm">
                cublas&lt;t&gt;dgmm
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part, is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        , then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                ,
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyrk.f">
                ssyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyrk.f">
                dsyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyrk.f">
                csyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyrk.f">
                zsyrk
            </a>
            and
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyr2k.f">
                ssyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyr2k.f">
                dsyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyr2k.f">
                csyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyr2k.f">
                zsyr2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.10.
            </span>
            cublas&lt;t&gt;trmm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trmm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStrmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtrmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtrmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtrmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the triangular matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha\text{op}(A)B} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha B\text{op}(A)} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrix, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            Notice that in order to achieve better parallelism cuBLAS differs from the BLAS API only for this routine.
            The BLAS API assumes an in-place implementation (with results written back to B), while the cuBLAS API
            assumes an out-of-place implementation (with results written into C). The application can obtain the
            in-place functionality of BLAS in the cuBLAS API by passing the address of the matrix B in place of the
            matrix C. No other overlapping in the input parameters is supported.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            alpha==0
                        </span>
                        then
                        <span class="pre">
                            A
                        </span>
                        is not referenced and
                        <span class="pre">
                            B
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                ,
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    side
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_SIDE_RIGHT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    side
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL if
                                <span class="pre">
                                    C
                                </span>
                                needs to be scaled
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strmm.f">
                strmm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrmm.f">
                dtrmm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrmm.f">
                ctrmm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrmm.f">
                ztrmm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.11.
            </span>
            cublas&lt;t&gt;trsm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasStrsm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDtrsm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCtrsm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZtrsm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function solves the triangular linear system with multiple right-hand-sides
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\left\{ \begin{matrix}
                {\text{op}(A)X = \alpha B} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {X\text{op}(A) = \alpha B} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal,
            <span class="math notranslate nohighlight">
                \(X\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            The solution
            <span class="math notranslate nohighlight">
                \(X\)
            </span>
            overwrites the right-hand-sides
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            on exit.
        </p>
        <p>
            No test for singularity or near-singularity is included in this function.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            X
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        is sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            alpha==0
                        </span>
                        then
                        <span class="pre">
                            A
                        </span>
                        is not referenced and
                        <span class="pre">
                            B
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array. It has dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    side
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_SIDE_RIGHT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    side
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strsm.f">
                strsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrsm.f">
                dtrsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrsm.f">
                ctrsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrsm.f">
                ztrsm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.12.
            </span>
            cublas&lt;t&gt;trsmBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsmbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasStrsmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">B</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasDtrsmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">B</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasCtrsmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">B</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">);</span>
<span class="n">cublasStatus_t</span><span class="nf">cublasZtrsmBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">B</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">);</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function solves an array of triangular linear systems with multiple right-hand-sides
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\left\{ \begin{matrix}
                {\text{op}(A\lbrack i\rbrack)X\lbrack i\rbrack = \alpha B\lbrack i\rbrack} &amp; {\text{if }\textsf{side
                == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {X\lbrack i\rbrack\text{op}(A\lbrack i\rbrack) = \alpha B\lbrack i\rbrack} &amp; {\text{if }\textsf{side
                == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\lbrack i\rbrack\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal,
            <span class="math notranslate nohighlight">
                \(X\lbrack i\rbrack\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack) = \left\{ \begin{matrix}
                {A\lbrack i\rbrack} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{T}\lbrack i\rbrack} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                {A^{H}\lbrack i\rbrack} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            The solution
            <span class="math notranslate nohighlight">
                \(X\lbrack i\rbrack\)
            </span>
            overwrites the right-hand-sides
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            on exit.
        </p>
        <p>
            No test for singularity or near-singularity is included in this function.
        </p>
        <p>
            This function works for any sizes but is intended to be used for matrices of small sizes where the launch
            overhead is a significant factor. For bigger sizes, it might be advantageous to call
            <span class="pre">
                batchCount
            </span>
            times the regular
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trsm">
                cublas&lt;t&gt;trsm
            </a>
            within a set of CUDA streams.
        </p>
        <p>
            The current implementation is limited to devices with compute capability above or equal 2.0.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A[i]
                        </span>
                        is on the left or right of
                        <span class="pre">
                            X[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A[i]
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A[i]
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            B[i]
                        </span>
                        , with matrix
                        <span class="pre">
                            A[i]
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            B[i]
                        </span>
                        , with matrix
                        <span class="pre">
                            A[i]
                        </span>
                        is sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            alpha==0
                        </span>
                        then
                        <span class="pre">
                            A[i]
                        </span>
                        is not referenced and
                        <span class="pre">
                            B[i]
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        . Matrices
                        <span class="pre">
                            B[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in A and B.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    batchCount
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    side
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_SIDE_RIGHT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    diag
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_DIAG_NON_UNIT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_DIAG_UNIT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    side
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strsm.f">
                strsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrsm.f">
                dtrsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrsm.f">
                ctrsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrsm.f">
                ztrsm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.13.
            </span>
            cublas&lt;t&gt;hemm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-hemm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasChemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZhemm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha AB + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha BA + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a Hermitian matrix stored in lower or upper mode,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side==CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise. The imaginary parts of the diagonal elements are assumed to be zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    side
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_SIDE_RIGHT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    side
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/chemm.f">
                chemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zhemm.f">
                zhemm
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.14.
            </span>
            cublas&lt;t&gt;herk()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-herk"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCherk</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZherk</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cherk.f">
                cherk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zherk.f">
                zherk
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.15.
            </span>
            cublas&lt;t&gt;her2k()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-her2k"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCher2k</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZher2k</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(2k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B)^{H} + \overset{}{\alpha}\text{op}(B)\text{op}(A)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{H}\text{ and }B^{H}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cher2k.f">
                cher2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zher2k.f">
                zher2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.7.16.
            </span>
            cublas&lt;t&gt;herkx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-herkx"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCherkx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZherkx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs a variation of the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{H}\text{ and }B^{H}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            This routine can be used when the matrix B is in such way that the result is guaranteed to be hermitian. An
            usual example is when the matrix B is a scaled form of the matrix A: this is equivalent to B being the
            product of the matrix A and a diagonal matrix. For an efficient computation of the product of a regular
            matrix with a diagonal matrix, refer to the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dgmm">
                cublas&lt;t&gt;dgmm
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        real scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    C
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cherk.f">
                cherk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zherk.f">
                zherk
            </a>
            and
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cher2k.f">
                cher2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zher2k.f">
                zher2k
            </a>
        </p>
        <h2>
            <span class="section-number">
                2.8.
            </span>
            BLAS-like Extension
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#blas-like-extension"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            This section describes the BLAS-extension functions that perform matrix-matrix operations.
        </p>
        <h3>
            <span class="section-number">
                2.8.1.
            </span>
            cublas&lt;t&gt;geam()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-geam"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgeam</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDgeam</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgeam</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZgeam</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix addition/transposition
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A) + \beta\text{op}(B)\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            .
        </p>
        <p>
            The operation is out-of-place if C does not overlap A or B.
        </p>
        <p>
            The in-place mode supports the following two operations,
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{*}C + \beta\text{op}(B)\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A) + \beta\text{*}C\)
            </span>
        </p>
        <p>
            For in-place mode, if
            <span class="pre">
                C
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                A
            </span>
            ,
            <span class="pre">
                ldc
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                lda
            </span>
            and
            <span class="pre">
                transa
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                CUBLAS_OP_N
            </span>
            . If
            <span class="pre">
                C
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                B
            </span>
            ,
            <span class="pre">
                ldc
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                ldb
            </span>
            and
            <span class="pre">
                transb
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                CUBLAS_OP_N
            </span>
            . If the user does not meet above requirements,
            <span class="pre">
                CUBLAS_STATUS_INVALID_VALUE
            </span>
            is returned.
        </p>
        <p>
            The operation includes the following special cases:
        </p>
        <p>
            the user can reset matrix C to zero by setting
            <span class="pre">
                *alpha=*beta=0
            </span>
            .
        </p>
        <p>
            the user can transpose matrix A by setting
            <span class="pre">
                *alpha=1
            </span>
            <span class="pre">
                and
            </span>
            <span class="pre">
                *beta=0
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            B
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            *alpha
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        ,
                        <span class="pre">
                            A
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            *beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        ,
                        <span class="pre">
                            B
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    A
                                </span>
                                ==
                                <span class="pre">
                                    C
                                </span>
                                , ((
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                !=
                                <span class="pre">
                                    transa
                                </span>
                                ) || (
                                <span class="pre">
                                    lda
                                </span>
                                !=
                                <span class="pre">
                                    ldc
                                </span>
                                )) or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    B
                                </span>
                                ==
                                <span class="pre">
                                    C
                                </span>
                                , ((
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                !=
                                <span class="pre">
                                    transb
                                </span>
                                ) || (
                                <span class="pre">
                                    ldb
                                </span>
                                !=
                                <span class="pre">
                                    ldc
                                </span>
                                )) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    alpha
                                </span>
                                == NULL or
                                <span class="pre">
                                    beta
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.8.2.
            </span>
            cublas&lt;t&gt;dgmm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id10"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSdgmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasSideMode_t</span><span class="n">mode</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasDdgmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasSideMode_t</span><span class="n">mode</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCdgmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasSideMode_t</span><span class="n">mode</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasZdgmm</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasSideMode_t</span><span class="n">mode</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {A \times diag(X)} &amp; {\text{if }\textsf{mode == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                {diag(X) \times A} &amp; {\text{if }\textsf{mode == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            .
            <span class="math notranslate nohighlight">
                \(X\)
            </span>
            is a vector of size
            <span class="math notranslate nohighlight">
                \(n\)
            </span>
            if
            <span class="pre">
                mode
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_SIDE_RIGHT
            </span>
            and of size
            <span class="math notranslate nohighlight">
                \(m\)
            </span>
            if
            <span class="pre">
                mode
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_SIDE_LEFT
            </span>
            .
            <span class="math notranslate nohighlight">
                \(X\)
            </span>
            is gathered from one-dimensional array x with stride
            <span class="pre">
                incx
            </span>
            . The absolute value of
            <span class="pre">
                incx
            </span>
            is the stride and the sign of
            <span class="pre">
                incx
            </span>
            is direction of the stride. If
            <span class="pre">
                incx
            </span>
            is positive, then we forward x from the first element. Otherwise, we backward x from the last element. The
            formula of X is
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(X\lbrack j\rbrack = \left\{ \begin{matrix}
                {x\lbrack j \times incx\rbrack} &amp; {\text{if }incx \geq 0} \\
                {x\lbrack(\chi - 1) \times |incx| - j \times |incx|\rbrack} &amp; {\text{if }incx &lt; 0} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\chi = m\)
            </span>
            if
            <span class="pre">
                mode
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_SIDE_LEFT
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\chi = n\)
            </span>
            if
            <span class="pre">
                mode
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_SIDE_RIGHT
            </span>
            .
        </p>
        <p>
            Example 1: if the user wants to perform
            <span class="math notranslate nohighlight">
                \(diag(diag(B)) \times A\)
            </span>
            , then
            <span class="math notranslate nohighlight">
                \(incx = ldb + 1\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(ldb\)
            </span>
            is leading dimension of matrix
            <span class="pre">
                B
            </span>
            , either row-major or column-major.
        </p>
        <p>
            Example 2: if the user wants to perform
            <span class="math notranslate nohighlight">
                \(\alpha \times A\)
            </span>
            , then there are two choices, either
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-geam">
                cublas&lt;t&gt;geam()
            </a>
            with
            <span class="pre">
                *beta=0
            </span>
            and
            <span class="pre">
                transa
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_OP_N
            </span>
            or
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dgmm">
                cublas&lt;t&gt;dgmm()
            </a>
            with
            <span class="pre">
                incx=0
            </span>
            and
            <span class="pre">
                x[0]=alpha
            </span>
            .
        </p>
        <p>
            The operation is out-of-place. The in-place only works if
            <span class="pre">
                lda
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                ldc
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        mode
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        left multiply if
                        <span class="pre">
                            mode
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        or right multiply if
                        <span class="pre">
                            mode
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_RIGHT
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A
                        </span>
                        and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            A
                        </span>
                        and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        one-dimensional &lt;type&gt; array of size
                        <span class="math notranslate nohighlight">
                            \(|inc| \times m\)
                        </span>
                        if
                        <span class="pre">
                            mode
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="math notranslate nohighlight">
                            \(|inc| \times n\)
                        </span>
                        if
                        <span class="pre">
                            mode
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_RIGHT
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride of one-dimensional array
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    mode
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_SIDE_LEFT
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_SIDE_RIGHT
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.8.3.
            </span>
            cublas&lt;t&gt;getrfBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrfbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSgetrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDgetrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCgetrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZgetrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>
</pre>
        <p>
            <span class="pre">
                Aarray
            </span>
            is an array of pointers to matrices stored in column-major format with dimensions
            <span class="pre">
                nxn
            </span>
            and leading dimension
            <span class="pre">
                lda
            </span>
            .
        </p>
        <p>
            This function performs the LU factorization of each
            <span class="pre">
                Aarray[i]
            </span>
            for i = 0, ,
            <span class="pre">
                batchSize-1
            </span>
            by the following equation
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{P}\text{*}{Aarray}\lbrack i\rbrack = L\text{*}U\)
            </span>
        </p>
        <p>
            where
            <span class="pre">
                P
            </span>
            is a permutation matrix which represents partial pivoting with row interchanges.
            <span class="pre">
                L
            </span>
            is a lower triangular matrix with unit diagonal and
            <span class="pre">
                U
            </span>
            is an upper triangular matrix.
        </p>
        <p>
            Formally
            <span class="pre">
                P
            </span>
            is written by a product of permutation matrices
            <span class="pre">
                Pj
            </span>
            , for
            <span class="pre">
                j
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                1,2,...,n
            </span>
            , say
            <span class="pre">
                P
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                P1
            </span>
            <span class="pre">
                *
            </span>
            <span class="pre">
                P2
            </span>
            <span class="pre">
                *
            </span>
            <span class="pre">
                P3
            </span>
            <span class="pre">
                *
            </span>
            <span class="pre">
                ....
            </span>
            <span class="pre">
                *
            </span>
            <span class="pre">
                Pn
            </span>
            .
            <span class="pre">
                Pj
            </span>
            is a permutation matrix which interchanges two rows of vector x when performing
            <span class="pre">
                Pj*x
            </span>
            .
            <span class="pre">
                Pj
            </span>
            can be constructed by
            <span class="pre">
                j
            </span>
            element of
            <span class="pre">
                PivotArray[i]
            </span>
            by the following Matlab code
        </p>
        <pre><span class="c1">// In Matlab PivotArray[i] is an array of base-1.</span>
<span class="c1">// In C, PivotArray[i] is base-0.</span>
<span class="n">Pj</span><span class="o">=</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="n">swap</span><span class="n">Pj</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="o">:</span><span class="p">)</span><span class="n">and</span><span class="n">Pj</span><span class="p">(</span><span class="n">PivotArray</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="p">,</span><span class="o">:</span><span class="p">)</span>
</pre>
        <p>
            <span class="pre">
                L
            </span>
            and
            <span class="pre">
                U
            </span>
            are written back to original matrix
            <span class="pre">
                A
            </span>
            , and diagonal elements of
            <span class="pre">
                L
            </span>
            are discarded. The
            <span class="pre">
                L
            </span>
            and
            <span class="pre">
                U
            </span>
            can be constructed by the following Matlab code
        </p>
        <pre><span class="c1">// A is a matrix of nxn after getrf.</span>
<span class="n">L</span><span class="o">=</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="k">for</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span>
<span class="n">L</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">)</span><span class="o">=</span><span class="n">A</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
<span class="n">end</span>
<span class="n">U</span><span class="o">=</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="k">for</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span>
<span class="n">U</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="o">=</span><span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="o">:</span><span class="n">n</span><span class="p">)</span>
<span class="n">end</span>
</pre>
        <p>
            If matrix
            <span class="pre">
                A(=Aarray[i])
            </span>
            is singular, getrf still works and the value of
            <span class="pre">
                info(=infoArray[i])
            </span>
            reports first row index that LU factorization cannot proceed. If info is
            <span class="pre">
                k
            </span>
            ,
            <span class="pre">
                U(k,k)
            </span>
            is zero. The equation
            <span class="pre">
                P*A=L*U
            </span>
            still holds, however
            <span class="pre">
                L
            </span>
            and
            <span class="pre">
                U
            </span>
            reconstruction needs different Matlab code as follows:
        </p>
        <pre><span class="c1">// A is a matrix of nxn after getrf.</span>
<span class="c1">// info is k, which means U(k,k) is zero.</span>
<span class="n">L</span><span class="o">=</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="k">for</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">k</span><span class="mi">-1</span>
<span class="n">L</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">)</span><span class="o">=</span><span class="n">A</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
<span class="n">end</span>
<span class="n">U</span><span class="o">=</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="k">for</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">k</span><span class="mi">-1</span>
<span class="n">U</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="o">=</span><span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="o">:</span><span class="n">n</span><span class="p">)</span>
<span class="n">end</span>
<span class="k">for</span><span class="n">i</span><span class="o">=</span><span class="n">k</span><span class="o">:</span><span class="n">n</span>
<span class="n">U</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="o">=</span><span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="o">:</span><span class="n">n</span><span class="p">)</span>
<span class="n">end</span>
</pre>
        <p>
            This function is intended to be used for matrices of small sizes where the launch overhead is a significant
            factor.
        </p>
        <p>
            cublas&lt;t&gt;getrfBatched supports non-pivot LU factorization if
            <span class="pre">
                PivotArray
            </span>
            is NULL.
        </p>
        <p>
            cublas&lt;t&gt;getrfBatched supports arbitrary dimension.
        </p>
        <p>
            cublas&lt;t&gt;getrfBatched only supports compute capability 2.0 or above.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input/output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        . Matrices
                        <span class="pre">
                            Aarray[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        PivotArray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of size
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            batchSize
                        </span>
                        that contains the pivoting sequence of each factorization of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        stored in a linear fashion. If
                        <span class="pre">
                            PivotArray
                        </span>
                        is NULL, pivoting is disabled.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        infoArray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of size
                        <span class="pre">
                            batchSize
                        </span>
                        that info(=infoArray[i]) contains the information of factorization of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                    <p>
                        If info=0, the execution is successful.
                    </p>
                    <p>
                        If info = -j, the j-th parameter had an illegal value.
                    </p>
                    <p>
                        If info = k, U(k,k) is 0. The factorization has been completed, but U is exactly singular.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchSize
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in A
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,batchSize,lda
                        </span>
                        <span class="pre">
                            &lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/single/sgetrf.f">
                sgeqrf
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/double/dgetrf.f">
                dgeqrf
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex/cgetrf.f">
                cgeqrf
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex16/zgetrf.f">
                zgeqrf
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.4.
            </span>
            cublas&lt;t&gt;getrsBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrsbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSgetrsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="o">*</span><span class="n">devIpiv</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDgetrsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="o">*</span><span class="n">devIpiv</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCgetrsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="o">*</span><span class="n">devIpiv</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZgetrsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="o">*</span><span class="n">devIpiv</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>
</pre>
        <p>
            This function solves an array of systems of linear equations of the form:
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i \rbrack) X\lbrack i\rbrack = B\lbrack i\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\lbrack i\rbrack\)
            </span>
            is a matrix which has been LU factorized with pivoting,
            <span class="math notranslate nohighlight">
                \(X\lbrack i\rbrack\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(n \times {nrhs}\)
            </span>
            matrices. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack) = \left\{ \begin{matrix}
                {A\lbrack i\rbrack} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{T}\lbrack i\rbrack} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                {A^{H}\lbrack i\rbrack} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            This function is intended to be used for matrices of small sizes where the launch overhead is a significant
            factor.
        </p>
        <p>
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrsbatched">
                cublas&lt;t&gt;getrsBatched
            </a>
            supports non-pivot LU factorization if
            <span class="pre">
                devIpiv
            </span>
            is NULL.
        </p>
        <p>
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrsbatched">
                cublas&lt;t&gt;getrsBatched
            </a>
            supports arbitrary dimension.
        </p>
        <p>
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrsbatched">
                cublas&lt;t&gt;getrsBatched
            </a>
            only supports compute capability 2.0 or above.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        nrhs
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of
                        <span class="pre">
                            Barray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        devIpiv
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of size
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            batchSize
                        </span>
                        that contains the pivoting sequence of each factorization of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        stored in a linear fashion. If
                        <span class="pre">
                            devIpiv
                        </span>
                        is NULL, pivoting for all
                        <span class="pre">
                            Aarray[i]
                        </span>
                        is ignored.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Barray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input/output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            nrhs
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        . Matrices
                        <span class="pre">
                            Barray[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each solution matrix
                        <span class="pre">
                            Barray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        info
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        If info=0, the execution is successful.
                    </p>
                    <p>
                        If info = -j, the j-th parameter had an illegal value.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchSize
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in A
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    nrhs
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/single/sgetrs.f">
                sgeqrs
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/double/dgetrs.f">
                dgeqrs
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex/cgetrs.f">
                cgeqrs
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex16/zgetrs.f">
                zgeqrs
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.5.
            </span>
            cublas&lt;t&gt;getriBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getribatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSgetriBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDgetriBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCgetriBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZgetriBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">PivotArray</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">infoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>
</pre>
        <p>
            <span class="pre">
                Aarray
            </span>
            and
            <span class="pre">
                Carray
            </span>
            are arrays of pointers to matrices stored in column-major format with dimensions
            <span class="pre">
                n*n
            </span>
            and leading dimension
            <span class="pre">
                lda
            </span>
            and
            <span class="pre">
                ldc
            </span>
            respectively.
        </p>
        <p>
            This function performs the inversion of matrices
            <span class="pre">
                A[i]
            </span>
            for i = 0, ,
            <span class="pre">
                batchSize-1
            </span>
            .
        </p>
        <p>
            Prior to calling cublas&lt;t&gt;getriBatched, the matrix
            <span class="pre">
                A[i]
            </span>
            must be factorized first using the routine cublas&lt;t&gt;getrfBatched. After the call of
            cublas&lt;t&gt;getrfBatched, the matrix pointing by
            <span class="pre">
                Aarray[i]
            </span>
            will contain the LU factors of the matrix
            <span class="pre">
                A[i]
            </span>
            and the vector pointing by
            <span class="pre">
                (PivotArray+i)
            </span>
            will contain the pivoting sequence.
        </p>
        <p>
            Following the LU factorization, cublas&lt;t&gt;getriBatched uses forward and backward triangular solvers to
            complete inversion of matrices
            <span class="pre">
                A[i]
            </span>
            for i = 0, ,
            <span class="pre">
                batchSize-1
            </span>
            . The inversion is out-of-place, so memory space of Carray[i] cannot overlap memory space of Array[i].
        </p>
        <p>
            Typically all parameters in cublas&lt;t&gt;getrfBatched would be passed into cublas&lt;t&gt;getriBatched.
            For example,
        </p>
        <pre><span class="c1">// step 1: perform in-place LU decomposition, P*A = L*U.</span>
<span class="c1">//      Aarray[i] is n*n matrix A[i]</span>
<span class="n">cublasDgetrfBatched</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">Aarray</span><span class="p">,</span><span class="n">lda</span><span class="p">,</span><span class="n">PivotArray</span><span class="p">,</span><span class="n">infoArray</span><span class="p">,</span><span class="n">batchSize</span><span class="p">);</span>
<span class="c1">//      check infoArray[i] to see if factorization of A[i] is successful or not.</span>
<span class="c1">//      Array[i] contains LU factorization of A[i]</span>

<span class="c1">// step 2: perform out-of-place inversion, Carray[i] = inv(A[i])</span>
<span class="n">cublasDgetriBatched</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">Aarray</span><span class="p">,</span><span class="n">lda</span><span class="p">,</span><span class="n">PivotArray</span><span class="p">,</span><span class="n">Carray</span><span class="p">,</span><span class="n">ldc</span><span class="p">,</span><span class="n">infoArray</span><span class="p">,</span><span class="n">batchSize</span><span class="p">);</span>
<span class="c1">//      check infoArray[i] to see if inversion of A[i] is successful or not.</span>
</pre>
        <p>
            The user can check singularity from either cublas&lt;t&gt;getrfBatched or cublas&lt;t&gt;getriBatched.
        </p>
        <p>
            This function is intended to be used for matrices of small sizes where the launch overhead is a significant
            factor.
        </p>
        <p>
            If cublas&lt;t&gt;getrfBatched is performed by non-pivoting,
            <span class="pre">
                PivotArray
            </span>
            of cublas&lt;t&gt;getriBatched should be NULL.
        </p>
        <p>
            cublas&lt;t&gt;getriBatched supports arbitrary dimension.
        </p>
        <p>
            cublas&lt;t&gt;getriBatched only supports compute capability 2.0 or above.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dimension
                        <span class="pre">
                            n*n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        PivotArray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of size
                        <span class="pre">
                            n*batchSize
                        </span>
                        that contains the pivoting sequence of each factorization of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        stored in a linear fashion. If
                        <span class="pre">
                            PivotArray
                        </span>
                        is NULL, pivoting is disabled.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Carray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dimension
                        <span class="pre">
                            n*n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . Matrices
                        <span class="pre">
                            Carray[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Carray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        infoArray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of size
                        <span class="pre">
                            batchSize
                        </span>
                        that info(=infoArray[i]) contains the information of inversion of
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                    <p>
                        If info=0, the execution is successful.
                    </p>
                    <p>
                        If info = k, U(k,k) is 0. The U is exactly singular and the inversion failed.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchSize
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in A
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    lda
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    batchSize
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt;
                                <span class="pre">
                                    n
                                </span>
                                or
                                <span class="pre">
                                    ldc
                                </span>
                                &lt;
                                <span class="pre">
                                    n
                                </span>
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.8.6.
            </span>
            cublas&lt;t&gt;matinvBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-matinvbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSmatinvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Ainv</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda_inv</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDmatinvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Ainv</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda_inv</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCmatinvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Ainv</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda_inv</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZmatinvBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">A</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Ainv</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda_inv</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>
</pre>
        <p>
            <span class="pre">
                A
            </span>
            and
            <span class="pre">
                Ainv
            </span>
            are arrays of pointers to matrices stored in column-major format with dimensions
            <span class="pre">
                n*n
            </span>
            and leading dimension
            <span class="pre">
                lda
            </span>
            and
            <span class="pre">
                lda_inv
            </span>
            respectively.
        </p>
        <p>
            This function performs the inversion of matrices
            <span class="pre">
                A[i]
            </span>
            for i = 0, ,
            <span class="pre">
                batchSize-1
            </span>
            .
        </p>
        <p>
            This function is a short cut of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrfbatched">
                cublas&lt;t&gt;getrfBatched
            </a>
            plus
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getribatched">
                cublas&lt;t&gt;getriBatched
            </a>
            . However it doesnt work if
            <span class="pre">
                n
            </span>
            is greater than 32. If not, the user has to go through
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrfbatched">
                cublas&lt;t&gt;getrfBatched
            </a>
            and
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getribatched">
                cublas&lt;t&gt;getriBatched
            </a>
            .
        </p>
        <p>
            If the matrix
            <span class="pre">
                A[i]
            </span>
            is singular, then
            <span class="pre">
                info[i]
            </span>
            reports singularity, the same as
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-getrfbatched">
                cublas&lt;t&gt;getrfBatched
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dimension
                        <span class="pre">
                            n*n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Ainv
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dimension
                        <span class="pre">
                            n*n
                        </span>
                        with
                        <span class="pre">
                            lda_inv&gt;=max(1,n)
                        </span>
                        . Matrices
                        <span class="pre">
                            Ainv[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda_inv
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Ainv[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        info
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of size
                        <span class="pre">
                            batchSize
                        </span>
                        that info[i] contains the information of inversion of
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                    <p>
                        If info[i]=0, the execution is successful.
                    </p>
                    <p>
                        If info[i]=k, U(k,k) is 0. The U is exactly singular and the inversion failed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        batchSize
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in A.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    lda
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    lda_inv
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    batchSize
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt;
                                <span class="pre">
                                    n
                                </span>
                                or
                                <span class="pre">
                                    lda_inv
                                </span>
                                &lt;
                                <span class="pre">
                                    n
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    n
                                </span>
                                &gt; 32
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.8.7.
            </span>
            cublas&lt;t&gt;geqrfBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-geqrfbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSgeqrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">TauArray</span><span class="p">[],</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDgeqrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">TauArray</span><span class="p">[],</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCgeqrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">TauArray</span><span class="p">[],</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZgeqrfBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">TauArray</span><span class="p">[],</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>
</pre>
        <p>
            <span class="pre">
                Aarray
            </span>
            is an array of pointers to matrices stored in column-major format with dimensions
            <span class="pre">
                m
            </span>
            <span class="pre">
                x
            </span>
            <span class="pre">
                n
            </span>
            and leading dimension
            <span class="pre">
                lda
            </span>
            .
            <span class="pre">
                TauArray
            </span>
            is an array of pointers to vectors of dimension of at least
            <span class="pre">
                max
            </span>
            <span class="pre">
                (1,
            </span>
            <span class="pre">
                min(m,
            </span>
            <span class="pre">
                n)
            </span>
            .
        </p>
        <p>
            This function performs the QR factorization of each
            <span class="pre">
                Aarray[i]
            </span>
            for
            <span class="pre">
                i
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                0,
            </span>
            <span class="pre">
                ...,batchSize-1
            </span>
            using Householder reflections. Each matrix
            <span class="pre">
                Q[i]
            </span>
            is represented as a product of elementary reflectors and is stored in the lower part of each
            <span class="pre">
                Aarray[i]
            </span>
            as follows :
        </p>
        <pre>Q[j] = H[j][1] H[j][2] . . . H[j](k), where k = min(m,n).
</pre>
        <p>
            Each H[j][i] has the form
        </p>
        <pre>H[j][i] = I - tau[j] * v * v'
</pre>
        <p>
            where
            <span class="pre">
                tau[j]
            </span>
            is a real scalar, and
            <span class="pre">
                v
            </span>
            is a real vector with
            <span class="pre">
                v(1:i-1)
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                0
            </span>
            and
            <span class="pre">
                v(i)
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                1
            </span>
            ;
            <span class="pre">
                v(i+1:m)
            </span>
            is stored on exit in
            <span class="pre">
                Aarray[j][i+1:m,i]
            </span>
            , and
            <span class="pre">
                tau
            </span>
            in
            <span class="pre">
                TauArray[j][i]
            </span>
            .
        </p>
        <p>
            This function is intended to be used for matrices of small sizes where the launch overhead is a significant
            factor.
        </p>
        <p>
            cublas&lt;t&gt;geqrfBatched supports arbitrary dimension.
        </p>
        <p>
            cublas&lt;t&gt;geqrfBatched only supports compute capability 2.0 or above.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            m
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        TauArray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; vector, with each vector of dim.
                        <span class="pre">
                            max(1,min(m,n))
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        info
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        If info=0, the parameters passed to the function are valid
                    </p>
                    <p>
                        If info&lt;0, the parameter in postion -info is invalid
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        batchSize
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in A
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    batchSize
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/single/sgeqrf.f">
                sgeqrf
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/double/dgeqrf.f">
                dgeqrf
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex/cgeqrf.f">
                cgeqrf
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex16/zgeqrf.f">
                zgeqrf
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.8.
            </span>
            cublas&lt;t&gt;gelsBatched()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gelsbatched"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasSgelsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">devInfoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDgelsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">devInfoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCgelsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">devInfoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZgelsBatched</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">nrhs</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">info</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">devInfoArray</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchSize</span><span class="p">);</span>
</pre>
        <p>
            <span class="pre">
                Aarray
            </span>
            is an array of pointers to matrices stored in column-major format.
            <span class="pre">
                Carray
            </span>
            is an array of pointers to matrices stored in column-major format.
        </p>
        <p>
            This function find the least squares solution of a batch of overdetermined systems: it solves the least
            squares problem described as follows :
        </p>
        <pre><span class="n">minimize</span><span class="o">||</span><span class="n">Carray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">Aarray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">Xarray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">||</span><span class="p">,</span><span class="n">with</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="p">...,</span><span class="n">batchSize</span><span class="mi">-1</span>
</pre>
        <p>
            On exit, each
            <span class="pre">
                Aarray[i]
            </span>
            is overwritten with their QR factorization and each
            <span class="pre">
                Carray[i]
            </span>
            is overwritten with the least square solution
        </p>
        <p>
            cublas&lt;t&gt;gelsBatched supports only the non-transpose operation and only solves over-determined systems
            (m &gt;= n).
        </p>
        <p>
            cublas&lt;t&gt;gelsBatched only supports compute capability 2.0 or above.
        </p>
        <p>
            This function is intended to be used for matrices of small sizes where the launch overhead is a significant
            factor.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            Aarray[i]
                        </span>
                        ) that is non- or (conj.) transpose. Only non-transpose operation is currently supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of each
                        <span class="pre">
                            Aarray[i]
                        </span>
                        and
                        <span class="pre">
                            Carray[i]
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        , numbers of columns of each
                        <span class="pre">
                            Aarray[i]
                        </span>
                        otherwise (not supported currently).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of each
                        <span class="pre">
                            Aarray[i]
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        , and number of rows of each
                        <span class="pre">
                            Aarray[i]
                        </span>
                        and
                        <span class="pre">
                            Carray[i]
                        </span>
                        otherwise (not supported currently).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        nrhs
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of each
                        <span class="pre">
                            Carray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input/output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            m
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        , and
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise (not supported currently). Matrices
                        <span class="pre">
                            Aarray[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Aarray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Carray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input/output
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            m
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            nrhs
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        , and
                        <span class="pre">
                            n
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            nrhs
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise (not supported currently). Matrices
                        <span class="pre">
                            Carray[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store each matrix
                        <span class="pre">
                            Carray[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        info
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        If info=0, the parameters passed to the function are valid
                    </p>
                    <p>
                        If info&lt;0, the parameter in position -info is invalid
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        devInfoArray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        optional array of integers of dimension batchsize.
                    </p>
                    <p>
                        If non-null, every element devInfoArray[i] contain a value V with the following meaning:
                    </p>
                    <p>
                        V = 0 : the i-th problem was sucessfully solved
                    </p>
                    <p>
                        V &gt; 0 : the V-th diagonal element of the Aarray[i] is zero. Aarray[i] does not have full
                        rank.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        batchSize
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of pointers contained in Aarray and Carray
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    nrhs
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    batchSize
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m
                        </span>
                        <span class="pre">
                            &lt;n
                        </span>
                        or
                        <span class="pre">
                            trans
                        </span>
                        is different from non-transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/single/sgels.f">
                sgels
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/double/dgels.f">
                dgels
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex/cgels.f">
                cgels
            </a>
            ,
            <a class="reference external" href="http://www.netlib.no/netlib/lapack/complex16/zgels.f">
                zgels
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.9.
            </span>
            cublas&lt;t&gt;tpttr()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-tpttr"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasStpttr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDtpttr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCtpttr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZtpttr</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">);</span>
</pre>
        <p>
            This function performs the conversion from the triangular packed format to the triangular format
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements of
            <span class="pre">
                AP
            </span>
            are copied into the lower triangular part of the triangular matrix
            <span class="pre">
                A
            </span>
            and the upper part of
            <span class="pre">
                A
            </span>
            is left untouched. If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements of
            <span class="pre">
                AP
            </span>
            are copied into the upper triangular part of the triangular matrix
            <span class="pre">
                A
            </span>
            and the lower part of
            <span class="pre">
                A
            </span>
            is left untouched.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            AP
                        </span>
                        contains lower or upper part of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        . The opposite side of A is left untouched.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/d7/d70/stpttr_8f.html">
                stpttr
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/df/d63/dtpttr_8f.html">
                dtpttr
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/de/d13/ctpttr_8f.html">
                ctpttr
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/d6/dbc/ztpttr_8f.html">
                ztpttr
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.10.
            </span>
            cublas&lt;t&gt;trttp()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-trttp"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasStrttp</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDtrttp</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasCtrttp</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasZtrttp</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">);</span>
</pre>
        <p>
            This function performs the conversion from the triangular format to the triangular packed format
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the lower triangular part of the triangular matrix
            <span class="pre">
                A
            </span>
            is copied into the array
            <span class="pre">
                AP
            </span>
            . If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then then the upper triangular part of the triangular matrix
            <span class="pre">
                A
            </span>
            is copied into the array
            <span class="pre">
                AP
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates which matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows and columns of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/d9/def/strttp_8f.html">
                strttp
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/d0/daf/dtrttp_8f.html">
                dtrttp
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/d7/d56/ctrttp_8f.html">
                ctrttp
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/explore-html/da/dc2/ztrttp_8f.html">
                ztrttp
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.11.
            </span>
            cublas&lt;t&gt;gemmEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasSgemmEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasCgemmEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm
            </a>
            . In this function the input matrices and output matrices can have a lower precision but the computation is
            still done in the type
            <span class="pre">
                &lt;t&gt;
            </span>
            . For example, in the type
            <span class="pre">
                float
            </span>
            for
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                cublasSgemmEx()
            </a>
            and in the type
            <span class="pre">
                cuComplex
            </span>
            for
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                cublasCgemmEx()
            </a>
            .
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            B
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            A
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Btype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The matrix types combinations supported for
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                cublasSgemmEx()
            </a>
            are listed below:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        C
                    </p>
                </th>
                <th class="head">
                    <p>
                        A/B
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The matrix types combinations supported for
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                cublasCgemmEx()
            </a>
            are listed below :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        C
                    </p>
                </th>
                <th class="head">
                    <p>
                        A/B
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <a class="reference external"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmex">
                            cublasCgemmEx()
                        </a>
                        is only supported for GPU with architecture capabilities equal or greater than 5.0
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        ,
                        <span class="pre">
                            Btype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        is not supported
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                or
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sgemm.f">
                sgemm
            </a>
        </p>
        <p>
            For more information about the numerical behavior of some GEMM algorithms, refer to the
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#gemm-algorithms-numerical-behavior">
                GEMM Algorithms Numerical Behavior
            </a>
            section.
        </p>
        <h3>
            <span class="section-number">
                2.8.12.
            </span>
            cublasGemmEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGemmEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cublasGemmAlgo_t</span><span class="n">algo</span><span class="p">)</span>

<span class="cp">#if defined(__cplusplus)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasGemmEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cublasGemmAlgo_t</span><span class="n">algo</span><span class="p">)</span>
<span class="cp">#endif</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm
            </a>
            that allows the user to individually specify the data types for each of the A, B and C matrices, the
            precision of computation and the GEMM algorithm to be run. Supported combinations of arguments are listed
            further down in this section.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The second variant of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                cublasGemmEx()
            </a>
            function is provided for backward compatibility with C++ applications code, where the
            <span class="pre">
                computeType
            </span>
            parameter is of
            <span class="pre">
                cudaDataType
            </span>
            instead of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                cublasComputeType_t
            </a>
            . C applications would still compile with the updated function signature.
        </p>
        <p>
            This function is only supported on devices with compute capability 5.0 or later.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            B
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of op(
                        <span class="pre">
                            A
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Scaling factor for A*B of the type that corresponds to the computeType and Ctype, see the table
                        below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Btype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Scaling factor for C of the type that corresponds to the computeType and Ctype, see the table
                        below for details. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the computation type.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the algorithm. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmalgo-t">
                            cublasGemmAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                cublasGemmEx()
            </a>
            supports the following Compute Type, Scale Type, Atype/Btype, and Ctype:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Compute Type
                    </p>
                </th>
                <th class="head">
                    <p>
                        Scale Type (alpha and beta)
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="8">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td rowspan="6">
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16BF
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_TF32
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="pre">
                CUBLAS_COMPUTE_32I
            </span>
            and
            <span class="pre">
                CUBLAS_COMPUTE_32I_PEDANTIC
            </span>
            compute types are only supported with A, B being 4-byte aligned and lda, ldb being multiples of 4. For
            better performance, it is also recommended that IMMA kernels requirements for a regular data ordering listed
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul-regular-imma-conditions">
                <span class="std std-ref">
                    here
                </span>
            </a>
            are met.
        </p>
        <p>
            The possible error values returned by this function and their meanings are listed in the following table.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmex">
                            cublasGemmEx()
                        </a>
                        is only supported for GPU with architecture capabilities equal or greater than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        ,
                        <span class="pre">
                            Btype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        or the algorithm,
                        <span class="pre">
                            algo
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                or
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Btype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                or
                                <span class="pre">
                                    algo
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Starting with release 11.2, using the typed functions instead of the extension functions (cublas**Ex())
            helps in reducing the binary size when linking to static cuBLAS Library.
        </p>
        <p>
            Also refer to:
            <a class="reference external" href="http://www.netlib.org/blas/sgemm.f">
                sgemm.
            </a>
        </p>
        <p>
            For more information about the numerical behavior of some GEMM algorithms, refer to the
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#gemm-algorithms-numerical-behavior">
                GEMM Algorithms Numerical Behavior
            </a>
            section.
        </p>
        <h3>
            <span class="section-number">
                2.8.13.
            </span>
            cublasGemmBatchedEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGemmBatchedEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cublasGemmAlgo_t</span><span class="n">algo</span><span class="p">)</span>

<span class="cp">#if defined(__cplusplus)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasGemmBatchedEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="n">cudaDataType</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cublasGemmAlgo_t</span><span class="n">algo</span><span class="p">)</span>
<span class="cp">#endif</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched">
                cublas&lt;t&gt;gemmBatched
            </a>
            that performs the matrix-matrix multiplication of a batch of matrices and allows the user to individually
            specify the data types for each of the A, B and C matrix arrays, the precision of computation and the GEMM
            algorithm to be run. Like
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmbatched">
                cublas&lt;t&gt;gemmBatched
            </a>
            , the batch is considered to be uniform, i.e. all instances have the same dimensions (m, n, k),
            leading dimensions (lda, ldb, ldc) and transpositions (transa, transb) for their respective A, B and C
            matrices. The address of the input matrices and the output matrix of each instance of the batch are read
            from arrays of pointers passed to the function by the caller. Supported combinations of arguments are listed
            further down in this section.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The second variant of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                cublasGemmBatchedEx()
            </a>
            function is provided for backward compatibility with C++ applications code, where the
            <span class="pre">
                computeType
            </span>
            parameter is of
            <span class="pre">
                cudaDataType
            </span>
            instead of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                cublasComputeType_t
            </a>
            . C applications would still compile with the updated function signature.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack = \alpha\text{op}(A\lbrack i\rbrack)\text{op}(B\lbrack i\rbrack) + \beta C\lbrack
                i\rbrack,\text{ for i } \in \lbrack 0,batchCount - 1\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are arrays of pointers to matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            matrices must not overlap, i.e. the individual gemm operations must be computable independently; otherwise,
            undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B[i]
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Scaling factor for A*B of the type that corresponds to the computeType and Ctype, see the table
                        below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Array of pointers to &lt;Atype&gt; array, with each array of dim.
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            Aarray
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Barray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Array of pointers to &lt;Btype&gt; array, with each array of dim.
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Btype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            Barray
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Scaling factor for C of the type that corresponds to the computeType and Ctype, see the table
                        below for details. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C[i]
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Carray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        Array of pointers to &lt;Ctype&gt; array. It has dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        . Matrices
                        <span class="pre">
                            C[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            Carray
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of a two-dimensional array used to store each matrix
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of pointers contained in Aarray, Barray and Carray.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the computation type.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the algorithm. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmalgo-t">
                            cublasGemmAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                cublasGemmBatchedEx()
            </a>
            supports the following Compute Type, Scale Type, Atype/Btype, and Ctype:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Compute Type
                    </p>
                </th>
                <th class="head">
                    <p>
                        Scale Type (alpha and beta)
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="8">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td rowspan="6">
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16BF
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_TF32
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            If
            <span class="pre">
                Atype
            </span>
            is
            <span class="pre">
                CUDA_R_16F
            </span>
            or
            <span class="pre">
                CUDA_R_16BF
            </span>
            , or
            <span class="pre">
                computeType
            </span>
            is any of the
            <span class="pre">
                FAST
            </span>
            options, or when math mode or
            <span class="pre">
                algo
            </span>
            enable fast math modes, pointers (not the pointer arrays) placed in the GPU memory must be properly aligned
            to avoid misaligned memory access errors. Ideally all pointers are aligned to at least 16 Bytes. Otherwise
            it is recommended that they meet the following rule:
        </p>
        <ul class="simple">
            <li>
                <p>
                    if
                    <span class="pre">
                        k%8==0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    ,
                </p>
            </li>
            <li>
                <p>
                    if
                    <span class="pre">
                        k%2==0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    
                    <span class="pre">
                        4
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    .
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            Compute types
            <span class="pre">
                CUBLAS_COMPUTE_32I
            </span>
            and
            <span class="pre">
                CUBLAS_COMPUTE_32I_PEDANTIC
            </span>
            are only supported with all pointers
            <span class="pre">
                A[i]
            </span>
            ,
            <span class="pre">
                B[i]
            </span>
            being 4-byte aligned and lda, ldb being multiples of 4. For a better performance, it is also recommended
            that IMMA kernels requirements for the regular data ordering listed
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul-regular-imma-conditions">
                <span class="std std-ref">
                    here
                </span>
            </a>
            are met.
        </p>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                            cublasGemmBatchedEx()
                        </a>
                        is only supported for GPU with architecture capabilities equal to or greater than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        ,
                        <span class="pre">
                            Btype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        or the algorithm,
                        <span class="pre">
                            algo
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                or
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Btype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                or
                                <span class="pre">
                                    algo
                                </span>
                                or
                                <span class="pre">
                                    computeType
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Also refer to:
            <a class="reference external" href="http://www.netlib.org/blas/sgemm.f">
                sgemm.
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.14.
            </span>
            cublasGemmStridedBatchedEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmstridedbatchedex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGemmStridedBatchedEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cublasGemmAlgo_t</span><span class="n">algo</span><span class="p">)</span>

<span class="cp">#if defined(__cplusplus)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasGemmStridedBatchedEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideA</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Btype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideB</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">,</span>
<span class="kt">long</span><span class="kt">long</span><span class="kt">int</span><span class="n">strideC</span><span class="p">,</span>
<span class="kt">int</span><span class="n">batchCount</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cublasGemmAlgo_t</span><span class="n">algo</span><span class="p">)</span>
<span class="cp">#endif</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmstridedbatched">
                cublas&lt;t&gt;gemmStridedBatched
            </a>
            that performs the matrix-matrix multiplication of a batch of matrices and allows the user to individually
            specify the data types for each of the A, B and C matrices, the precision of computation and the GEMM
            algorithm to be run. Like
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemmstridedbatched">
                cublas&lt;t&gt;gemmStridedBatched
            </a>
            , the batch is considered to be uniform, i.e. all instances have the same dimensions (m, n, k),
            leading dimensions (lda, ldb, ldc) and transpositions (transa, transb) for their respective A, B and C
            matrices. Input matrices A, B and output matrix C for each instance of the batch are located at fixed
            offsets in number of elements from their locations in the previous instance. Pointers to A, B and C matrices
            for the first instance are passed to the function by the user along with the offsets in number of elements -
            strideA, strideB and strideC that determine the locations of input and output matrices in future instances.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The second variant of
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmstridedbatchedex">
                cublasGemmStridedBatchedEx()
            </a>
            function is provided for backward compatibility with C++ applications code, where the
            <span class="pre">
                computeType
            </span>
            parameter is of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t">
                cudaDataType_t
            </a>
            instead of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                cublasComputeType_t
            </a>
            . C applications would still compile with the updated function signature.
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C + i*{strideC} = \alpha\text{op}(A + i*{strideA})\text{op}(B + i*{strideB}) + \beta(C +
                i*{strideC}),\text{ for i } \in \lbrack 0,batchCount - 1\rbrack\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are arrays of pointers to matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B\lbrack i\rbrack)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\lbrack i\rbrack\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack i\rbrack\)
            </span>
            matrices must not overlap, i.e. the individual gemm operations must be computable independently; otherwise,
            undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-gemm">
                cublas&lt;t&gt;gemm
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            In the table below, we use
            <span class="pre">
                A[i],
            </span>
            <span class="pre">
                B[i],
            </span>
            <span class="pre">
                C[i]
            </span>
            as notation for A, B and C matrices in the ith instance of the batch, implicitly assuming they are
            respectively offsets in number of elements
            <span class="pre">
                strideA,
            </span>
            <span class="pre">
                strideB,
            </span>
            <span class="pre">
                strideC
            </span>
            away from
            <span class="pre">
                A[i-1],
            </span>
            <span class="pre">
                B[i-1],
            </span>
            <span class="pre">
                C[i-1]
            </span>
            . The unit for the offset is number of elements and must not be zero .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            B[i]
                        </span>
                        ) and
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of op(
                        <span class="pre">
                            A[i]
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B[i]
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Scaling factor for A*B of the type that corresponds to the computeType and Ctype, see the table
                        below for details.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to &lt;Atype&gt; matrix, A, corresponds to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        strideA
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            A[i]
                        </span>
                        and
                        <span class="pre">
                            A[i+1]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to &lt;Btype&gt; matrix, B, corresponds to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Btype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        strideB
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            B[i]
                        </span>
                        and
                        <span class="pre">
                            B[i+1]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Scaling factor for C of the type that corresponds to the computeType and Ctype, see the table
                        below for details. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C[i]
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to &lt;Ctype&gt; matrix, C, corresponds to the first instance of the batch, with
                        dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        . Matrices
                        <span class="pre">
                            C[i]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of a two-dimensional array used to store each matrix
                        <span class="pre">
                            C[i]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        strideC
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Value of type long long int that gives the offset in number of elements between
                        <span class="pre">
                            C[i]
                        </span>
                        and
                        <span class="pre">
                            C[i+1]
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        batchCount
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of GEMMs to perform in the batch.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the computation type.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the algorithm. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmalgo-t">
                            cublasGemmAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmstridedbatchedex">
                cublasGemmStridedBatchedEx()
            </a>
            supports the following Compute Type, Scale Type, Atype/Btype, and Ctype:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Compute Type
                    </p>
                </th>
                <th class="head">
                    <p>
                        Scale Type (alpha and beta)
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_16F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32I_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32I
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="8">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td rowspan="6">
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_16BF
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_TF32
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p class="admonition-title">
            Note
        </p>
        <p>
            Compute types
            <span class="pre">
                CUBLAS_COMPUTE_32I
            </span>
            and
            <span class="pre">
                CUBLAS_COMPUTE_32I_PEDANTIC
            </span>
            are only supported with all pointers
            <span class="pre">
                A[i]
            </span>
            ,
            <span class="pre">
                B[i]
            </span>
            being 4-byte aligned and lda, ldb being multiples of 4. For a better performance, it is also recommended
            that IMMA kernels requirements for the regular data ordering listed
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul-regular-imma-conditions">
                <span class="std std-ref">
                    here
                </span>
            </a>
            are met.
        </p>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                            cublasGemmBatchedEx()
                        </a>
                        is only supported for GPU with architecture capabilities equal or greater than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        ,
                        <span class="pre">
                            Btype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        or the algorithm,
                        <span class="pre">
                            algo
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    m
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa
                                </span>
                                or
                                <span class="pre">
                                    transb
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) if
                                <span class="pre">
                                    transa
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) if
                                <span class="pre">
                                    transb
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Btype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                or
                                <span class="pre">
                                    algo
                                </span>
                                or
                                <span class="pre">
                                    computeType
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Also refer to:
            <a class="reference external" href="http://www.netlib.org/blas/sgemm.f">
                sgemm.
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.15.
            </span>
            cublasGemmGroupedBatchedEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmgroupedbatchedex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasGemmGroupedBatchedEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="k">const</span><span class="n">cublasOperation_t</span><span class="n">transa_array</span><span class="p">[],</span>
<span class="k">const</span><span class="n">cublasOperation_t</span><span class="n">transb_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">m_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">n_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">int</span><span class="n">k_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha_array</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Aarray</span><span class="p">[],</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="n">lda_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Barray</span><span class="p">[],</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="n">ldb_array</span><span class="p">[],</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta_array</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="k">const</span><span class="n">Carray</span><span class="p">[],</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="n">ldc_array</span><span class="p">[],</span>
<span class="kt">int</span><span class="n">group_count</span><span class="p">,</span>
<span class="k">const</span><span class="kt">int</span><span class="n">group_size</span><span class="p">[],</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function performs the matrix-matrix multiplication on groups of matrices. A given group is considered
            to be uniform, i.e. all instances have the same dimensions (m, n, k), leading dimensions (lda, ldb,
            ldc) and transpositions (transa, transb) for their respective A, B and C matrices. However, the dimensions,
            leading dimensions, transpositions, and scaling factors (alpha, beta) may vary between groups. The address
            of the input matrices and the output matrix of each instance of the batch are read from arrays of pointers
            passed to the function by the caller. This is functionally equivalent to the following:
        </p>
        <pre><span class="n">idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="k">for</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span><span class="n">group_count</span><span class="o">-</span><span class="mi">1</span>
<span class="k">for</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="o">:</span><span class="n">group_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>
<span class="n">gemmEx</span><span class="p">(</span><span class="n">transa_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">transb_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">m_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">n_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">k_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">alpha_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">Aarray</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">Atype</span><span class="p">,</span><span class="n">lda_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">Barray</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">Btype</span><span class="p">,</span>
<span class="n">ldb_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">beta_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">Carray</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">Ctype</span><span class="p">,</span><span class="n">ldc_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<span class="n">computeType</span><span class="p">,</span><span class="n">CUBLAS_GEMM_DEFAULT</span><span class="p">);</span>
<span class="n">idx</span><span class="o">+=</span><span class="mi">1</span><span class="p">;</span>
<span class="n">end</span>
<span class="n">end</span>
</pre>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\text{$\mathrm{alpha\_array}$}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{$\mathrm{beta\_array}$}\)
            </span>
            are arrays of scaling factors, and
            <span class="math notranslate nohighlight">
                \(\text{Aarray}\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{Barray}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{Carray}\)
            </span>
            are arrays of pointers to matrices stored in column-major format. For a given index,
            <span class="math notranslate nohighlight">
                \(\text{idx}\)
            </span>
            , that is part of group
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
            , the dimensions are:
        </p>
        <ul class="simple">
            <li>
                <p>
                    <span class="math notranslate nohighlight">
                        \(\text{op}(\text{Aarray}\lbrack\text{idx}\rbrack)\)
                    </span>
                    :
                    <span class="math notranslate nohighlight">
                        \(\text{$\mathrm{m\_array}$}\lbrack i\rbrack \times \text{$\mathrm{k\_array}$}\lbrack i\rbrack\)
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="math notranslate nohighlight">
                        \(\text{op}(\text{Barray}\lbrack\text{idx}\rbrack)\)
                    </span>
                    :
                    <span class="math notranslate nohighlight">
                        \(\text{$\mathrm{k\_array}$}\lbrack i\rbrack \times \text{$\mathrm{n\_array}$}\lbrack i\rbrack\)
                    </span>
                </p>
            </li>
            <li>
                <p>
                    <span class="math notranslate nohighlight">
                        \(\text{Carray}\lbrack\text{idx}\rbrack\)
                    </span>
                    :
                    <span class="math notranslate nohighlight">
                        \(\text{$\mathrm{m\_array}$}\lbrack i\rbrack \times \text{$\mathrm{n\_array}$}\lbrack i\rbrack\)
                    </span>
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This API takes arrays of two different lengths. The arrays of dimensions, leading dimensions,
            transpositions, and scaling factors are of length
            <span class="pre">
                group_count
            </span>
            and the arrays of matrices are of length
            <span class="pre">
                problem_count
            </span>
            where
            <span class="math notranslate nohighlight">
                \(\text{$\mathrm{problem\_count}$} = \sum_{i = 0}^{\text{$\mathrm{group\_count}$} - 1}
                \text{$\mathrm{group\_size}$}\lbrack i\rbrack\)
            </span>
        </p>
        <p>
            For matrix
            <span class="math notranslate nohighlight">
                \(A[\text{idx}]\)
            </span>
            in group
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A[\text{idx}]) = \left\{ \begin{matrix}
                A[\text{idx}] &amp; {\text{if }\textsf{$\mathrm{transa\_array}\lbrack i\rbrack$ ==
                $\mathrm{CUBLAS\_OP\_N}$}} \\
                A[\text{idx}]^{T} &amp; {\text{if }\textsf{$\mathrm{transa\_array}\lbrack i\rbrack$ ==
                $\mathrm{CUBLAS\_OP\_T}$}} \\
                A[\text{idx}]^{H} &amp; {\text{if }\textsf{$\mathrm{transa\_array}\lbrack i\rbrack$ ==
                $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B[\text{idx}])\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B[\text{idx}]\)
            </span>
            in group
            <span class="math notranslate nohighlight">
                \(i\)
            </span>
            .
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C\lbrack\text{idx}\rbrack\)
            </span>
            matrices must not overlap, that is, the individual gemm operations must be computable independently;
            otherwise, undefined behavior is expected.
        </p>
        <p>
            On certain problem sizes, it might be advantageous to make multiple calls to
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmbatchedex">
                cublasGemmBatchedEx()
            </a>
            in different CUDA streams, rather than use this API.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
                <th class="head">
                    <p>
                        Array Length
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the operations, op(
                        <span class="pre">
                            A[idx]
                        </span>
                        ), that is non- or (conj.) transpose for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the operations, op(
                        <span class="pre">
                            B[idx]
                        </span>
                        ), that is non- or (conj.) transpose for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the number of rows of matrix op(
                        <span class="pre">
                            A[idx]
                        </span>
                        ) and
                        <span class="pre">
                            C[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the number of columns of op(
                        <span class="pre">
                            B[idx]
                        </span>
                        ) and
                        <span class="pre">
                            C[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the number of columns of op(
                        <span class="pre">
                            A[idx]
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B[idx]
                        </span>
                        ) for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the &lt;type&gt; scalar used for multiplication for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Aarray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            lda[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k[i]
                        </span>
                        with
                        <span class="pre">
                            lda[i]&gt;=max(1,m[i])
                        </span>
                        if
                        <span class="pre">
                            transa[i]==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m[i]
                        </span>
                        with
                        <span class="pre">
                            lda[i]&gt;=max(1,k[i])
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
                <td>
                    <p>
                        problem_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the leading dimensions of two-dimensional arrays used to store each matrix
                        <span class="pre">
                            A[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Barray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array, with each array of dim.
                        <span class="pre">
                            ldb[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n[i]
                        </span>
                        with
                        <span class="pre">
                            ldb[i]&gt;=max(1,k[i])
                        </span>
                        if
                        <span class="pre">
                            transb[i]==CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k[i]
                        </span>
                        with
                        <span class="pre">
                            ldb[i]&gt;=max(1,n[i])
                        </span>
                        otherwise.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
                <td>
                    <p>
                        problem_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Btype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the leading dimensions of two-dimensional arrays used to store each matrix
                        <span class="pre">
                            B[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the &lt;type&gt; scalar used for multiplication for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Carray
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        array of pointers to &lt;type&gt; array. It has dimensions
                        <span class="pre">
                            ldc[i]
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n[i]
                        </span>
                        with
                        <span class="pre">
                            ldc[i]&gt;=max(1,m[i])
                        </span>
                        . Matrices
                        <span class="pre">
                            C[idx]
                        </span>
                        should not overlap; otherwise, undefined behavior is expected.
                    </p>
                    <p>
                        All pointers must meet certain alignment criteria. Please see below for details.
                    </p>
                </td>
                <td>
                    <p>
                        problem_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc_array
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containing the leading dimensions of two-dimensional arrays used to store each matrix
                        <span class="pre">
                            C[idx]
                        </span>
                        for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        group_count
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of groups
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        group_size
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        array containg the number of pointers contained in Aarray, Barray and Carray for each group.
                    </p>
                </td>
                <td>
                    <p>
                        group_count
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the computation type.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasgemmgroupedbatchedex">
                cublasGemmGroupedBatchedEx()
            </a>
            supports the following Compute Type, Scale Type, Atype/Btype, and Ctype:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Compute Type
                    </p>
                </th>
                <th class="head">
                    <p>
                        Scale Type (alpha and beta)
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td rowspan="3">
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F
                        </span>
                    </p>
                </td>
                <td rowspan="3">
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_32F_FAST_TF32
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F
                        </span>
                        or
                    </p>
                    <p>
                        <span class="pre">
                            CUBLAS_COMPUTE_64F_PEDANTIC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            If
            <span class="pre">
                Atype
            </span>
            is
            <span class="pre">
                CUDA_R_16F
            </span>
            or
            <span class="pre">
                CUDA_R_16BF
            </span>
            or if the
            <span class="pre">
                computeType
            </span>
            is any of the
            <span class="pre">
                FAST
            </span>
            options, pointers (not the pointer arrays) placed in the GPU memory must be properly aligned to avoid
            misaligned memory access errors. Ideally all pointers are aligned to at least 16 Bytes. Otherwise it is
            required that they meet the following rule:
        </p>
        <ul class="simple">
            <li>
                <p>
                    if
                    <span class="pre">
                        (k
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        AtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        16
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    ,
                </p>
            </li>
            <li>
                <p>
                    if
                    <span class="pre">
                        (k
                    </span>
                    <span class="pre">
                        *
                    </span>
                    <span class="pre">
                        AtypeSize)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        4
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    then ensure
                    <span class="pre">
                        intptr_t(ptr)
                    </span>
                    <span class="pre">
                        %
                    </span>
                    <span class="pre">
                        4
                    </span>
                    <span class="pre">
                        ==
                    </span>
                    <span class="pre">
                        0
                    </span>
                    .
                </p>
            </li>
        </ul>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    transa_array
                                </span>
                                ,
                                <span class="pre">
                                    transb_array
                                </span>
                                ,
                                <span class="pre">
                                    m_array
                                </span>
                                ,
                                <span class="pre">
                                    n_array
                                </span>
                                ,
                                <span class="pre">
                                    k_array
                                </span>
                                ,
                                <span class="pre">
                                    alpha_array
                                </span>
                                ,
                                <span class="pre">
                                    lda_array
                                </span>
                                ,
                                <span class="pre">
                                    ldb_array
                                </span>
                                ,
                                <span class="pre">
                                    beta_array
                                </span>
                                ,
                                <span class="pre">
                                    ldc_array
                                </span>
                                , or
                                <span class="pre">
                                    group_size
                                </span>
                                are NULL or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    group_count
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    m_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    n_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    k_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    group_size[i]
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    transa_array[i]
                                </span>
                                ,
                                <span class="pre">
                                    transb_array[i]
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m_array[i]
                                </span>
                                ) if
                                <span class="pre">
                                    transa_array[i]
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k_array[i]
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldb_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k_array[i]
                                </span>
                                ) if
                                <span class="pre">
                                    transb_array[i]
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    ldb_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n_array[i]
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc_array[i]
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    m_array[i]
                                </span>
                                )
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                the pointer mode is set to
                                <span class="pre">
                                    CUBLAS_POINTER_MODE_DEVICE
                                </span>
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Btype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                or
                                <span class="pre">
                                    computeType
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                2.8.16.
            </span>
            cublasCsyrkEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascsyrkex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCsyrkEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syrk">
                cublasCsyrk()
            </a>
            where the input matrix and output matrix can have a lower precision but the computation is still done in the
            type
            <span class="pre">
                cuComplex
            </span>
        </p>
        <p>
            This function performs the symmetric rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{T} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This routine is only supported on GPUs with architecture capabilities equal to or greater than 5.0
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix A.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The matrix types combinations supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascsyrkex">
                cublasCsyrkEx()
            </a>
            are listed below:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        A
                    </p>
                </th>
                <th class="head">
                    <p>
                        C
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The device has a compute capability lower than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyrk.f">
                ssyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyrk.f">
                dsyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyrk.f">
                csyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyrk.f">
                zsyrk
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.17.
            </span>
            cublasCsyrk3mEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascsyrk3mex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCsyrk3mEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-syrk">
                cublasCsyrk()
            </a>
            where the input matrix and output matrix can have a lower precision but the computation is still done in the
            type
            <span class="pre">
                cuComplex
            </span>
            . This routine is implemented using the Gauss complexity reduction algorithm which can lead to an increase
            in performance up to 25%
        </p>
        <p>
            This function performs the symmetric rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{T} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This routine is only supported on GPUs with architecture capabilities equal to or greater than 5.0
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix A.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The matrix types combinations supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascsyrk3mex">
                cublasCsyrk3mEx()
            </a>
            are listed below :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        A
                    </p>
                </th>
                <th class="head">
                    <p>
                        C
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The device has a compute capability lower than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyrk.f">
                ssyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyrk.f">
                dsyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyrk.f">
                csyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyrk.f">
                zsyrk
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.18.
            </span>
            cublasCherkEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascherkex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCherkEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-herk">
                cublasCherk()
            </a>
            where the input matrix and output matrix can have a lower precision but the computation is still done in the
            type
            <span class="pre">
                cuComplex
            </span>
        </p>
        <p>
            This function performs the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This routine is only supported on GPUs with architecture capabilities equal to or greater than 5.0
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The matrix types combinations supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascherkex">
                cublasCherkEx()
            </a>
            are listed in the following table:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        A
                    </p>
                </th>
                <th class="head">
                    <p>
                        C
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The device has a compute capability lower than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cherk.f">
                cherk
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.19.
            </span>
            cublasCherk3mEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascherk3mex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasCherk3mEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Atype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">Ctype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension of
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-herk">
                cublasCherk()
            </a>
            where the input matrix and output matrix can have a lower precision but the computation is still done in the
            type
            <span class="pre">
                cuComplex
            </span>
            . This routine is implemented using the Gauss complexity reduction algorithm which can lead to an increase
            in performance up to 25%
        </p>
        <p>
            This function performs the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This routine is only supported on GPUs with architecture capabilities equal to or greater than 5.0
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Atype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Ctype
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The matrix types combinations supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascherk3mex">
                cublasCherk3mEx()
            </a>
            are listed in the following table:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        A
                    </p>
                </th>
                <th class="head">
                    <p>
                        C
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_8I
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    n
                                </span>
                                &lt; 0 or
                                <span class="pre">
                                    k
                                </span>
                                &lt; 0 or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    uplo
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_FILL_MODE_UPPER
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_FILL_MODE_LOWER
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    trans
                                </span>
                                !=
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_C
                                </span>
                                ,
                                <span class="pre">
                                    CUBLAS_OP_T
                                </span>
                                or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) if
                                <span class="pre">
                                    trans
                                </span>
                                ==
                                <span class="pre">
                                    CUBLAS_OP_N
                                </span>
                                and
                                <span class="pre">
                                    lda
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    k
                                </span>
                                ) otherwise or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    ldc
                                </span>
                                &lt; max(1,
                                <span class="pre">
                                    n
                                </span>
                                ) or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    Atype
                                </span>
                                or
                                <span class="pre">
                                    Ctype
                                </span>
                                is not supported
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            Atype
                        </span>
                        and
                        <span class="pre">
                            Ctype
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The device has a compute capability lower than 5.0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cherk.f">
                cherk
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.20.
            </span>
            cublasNrm2Ex()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasnrm2ex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasNrm2Ex</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">xType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">result</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">resultType</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">executionType</span><span class="p">)</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an API generalization of the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-nrm2">
                cublas&lt;t&gt;nrm2
            </a>
            where input data, output data and compute type can be specified independently.
        </p>
        <p>
            This function computes the Euclidean norm of the vector
            <span class="pre">
                x
            </span>
            . The code uses a multiphase model of accumulation to avoid intermediate underflow and overflow, with the
            result being equivalent to
            <span class="math notranslate nohighlight">
                \(\sqrt{\sum_{i = 1}^{n}\left( {\mathbf{x}\lbrack j\rbrack \times \mathbf{x}\lbrack j\rbrack} \right)}\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            in exact arithmetic. Notice that the last equation reflects 1-based indexing used for compatibility with
            Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        xType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        the resulting norm, which is
                        <span class="pre">
                            0.0
                        </span>
                        if
                        <span class="pre">
                            n,incx&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        resultType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of the
                        <span class="pre">
                            result
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        executionType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype in which the computation is executed.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The datatypes combinations currently supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasnrm2ex">
                cublasNrm2Ex()
            </a>
            are listed below :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        x
                    </p>
                </th>
                <th class="head">
                    <p>
                        result
                    </p>
                </th>
                <th class="head">
                    <p>
                        execution
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the reduction buffer could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the combination of the parameters
                        <span class="pre">
                            xType
                        </span>
                        ,
                        <span class="pre">
                            resultType
                        </span>
                        and
                        <span class="pre">
                            executionType
                        </span>
                        is not supported
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    xType
                                </span>
                                or
                                <span class="pre">
                                    resultType
                                </span>
                                or
                                <span class="pre">
                                    executionType
                                </span>
                                is not supported or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    result
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/snrm2.f90">
                snrm2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dnrm2.f90">
                dnrm2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/scnrm2.f90">
                scnrm2
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dznrm2.f90">
                dznrm2
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.21.
            </span>
            cublasAxpyEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasaxpyex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasAxpyEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">alphaType</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">xType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">y</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">yType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">executiontype</span><span class="p">);</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an API generalization of the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-axpy">
                cublas&lt;t&gt;axpy
            </a>
            where input data, output data and compute type can be specified independently.
        </p>
        <p>
            This function multiplies the vector
            <span class="pre">
                x
            </span>
            by the scalar
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and adds it to the vector
            <span class="pre">
                y
            </span>
            overwriting the latest vector with the result. Hence, the performed operation is
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\lbrack j\rbrack = \alpha \times \mathbf{x}\lbrack k\rbrack + \mathbf{y}\lbrack j\rbrack\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alphaType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of scalar
                        <span class="pre">
                            alpha
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        xType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        yType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of vector
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        executionType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype in which the computation is executed.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The datatypes combinations currently supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasaxpyex">
                cublasAxpyEx()
            </a>
            are listed in the following table:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        alpha
                    </p>
                </th>
                <th class="head">
                    <p>
                        x
                    </p>
                </th>
                <th class="head">
                    <p>
                        y
                    </p>
                </th>
                <th class="head">
                    <p>
                        execution
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            xType
                        </span>
                        ,
                        <span class="pre">
                            yType
                        </span>
                        , and
                        <span class="pre">
                            executionType
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            alphaType
                        </span>
                        or
                        <span class="pre">
                            xType
                        </span>
                        or
                        <span class="pre">
                            yType
                        </span>
                        or
                        <span class="pre">
                            executionType
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/saxpy.f">
                saxpy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/daxpy.f">
                daxpy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/caxpy.f">
                caxpy
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zaxpy.f">
                zaxpy
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.22.
            </span>
            cublasDotEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdotex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasDotEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">xType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">y</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">yType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">result</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">resultType</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">executionType</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasDotcEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">xType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">y</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">yType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">result</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">resultType</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">executionType</span><span class="p">);</span>
</pre>
        <p>
            These functions support the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            These functions are an API generalization of the routines
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#id3">
                cublas&lt;t&gt;dot
            </a>
            and
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dotc">
                cublas&lt;t&gt;dotc
            </a>
            where input data, output data and compute type can be specified independently. Note:
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dotc">
                cublas&lt;t&gt;dotc
            </a>
            is dot product conjugated,
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-dotu">
                cublas&lt;t&gt;dotu
            </a>
            is dot product unconjugated.
        </p>
        <p>
            This function computes the dot product of vectors
            <span class="pre">
                x
            </span>
            and
            <span class="pre">
                y
            </span>
            . Hence, the result is
            <span class="math notranslate nohighlight">
                \(\sum_{i = 1}^{n}\left( {\mathbf{x}\lbrack k\rbrack \times \mathbf{y}\lbrack j\rbrack} \right)\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that in the first equation the conjugate of the element of vector x should be used if the function
            name ends in character c and that the last two equations reflect 1-based indexing used for
            compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Number of elements in the vectors
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        xType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        yType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of vector
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        output
                    </p>
                </td>
                <td>
                    <p>
                        The resulting dot product, which is
                        <span class="pre">
                            0.0
                        </span>
                        if
                        <span class="pre">
                            n&lt;=0
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        resultType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype of the
                        <span class="pre">
                            result
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        executionType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant specifying the datatype in which the computation is executed.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The datatypes combinations currently supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdotex">
                cublasDotEx()
            </a>
            and
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdotex">
                cublasDotcEx()
            </a>
            are listed below:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        x
                    </p>
                </th>
                <th class="head">
                    <p>
                        y
                    </p>
                </th>
                <th class="head">
                    <p>
                        result
                    </p>
                </th>
                <th class="head">
                    <p>
                        execution
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed in the following table:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The operation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The reduction buffer could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The combination of the parameters
                        <span class="pre">
                            xType
                        </span>
                        ,
                        <span class="pre">
                            yType
                        </span>
                        ,
                        <span class="pre">
                            resultType
                        </span>
                        and
                        <span class="pre">
                            executionType
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The function failed to launch on the GPU.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            xType
                        </span>
                        or
                        <span class="pre">
                            yType
                        </span>
                        or
                        <span class="pre">
                            resultType
                        </span>
                        or
                        <span class="pre">
                            executionType
                        </span>
                        is not supported.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sdot.f">
                sdot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ddot.f">
                ddot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cdotu.f">
                cdotu
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cdotc.f">
                cdotc
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdotu.f">
                zdotu
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdotc.f">
                zdotc
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.23.
            </span>
            cublasRotEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasrotex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasRotEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">xType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">y</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">yType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incy</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">c</span><span class="p">,</span><span class="cm">/* host or device pointer */</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">s</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">csType</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">executiontype</span><span class="p">);</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function is an extension to the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-t-rot">
                cublas&lt;t&gt;rot
            </a>
            where input data, output data, cosine/sine type, and compute type can be specified independently.
        </p>
        <p>
            This function applies Givens rotation matrix (i.e., rotation in the x,y plane counter-clockwise by angle
            defined by cos(alpha)=c, sin(alpha)=s):
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(G = \begin{pmatrix}
                c &amp; s \\
                {- s} &amp; c \\
                \end{pmatrix}\)
            </span>
        </p>
        <p>
            to vectors
            <span class="pre">
                x
            </span>
            and
            <span class="pre">
                y
            </span>
            .
        </p>
        <p>
            Hence, the result is
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\lbrack k\rbrack = c \times \mathbf{x}\lbrack k\rbrack + s \times \mathbf{y}\lbrack
                j\rbrack\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\lbrack j\rbrack = - s \times \mathbf{x}\lbrack k\rbrack + c \times \mathbf{y}\lbrack
                j\rbrack\)
            </span>
            where
            <span class="math notranslate nohighlight">
                \(k = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incy}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vectors
                        <span class="pre">
                            x
                        </span>
                        and
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        xType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        y
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        yType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of vector
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        incy
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            y
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        c
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        cosine element of the rotation matrix.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        s
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        sine element of the rotation matrix.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        csType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of
                        <span class="pre">
                            c
                        </span>
                        and
                        <span class="pre">
                            s
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        executionType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype in which the computation is executed.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The datatypes combinations currently supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasrotex">
                cublasRotEx()
            </a>
            are listed below :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        executionType
                    </p>
                </th>
                <th class="head">
                    <p>
                        xType / yType
                    </p>
                </th>
                <th class="head">
                    <p>
                        csType
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/srot.f">
                srot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/drot.f">
                drot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/lapack_routine/crot.f">
                crot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csrot.f">
                csrot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/lapack/lapack_routine/zrot.f">
                zrot
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdrot.f">
                zdrot
            </a>
        </p>
        <h3>
            <span class="section-number">
                2.8.24.
            </span>
            cublasScalEx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasscalex"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasScalEx</span><span class="p">(</span><span class="n">cublasHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">alphaType</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">x</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">xType</span><span class="p">,</span>
<span class="kt">int</span><span class="n">incx</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">executionType</span><span class="p">);</span>
</pre>
        <p>
            This function supports the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#bit-integer-interface">
                64-bit Integer Interface
            </a>
            .
        </p>
        <p>
            This function scales the vector
            <span class="pre">
                x
            </span>
            by the scalar
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and overwrites it with the result. Hence, the performed operation is
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\lbrack j\rbrack = \alpha \times \mathbf{x}\lbrack j\rbrack\)
            </span>
            for
            <span class="math notranslate nohighlight">
                \(i = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(j = 1 + \left( {i - 1} \right)*\text{incx}\)
            </span>
            . Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLAS library context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of elements in the vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alphaType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of scalar
                        <span class="pre">
                            alpha
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        x
                    </p>
                </td>
                <td>
                    <p>
                        device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; vector with
                        <span class="pre">
                            n
                        </span>
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        xType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype of vector
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        incx
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        stride between consecutive elements of
                        <span class="pre">
                            x
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        executionType
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        enumerant specifying the datatype in which the computation is executed.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The datatypes combinations currently supported for
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasscalex">
                cublasScalEx()
            </a>
            are listed below :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        alpha
                    </p>
                </th>
                <th class="head">
                    <p>
                        x
                    </p>
                </th>
                <th class="head">
                    <p>
                        execution
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_R_64F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_32F
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            CUDA_C_64F
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the combination of the parameters
                        <span class="pre">
                            xType
                        </span>
                        and
                        <span class="pre">
                            executionType
                        </span>
                        is not supported
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            alphaType
                        </span>
                        or
                        <span class="pre">
                            xType
                        </span>
                        or
                        <span class="pre">
                            executionType
                        </span>
                        is not supported
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sscal.f">
                sscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dscal.f">
                dscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csscal.f">
                csscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cscal.f">
                cscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zdscal.f">
                zdscal
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zscal.f">
                zscal
            </a>
        </p>
        <h1>
            <span class="section-number">
                3.
            </span>
            Using the cuBLASLt API
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublaslt-api"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <h2>
            <span class="section-number">
                3.1.
            </span>
            General Description
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id41"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The cuBLASLt library is a new lightweight library dedicated to GEneral Matrix-to-matrix Multiply (GEMM)
            operations with a new flexible API. This new library adds flexibility in matrix data layouts, input types,
            compute types, and also in choosing the algorithmic implementations and heuristics through parameter
            programmability.
        </p>
        <p>
            Once a set of options for the intended GEMM operation are identified by the user, these options can be used
            repeatedly for different inputs. This is analogous to how cuFFT and FFTW first create a plan and reuse for
            same size and type FFTs with different input data.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The cuBLASLt library does not guarantee the support of all possible sizes and configurations, however, since
            CUDA 12.2 update 2, the problem size limitations on m, n, and batch size have been largely resolved. The
            main focus of the library is to provide the most performant kernels, which might have some implied
            limitations. Some non-standard configurations may require a user to handle them manually, typically by
            decomposing the problem into smaller parts (see
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#problem-size-limitations">
                Problem Size Limitations
            </a>
            ).
        </p>
        <h3>
            <span class="section-number">
                3.1.1.
            </span>
            Problem Size Limitations
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#problem-size-limitations"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            There are inherent problem size limitations that are a result of limitations in CUDA grid dimensions. For
            example, many kernels do not support batch sizes greater than 65535 due to a limitation on the
            z
            dimension of a grid. There are similar restriction on the m and n values for a given problem.
        </p>
        <p>
            In cases where a problem cannot be run by a single kernel, cuBLASLt will attempt to decompose the problem
            into multiple sub-problems and solve it by running the kernel on each sub-problem.
        </p>
        There are some restrictions on cuBLASLt internal problem decomposition which are summarized below:
        <ul class="simple">
            <li>
                <p>
                    Amax computations are not supported. This means that
                    <span class="pre">
                        CUBLASLT_MATMUL_DESC_AMAX_D_POINTER
                    </span>
                    and
                    <span class="pre">
                        CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_AMAX_POINTER
                    </span>
                    must be left unset (see
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                        cublasLtMatmulDescAttributes_t
                    </a>
                    )
                </p>
            </li>
            <li>
                <p>
                    All matrix layouts must have
                    <span class="pre">
                        CUBLASLT_MATRIX_LAYOUT_ORDER
                    </span>
                    set to
                    <span class="pre">
                        CUBLASLT_ORDER_COL
                    </span>
                    (see
                    <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                        cublasLtOrder_t
                    </a>
                    )
                </p>
            </li>
            <li>
                <p>
                    cuBLASLt will not partition along the n dimension when
                    <span class="pre">
                        CUBLASLT_MATMUL_DESC_EPILOGUE
                    </span>
                    is set to
                    <span class="pre">
                        CUBLASLT_EPILOGUE_DRELU_BGRAD
                    </span>
                    or
                    <span class="pre">
                        CUBLASLT_EPILOGUE_DGELU_BGRAD
                    </span>
                    (see
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltepilogue-t">
                        cublasLtEpilogue_t
                    </a>
                    )
                </p>
            </li>
        </ul>
        <p>
            To overcome these limitations, a user may want to partition the problem themself, launch kernels for each
            sub-problem, and compute any necessary reductions to combine the results.
        </p>
        <h3>
            <span class="section-number">
                3.1.2.
            </span>
            Heuristics Cache
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#heuristics-cache"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            cuBLASLt uses heuristics to pick the most suitable matmul kernel for execution based on the problem sizes,
            GPU configuration, and other parameters. This requires performing some computations on the host CPU, which
            could take tens of microseconds. To overcome this overhead, it is recommended to query the heuristics once
            using
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic">
                cublasLtMatmulAlgoGetHeuristic()
            </a>
            and then reuse the result for subsequent computations using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            .
        </p>
        <p>
            For the cases where querying heuristics once and then reusing them is not feasible, cuBLASLt implements a
            heuristics cache that maps matmul problems to kernels previously selected by heuristics. The heuristics
            cache uses an LRU-like eviction policy and is thread-safe.
        </p>
        <p>
            The user can control the heuristics cache capacity with the
            <span class="pre">
                CUBLASLT_HEURISTICS_CACHE_CAPACITY
            </span>
            environment variable or with the
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachesetcapacity">
                cublasLtHeuristicsCacheSetCapacity()
            </a>
            function which has higher precedence. The capacity is measured in number of entries and might be rounded up
            to the nearest multiple of some factor for performance reasons. Each entry takes about 360 bytes but is
            subject to change. The default capacity is 8192 entries.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            Setting capacity to zero disables the cache completely. This can be useful for workloads that do not have a
            steady state and for which cache operations may have higher overhead than regular heuristics computations.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The cache is not ideal for performance reasons, so it is sometimes necessary to increase its capacity
            1.5x-2.x over the anticipated number of unique matmul problems to achieve a nearly perfect hit rate.
        </p>
        <p>
            See also:
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachegetcapacity">
                cublasLtHeuristicsCacheGetCapacity()
            </a>
            ,
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachesetcapacity">
                cublasLtHeuristicsCacheSetCapacity()
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                3.1.3.
            </span>
            cuBLASLt Logging
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-logging"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            cuBLASLt logging mechanism can be enabled by setting the following environment variables before launching
            the target application:
        </p>
        <ul>
            <li>
                <p>
                    <span class="pre">
                        CUBLASLT_LOG_LEVEL=&lt;level&gt;
                    </span>
                    , where
                    <span class="pre">
                        &lt;level&gt;
                    </span>
                    is one of the following levels:
                </p>
                <ul class="simple">
                    <li>
                        <p>
                            0 - Off - logging is disabled (default)
                        </p>
                    </li>
                    <li>
                        <p>
                            1 - Error - only errors will be logged
                        </p>
                    </li>
                    <li>
                        <p>
                            2 - Trace - API calls that launch CUDA kernels will log their parameters and important
                            information
                        </p>
                    </li>
                    <li>
                        <p>
                            3 - Hints - hints that can potentially improve the applications performance
                        </p>
                    </li>
                    <li>
                        <p>
                            4 - Info - provides general information about the library execution, may contain
                            details about heuristic status
                        </p>
                    </li>
                    <li>
                        <p>
                            5 - API Trace - API calls will log their parameter and important information
                        </p>
                    </li>
                </ul>
            </li>
            <li>
                <p>
                    <span class="pre">
                        CUBLASLT_LOG_MASK=&lt;mask&gt;
                    </span>
                    , where
                    <span class="pre">
                        &lt;mask&gt;
                    </span>
                    is a combination of the following flags:
                </p>
                <ul class="simple">
                    <li>
                        <p>
                            0 - Off
                        </p>
                    </li>
                    <li>
                        <p>
                            1 - Error
                        </p>
                    </li>
                    <li>
                        <p>
                            2 - Trace
                        </p>
                    </li>
                    <li>
                        <p>
                            4 - Hints
                        </p>
                    </li>
                    <li>
                        <p>
                            8 - Info
                        </p>
                    </li>
                    <li>
                        <p>
                            16 - API Trace
                        </p>
                    </li>
                </ul>
                <p>
                    For example, use
                    <span class="pre">
                        CUBLASLT_LOG_MASK=5
                    </span>
                    to enable Error and Hints messages.
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        CUBLASLT_LOG_FILE=&lt;file_name&gt;
                    </span>
                    , where
                    <span class="pre">
                        &lt;file_name&gt;
                    </span>
                    is a path to a logging file. File name may contain
                    <span class="pre">
                        %i
                    </span>
                    , that will be replaced with the process ID. For example
                    <span class="pre">
                        &lt;file_name&gt;_%i.log
                    </span>
                    .
                </p>
            </li>
        </ul>
        <p>
            If
            <span class="pre">
                CUBLASLT_LOG_FILE
            </span>
            is not defined, the log messages are printed to stdout.
        </p>
        <p>
            Another option is to use the experimental cuBLASLt logging API. See:
        </p>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetcallback">
                cublasLtLoggerSetCallback()
            </a>
            ,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetfile">
                cublasLtLoggerSetFile()
            </a>
            ,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggeropenfile">
                cublasLtLoggerOpenFile()
            </a>
            ,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetlevel">
                cublasLtLoggerSetLevel()
            </a>
            ,
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetmask">
                cublasLtLoggerSetMask()
            </a>
            ,
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggerforcedisable">
                cublasLtLoggerForceDisable()
            </a>
        </p>
        <h3>
            <span class="section-number">
                3.1.4.
            </span>
            8-bit Floating Point Data Types (FP8) Usage
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#bit-floating-point-data-types-fp8-usage"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            FP8 was first introduced with Ada and Hopper GPUs (compute capability 8.9 and above) and is designed to
            further accelerate matrix multiplications. There are two types of FP8 available:
        </p>
        <ul class="simple">
            <li>
                <p>
                    <span class="pre">
                        CUDA_R_8F_E4M3
                    </span>
                    is designed to be accurate at a smaller dynamic range than half precision. The E4 and M3 represent a
                    4-bit exponent and a 3-bit mantissa respectively. For more details, see
                    <a class="reference external"
                        href="https://docs.nvidia.com/cuda/cuda-math-api/struct____nv__fp8__e4m3.html#struct____nv__fp8__e4m3">
                        __nv__fp8__e4m3
                    </a>
                    .
                </p>
            </li>
            <li>
                <p>
                    <span class="pre">
                        CUDA_R_8F_E5M2
                    </span>
                    is designed to be accurate at a similar dynamic range as half precision. The E5 and M2 represent a
                    5-bit exponent and a 2-bit mantissa respectively. For more information see
                    <a class="reference external"
                        href="https://docs.nvidia.com/cuda/cuda-math-api/struct____nv__fp8__e5m2.html#struct____nv__fp8__e5m2">
                        __nv__fp8__e5m2
                    </a>
                    .
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            Unless otherwise stated, FP8 refers to both
            <span class="pre">
                CUDA_R_8F_E4M3
            </span>
            and
            <span class="pre">
                CUDA_R_8F_E5M2
            </span>
            .
        </p>
        <p>
            In order to maintain accurate FP8 matrix multiplications, we define native compute FP8 matrix multiplication
            as follows:
        </p>
        \[D = scale_D \cdot (\alpha \cdot scale_A \cdot scale_B \cdot \text{op}(A) \text{op}(B) + \beta \cdot scale_C
        \cdot C)\]
        <p>
            where A, B, and C are input matrices, and scaleA, scaleB, scaleC, scaleD, alpha, and beta are input scalars.
            This differs from the other matrix multiplication routines because of this addition of scaling factors for
            each matrix. The scaleA, scaleB, and scaleC are used for de-quantization, and scaleD is used for
            quantization. Note that all the scaling factors are applied multiplicatively. This means that sometimes it
            is necessary to use a scaling factor or its reciprocal depending on the context in which it is applied. For
            more information on FP8, see
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                cublasLtMatmulDescAttributes_t
            </a>
            .
        </p>
        <p>
            For FP8 matrix multiplications, epilogues and amaxD may be computed as follows:
        </p>
        \[\begin{split}D_{temp}, Aux_{temp} &amp; = \mathop{Epilogue}(\alpha \cdot scale_A \cdot scale_B \cdot
        \text{op}(A) \text{op}(B) + \beta \cdot scale_C \cdot C) \\
        amax_{D} &amp; = \mathop{absmax}(D_{temp}) \\
        amax_{Aux} &amp; = \mathop{absmax}(Aux_{temp}) \\
        D &amp; = scale_D * D_{temp} \\
        Aux &amp; = scale_{Aux} * Aux_{temp} \\\end{split}\]
        <p>
            Here Aux is an auxiliary output of an epilogue function like GELU, scaleAux is an optional scaling factor
            that can be applied to Aux, and amaxAux is the maximum absolute value in Aux before scaling. For more
            information, see attributes
            <span class="pre">
                CUBLASLT_MATMUL_DESC_AMAX_D_POINTER
            </span>
            and
            <span class="pre">
                CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_AMAX_POINTER
            </span>
            in
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                cublasLtMatmulDescAttributes_t
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                3.1.5.
            </span>
            Disabling CPU Instructions
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#disabling-cpu-instructions"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            As mentioned in the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#heuristics-cache">
                Heuristics Cache
            </a>
            section, cuBLASLt heuristics perform some compute-intensive operations on the host CPU.
            To speed-up the operations, the implementation detects CPU capabilities and may use special instructions,
            such as Advanced Vector Extensions (AVX) on x86-64 CPUs.
            However, in some rare cases this might be not desirable. For instance, using advanced instructions may
            result in CPU running at a lower frequency, which would affect performance of the other host code.
        </p>
        <p>
            The user can optionally instruct the cuBLASLt library to not use some CPU instructions with the
            <span class="pre">
                CUBLASLT_DISABLE_CPU_INSTRUCTIONS_MASK
            </span>
            environment variable or with the
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdisablecpuinstructionssetmask">
                cublasLtDisableCpuInstructionsSetMask()
            </a>
            function which has higher precedence.
            The default mask is 0, meaning that there are no restrictions.
        </p>
        <p>
            Please check
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdisablecpuinstructionssetmask">
                cublasLtDisableCpuInstructionsSetMask()
            </a>
            for more information.
        </p>
        <h3>
            <span class="section-number">
                3.1.6.
            </span>
            Atomics Synchronization
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            Atomics synchronization allows optimizing matmul workloads by enabling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            to have a producer or consumer relationship with another concurrently running kernel. This allows
            overlapping computation and communication with a finer granularity. Conceptually, matmul is provided with an
            array containing 32-bit integer counters, and then:
        </p>
        <ul class="simple">
            <li>
                <p>
                    In the consumer mode, either matrix A is partitioned into chunks by rows, or matrix B is partitioned
                    into chunks by columns
                    <a class="footnote-reference brackets"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#ascolrow" id="id42">
                        1
                    </a>
                    . A chunk can be read from memory and used in computations only when the corresponding atomic
                    counter reaches value of 0. The producer should execute a memory fence to ensure that the written
                    value is visible to the concurrently running matmul kernel
                    <a class="footnote-reference brackets"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#asmemfence" id="id43">
                        2
                    </a>
                    .
                </p>
            </li>
            <li>
                <p>
                    In the producer mode, the output matrix C (or D in the out-of-place mode), is partitioned by rows or
                    columns, and after a chunk is computed, the corresponding atomic counter is set to 0. Each counter
                    must be initialized to 1 before the matmul kernel runs.
                </p>
            </li>
        </ul>
        <span class="brackets">
            <a class="fn-backref" href="https://docs.nvidia.com/cuda/cublas/index.html#id42">
                1
            </a>
        </span>
        <p>
            The current implementation allows partitioning either the rows or the columns of the matrixes, but not both.
            Batched cases are not supported.
        </p>
        <span class="brackets">
            <a class="fn-backref" href="https://docs.nvidia.com/cuda/cublas/index.html#id43">
                2
            </a>
        </span>
        <p>
            One possible implementation of a memory fence is
            <span class="pre">
                cuda::atomic_thread_fence(cuda::memory_order_seq_cst,
            </span>
            <span class="pre">
                cuda::thread_scope::thread_scope_device)
            </span>
            (see
            <a class="reference external"
                href="https://nvidia.github.io/libcudacxx/extended_api/synchronization_primitives/atomic/atomic_thread_fence.html">
                cuda::atomic_thread_fence()
            </a>
            for more details).
        </p>
        <p>
            The array of counters are passed to matmuls via the
            <span class="pre">
                CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_IN_COUNTERS_POINTER
            </span>
            and
            <span class="pre">
                CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_OUT_COUNTERS_POINTER
            </span>
            compute descriptor attributes for the consumer and producer modes respectively
            <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#asmode"
                id="id44">
                3
            </a>
            . The arrays must have a sufficient number of elements for all the chunks.
        </p>
        <span class="brackets">
            <a class="fn-backref" href="https://docs.nvidia.com/cuda/cublas/index.html#id44">
                3
            </a>
        </span>
        <p>
            The current implementation allows to only enable either the producer or the consumer mode, but not both.
            Matmul will return an error if both input and output counter pointers to a non-NULL value.
        </p>
        <p>
            The number of chunks is controlled by
            <span class="pre">
                CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_NUM_CHUNKS_D_ROWS
            </span>
            and
            <span class="pre">
                CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_NUM_CHUNKS_D_COLS
            </span>
            compute descriptor attributes. Both of these attributes must be set to a value greater than zero for the
            feature to be enabled. For the column-major layout, the number of chunks must satisfy:
        </p>
        \[\begin{split}0 \leq \text{$\mathrm{NUM\_CHUNKS\_ROWS}$} \leq &amp; \mathop{\text{floor}}\left(
        \frac{\text{M}}{\text{$\mathrm{TILE\_SIZE\_M}$} * \text{$\mathrm{CLUSTER\_SHAPE\_M}$}} \right) \\
        0 \leq \text{$\mathrm{NUM\_CHUNKS\_COLS}$} \leq &amp; \mathop{\text{floor}}\left(
        \frac{\text{N}}{\text{$\mathrm{TILE\_SIZE\_N}$} * \text{$\mathrm{CLUSTER\_SHAPE\_N}$}} \right)\end{split}\]
        <p>
            For row-major layout, M and N in tile size and cluster shape must be swapped. These restrictions mean that
            it is required to first query heuristic via
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic">
                cublasLtMatmulAlgoGetHeuristic()
            </a>
            and inspect the result for tile and cluster shapes, and only then set the number of chunks.
        </p>
        <p>
            The pseudocode below shows the principles of operation:
        </p>
        <pre><span class="c1">// The code below shows operation when partitioning over</span>
<span class="c1">// rows assuming column-major layout and TN case.</span>
<span class="c1">//</span>
<span class="c1">// The case when partitioning is done over columns or</span>
<span class="c1">// row-major case are handled in a similar fashion,</span>
<span class="c1">// with the main difference being the offsets</span>
<span class="c1">// computations.</span>
<span class="c1">//</span>
<span class="c1">// Note that the actual implementation does not</span>
<span class="c1">// guarantee in which order the chunks are computed,</span>
<span class="c1">// and may employ various optimizations to improve</span>
<span class="c1">// overall performance.</span>
<span class="c1">//</span>
<span class="c1">// Here:</span>
<span class="c1">//   - A, B, C -- input matrices in the column-major layout</span>
<span class="c1">//   - lda -- leading dimension of matrix A</span>
<span class="c1">//   - M, N, K -- the original problem dimensions</span>
<span class="c1">//   - counters_in[] and counters_out[] -- the arrays of</span>
<span class="c1">//     input and output atomic counters</span>
<span class="c1">//</span>
<span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">NUM_CHUNKS_ROWS</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="c1">// Consumer: wait for the input counter to become 0</span>
<span class="k">if</span><span class="p">(</span><span class="n">consumer</span><span class="p">)</span><span class="p">{</span>
<span class="k">while</span><span class="p">(</span><span class="n">counters_in</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">!=</span><span class="mi">0</span><span class="p">);</span><span class="c1">// spin</span>
<span class="p">}</span>

<span class="c1">// compute chunk dimensions</span>
<span class="n">chunk_m_begin</span><span class="o">=</span><span class="n">floor</span><span class="p">((</span><span class="kt">double</span><span class="p">)</span><span class="n">M</span><span class="o">/</span><span class="n">NUM_CHUNKS_ROWS</span><span class="o">*</span><span class="n">i</span><span class="p">);</span>
<span class="n">chunk_m_end</span><span class="o">=</span><span class="n">floor</span><span class="p">((</span><span class="kt">double</span><span class="p">)</span><span class="n">M</span><span class="o">/</span><span class="n">NUM_CHUNKS_ROWS</span><span class="o">*</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">));</span>
<span class="n">chunk_m</span><span class="o">=</span><span class="n">chunk_m_end</span><span class="o">-</span><span class="n">chunk_m_begin</span><span class="p">;</span>

<span class="c1">// Compute the current chunk</span>
<span class="n">matmul</span><span class="p">(</span><span class="n">chunk_m</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">K</span><span class="p">,</span>
<span class="n">A</span><span class="p">[</span><span class="n">chunk_m_begin</span><span class="o">*</span><span class="n">lda</span><span class="p">],</span><span class="c1">// A is col-major transposed</span>
<span class="n">B</span><span class="p">,</span><span class="c1">// B is not partitioned</span>
<span class="n">C</span><span class="p">[</span><span class="n">chunk_m_begin</span><span class="p">]</span><span class="c1">// C is col-major non-transposed</span>
<span class="p">);</span>

<span class="c1">// Producer: set the counter to 0 when done</span>
<span class="k">if</span><span class="p">(</span><span class="n">producer</span><span class="p">)</span><span class="p">{</span>
<span class="n">counters_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="c1">// make the written value visible to the consumer kernel</span>
<span class="n">memory_fence</span><span class="p">();</span>
<span class="p">}</span>
<span class="p">}</span>
</pre>
        <p>
            It should be noted that, in general, CUDA programming model provides few kernel co-scheduling guarantees.
            Thus, use of this feature requires careful orchestration of producer and consumer kernels launch order and
            resource availability, as it easy to create a deadlock situation. A deadlock may occur in the following
            cases (this is not an exhaustive list):
        </p>
        <ul class="simple">
            <li>
                <p>
                    If a producer kernel cannot start because consumer kernel was launched first and is occupying some
                    of SMs that are needed by the producer kernel to launch. It is strongly recommended to set
                    <span class="pre">
                        CUBLASLT_MATMUL_DESC_SM_COUNT_TARGET
                    </span>
                    to carve out some SMs for non-matmul (typically communication) kernels to execute on.
                </p>
            </li>
            <li>
                <p>
                    If
                    <a class="reference external"
                        href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html">
                        cudaDeviceSynchronize()
                    </a>
                    is called after consumer kernel starts but before the producer kernel does.
                </p>
            </li>
            <li>
                <p>
                    When
                    <a class="reference external"
                        href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/lazy-loading.html#lazy-loading">
                        lazy module
                    </a>
                    loading is enabled, and producer kernel cannot be loaded while the consumer kernel is running due to
                    locking in the CUDA runtime library. Both kernels also must be loaded before they are run together
                    to avoid this situation. Using
                    <a class="reference external"
                        href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-graphs">
                        CUDA Graphs
                    </a>
                    is another way to avoid deadlocks due to lazy loading.
                </p>
            </li>
        </ul>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This feature is aimed at advanced users and is only available on Hopper architecture for FP8 non-batched
            cases with fast accumulation mode enabled, and is considered to have beta quality due to the large number of
            restrictions on its use.
        </p>
        <h2>
            <span class="section-number">
                3.2.
            </span>
            cuBLASLt Code Examples
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-code-examples"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            Please visit
            <a class="reference external" href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLASLt">
                https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLASLt
            </a>
            for updated code examples.
        </p>
        <h2>
            <span class="section-number">
                3.3.
            </span>
            cuBLASLt Datatypes Reference
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-datatypes-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <h3>
            <span class="section-number">
                3.3.1.
            </span>
            cublasLtClusterShape_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltclustershape-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltclustershape-t">
                cublasLtClusterShape_t
            </a>
            is an enumerated type used to configure thread block cluster dimensions. Thread block clusters add an
            optional hierarchical level and are made up of thread blocks. Similar to thread blocks, these can be one,
            two, or three-dimensional. See also
            <a class="reference external"
                href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-block-clusters">
                Thread Block Clusters
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_AUTO
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is automatically selected.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x4x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 4 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x4x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 4 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_4x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 4 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_4x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 4 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_4x4x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 4 x 4 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x8x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 8 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_8x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 8 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x8x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 8 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_8x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 8 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x16x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 16 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_16x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 16 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x3x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 3 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x5x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 5 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x6x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 6 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x7x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 7 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x9x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 9 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x10x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 10 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x11x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 11 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x12x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 12 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x13x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 13 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x14x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 14 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_1x15x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 1 x 15 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x3x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 3 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x5x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 5 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x6x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 6 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_2x7x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 2 x 7 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_3x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 3 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_3x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 3 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_3x3x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 3 x 3 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_3x4x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 3 x 4 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_3x5x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 3 x 5 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_4x3x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 4 x 3 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_5x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 5 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_5x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 5 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_5x3x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 5 x 3 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_6x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 6 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_6x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 6 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_7x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 7 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_7x2x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 7 x 2 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_9x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 9 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_10x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 10 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_11x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 11 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_12x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 12 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_13x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 13 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_14x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 14 x 1 x 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_15x1x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape is 15 x 1 x 1.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.2.
            </span>
            cublasLtEpilogue_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltepilogue-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltepilogue-t">
                cublasLtEpilogue_t
            </a>
            is an enum type to set the postprocessing options for the epilogue.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_DEFAULT = 1
                    </p>
                </td>
                <td>
                    <p>
                        No special postprocessing, just scale and quantize the results if necessary.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_RELU = 2
                    </p>
                </td>
                <td>
                    <p>
                        Apply ReLU point-wise transform to the results (
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            :=
                        </span>
                        <span class="pre">
                            max(x,
                        </span>
                        <span class="pre">
                            0)
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_RELU_AUX = CUBLASLT_EPILOGUE_RELU | 128
                    </p>
                </td>
                <td>
                    <p>
                        Apply ReLU point-wise transform to the results (
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            :=
                        </span>
                        <span class="pre">
                            max(x,
                        </span>
                        <span class="pre">
                            0)
                        </span>
                        ). This epilogue mode produces an extra output, see CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_BIAS = 4
                    </p>
                </td>
                <td>
                    <p>
                        Apply (broadcast) bias from the bias vector. Bias vector length must match matrix D rows, and it
                        must be packed (such as stride between vector elements is 1). Bias vector is broadcast to all
                        columns and added before applying the final postprocessing.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_RELU_BIAS = CUBLASLT_EPILOGUE_RELU | CUBLASLT_EPILOGUE_BIAS
                    </p>
                </td>
                <td>
                    <p>
                        Apply bias and then ReLU transform.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_RELU_AUX_BIAS = CUBLASLT_EPILOGUE_RELU_AUX | CUBLASLT_EPILOGUE_BIAS
                    </p>
                </td>
                <td>
                    <p>
                        Apply bias and then ReLU transform. This epilogue mode produces an extra output, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_DRELU = 8 | 128
                    </p>
                </td>
                <td>
                    <p>
                        Apply ReLu gradient to matmul output. Store ReLu gradient in the output matrix. This epilogue
                        mode requires an extra input, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_DRELU_BGRAD = CUBLASLT_EPILOGUE_DRELU | 16
                    </p>
                </td>
                <td>
                    <p>
                        Apply independently ReLu and Bias gradient to matmul output. Store ReLu gradient in the output
                        matrix, and Bias gradient in the bias buffer (see CUBLASLT_MATMUL_DESC_BIAS_POINTER). This
                        epilogue mode requires an extra input, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_GELU = 32
                    </p>
                </td>
                <td>
                    <p>
                        Apply GELU point-wise transform to the results (
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            :=
                        </span>
                        <span class="pre">
                            GELU(x)
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_GELU_AUX = CUBLASLT_EPILOGUE_GELU | 128
                    </p>
                </td>
                <td>
                    <p>
                        Apply GELU point-wise transform to the results (
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            :=
                        </span>
                        <span class="pre">
                            GELU(x)
                        </span>
                        ). This epilogue mode outputs GELU input as a separate matrix (useful for training). See
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_GELU_BIAS = CUBLASLT_EPILOGUE_GELU | CUBLASLT_EPILOGUE_BIAS
                    </p>
                </td>
                <td>
                    <p>
                        Apply Bias and then GELU transform
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#gelu" id="id45">
                            4
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_GELU_AUX_BIAS = CUBLASLT_EPILOGUE_GELU_AUX | CUBLASLT_EPILOGUE_BIAS
                    </p>
                </td>
                <td>
                    <p>
                        Apply Bias and then GELU transform
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#gelu" id="id46">
                            4
                        </a>
                        . This epilogue mode outputs GELU input as a separate matrix (useful for training). See
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_DGELU = 64 | 128
                    </p>
                </td>
                <td>
                    <p>
                        Apply GELU gradient to matmul output. Store GELU gradient in the output matrix. This epilogue
                        mode requires an extra input, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_DGELU_BGRAD = CUBLASLT_EPILOGUE_DGELU | 16
                    </p>
                </td>
                <td>
                    <p>
                        Apply independently GELU and Bias gradient to matmul output. Store GELU gradient in the output
                        matrix, and Bias gradient in the bias buffer (see CUBLASLT_MATMUL_DESC_BIAS_POINTER). This
                        epilogue mode requires an extra input, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_BGRADA = 256
                    </p>
                </td>
                <td>
                    <p>
                        Apply Bias gradient to the input matrix A. The bias size corresponds to the number of rows of
                        the matrix D. The reduction happens over the GEMMs k dimension. Store Bias gradient in
                        the bias buffer, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_BIAS_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_EPILOGUE_BGRADB = 512
                    </p>
                </td>
                <td>
                    <p>
                        Apply Bias gradient to the input matrix B. The bias size corresponds to the number of columns of
                        the matrix D. The reduction happens over the GEMMs k dimension. Store Bias gradient in
                        the bias buffer, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_BIAS_POINTER
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            NOTES:
        </p>
        <span class="brackets">
            4
        </span>
        <span class="fn-backref">
            (
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id45">
                1
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id46">
                2
            </a>
            )
        </span>
        <p>
            GELU (Gaussian Error Linear Unit) is approximated by:
            <span class="math notranslate nohighlight">
                \({0.5}x\left( 1 + \text{tanh}\left( \sqrt{2/\pi}\left( x + {0.044715}x^{3} \right) \right) \right)\)
            </span>
        </p>
        <h3>
            <span class="section-number">
                3.3.3.
            </span>
            cublasLtHandle_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                cublasLtHandle_t
            </a>
            type is a pointer type to an opaque structure holding the cuBLASLt library context. Use
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltcreate">
                cublasLtCreate()
            </a>
            to initialize the cuBLASLt library context and return a handle to an opaque structure holding the cuBLASLt
            library context, and use
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdestroy">
                cublasLtDestroy()
            </a>
            to destroy a previously created cuBLASLt library context descriptor and release the resources.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            cuBLAS handle (
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t">
                cublasHandle_t
            </a>
            ) encapsulates a cuBLASLt handle. Any valid
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublashandle-t">
                cublasHandle_t
            </a>
            can be used in place of
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                cublasLtHandle_t
            </a>
            with a simple cast. However, unlike a cuBLAS handle, a cuBLASLt handle is not tied to any particular CUDA
            context.
        </p>
        <h3>
            <span class="section-number">
                3.3.4.
            </span>
            cublasLtLoggerCallback_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggercallback-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggercallback-t">
                cublasLtLoggerCallback_t
            </a>
            is a callback function pointer type. A callback function can be set using
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetcallback">
                cublasLtLoggerSetCallback()
            </a>
            .
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        logLevel
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-logging">
                            cuBLASLt Logging
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        functionName
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        The name of the API that logged this message.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        message
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        The log message.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.5.
            </span>
            cublasLtMatmulAlgo_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                cublasLtMatmulAlgo_t
            </a>
            is an opaque structure holding the description of the matrix multiplication algorithm. This structure can be
            trivially serialized and later restored for use with the same version of cuBLAS library to save on selecting
            the right configuration again.
        </p>
        <h3>
            <span class="section-number">
                3.3.6.
            </span>
            cublasLtMatmulAlgoCapAttributes_t
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t">
                cublasLtMatmulAlgoCapAttributes_t
            </a>
            enumerates matrix multiplication algorithm capability attributes that can be retrieved from an initialized
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                cublasLtMatmulAlgo_t
            </a>
            descriptor using
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapgetattribute">
                cublasLtMatmulAlgoCapGetAttribute()
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_SPLITK_SUPPORT
                    </p>
                </td>
                <td>
                    <p>
                        Support for split-K. Boolean (0 or 1) to express if split-K implementation is supported. 0 means
                        no support, and supported otherwise. See CUBLASLT_ALGO_CONFIG_SPLITK_NUM of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                            cublasLtMatmulAlgoConfigAttributes_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_REDUCTION_SCHEME_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Mask to express the types of reduction schemes supported, see
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltreductionscheme-t">
                            cublasLtReductionScheme_t
                        </a>
                        . If the reduction scheme is not masked out then it is supported. For example:
                        <span class="pre">
                            int
                        </span>
                        <span class="pre">
                            isReductionSchemeComputeTypeSupported
                        </span>
                        <span class="pre">
                            ?
                        </span>
                        <span class="pre">
                            (reductionSchemeMask
                        </span>
                        <span class="pre">
                            &amp;
                        </span>
                        <span class="pre">
                            CUBLASLT_REDUCTION_SCHEME_COMPUTE_TYPE)
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLASLT_REDUCTION_SCHEME_COMPUTE_TYPE
                        </span>
                        <span class="pre">
                            ?
                        </span>
                        <span class="pre">
                            1
                        </span>
                        <span class="pre">
                            :
                        </span>
                        <span class="pre">
                            0;
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_CTA_SWIZZLING_SUPPORT
                    </p>
                </td>
                <td>
                    <p>
                        Support for CTA-swizzling. Boolean (0 or 1) to express if CTA-swizzling implementation is
                        supported. 0 means no support, and 1 means supported value of 1; other values are reserved. See
                        also CUBLASLT_ALGO_CONFIG_CTA_SWIZZLING of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                            cublasLtMatmulAlgoConfigAttributes_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_STRIDED_BATCH_SUPPORT
                    </p>
                </td>
                <td>
                    <p>
                        Support strided batch. 0 means no support, supported otherwise.
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_OUT_OF_PLACE_RESULT_SUPPORT
                    </p>
                </td>
                <td>
                    <p>
                        Support results out of place (D != C in D = alpha.A.B + beta.C). 0 means no support, supported
                        otherwise.
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_UPLO_SUPPORT
                    </p>
                </td>
                <td>
                    <p>
                        Syrk (symmetric rank k update)/herk (Hermitian rank k update) support (on top of regular gemm).
                        0 means no support, supported otherwise.
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_TILE_IDS
                    </p>
                </td>
                <td>
                    <p>
                        The tile ids possible to use. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmultile-t">
                            cublasLtMatmulTile_t
                        </a>
                        . If no tile ids are supported then use CUBLASLT_MATMUL_TILE_UNDEFINED. Use
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapgetattribute">
                            cublasLtMatmulAlgoCapGetAttribute()
                        </a>
                        with
                        <span class="pre">
                            sizeInBytes
                        </span>
                        <span class="pre">
                            =
                        </span>
                        <span class="pre">
                            0
                        </span>
                        to query the actual count.
                    </p>
                </td>
                <td>
                    <p>
                        Array of uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_STAGES_IDS
                    </p>
                </td>
                <td>
                    <p>
                        The stages ids possible to use. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulstages-t">
                            cublasLtMatmulStages_t
                        </a>
                        . If no stages ids are supported then use CUBLASLT_MATMUL_STAGES_UNDEFINED. Use
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapgetattribute">
                            cublasLtMatmulAlgoCapGetAttribute()
                        </a>
                        with
                        <span class="pre">
                            sizeInBytes
                        </span>
                        <span class="pre">
                            =
                        </span>
                        <span class="pre">
                            0
                        </span>
                        to query the actual count.
                    </p>
                </td>
                <td>
                    <p>
                        Array of uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_CUSTOM_OPTION_MAX
                    </p>
                </td>
                <td>
                    <p>
                        Custom option range is from 0 to CUBLASLT_ALGO_CAP_CUSTOM_OPTION_MAX (inclusive). See
                        CUBLASLT_ALGO_CONFIG_CUSTOM_OPTION of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                            cublasLtMatmulAlgoConfigAttributes_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_MATHMODE_IMPL
                    </p>
                </td>
                <td>
                    <p>
                        Indicates whether the algorithm is using regular compute or tensor operations. 0 means regular
                        compute, 1 means tensor operations.
                        DEPRECATED
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_GAUSSIAN_IMPL
                    </p>
                </td>
                <td>
                    <p>
                        Indicate whether the algorithm implements the Gaussian optimization of complex matrix
                        multiplication. 0 means regular compute; 1 means Gaussian. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasmath-t">
                            cublasMath_t
                        </a>
                        .
                        DEPRECATED
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_CUSTOM_MEMORY_ORDER
                    </p>
                </td>
                <td>
                    <p>
                        Indicates whether the algorithm supports custom (not COL or ROW memory order). 0 means only COL
                        and ROW memory order is allowed, non-zero means that algo might have different requirements. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                            cublasLtOrder_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_POINTER_MODE_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Bitmask enumerating the pointer modes the algorithm supports. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermodemask-t">
                            cublasLtPointerModeMask_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_EPILOGUE_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Bitmask enumerating the kinds of postprocessing algorithm supported in the epilogue. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltepilogue-t">
                            cublasLtEpilogue_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_LD_NEGATIVE
                    </p>
                </td>
                <td>
                    <p>
                        Support for negative ld for all of the matrices. 0 means no support, supported otherwise.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_NUMERICAL_IMPL_FLAGS
                    </p>
                </td>
                <td>
                    <p>
                        Details about algorithms implementation that affect its numerical behavior. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltnumericalimplflags-t">
                            cublasLtNumericalImplFlags_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint64_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_MIN_ALIGNMENT_A_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum alignment required for A matrix in bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_MIN_ALIGNMENT_B_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum alignment required for B matrix in bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_MIN_ALIGNMENT_C_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum alignment required for C matrix in bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_MIN_ALIGNMENT_D_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum alignment required for D matrix in bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ALGO_CAP_ATOMIC_SYNC
                    </p>
                </td>
                <td>
                    <p>
                        Support for synchronization via atomic counters. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization">
                            Atomics Synchronization
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.7.
            </span>
            cublasLtMatmulAlgoConfigAttributes_t
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                cublasLtMatmulAlgoConfigAttributes_t
            </a>
            is an enumerated type that contains the configuration attributes for cuBLASLt matrix multiply algorithms.
            The configuration attributes are algorithm-specific, and can be set. The attributes configuration of a given
            algorithm should agree with its capability attributes. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfiggetattribute">
                cublasLtMatmulAlgoConfigGetAttribute()
            </a>
            and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigsetattribute">
                cublasLtMatmulAlgoConfigSetAttribute()
            </a>
            to get and set the attribute value of a matmul algorithm descriptor.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_ID
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Read-only attribute. Algorithm index. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetids">
                            cublasLtMatmulAlgoGetIds()
                        </a>
                        . Set by
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoinit">
                            cublasLtMatmulAlgoInit()
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_TILE_ID
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Tile id. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmultile-t">
                            cublasLtMatmulTile_t
                        </a>
                        . Default:
                        <span class="pre">
                            CUBLASLT_MATMUL_TILE_UNDEFINED
                        </span>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_STAGES_ID
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        stages id, see
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulstages-t">
                            cublasLtMatmulStages_t
                        </a>
                        . Default:
                        <span class="pre">
                            CUBLASLT_MATMUL_STAGES_UNDEFINED
                        </span>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_SPLITK_NUM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Number of K splits. If the number of K splits is greater than one, SPLITK_NUM parts of matrix
                        multiplication will be computed in parallel. The results will be accumulated according to
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_REDUCTION_SCHEME
                        </span>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_REDUCTION_SCHEME
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Reduction scheme to use when splitK value &gt; 1. Default:
                        <span class="pre">
                            CUBLASLT_REDUCTION_SCHEME_NONE
                        </span>
                        . See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltreductionscheme-t">
                            cublasLtReductionScheme_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_CTA_SWIZZLING
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Enable/Disable CTA swizzling. Change mapping from CUDA grid coordinates to parts of the
                        matrices. Possible values: 0 and 1; other values reserved.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_CUSTOM_OPTION
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Custom option value. Each algorithm can support some custom options that dont fit the
                        description of the other configuration attributes. See the
                        <span class="pre">
                            CUBLASLT_ALGO_CAP_CUSTOM_OPTION_MAX
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t">
                            cublasLtMatmulAlgoCapAttributes_t
                        </a>
                        for the accepted range for a specific case.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_INNER_SHAPE_ID
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Inner shape ID. Refer to
                        <span class="pre">
                            cublasLtMatmulInnerShape_t.
                        </span>
                        Default:
                        <span class="pre">
                            CUBLASLT_MATMUL_INNER_SHAPE_UNDEFINED
                        </span>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint16_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_ALGO_CONFIG_CLUSTER_SHAPE_ID
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Cluster shape ID. Refer to
                        <span class="pre">
                            cublasLtClusterShape_t.
                        </span>
                        Default:
                        <span class="pre">
                            CUBLASLT_CLUSTER_SHAPE_AUTO
                        </span>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint16_t
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.8.
            </span>
            cublasLtMatmulDesc_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                cublasLtMatmulDesc_t
            </a>
            is a pointer to an opaque structure holding the description of the matrix multiplication operation
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            . A descriptor can be created by calling
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesccreate">
                cublasLtMatmulDescCreate()
            </a>
            and destroyed by calling
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescdestroy">
                cublasLtMatmulDescDestroy()
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                3.3.9.
            </span>
            cublasLtMatmulDescAttributes_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                cublasLtMatmulDescAttributes_t
            </a>
            is a descriptor structure containing the attributes that define the specifics of the matrix multiply
            operation. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescgetattribute">
                cublasLtMatmulDescGetAttribute()
            </a>
            and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescsetattribute">
                cublasLtMatmulDescSetAttribute()
            </a>
            to get and set the attribute value of a matmul descriptor.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Attribute Name
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_COMPUTE_TYPE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Compute type. Defines the data type used for multiply and accumulate operations, and the
                        accumulator during the matrix multiplication. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                            cublasComputeType_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_SCALE_TYPE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Scale type. Defines the data type of the scaling factors
                        <span class="pre">
                            alpha
                        </span>
                        and
                        <span class="pre">
                            beta
                        </span>
                        . The accumulator value and the value from matrix C are typically converted to scale type before
                        final scaling. The value is then converted from scale type to the type of matrix D before
                        storing in memory. Default value is aligned with CUBLASLT_MATMUL_DESC_COMPUTE_TYPE. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t">
                            cudaDataType_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_POINTER_MODE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Specifies
                        <span class="pre">
                            alpha
                        </span>
                        and
                        <span class="pre">
                            beta
                        </span>
                        are passed by reference, whether they are scalars on the host or on the device, or device
                        vectors. Default value is:
                        <span class="pre">
                            CUBLASLT_POINTER_MODE_HOST
                        </span>
                        (i.e., on the host). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_TRANSA
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the type of transformation operation that should be performed on matrix A. Default
                        value is:
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        (i.e., non-transpose operation). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                            cublasOperation_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_TRANSB
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the type of transformation operation that should be performed on matrix B. Default
                        value is:
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        (i.e., non-transpose operation). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                            cublasOperation_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_TRANSC
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the type of transformation operation that should be performed on matrix C. Currently
                        only
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        is supported. Default value is:
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        (i.e., non-transpose operation). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                            cublasOperation_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_FILL_MODE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Indicates whether the lower or upper part of the dense matrix was filled, and consequently
                        should be used by the function. Default value is:
                        <span class="pre">
                            CUBLAS_FILL_MODE_FULL
                        </span>
                        .See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasfillmode-t">
                            cublasFillMode_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Epilogue function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltepilogue-t">
                            cublasLtEpilogue_t
                        </a>
                        . Default value is:
                        <span class="pre">
                            CUBLASLT_EPILOGUE_DEFAULT
                        </span>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_BIAS_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Bias or Bias gradient vector pointer in the device memory.
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                Input vector with length that matches the number of rows of matrix D when one of the
                                following epilogues is used:
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_GELU_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_GELU_AUX_BIAS
                                </span>
                                .
                            </p>
                        </li>
                        <li>
                            <p>
                                Output vector with length that matches the number of rows of matrix D when one of the
                                following epilogues is used:
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU_BGRAD
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DGELU_BGRAD
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_BGRADA
                                </span>
                                .
                            </p>
                        </li>
                        <li>
                            <p>
                                Output vector with length that matches the number of columns of matrix D when one of the
                                following epilogues is used:
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_BGRADB
                                </span>
                                .
                            </p>
                        </li>
                    </ul>
                    <p>
                        Bias vector elements are the same type as
                        <span class="pre">
                            alpha
                        </span>
                        and
                        <span class="pre">
                            beta
                        </span>
                        (see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_SCALE_TYPE
                        </span>
                        in this table) when matrix D datatype is
                        <span class="pre">
                            CUDA_R_8I
                        </span>
                        and same as matrix D datatype otherwise. See the datatypes table under
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        for detailed mapping. Default value is: NULL.
                    </p>
                </td>
                <td>
                    <p>
                        void * / const void *
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_BIAS_BATCH_STRIDE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Stride (in elements) to the next bias or bias gradient vector for strided batch operations. The
                        default value is 0.
                    </p>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Pointer for epilogue auxiliary buffer.
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                Output vector for ReLu bit-mask in forward pass when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX
                                </span>
                                or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX_BIAS
                                </span>
                                epilogue is used.
                            </p>
                        </li>
                        <li>
                            <p>
                                Input vector for ReLu bit-mask in backward pass when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU
                                </span>
                                or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU_BGRAD
                                </span>
                                epilogue is used.
                            </p>
                        </li>
                        <li>
                            <p>
                                Output of GELU input matrix in forward pass when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_GELU_AUX_BIAS
                                </span>
                                epilogue is used.
                            </p>
                        </li>
                        <li>
                            <p>
                                Input of GELU input matrix for backward pass when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DGELU
                                </span>
                                or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DGELU_BGRAD
                                </span>
                                epilogue is used.
                            </p>
                        </li>
                    </ul>
                    <p>
                        For aux data type, see
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_DATA_TYPE
                        </span>
                        . Routines that dont dereference this pointer, like
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic">
                            cublasLtMatmulAlgoGetHeuristic()
                        </a>
                        depend on its value to determine expected pointer alignment. Requires setting the
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_LD
                        </span>
                        attribute.
                    </p>
                </td>
                <td>
                    <p>
                        void * / const void *
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_LD
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Leading dimension for epilogue auxiliary buffer.
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                ReLu bit-mask matrix leading dimension in elements (i.e. bits) when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU_BGRAD
                                </span>
                                , or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU_BGRAD
                                </span>
                                epilogue is used. Must be divisible by 128 and be no less than the number of rows in the
                                output matrix.
                            </p>
                        </li>
                        <li>
                            <p>
                                GELU input matrix leading dimension in elements when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_GELU_AUX_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DGELU
                                </span>
                                , or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DGELU_BGRAD
                                </span>
                                epilogue used. Must be divisible by 8 and be no less than the number of rows in the
                                output matrix.
                            </p>
                        </li>
                    </ul>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_BATCH_STRIDE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Batch stride for epilogue auxiliary buffer.
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                ReLu bit-mask matrix batch stride in elements (i.e. bits) when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_RELU_AUX_BIAS
                                </span>
                                or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU_BGRAD
                                </span>
                                epilogue is used. Must be divisible by 128.
                            </p>
                        </li>
                        <li>
                            <p>
                                GELU input matrix batch stride in elements when
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_GELU_AUX_BIAS
                                </span>
                                ,
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DRELU
                                </span>
                                , or
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_DGELU_BGRAD
                                </span>
                                epilogue used. Must be divisible by 8.
                            </p>
                        </li>
                    </ul>
                    <p>
                        Default value: 0.
                    </p>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_ALPHA_VECTOR_BATCH_STRIDE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Batch stride for alpha vector. Used together with
                        <span class="pre">
                            CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_HOST
                        </span>
                        when matrix Ds
                        <span class="pre">
                            CUBLASLT_MATRIX_LAYOUT_BATCH_COUNT
                        </span>
                        is greater than 1. If
                        <span class="pre">
                            CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_ZERO
                        </span>
                        is set then
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_ALPHA_VECTOR_BATCH_STRIDE
                        </span>
                        must be set to 0 as this mode doesnt support batched alpha vector. Default value: 0.
                    </p>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_SM_COUNT_TARGET
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Number of SMs to target for parallel execution. Optimizes heuristics for execution on a
                        different number of SMs when user expects a concurrent stream to be using some of the device
                        resources. Default value: 0.
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_A_SCALE_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Device pointer to the scale factor value that converts data in matrix A to the compute data type
                        range. The scaling factor must have the same type as the compute type. If not specified, or set
                        to NULL, the scaling factor is assumed to be 1. If set for an unsupported matrix data, scale,
                        and compute type combination, calling
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        will return
                        <span class="pre">
                            CUBLAS_INVALID_VALUE
                        </span>
                        . Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        const void*
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_B_SCALE_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Equivalent to
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_A_SCALE_POINTER
                        </span>
                        for matrix B. Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        const void*
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_C_SCALE_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Equivalent to
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_A_SCALE_POINTER
                        </span>
                        for matrix C. Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        const void*
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_D_SCALE_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Equivalent to
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_A_SCALE_POINTER
                        </span>
                        for matrix D. Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        const void*
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_AMAX_D_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Device pointer to the memory location that on completion will be set to the maximum of absolute
                        values in the output matrix. The computed value has the same type as the compute type. If not
                        specified, or set to NULL, the maximum absolute value is not computed. If set for an unsupported
                        matrix data, scale, and compute type combination, calling
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        will return
                        <span class="pre">
                            CUBLAS_INVALID_VALUE
                        </span>
                        . Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        void *
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_DATA_TYPE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The type of the data that will be stored in
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        . If unset (or set to the default value of -1), the data type is set to be the output matrix
                        element data type (DType) with some exceptions:
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                ReLu uses a bit-mask.
                            </p>
                        </li>
                        <li>
                            <p>
                                For FP8 kernels with an output type (DType) of
                                <span class="pre">
                                    CUDA_R_8F_E4M3
                                </span>
                                , the data type can be set to a non-default value if:
                            </p>
                        </li>
                    </ul>
                    <ol class="arabic simple">
                        <li>
                            <p>
                                AType and BType are
                                <span class="pre">
                                    CUDA_R_8F_E4M3
                                </span>
                                .
                            </p>
                        </li>
                        <li>
                            <p>
                                Bias Type is
                                <span class="pre">
                                    CUDA_R_16F
                                </span>
                                .
                            </p>
                        </li>
                        <li>
                            <p>
                                CType is
                                <span class="pre">
                                    CUDA_R_16BF
                                </span>
                                or
                                <span class="pre">
                                    CUDA_R_16F
                                </span>
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    CUBLASLT_MATMUL_DESC_EPILOGUE
                                </span>
                                is set to
                                <span class="pre">
                                    CUBLASLT_EPILOGUE_GELU_AUX
                                </span>
                            </p>
                        </li>
                    </ol>
                    <p>
                        When CType is
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                        , the data type may be set to
                        <span class="pre">
                            CUDA_R_16BF
                        </span>
                        or
                        <span class="pre">
                            CUDA_R_8F_E4M3
                        </span>
                        . When CType is
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                        , the data type may be set to
                        <span class="pre">
                            CUDA_R_16F
                        </span>
                        . Otherwise, the data type should be left unset or set to the default value of -1.
                    </p>
                    <p>
                        If set for an unsupported matrix data, scale, and compute type combination, calling
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        will return
                        <span class="pre">
                            CUBLAS_INVALID_VALUE
                        </span>
                        . Default value: -1
                    </p>
                </td>
                <td>
                    <p>
                        int32_t based on cudaDataType
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_SCALE_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Device pointer to the scaling factor value to convert results from compute type data range to
                        storage data range in the auxiliary matrix that is set via
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        . The scaling factor value must have the same type as the compute type. If not specified, or set
                        to NULL, the scaling factor is assumed to be 1. If set for an unsupported matrix data, scale,
                        and compute type combination, calling
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        will return
                        <span class="pre">
                            CUBLAS_INVALID_VALUE
                        </span>
                        . Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        void *
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_AMAX_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Device pointer to the memory location that on completion will be set to the maximum of absolute
                        values in the buffer that is set via
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_POINTER
                        </span>
                        . The computed value has the same type as the compute type. If not specified, or set to NULL,
                        the maximum absolute value is not computed. If set for an unsupported matrix data, scale, and
                        compute type combination, calling
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        will return CUBLAS_INVALID_VALUE. Default value: NULL
                    </p>
                </td>
                <td>
                    <p>
                        void *
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_FAST_ACCUM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Flag for managing FP8 fast accumulation mode. When enabled, problem execution might be faster
                        but at the cost of lower accuracy because intermediate results will not periodically be promoted
                        to a higher precision. Default value: 0 - fast accumulation mode is disabled
                    </p>
                </td>
                <td>
                    <p>
                        int8_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_BIAS_DATA_TYPE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Type of the bias or bias gradient vector in the device memory. Bias case: see
                        <span class="pre">
                            CUBLASLT_EPILOGUE_BIAS
                        </span>
                        . If unset (or set to the default value of -1), the bias vector elements are the same type as
                        the elements of the output matrix (Dtype) with the following exceptions:
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                IMMA kernels with computeType=
                                <span class="pre">
                                    CUDA_R_32I
                                </span>
                                and
                                <span class="pre">
                                    Ctype=CUDA_R_8I
                                </span>
                                where the bias vector elements are the same type as alpha, beta (
                                <span class="pre">
                                    CUBLASLT_MATMUL_DESC_SCALE_TYPE=CUDA_R_32F
                                </span>
                                )
                            </p>
                        </li>
                        <li>
                            <p>
                                For FP8 kernels with an output type of
                                <span class="pre">
                                    CUDA_R_32F
                                </span>
                                ,
                                <span class="pre">
                                    CUDA_R_8F_E4M3
                                </span>
                                or
                                <span class="pre">
                                    CUDA_R_8F_E5M2
                                </span>
                                . See
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                                    cublasLtMatmul()
                                </a>
                                for more details.
                            </p>
                        </li>
                    </ul>
                    <p>
                        Default value: -1
                    </p>
                </td>
                <td>
                    <p>
                        int32_t based on cudaDataType
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_IN_COUNTERS_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to a device array of input atomic counters consumed by a matmul. When a counter reaches
                        zero, computation of the corresponding chunk of the output tensor is allowed to start. Default:
                        NULL. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization">
                            Atomics Synchronization
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t *
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_OUT_COUNTERS_POINTER
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to a device array of output atomic counters produced by a matmul. A matmul kernel sets a
                        counter to zero when the computations of the corresponding chunk of the output tensor have
                        completed. All the counters must be initialized to 1 before a matmul kernel is run. Default:
                        NULL. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization">
                            Atomics Synchronization
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t *
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_NUM_CHUNKS_D_ROWS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Number of atomic synchronization chunks in the row dimension of the output matrix D. Each chunk
                        corresponds to a single atomic counter. Default: 0 (atomics synchronization disabled). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization">
                            Atomics Synchronization
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_ATOMIC_SYNC_NUM_CHUNKS_D_COLS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Number of atomic synchronization chunks in the column dimension of the output matrix D. Each
                        chunk corresponds to a single atomic counter. Default: 0 (atomics synchronization disabled). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#atomics-synchronization">
                            Atomics Synchronization
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.10.
            </span>
            cublasLtMatmulHeuristicResult_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulheuristicresult-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulheuristicresult-t">
                cublasLtMatmulHeuristicResult_t
            </a>
            is a descriptor that holds the configured matrix multiplication algorithm descriptor and its runtime
            properties.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Member
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Must be initialized with
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoinit">
                            cublasLtMatmulAlgoInit()
                        </a>
                        if the preference CUBLASLT_MATMUL_PERF_SEARCH_MODE is set to CUBLASLT_SEARCH_LIMITED_BY_ALGO_ID.
                        See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulsearch-t">
                            cublasLtMatmulSearch_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            size_t
                        </span>
                        workspaceSize;
                    </p>
                </td>
                <td>
                    <p>
                        Actual size of workspace memory required.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                            cublasStatus_t
                        </a>
                        state;
                    </p>
                </td>
                <td>
                    <p>
                        Result status. Other fields are valid only if, after call to
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic">
                            cublasLtMatmulAlgoGetHeuristic()
                        </a>
                        , this member is set to CUBLAS_STATUS_SUCCESS.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            float
                        </span>
                        wavesCount;
                    </p>
                </td>
                <td>
                    <p>
                        Waves count is a device utilization metric. A
                        <span class="pre">
                            wavesCount
                        </span>
                        value of 1.0f suggests that when the kernel is launched it will fully occupy the GPU.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            int
                        </span>
                        reserved[4];
                    </p>
                </td>
                <td>
                    <p>
                        Reserved.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.11.
            </span>
            cublasLtMatmulInnerShape_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulinnershape-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulinnershape-t">
                cublasLtMatmulInnerShape_t
            </a>
            is an enumerated type used to configure various aspects of the internal kernel design. This does not impact
            the CUDA grid size.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_INNER_SHAPE_UNDEFINED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Inner shape is undefined.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_INNER_SHAPE_MMA884
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Inner shape is MMA884.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_INNER_SHAPE_MMA1684
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Inner shape is MMA1684.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_INNER_SHAPE_MMA1688
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Inner shape is MMA1688.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASLT_MATMUL_INNER_SHAPE_MMA16816
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Inner shape is MMA16816.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.12.
            </span>
            cublasLtMatmulPreference_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t">
                cublasLtMatmulPreference_t
            </a>
            is a pointer to an opaque structure holding the description of the preferences for
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic">
                cublasLtMatmulAlgoGetHeuristic()
            </a>
            configuration. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencecreate">
                cublasLtMatmulPreferenceCreate()
            </a>
            to create one instance of the descriptor and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencedestroy">
                cublasLtMatmulPreferenceDestroy()
            </a>
            to destroy a previously created descriptor and release the resources.
        </p>
        <h3>
            <span class="section-number">
                3.3.13.
            </span>
            cublasLtMatmulPreferenceAttributes_t
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceattributes-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceattributes-t">
                cublasLtMatmulPreferenceAttributes_t
            </a>
            is an enumerated type used to apply algorithm search preferences while fine-tuning the heuristic function.
            Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencegetattribute">
                cublasLtMatmulPreferenceGetAttribute()
            </a>
            and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencesetattribute">
                cublasLtMatmulPreferenceSetAttribute()
            </a>
            to get and set the attribute value of a matmul preference descriptor.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_SEARCH_MODE
                    </p>
                </td>
                <td>
                    <p>
                        Search mode. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulsearch-t">
                            cublasLtMatmulSearch_t
                        </a>
                        . Default is CUBLASLT_SEARCH_BEST_FIT.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Maximum allowed workspace memory. Default is 0 (no workspace memory allowed).
                    </p>
                </td>
                <td>
                    <p>
                        uint64_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_REDUCTION_SCHEME_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Reduction scheme mask. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltreductionscheme-t">
                            cublasLtReductionScheme_t
                        </a>
                        . Only algorithm configurations specifying CUBLASLT_ALGO_CONFIG_REDUCTION_SCHEME that is not
                        masked out by this attribute are allowed. For example, a mask value of 0x03 will allow only
                        INPLACE and COMPUTE_TYPE reduction schemes. Default is CUBLASLT_REDUCTION_SCHEME_MASK (i.e.,
                        allows all reduction schemes).
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_MIN_ALIGNMENT_A_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum buffer alignment for matrix A (in bytes). Selecting a smaller value will exclude
                        algorithms that can not work with matrix A, which is not as strictly aligned as the algorithms
                        need. Default is 256 bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_MIN_ALIGNMENT_B_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum buffer alignment for matrix B (in bytes). Selecting a smaller value will exclude
                        algorithms that can not work with matrix B, which is not as strictly aligned as the algorithms
                        need. Default is 256 bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_MIN_ALIGNMENT_C_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum buffer alignment for matrix C (in bytes). Selecting a smaller value will exclude
                        algorithms that can not work with matrix C, which is not as strictly aligned as the algorithms
                        need. Default is 256 bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_MIN_ALIGNMENT_D_BYTES
                    </p>
                </td>
                <td>
                    <p>
                        Minimum buffer alignment for matrix D (in bytes). Selecting a smaller value will exclude
                        algorithms that can not work with matrix D, which is not as strictly aligned as the algorithms
                        need. Default is 256 bytes.
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_MAX_WAVES_COUNT
                    </p>
                </td>
                <td>
                    <p>
                        Maximum wave count. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulheuristicresult-t">
                            cublasLtMatmulHeuristicResult_t
                        </a>
                        <span class="pre">
                            ::wavesCount.
                        </span>
                        Selecting a non-zero value will exclude algorithms that report device utilization higher than
                        specified. Default is
                        <span class="pre">
                            0.0f.
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        float
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_PREF_IMPL_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Numerical implementation details mask. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltnumericalimplflags-t">
                            cublasLtNumericalImplFlags_t
                        </a>
                        . Filters heuristic result to only include algorithms that use the allowed implementations.
                        default: uint64_t(-1) (allow everything)
                    </p>
                </td>
                <td>
                    <p>
                        uint64_t
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.14.
            </span>
            cublasLtMatmulSearch_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulsearch-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulsearch-t">
                cublasLtMatmulSearch_t
            </a>
            is an enumerated type that contains the attributes for heuristics search type.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_SEARCH_BEST_FIT
                    </p>
                </td>
                <td>
                    <p>
                        Request heuristics for the best algorithm for the given use case.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_SEARCH_LIMITED_BY_ALGO_ID
                    </p>
                </td>
                <td>
                    <p>
                        Request heuristics only for the pre-configured algo id.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.15.
            </span>
            cublasLtMatmulTile_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmultile-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmultile-t">
                cublasLtMatmulTile_t
            </a>
            is an enumerated type used to set the tile size in
            <span class="pre">
                rows
            </span>
            <span class="pre">
                x
            </span>
            <span class="pre">
                columns.
            </span>
            See also
            <a class="reference external"
                href="https://www.google.com/url?q=https://devblogs.nvidia.com/cutlass-linear-algebra-cuda/&amp;sa=D&amp;ust=1543610995532000&amp;usg=AFQjCNE3tHlNsXDOnOhbVeeH1uXWQFLzLA">
                CUTLASS: Fast Linear Algebra in CUDA C++
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_UNDEFINED
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is undefined.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_8x8
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 8 rows x 8 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_8x16
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 8 rows x 16 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_16x8
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 16 rows x 8 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_8x32
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 8 rows x 32 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_16x16
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 16 rows x 16 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_32x8
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 32 rows x 8 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_8x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 8 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_16x32
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 16 rows x 32 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_32x16
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 32 rows x 16 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x8
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 8 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_32x32
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 32 rows x 32 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_32x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 32 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x32
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 32 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_32x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 32 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x32
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 32 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x256
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 256 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_256x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 256 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x512
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 512 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x256
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 256 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_256x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 256 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_512x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 512 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_64x96
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 64 rows x 96 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_96x64
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 96 rows x 64 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_96x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 96 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x160
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 160 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_160x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 160 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_192x128
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 192 rows x 128 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x192
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 192 columns.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_TILE_128x96
                    </p>
                </td>
                <td>
                    <p>
                        Tile size is 128 rows x 96 columns.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.16.
            </span>
            cublasLtMatmulStages_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulstages-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulstages-t">
                cublasLtMatmulStages_t
            </a>
            is an enumerated type used to configure the size and number of shared memory buffers where input elements
            are staged. Number of staging buffers defines kernels pipeline depth.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_UNDEFINED
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is undefined.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x1
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x2
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 2.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x3
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 3.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x4
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 4.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x5
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 5.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x6
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 6.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x1
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x2
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 2.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x3
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 3.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x4
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 4.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x5
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 5.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x6
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 6.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64x1
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64x2
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is 2.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64x3
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is 3.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64x4
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is 4.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64x5
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is 5.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64x6
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is 6.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128x1
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is 1.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128x2
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is 2.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128x3
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is 3.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128x4
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is 4.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128x5
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is 5.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128x6
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is 6.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32x10
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is 10.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_8x4
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 8, number of stages is 4.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16x10
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is 10.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_8x5
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 8, number of stages is 5.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_8x3
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 8, number of stages is 3.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_8xAUTO
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 8, number of stages is selected automatically.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_16xAUTO
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 16, number of stages is selected automatically.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_32xAUTO
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 32, number of stages is selected automatically.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_64xAUTO
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 64, number of stages is selected automatically.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATMUL_STAGES_128xAUTO
                    </p>
                </td>
                <td>
                    <p>
                        Stage size is 128, number of stages is selected automatically.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.17.
            </span>
            cublasLtNumericalImplFlags_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltnumericalimplflags-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltnumericalimplflags-t">
                cublasLtNumericalImplFlags_t
            </a>
            : a set of bit-flags that can be specified to select implementation details that may affect numerical
            behavior of algorithms.
        </p>
        <p>
            Flags below can be combined using the bit OR operator |.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_FMA
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementation is based on [H,F,D]FMA (fused multiply-add) family instructions.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_HMMA
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementation is based on HMMA (tensor operation) family instructions.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_IMMA
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementation is based on IMMA (integer tensor operation) family instructions.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_DMMA
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementation is based on DMMA (double precision tensor operation) family
                        instructions.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_TENSOR_OP_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Mask to filter implementations using any of the above kinds of tensor operations.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_OP_TYPE_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Mask to filter implementation details about multiply-accumulate instructions used.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_ACCUMULATOR_16F
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product is using half precision accumulator.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_ACCUMULATOR_32F
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product is using single precision accumulator.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_ACCUMULATOR_64F
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product is using double precision accumulator.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_ACCUMULATOR_32I
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product is using 32 bit signed integer precision
                        accumulator.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_ACCUMULATOR_TYPE_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Mask to filter implementation details about accumulator used.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_INPUT_16F
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product multiply-accumulate instruction is using
                        half-precision inputs.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_INPUT_16BF
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product multiply-accumulate instruction is using
                        bfloat16 inputs.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_INPUT_TF32
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product multiply-accumulate instruction is using
                        TF32 inputs.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_INPUT_32F
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product multiply-accumulate instruction is using
                        single-precision inputs.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_INPUT_64F
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product multiply-accumulate instruction is using
                        double-precision inputs.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_INPUT_8I
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementations inner dot product multiply-accumulate instruction is using
                        8-bit integer inputs.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_OP_INPUT_TYPE_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Mask to filter implementation details about accumulator input used.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_NUMERICAL_IMPL_FLAGS_GAUSSIAN
                    </p>
                </td>
                <td>
                    <p>
                        Specify that the implementation applies Gauss complexity reduction algorithm to reduce
                        arithmetic complexity of the complex matrix multiplication problem
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.18.
            </span>
            cublasLtMatrixLayout_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                cublasLtMatrixLayout_t
            </a>
            is a pointer to an opaque structure holding the description of a matrix layout. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutcreate">
                cublasLtMatrixLayoutCreate()
            </a>
            to create one instance of the descriptor and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutdestroy">
                cublasLtMatrixLayoutDestroy()
            </a>
            to destroy a previously created descriptor and release the resources.
        </p>
        <h3>
            <span class="section-number">
                3.3.19.
            </span>
            cublasLtMatrixLayoutAttribute_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutattribute-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutattribute-t">
                cublasLtMatrixLayoutAttribute_t
            </a>
            is a descriptor structure containing the attributes that define the details of the matrix operation. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutgetattribute">
                cublasLtMatrixLayoutGetAttribute()
            </a>
            and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutsetattribute">
                cublasLtMatrixLayoutSetAttribute()
            </a>
            to get and set the attribute value of a matrix layout descriptor.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Attribute Name
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_TYPE
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the data precision type. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t">
                            cudaDataType_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        uint32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_ORDER
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the memory order of the data of the matrix. Default value is CUBLASLT_ORDER_COL. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                            cublasLtOrder_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_ROWS
                    </p>
                </td>
                <td>
                    <p>
                        Describes the number of rows in the matrix. Normally only values that can be expressed as
                        <span class="pre">
                            int32_t
                        </span>
                        are supported.
                    </p>
                </td>
                <td>
                    <p>
                        uint64_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_COLS
                    </p>
                </td>
                <td>
                    <p>
                        Describes the number of columns in the matrix. Normally only values that can be expressed as
                        <span class="pre">
                            int32_t
                        </span>
                        are supported.
                    </p>
                </td>
                <td>
                    <p>
                        uint64_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_LD
                    </p>
                </td>
                <td>
                    <p>
                        The leading dimension of the matrix. For CUBLASLT_ORDER_COL this is the stride (in elements) of
                        matrix column. See also
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                            cublasLtOrder_t
                        </a>
                        .
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                Currently only non-negative values are supported.
                            </p>
                        </li>
                        <li>
                            <p>
                                Must be large enough so that matrix memory locations are not overlapping (e.g., greater
                                or equal to CUBLASLT_MATRIX_LAYOUT_ROWS in case of CUBLASLT_ORDER_COL).
                            </p>
                        </li>
                    </ul>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_BATCH_COUNT
                    </p>
                </td>
                <td>
                    <p>
                        Number of matmul operations to perform in the batch. Default value is 1. See also
                        CUBLASLT_ALGO_CAP_STRIDED_BATCH_SUPPORT in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t">
                            cublasLtMatmulAlgoCapAttributes_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_STRIDED_BATCH_OFFSET
                    </p>
                </td>
                <td>
                    <p>
                        Stride (in elements) to the next matrix for the strided batch operation. Default value is 0.
                        When matrix type is planar-complex (CUBLASLT_MATRIX_LAYOUT_PLANE_OFFSET != 0), batch stride is
                        interpreted by
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                            cublasLtMatmul()
                        </a>
                        in number of real valued sub-elements. E.g. for data of type CUDA_C_16F, offset of 1024B is
                        encoded as a stride of value 512 (since each element of the real and imaginary matrices is a 2B
                        (16bit) floating point type). NOTE: A bug in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransform">
                            cublasLtMatrixTransform()
                        </a>
                        causes it to interpret the batch stride for a planar-complex matrix as if it was specified in
                        number of complex elements. Therefore an offset of 1024B must be encoded as stride value 256
                        when calling
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransform">
                            cublasLtMatrixTransform()
                        </a>
                        (each complex element is 4B with real and imaginary values 2B each). This behavior is expected
                        to be corrected in the next major cuBLAS version.
                    </p>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATRIX_LAYOUT_PLANE_OFFSET
                    </p>
                </td>
                <td>
                    <p>
                        Stride (in bytes) to the imaginary plane for planar-complex layout. Default value is 0,
                        indicating that the layout is regular (real and imaginary parts of complex numbers are
                        interleaved in memory for each element).
                    </p>
                </td>
                <td>
                    <p>
                        int64_t
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.20.
            </span>
            cublasLtMatrixTransformDesc_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                cublasLtMatrixTransformDesc_t
            </a>
            is a pointer to an opaque structure holding the description of a matrix transformation operation. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesccreate">
                cublasLtMatrixTransformDescCreate()
            </a>
            to create one instance of the descriptor and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescdestroy">
                cublasLtMatrixTransformDescDestroy()
            </a>
            to destroy a previously created descriptor and release the resources.
        </p>
        <h3>
            <span class="section-number">
                3.3.21.
            </span>
            cublasLtMatrixTransformDescAttributes_t
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescattributes-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescattributes-t">
                cublasLtMatrixTransformDescAttributes_t
            </a>
            is a descriptor structure containing the attributes that define the specifics of the matrix transform
            operation. Use
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescgetattribute">
                cublasLtMatrixTransformDescGetAttribute()
            </a>
            and
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescsetattribute">
                cublasLtMatrixTransformDescSetAttribute()
            </a>
            to set the attribute value of a matrix transform descriptor.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Transform Attribute Name
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATRIX_TRANSFORM_DESC_SCALE_TYPE
                    </p>
                </td>
                <td>
                    <p>
                        Scale type. Inputs are converted to the scale type for scaling and summation, and results are
                        then converted to the output type to store in the memory. For the supported data types see
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t">
                            cudaDataType_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATRIX_TRANSFORM_DESC_POINTER_MODE
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the scalars alpha and beta are passed by reference whether on the host or on the
                        device. Default value is: CUBLASLT_POINTER_MODE_HOST (i.e., on the host). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_MATRIX_TRANSFORM_DESC_TRANSA
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the type of operation that should be performed on the matrix A. Default value is:
                        CUBLAS_OP_N (i.e., non-transpose operation). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                            cublasOperation_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_MATRIX_TRANSFORM_DESC_TRANSB
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the type of operation that should be performed on the matrix B. Default value is:
                        CUBLAS_OP_N (i.e., non-transpose operation). See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasoperation-t">
                            cublasOperation_t
                        </a>
                        .
                    </p>
                </td>
                <td>
                    <p>
                        int32_t
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.22.
            </span>
            cublasLtOrder_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                cublasLtOrder_t
            </a>
            is an enumerated type used to indicate the data ordering of the matrix.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Data Order Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ORDER_COL
                    </p>
                </td>
                <td>
                    <p>
                        Data is ordered in column-major format. The leading dimension is the stride (in elements) to the
                        beginning of next column in memory.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ORDER_ROW
                    </p>
                </td>
                <td>
                    <p>
                        Data is ordered in row-major format. The leading dimension is the stride (in elements) to the
                        beginning of next row in memory.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ORDER_COL32
                    </p>
                </td>
                <td>
                    <p>
                        Data is ordered in column-major ordered tiles of 32 columns. The leading dimension is the stride
                        (in elements) to the beginning of next group of 32-columns. For example, if the matrix has 33
                        columns and 2 rows, then the leading dimension must be at least (32) * 2 = 64.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_ORDER_COL4_4R2_8C
                    </p>
                </td>
                <td>
                    <p>
                        Data is ordered in column-major ordered tiles of composite tiles with total 32 columns and 8
                        rows. A tile is composed of interleaved inner tiles of 4 columns within 4 even or odd rows in an
                        alternating pattern. The leading dimension is the stride (in elements) to the beginning of the
                        first 32 column x 8 row tile for the next 32-wide group of columns. For example, if the matrix
                        has 33 columns and 1 row, the leading dimension must be at least (32 * 8) * 1 = 256.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_ORDER_COL32_2R_4R4
                    </p>
                </td>
                <td>
                    <p>
                        Data is ordered in column-major ordered tiles of composite tiles with total 32 columns ands 32
                        rows. Element offset within the tile is calculated as (((row%8)/2*4+row/8)*2+row%2)*32+col.
                        Leading dimension is the stride (in elements) to the beginning of the first 32 column x 32 row
                        tile for the next 32-wide group of columns. E.g. if matrix has 33 columns and 1 row, ld must be
                        at least (32*32)*1 = 1024.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.23.
            </span>
            cublasLtPointerMode_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                cublasLtPointerMode_t
            </a>
            is an enumerated type used to set the pointer mode for the scaling factors
            <span class="pre">
                alpha
            </span>
            and
            <span class="pre">
                beta
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_HOST = CUBLAS_POINTER_MODE_HOST
                    </p>
                </td>
                <td>
                    <p>
                        Matches CUBLAS_POINTER_MODE_HOST, and the pointer targets a single value host memory.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_DEVICE = CUBLAS_POINTER_MODE_DEVICE
                    </p>
                </td>
                <td>
                    <p>
                        Matches CUBLAS_POINTER_MODE_DEVICE, and the pointer targets a single value device memory.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_DEVICE_VECTOR = 2
                    </p>
                </td>
                <td>
                    <p>
                        Pointers target device memory vectors of length equal to the number of rows of matrix D.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_ZERO = 3
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            alpha
                        </span>
                        pointer targets a device memory vector of length equal to the number of rows of matrix D, and
                        <span class="pre">
                            beta
                        </span>
                        is zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_HOST = 4
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            alpha
                        </span>
                        pointer targets a device memory vector of length equal to the number of rows of matrix D, and
                        <span class="pre">
                            beta
                        </span>
                        is a single value in host memory.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.24.
            </span>
            cublasLtPointerModeMask_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermodemask-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermodemask-t">
                cublasLtPointerModeMask_t
            </a>
            is an enumerated type used to define and query the pointer mode capability.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_MASK_HOST = 1
                    </p>
                </td>
                <td>
                    <p>
                        See CUBLASLT_POINTER_MODE_HOST in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_MASK_DEVICE = 2
                    </p>
                </td>
                <td>
                    <p>
                        See CUBLASLT_POINTER_MODE_DEVICE in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_MASK_DEVICE_VECTOR = 4
                    </p>
                </td>
                <td>
                    <p>
                        See CUBLASLT_POINTER_MODE_DEVICE_VECTOR in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_MASK_ALPHA_DEVICE_VECTOR_BETA_ZERO = 8
                    </p>
                </td>
                <td>
                    <p>
                        See CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_ZERO in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_POINTER_MODE_MASK_ALPHA_DEVICE_VECTOR_BETA_HOST = 16
                    </p>
                </td>
                <td>
                    <p>
                        See CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_HOST in
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltpointermode-t">
                            cublasLtPointerMode_t
                        </a>
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.3.25.
            </span>
            cublasLtReductionScheme_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltreductionscheme-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltreductionscheme-t">
                cublasLtReductionScheme_t
            </a>
            is an enumerated type used to specify a reduction scheme for the portions of the dot-product calculated in
            parallel (i.e., split - K).
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_REDUCTION_SCHEME_NONE
                    </p>
                </td>
                <td>
                    <p>
                        Do not apply reduction. The dot-product will be performed in one sequence.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_REDUCTION_SCHEME_INPLACE
                    </p>
                </td>
                <td>
                    <p>
                        Reduction is performed in place using the output buffer, parts are added up in the output
                        data type. Workspace is only used for counters that guarantee sequentiality.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_REDUCTION_SCHEME_COMPUTE_TYPE
                    </p>
                </td>
                <td>
                    <p>
                        Reduction done out of place in a user-provided workspace. The intermediate results are stored in
                        the compute type in the workspace and reduced in a separate step.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLASLT_REDUCTION_SCHEME_OUTPUT_TYPE
                    </p>
                </td>
                <td>
                    <p>
                        Reduction done out of place in a user-provided workspace. The intermediate results are stored in
                        the output type in the workspace and reduced in a separate step.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLASLT_REDUCTION_SCHEME_MASK
                    </p>
                </td>
                <td>
                    <p>
                        Allows all reduction schemes.
                    </p>
                </td>
            </tr>
        </table>
        <h2>
            <span class="section-number">
                3.4.
            </span>
            cuBLASLt API Reference
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-api-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <h3>
            <span class="section-number">
                3.4.1.
            </span>
            cublasLtCreate()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltcreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasLtCreate</span><span class="p">(</span><span class="n">cublasLtHandle_t</span><span class="o">*</span><span class="n">lighthandle</span><span class="p">)</span>
</pre>
        <p>
            This function initializes the cuBLASLt library and creates a handle to an opaque structure holding the
            cuBLASLt library context. It allocates light hardware resources on the host and device, and must be called
            prior to making any other cuBLASLt library calls.
        </p>
        <p>
            The cuBLASLt library context is tied to the current CUDA device. To use the library on multiple devices, one
            cuBLASLt handle should be created for each device.
        </p>
        <p>
            Parameters:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the created cuBLASLt context.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        The allocation completed successfully.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_INITIALIZED
                    </p>
                </td>
                <td>
                    <p>
                        The cuBLASLt library was not initialized. This usually happens:
                    </p>
                    <ul class="simple">
                        <li>
                            <p>
                                when
                                <a class="reference internal"
                                    href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltcreate">
                                    cublasLtCreate()
                                </a>
                                is not called first
                            </p>
                        </li>
                        <li>
                            <p>
                                an error in the CUDA Runtime API called by the cuBLASLt routine, or
                            </p>
                        </li>
                        <li>
                            <p>
                                an error in the hardware setup.
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        Resource allocation failed inside the cuBLASLt library. This is usually caused by a cudaMalloc()
                        failure.
                    </p>
                    <p>
                        To correct: prior to the function call, deallocate the previously allocated memory as much as
                        possible.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            lighthandle
                        </span>
                        == NULL
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.2.
            </span>
            cublasLtDestroy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasLtDestroy</span><span class="p">(</span><span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">)</span>
</pre>
        <p>
            This function releases hardware resources used by the cuBLASLt library. This function is usually the last
            call with a particular handle to the cuBLASLt library. Because
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltcreate">
                cublasLtCreate()
            </a>
            allocates some internal resources and the release of those resources by calling
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdestroy">
                cublasLtDestroy()
            </a>
            will implicitly call
            <span class="pre">
                cudaDeviceSynchronize()
            </span>
            , it is recommended to minimize the number of times these functions are called.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the cuBLASLt handle to be destroyed.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The cuBLASLt context was successfully destroyed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The cuBLASLt library was not initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        <span class="pre">
                            lightHandle
                        </span>
                        == NULL
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.3.
            </span>
            cublasLtDisableCpuInstructionsSetMask()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltdisablecpuinstructionssetmask"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="kt">unsigned</span><span class="nf">cublasLtDisableCpuInstructionsSetMask</span><span class="p">(</span><span class="kt">unsigned</span><span class="n">mask</span><span class="p">);</span>
</pre>
        <p>
            Instructs cuBLASLt library to not use
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/DisablingCPUInstructions">
                CPU instructions
            </a>
            specified by the flags in the
            <span class="pre">
                mask
            </span>
            .
            The function takes precedence over the
            <span class="pre">
                CUBLASLT_DISABLE_CPU_INSTRUCTIONS_MASK
            </span>
            environment variable.
        </p>
        <p>
            Parameters:
            <span class="pre">
                mask
            </span>
             the flags combined with bitwise
            <span class="pre">
                OR(|)
            </span>
            operator that specify which CPU instructions should not be used.
        </p>
        <p>
            Supported flags:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            0x1
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        x86-64 AVX512 ISA.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns:
            the previous value of the
            <span class="pre">
                mask
            </span>
            .
        </p>
        <h3>
            <span class="section-number">
                3.4.4.
            </span>
            cublasLtGetCudartVersion()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetcudartversion"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="kt">size_t</span><span class="nf">cublasLtGetCudartVersion</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
</pre>
        <p>
            This function returns the version number of the CUDA Runtime library.
        </p>
        <p>
            Parameters:
            None.
        </p>
        <p>
            Returns:
            <span class="pre">
                size_t
            </span>
            - The version number of the CUDA Runtime library.
        </p>
        <h3>
            <span class="section-number">
                3.4.5.
            </span>
            cublasLtGetProperty()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetproperty"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtGetProperty</span><span class="p">(</span><span class="n">libraryPropertyType</span><span class="n">type</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">value</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the requested property by writing it to the memory location pointed to by
            the value parameter.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        type
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Of the type
                        <span class="pre">
                            libraryPropertyType
                        </span>
                        , whose value is requested from the property. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#librarypropertytype-t">
                            libraryPropertyType_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        value
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the host memory location where the requested information should be written.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The requested
                        <span class="pre">
                            libraryPropertyType
                        </span>
                        information is successfully written at the provided address.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If invalid value of the
                                <span class="pre">
                                    type
                                </span>
                                input argument or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    value
                                </span>
                                == NULL
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.6.
            </span>
            cublasLtGetStatusName()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetstatusname"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="k">const</span><span class="kt">char</span><span class="o">*</span><span class="nf">cublasLtGetStatusName</span><span class="p">(</span><span class="n">cublasStatus_t</span><span class="n">status</span><span class="p">);</span>
</pre>
        <p>
            Returns the string representation of a given status.
        </p>
        <p>
            Parameters:
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            - the status.
        </p>
        <p>
            Returns:
            <span class="pre">
                const
            </span>
            <span class="pre">
                char*
            </span>
            - the NULL-terminated string.
        </p>
        <h3>
            <span class="section-number">
                3.4.7.
            </span>
            cublasLtGetStatusString()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetstatusstring"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="k">const</span><span class="kt">char</span><span class="o">*</span><span class="nf">cublasLtGetStatusString</span><span class="p">(</span><span class="n">cublasStatus_t</span><span class="n">status</span><span class="p">);</span>
</pre>
        <p>
            Returns the description string for a given status.
        </p>
        <p>
            Parameters:
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            - the status.
        </p>
        <p>
            Returns:
            <span class="pre">
                const
            </span>
            <span class="pre">
                char*
            </span>
            - the NULL-terminated string.
        </p>
        <h3>
            <span class="section-number">
                3.4.8.
            </span>
            cublasLtHeuristicsCacheGetCapacity()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachegetcapacity"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtHeuristicsCacheGetCapacity</span><span class="p">(</span><span class="kt">size_t</span><span class="o">*</span><span class="n">capacity</span><span class="p">);</span>
</pre>
        <p>
            Returns the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#heuristics-cache">
                Heuristics Cache
            </a>
            capacity.
        </p>
        <p>
            Parameters:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            capacity
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The pointer to the returned capacity value.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The capacity was successfully written.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The capacity was successfully set.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.4.9.
            </span>
            cublasLtHeuristicsCacheSetCapacity()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltheuristicscachesetcapacity"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtHeuristicsCacheSetCapacity</span><span class="p">(</span><span class="kt">size_t</span><span class="n">capacity</span><span class="p">);</span>
</pre>
        <p>
            Sets the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#heuristics-cache">
                Heuristics Cache
            </a>
            capacity. Set the capacity to 0 to disable the heuristics cache.
        </p>
        <p>
            This function takes precedence over
            <span class="pre">
                CUBLASLT_HEURISTICS_CACHE_CAPACITY
            </span>
            environment variable.
        </p>
        <p>
            Parameters:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            capacity
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The desirable heuristics cache capacity.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        The capacity was successfully set.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                3.4.10.
            </span>
            cublasLtGetVersion()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltgetversion"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="kt">size_t</span><span class="nf">cublasLtGetVersion</span><span class="p">(</span><span class="kt">void</span><span class="p">);</span>
</pre>
        <p>
            This function returns the version number of cuBLASLt library.
        </p>
        <p>
            Parameters:
            None.
        </p>
        <p>
            Returns:
            <span class="pre">
                size_t
            </span>
            - The version number of cuBLASLt library.
        </p>
        <h3>
            <span class="section-number">
                3.4.11.
            </span>
            cublasLtLoggerSetCallback()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetcallback"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtLoggerSetCallback</span><span class="p">(</span><span class="n">cublasLtLoggerCallback_t</span><span class="n">callback</span><span class="p">);</span>
</pre>
        <p>
            Experimental: This function sets the logging callback function.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        callback
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to a callback function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggercallback-t">
                            cublasLtLoggerCallback_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the callback function was successfully set.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            cublasStatus_t
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.12.
            </span>
            cublasLtLoggerSetFile()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetfile"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtLoggerSetFile</span><span class="p">(</span><span class="kt">FILE</span><span class="o">*</span><span class="n">file</span><span class="p">);</span>
</pre>
        <p>
            Experimental: This function sets the logging output file. Note: once registered using this function call,
            the provided file handle must not be closed unless the function is called again to switch to a different
            file handle.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        file
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to an open file. File should have write permission.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If logging file was successfully set.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.13.
            </span>
            cublasLtLoggerOpenFile()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggeropenfile"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtLoggerOpenFile</span><span class="p">(</span><span class="k">const</span><span class="kt">char</span><span class="o">*</span><span class="n">logFile</span><span class="p">);</span>
</pre>
        <p>
            Experimental: This function opens a logging output file in the given path.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        logFile
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Path of the logging output file.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the logging file was successfully opened.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.14.
            </span>
            cublasLtLoggerSetLevel()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetlevel"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtLoggerSetLevel</span><span class="p">(</span><span class="kt">int</span><span class="n">level</span><span class="p">);</span>
</pre>
        <p>
            Experimental: This function sets the value of the logging level.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        level
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Value of the logging level. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-logging">
                            cuBLASLt Logging
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If the value was not a valid logging level. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-logging">
                            cuBLASLt Logging
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the logging level was successfully set.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.15.
            </span>
            cublasLtLoggerSetMask()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggersetmask"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtLoggerSetMask</span><span class="p">(</span><span class="kt">int</span><span class="n">mask</span><span class="p">);</span>
</pre>
        <p>
            Experimental: This function sets the value of the logging mask.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        mask
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Value of the logging mask. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslt-logging">
                            cuBLASLt Logging
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the logging mask was successfully set.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.16.
            </span>
            cublasLtLoggerForceDisable()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltloggerforcedisable"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtLoggerForceDisable</span><span class="p">();</span>
</pre>
        <p>
            Experimental: This function disables logging for the entire run.
        </p>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If logging was successfully disabled.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.17.
            </span>
            cublasLtMatmul()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmul</span><span class="p">(</span>
<span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">,</span>
<span class="n">cublasLtMatmulDesc_t</span><span class="n">computeDesc</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Adesc</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Bdesc</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Cdesc</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">D</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Ddesc</span><span class="p">,</span>
<span class="k">const</span><span class="n">cublasLtMatmulAlgo_t</span><span class="o">*</span><span class="n">algo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">workspace</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">workspaceSizeInBytes</span><span class="p">,</span>
<span class="n">cudaStream_t</span><span class="n">stream</span><span class="p">);</span>
</pre>
        <p>
            This function computes the matrix multiplication of matrices A and B to produce the output matrix D,
            according to the following operation:
        </p>
        <p>
            <span class="pre">
                D
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                alpha*(A*B)
            </span>
            <span class="pre">
                +
            </span>
            <span class="pre">
                beta*(C),
            </span>
        </p>
        <p>
            where
            <span class="pre">
                A
            </span>
            ,
            <span class="pre">
                B
            </span>
            , and
            <span class="pre">
                C
            </span>
            are input matrices, and
            <span class="pre">
                alpha
            </span>
            and
            <span class="pre">
                beta
            </span>
            are input scalars.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This function supports both in-place matrix multiplication (
            <span class="pre">
                C
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                D
            </span>
            and
            <span class="pre">
                Cdesc
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                Ddesc
            </span>
            ) and out-of-place matrix multiplication (
            <span class="pre">
                C
            </span>
            <span class="pre">
                !=
            </span>
            <span class="pre">
                D
            </span>
            , both matrices must have the same data type, number of rows, number of columns, batch size, and memory
            order). In the out-of-place case, the leading dimension of C can be different from the leading dimension of
            D. Specifically the leading dimension of C can be 0 to achieve row or column broadcast. If
            <span class="pre">
                Cdesc
            </span>
            is omitted, this function assumes it to be equal to
            <span class="pre">
                Ddesc
            </span>
            .
        </p>
        <p>
            The
            <span class="pre">
                workspace
            </span>
            pointer must be aligned to at least a multiple of 256 bytes.
            The recommendations on
            <span class="pre">
                workspaceSizeInBytes
            </span>
            are the same as mentioned in the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace">
                cublasSetWorkspace()
            </a>
            section.
        </p>
        <p>
            Datatypes Supported:
        </p>
        <p>
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            supports the following computeType, scaleType, Atype/Btype, and Ctype. Footnotes can be found at the end of
            this section.
        </p>
        <table class="table-no-stripes docutils align-default" id="id103">
            <span class="caption-text">
                Table 1. When A, B, C, and D are Regular Column- or Row-major Matrices
            </span>
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id103"
                title="Permalink to this table">
                
            </a>
            <tr class="row-odd">
                <th class="head">
                    <p>
                        computeType
                    </p>
                </th>
                <th class="head">
                    <p>
                        scaleType
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Bias Type
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id47">
                            5
                        </a>
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_COMPUTE_16F or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_16F_PEDANTIC
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id48">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="2">
                    <p>
                        CUBLAS_COMPUTE_32I or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_32I_PEDANTIC
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32I
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="8">
                    <p>
                        CUBLAS_COMPUTE_32F or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_32F_PEDANTIC
                    </p>
                </td>
                <td rowspan="6">
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id49">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id50">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id51">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id52">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id53">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="2">
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id54">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_8I
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id55">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id56">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id57">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id58">
                            6
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="2">
                    <p>
                        CUBLAS_COMPUTE_32F_FAST_16F or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_32F_FAST_16BF or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_32F_FAST_TF32
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id59">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id60">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id61">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id62">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="2">
                    <p>
                        CUBLAS_COMPUTE_64F or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_64F_PEDANTIC
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_64F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_64F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_64F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_64F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id63">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_C_64F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id64">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_64F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id65">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_64F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id66">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
        </table>
        <p id="cublasltmatmul-regular-imma-conditions">
            To use IMMA kernels, one of the following sets of requirements, with the first being the preferred one, must
            be met:
        </p>
        <ol class="arabic simple">
            <li>
                <p>
                    Using a regular data ordering:
                </p>
                <ul class="simple">
                    <li>
                        <p>
                            All matrix pointers must be 4-byte aligned. For even better performance, this condition
                            should hold with 16 instead of 4.
                        </p>
                    </li>
                    <li>
                        <p>
                            Leading dimensions of matrices A, B, C must be multiples of 4.
                        </p>
                    </li>
                    <li>
                        <p>
                            Only the TN format is supported - A must be transposed and B non-transposed.
                        </p>
                    </li>
                    <li>
                        <p>
                            Pointer mode can be
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_HOST
                            </span>
                            ,
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_DEVICE
                            </span>
                            or
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_HOST
                            </span>
                            . With the latter mode, the kernels support the
                            <span class="pre">
                                CUBLASLT_MATMUL_DESC_ALPHA_VECTOR_BATCH_STRIDE
                            </span>
                            attribute.
                        </p>
                    </li>
                    <li>
                        <p>
                            Dimensions m and k must be multiples of 4.
                        </p>
                    </li>
                </ul>
            </li>
            <li>
                <p>
                    Using the IMMA-specific data ordering on Ampere or Turing (but not Hopper) architecture -
                    <span class="pre">
                        CUBLASLT_ORDER_COL32`
                    </span>
                    for matrices A, C, D, and
                    CUBLASLT_ORDER_COL4_4R2_8C
                    (on Turing or Ampere architecture) or
                    <span class="pre">
                        CUBLASLT_ORDER_COL32_2R_4R4
                    </span>
                    (on Ampere architecture) for matrix B:
                </p>
                <ul class="simple">
                    <li>
                        <p>
                            Leading dimensions of matrices A, B, C must fulfill conditions specific to the memory
                            ordering (see
                            <a class="reference internal"
                                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltorder-t">
                                cublasLtOrder_t
                            </a>
                            ).
                        </p>
                    </li>
                    <li>
                        <p>
                            Matmul descriptor must specify
                            <span class="pre">
                                CUBLAS_OP_T
                            </span>
                            on matrix B and
                            <span class="pre">
                                CUBLAS_OP_N
                            </span>
                            (default) on matrix A and C.
                        </p>
                    </li>
                    <li>
                        <p>
                            If scaleType
                            <span class="pre">
                                CUDA_R_32I
                            </span>
                            is used, the only supported values for
                            <span class="pre">
                                alpha
                            </span>
                            and
                            <span class="pre">
                                beta
                            </span>
                            are
                            <span class="pre">
                                0
                            </span>
                            or
                            <span class="pre">
                                1
                            </span>
                            .
                        </p>
                    </li>
                    <li>
                        <p>
                            Pointer mode can be
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_HOST
                            </span>
                            ,
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_DEVICE
                            </span>
                            ,
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_DEVICE_VECTOR
                            </span>
                            or
                            <span class="pre">
                                CUBLASLT_POINTER_MODE_ALPHA_DEVICE_VECTOR_BETA_ZERO
                            </span>
                            . These kernels do not support
                            <span class="pre">
                                CUBLASLT_MATMUL_DESC_ALPHA_VECTOR_BATCH_STRIDE
                            </span>
                            .
                        </p>
                    </li>
                    <li>
                        <p>
                            Only the NT format is supported - A must be transposed and B non-transposed.
                        </p>
                    </li>
                </ul>
            </li>
        </ol>
        <table class="table-no-stripes docutils align-default" id="id104">
            <span class="caption-text">
                Table 2. When A, B, C, and D Use Layouts for IMMA
            </span>
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id104"
                title="Permalink to this table">
                
            </a>
            <tr class="row-odd">
                <th class="head">
                    <p>
                        computeType
                    </p>
                </th>
                <th class="head">
                    <p>
                        scaleType
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Bias Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        CUBLAS_COMPUTE_32I or
                    </p>
                    <p>
                        CUBLAS_COMPUTE_32I_PEDANTIC
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32I
                    </p>
                </td>
                <td>
                    <p>
                        Non-default epilogue not supported.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8I
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
            </tr>
        </table>
        <p>
            To use FP8 kernels, the following set of requirements must be satisfied:
        </p>
        <ul class="simple">
            <li>
                <p>
                    All matrix dimensions must meet the optimal requirements listed in
                    <a class="reference internal"
                        href="https://docs.nvidia.com/cuda/cublas/index.html#tensor-core-usage">
                        Tensor Core Usage
                    </a>
                    (i.e. pointers and matrix dimension must support 16-byte alignment).
                </p>
            </li>
            <li>
                <p>
                    A must be transposed and B non-transposed (The TN format).
                </p>
            </li>
            <li>
                <p>
                    The compute type must be
                    <span class="pre">
                        CUBLAS_COMPUTE_32F
                    </span>
                    .
                </p>
            </li>
            <li>
                <p>
                    The scale type must be
                    <span class="pre">
                        CUDA_R_32F
                    </span>
                    .
                </p>
            </li>
        </ul>
        <p>
            See the table below when using FP8 kernels:
        </p>
        <table class="table-no-stripes docutils align-default" id="id105">
            <span class="caption-text">
                Table 3. When A, B, C, and D Use Layouts for FP8
            </span>
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id105"
                title="Permalink to this table">
                
            </a>
            <tr class="row-odd">
                <th class="head">
                    <p>
                        AType
                    </p>
                </th>
                <th class="head">
                    <p>
                        BType
                    </p>
                </th>
                <th class="head">
                    <p>
                        CType
                    </p>
                </th>
                <th class="head">
                    <p>
                        DType
                    </p>
                </th>
                <th class="head">
                    <p>
                        Bias Type
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td rowspan="12">
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td rowspan="5">
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td rowspan="2">
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id67">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id68">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id69">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id70">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id71">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="7">
                    <p>
                        CUDA_R_8F_E5M2
                    </p>
                </td>
                <td rowspan="3">
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id72">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id73">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_8F_E5M2
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id74">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="3">
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id75">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_8F_E5M2
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id76">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id77">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id78">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="7">
                    <p>
                        CUDA_R_8F_E5M2
                    </p>
                </td>
                <td rowspan="7">
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td rowspan="3">
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id79">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id80">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_8F_E5M2
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id81">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td rowspan="3">
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_8F_E4M3
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id82">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_8F_E5M2
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id83">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_R_16F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16F
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id84">
                            5
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_32F
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_R_16BF
                        <a class="footnote-reference brackets" href="https://docs.nvidia.com/cuda/cublas/index.html#epi"
                            id="id85">
                            5
                        </a>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            And finally, see below table when A,B,C,D are planar-complex matrices (
            <span class="pre">
                CUBLASLT_MATRIX_LAYOUT_PLANE_OFFSET
            </span>
            <span class="pre">
                !=
            </span>
            <span class="pre">
                0
            </span>
            , see
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutattribute-t">
                cublasLtMatrixLayoutAttribute_t
            </a>
            ) to make use of mixed precision tensor core acceleration.
        </p>
        <table class="table-no-stripes docutils align-default" id="id106">
            <span class="caption-text">
                Table 4. When A, B, C, and D are Planar-Complex Matrices
            </span>
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id106"
                title="Permalink to this table">
                
            </a>
            <tr class="row-odd">
                <th class="head">
                    <p>
                        computeType
                    </p>
                </th>
                <th class="head">
                    <p>
                        scaleType
                    </p>
                </th>
                <th class="head">
                    <p>
                        Atype/Btype
                    </p>
                </th>
                <th class="head">
                    <p>
                        Ctype
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td rowspan="4">
                    <p>
                        CUBLAS_COMPUTE_32F
                    </p>
                </td>
                <td rowspan="4">
                    <p>
                        CUDA_C_32F
                    </p>
                </td>
                <td rowspan="2">
                    <p>
                        CUDA_C_16F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id86">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_16F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id87">
                            6
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id88">
                            6
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td rowspan="2">
                    <p>
                        CUDA_C_16BF
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id89">
                            6
                        </a>
                    </p>
                </td>
                <td>
                    <p>
                        CUDA_C_16BF
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id90">
                            6
                        </a>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUDA_C_32F
                        <a class="footnote-reference brackets"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#herm" id="id91">
                            6
                        </a>
                    </p>
                </td>
            </tr>
        </table>
        <p>
            NOTES:
        </p>
        <span class="brackets">
            5
        </span>
        <span class="fn-backref">
            (
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id47">
                1
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id48">
                2
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id49">
                3
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id50">
                4
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id51">
                5
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id52">
                6
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id53">
                7
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id59">
                8
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id63">
                9
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id67">
                10
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id68">
                11
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id69">
                12
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id70">
                13
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id71">
                14
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id72">
                15
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id73">
                16
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id74">
                17
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id75">
                18
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id76">
                19
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id77">
                20
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id78">
                21
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id79">
                22
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id80">
                23
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id81">
                24
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id82">
                25
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id83">
                26
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id84">
                27
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id85">
                28
            </a>
            )
        </span>
        <p>
            ReLU, dReLu, GELU, dGELU and Bias epilogue modes (see
            <span class="pre">
                CUBLASLT_MATMUL_DESC_EPILOGUE
            </span>
            in
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                cublasLtMatmulDescAttributes_t
            </a>
            ) are not supported when D matrix memory order is defined as
            <span class="pre">
                CUBLASLT_ORDER_ROW
            </span>
            . For best performance when using the bias vector, specify zero beta and set pointer mode to
            <span class="pre">
                CUBLASLT_POINTER_MODE_HOST
            </span>
            .
        </p>
        <span class="brackets">
            6
        </span>
        <span class="fn-backref">
            (
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id54">
                1
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id55">
                2
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id56">
                3
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id57">
                4
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id58">
                5
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id60">
                6
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id61">
                7
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id62">
                8
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id64">
                9
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id65">
                10
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id66">
                11
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id86">
                12
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id87">
                13
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id88">
                14
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id89">
                15
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id90">
                16
            </a>
            ,
            <a href="https://docs.nvidia.com/cuda/cublas/index.html#id91">
                17
            </a>
            )
        </span>
        <p>
            Use of
            <span class="pre">
                CUBLAS_ORDER_ROW
            </span>
            together with
            <span class="pre">
                CUBLAS_OP_C
            </span>
            (Hermitian operator) is not supported unless all of A, B, C, and D matrices use the
            <span class="pre">
                CUBLAS_ORDER_ROW
            </span>
            ordering.
        </p>
        <p>
            Parameters:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the cuBLASLt context. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                            cublasLtHandle_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to a previously created matrix multiplication descriptor of type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha, beta
                    </p>
                </td>
                <td>
                    <p>
                        Device or host
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointers to the scalars used in the multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A, B, and C
                    </p>
                </td>
                <td>
                    <p>
                        Device
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointers to the GPU memory associated with the corresponding descriptors Adesc, Bdesc and Cdesc.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Adesc, Bdesc and Cdesc.
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handles to the previous created descriptors of the type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        D
                    </p>
                </td>
                <td>
                    <p>
                        Device
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the GPU memory associated with the descriptor Ddesc.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Ddesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to the previous created descriptor of the type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handle for matrix multiplication algorithm to be used. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        . When NULL, an implicit heuritics query with default search preferences will be performed to
                        determine actual algorithm to use.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        workspace
                    </p>
                </td>
                <td>
                    <p>
                        Device
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the workspace buffer allocated in the GPU memory. Must be 256B aligned (i.e. lowest 8
                        bits of address must be 0).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        workspaceSizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of the workspace.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        stream
                    </p>
                </td>
                <td>
                    <p>
                        Host
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The CUDA stream where all the GPU work will be submitted.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_INITIALIZED
                    </p>
                </td>
                <td>
                    <p>
                        If cuBLASLt handle has not been initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If the parameters are unexpectedly NULL, in conflict or in an impossible configuration. For
                        example, when
                        <span class="pre">
                            workspaceSizeInBytes
                        </span>
                        is less than workspace required by the configured algo.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_SUPPORTED
                    </p>
                </td>
                <td>
                    <p>
                        If the current implementation on the selected device doesnt support the configured operation.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_ARCH_MISMATCH
                    </p>
                </td>
                <td>
                    <p>
                        If the configured operation cannot be run using the selected device.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_EXECUTION_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If CUDA reported an execution error from the device.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the operation completed successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.18.
            </span>
            cublasLtMatmulAlgoCapGetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapgetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoCapGetAttribute</span><span class="p">(</span>
<span class="k">const</span><span class="n">cublasLtMatmulAlgo_t</span><span class="o">*</span><span class="n">algo</span><span class="p">,</span>
<span class="n">cublasLtMatmulAlgoCapAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">sizeWritten</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the queried capability attribute for an initialized
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                cublasLtMatmulAlgo_t
            </a>
            descriptor structure. The capability attribute value is retrieved from the enumerated type
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t">
                cublasLtMatmulAlgoCapAttributes_t
            </a>
            .
        </p>
        <p>
            For example, to get list of supported Tile IDs:
        </p>
        <pre><span class="n">cublasLtMatmulTile_t</span><span class="n">tiles</span><span class="p">[</span><span class="n">CUBLASLT_MATMUL_TILE_END</span><span class="p">];</span>
<span class="kt">size_t</span><span class="n">num_tiles</span><span class="p">,</span><span class="n">size_written</span><span class="p">;</span>
<span class="k">if</span><span class="p">(</span><span class="n">cublasLtMatmulAlgoCapGetAttribute</span><span class="p">(</span><span class="n">algo</span><span class="p">,</span><span class="n">CUBLASLT_ALGO_CAP_TILE_IDS</span><span class="p">,</span><span class="n">tiles</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="n">tiles</span><span class="p">),</span><span class="o">&amp;</span><span class="n">size_written</span><span class="p">)</span><span class="o">==</span><span class="n">CUBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">num_tiles</span><span class="o">=</span><span class="n">size_written</span><span class="o">/</span><span class="k">sizeof</span><span class="p">(</span><span class="n">tiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]);}</span>
</pre>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created opaque structure holding the matrix multiply algorithm
                        descriptor. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The capability attribute whose value will be retrieved by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocapattributes-t">
                            cublasLtMatmulAlgoCapAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        The attribute value returned by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        sizeWritten
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Valid only when the return value is CUBLAS_STATUS_SUCCESS. If
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is non-zero: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes actually written; if
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is 0: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes needed to write full contents.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is 0 and
                                <span class="pre">
                                    sizeWritten
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is non-zero and
                                <span class="pre">
                                    buf
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                doesnt match size of internal storage for the selected attribute
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attributes value was successfully written to user memory.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.19.
            </span>
            cublasLtMatmulAlgoCheck()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocheck"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoCheck</span><span class="p">(</span>
<span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">,</span>
<span class="n">cublasLtMatmulDesc_t</span><span class="n">operationDesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Adesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Bdesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Cdesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Ddesc</span><span class="p">,</span>
<span class="k">const</span><span class="n">cublasLtMatmulAlgo_t</span><span class="o">*</span><span class="n">algo</span><span class="p">,</span>
<span class="n">cublasLtMatmulHeuristicResult_t</span><span class="o">*</span><span class="n">result</span><span class="p">);</span>
</pre>
        <p>
            This function performs the correctness check on the matrix multiply algorithm descriptor for the matrix
            multiply operation
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            function with the given input matrices A, B and C, and the output matrix D. It checks whether the descriptor
            is supported on the current device, and returns the result containing the required workspace and the
            calculated wave count.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            CUBLAS_STATUS_SUCCESS doesnt fully guarantee that the algo will run. The algo will fail if, for example,
            the buffers are not correctly aligned. However, if
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgocheck">
                cublasLtMatmulAlgoCheck()
            </a>
            fails, the algo will not run.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the cuBLASLt context. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                            cublasLtHandle_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        operationDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to a previously created matrix multiplication descriptor of type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Adesc, Bdesc, Cdesc, and Ddesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handles to the previously created matrix layout descriptors of the type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Descriptor which specifies which matrix multiplication algorithm should be used. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        . May point to
                        <span class="pre">
                            result-&gt;algo
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        result
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the results returned by this function. The results comprise of
                        the required workspace and the calculated wave count. The algo field is never updated. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulheuristicresult-t">
                            cublasLtMatmulHeuristicResult_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If matrix layout descriptors or the operation descriptor do not match the algo descriptor.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_SUPPORTED
                    </p>
                </td>
                <td>
                    <p>
                        If the algo configuration or data type combination is not currently supported on the given
                        device.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ARCH_MISMATCH
                    </p>
                </td>
                <td>
                    <p>
                        If the algo configuration cannot be run using the selected device.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the check was successful.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.20.
            </span>
            cublasLtMatmulAlgoConfigGetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfiggetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoConfigGetAttribute</span><span class="p">(</span>
<span class="k">const</span><span class="n">cublasLtMatmulAlgo_t</span><span class="o">*</span><span class="n">algo</span><span class="p">,</span>
<span class="n">cublasLtMatmulAlgoConfigAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">sizeWritten</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the queried configuration attribute for an initialized
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                cublasLtMatmulAlgo_t
            </a>
            descriptor. The configuration attribute value is retrieved from the enumerated type
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                cublasLtMatmulAlgoConfigAttributes_t
            </a>
            .
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created opaque structure holding the matrix multiply algorithm
                        descriptor. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The configuration attribute whose value will be retrieved by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                            cublasLtMatmulAlgoConfigAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        The attribute value returned by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        sizeWritten
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Valid only when the return value is CUBLAS_STATUS_SUCCESS. If
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is non-zero: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes actually written; if
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is 0: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes needed to write full contents.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is 0 and
                                <span class="pre">
                                    sizeWritten
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is non-zero and
                                <span class="pre">
                                    buf
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                doesnt match size of internal storage for the selected attribute
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attributes value was successfully written to user memory.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.21.
            </span>
            cublasLtMatmulAlgoConfigSetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigsetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoConfigSetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatmulAlgo_t</span><span class="o">*</span><span class="n">algo</span><span class="p">,</span>
<span class="n">cublasLtMatmulAlgoConfigAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">);</span>
</pre>
        <p>
            This function sets the value of the specified configuration attribute for an initialized
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                cublasLtMatmulAlgo_t
            </a>
            descriptor. The configuration attribute is an enumerant of the type
            <a class="reference internal"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                cublasLtMatmulAlgoConfigAttributes_t
            </a>
            .
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created opaque structure holding the matrix multiply algorithm
                        descriptor. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The configuration attribute whose value will be set by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoconfigattributes-t">
                            cublasLtMatmulAlgoConfigAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The value to which the configuration attribute should be set.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            buf
                        </span>
                        is NULL or
                        <span class="pre">
                            sizeInBytes
                        </span>
                        doesnt match the size of the internal storage for the selected attribute.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the attribute was set successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.22.
            </span>
            cublasLtMatmulAlgoGetHeuristic()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetheuristic"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoGetHeuristic</span><span class="p">(</span>
<span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">,</span>
<span class="n">cublasLtMatmulDesc_t</span><span class="n">operationDesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Adesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Bdesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Cdesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Ddesc</span><span class="p">,</span>
<span class="n">cublasLtMatmulPreference_t</span><span class="n">preference</span><span class="p">,</span>
<span class="kt">int</span><span class="n">requestedAlgoCount</span><span class="p">,</span>
<span class="n">cublasLtMatmulHeuristicResult_t</span><span class="n">heuristicResultsArray</span><span class="p">[]</span>
<span class="kt">int</span><span class="o">*</span><span class="n">returnAlgoCount</span><span class="p">);</span>
</pre>
        <p>
            This function retrieves the possible algorithms for the matrix multiply operation
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            function with the given input matrices A, B and C, and the output matrix D. The output is placed in
            <span class="pre">
                heuristicResultsArray[]
            </span>
            in the order of increasing estimated compute time.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the cuBLASLt context. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                            cublasLtHandle_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        operationDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handle to a previously created matrix multiplication descriptor of type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Adesc, Bdesc, Cdesc, and Ddesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handles to the previously created matrix layout descriptors of the type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        preference
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the heuristic search preferences descriptor. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t">
                            cublasLtMatmulPreference_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        requestedAlgoCount
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of the
                        <span class="pre">
                            heuristicResultsArray
                        </span>
                        (in elements). This is the requested maximum number of algorithms to return.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        heuristicResultsArray[]
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Array containing the algorithm heuristics and associated runtime characteristics, returned by
                        this function, in the order of increasing estimated compute time.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        returnAlgoCount
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Number of algorithms returned by this function. This is the number of
                        <span class="pre">
                            heuristicResultsArray
                        </span>
                        elements written.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            requestedAlgoCount
                        </span>
                        is less or equal to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_SUPPORTED
                    </p>
                </td>
                <td>
                    <p>
                        If no heuristic function available for current configuration.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If query was successful. Inspect
                        <span class="pre">
                            heuristicResultsArray[0
                        </span>
                        <span class="pre">
                            to
                        </span>
                        <span class="pre">
                            (returnAlgoCount
                        </span>
                        <span class="pre">
                            -1)].state
                        </span>
                        for the status of the results.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            This function may load some kernels using CUDA Driver API which may fail when there is no available GPU
            memory. Do not allocate the entire VRAM before running
            <span class="pre">
                cublasLtMatmulAlgoGetHeuristic()
            </span>
            .
        </p>
        <h3>
            <span class="section-number">
                3.4.23.
            </span>
            cublasLtMatmulAlgoGetIds()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetids"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoGetIds</span><span class="p">(</span>
<span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">scaleType</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Dtype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">requestedAlgoCount</span><span class="p">,</span>
<span class="kt">int</span><span class="n">algoIdsArray</span><span class="p">[],</span>
<span class="kt">int</span><span class="o">*</span><span class="n">returnAlgoCount</span><span class="p">);</span>
</pre>
        <p>
            This function retrieves the IDs of all the matrix multiply algorithms that are valid, and can potentially be
            run by the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            function, for given types of the input matrices A, B and C, and of the output matrix D.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The IDs are returned in no particular order. To make sure the best possible algo is contained in the list,
            make
            <span class="pre">
                requestedAlgoCount
            </span>
            large enough to receive the full list. The list is guaranteed to be full if
            <span class="pre">
                returnAlgoCount
            </span>
            <span class="pre">
                &lt;
            </span>
            <span class="pre">
                requestedAlgoCount
            </span>
            .
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the cuBLASLt context. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                            cublasLtHandle_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType, scaleType, Atype, Btype, Ctype, and Dtype
                    </p>
                </td>
                <td>
                    <p>
                        Inputs
                    </p>
                </td>
                <td>
                    <p>
                        Data types of the computation type, scaling factors and of the operand matrices. See
                        <span class="pre">
                            cudaDataType_t
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        requestedAlgoCount
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Number of algorithms requested. Must be &gt; 0.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        algoIdsArray[]
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Array containing the algorithm IDs returned by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        returnAlgoCount
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Number of algorithms actually returned by this function.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            requestedAlgoCount
                        </span>
                        is less or equal to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If query was successful. Inspect
                        <span class="pre">
                            returnAlgoCount
                        </span>
                        to get actual number of IDs available.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.24.
            </span>
            cublasLtMatmulAlgoInit()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgoinit"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulAlgoInit</span><span class="p">(</span>
<span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">scaleType</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Atype</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Btype</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Ctype</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">Dtype</span><span class="p">,</span>
<span class="kt">int</span><span class="n">algoId</span><span class="p">,</span>
<span class="n">cublasLtMatmulAlgo_t</span><span class="o">*</span><span class="n">algo</span><span class="p">);</span>
</pre>
        <p>
            This function initializes the matrix multiply algorithm structure for the
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmul">
                cublasLtMatmul()
            </a>
            , for a specified matrix multiply algorithm and input matrices A, B and C, and the output matrix D.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the cuBLASLt context. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                            cublasLtHandle_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Compute type. See
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_COMPUTE_TYPE
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        scaleType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Scale type. See
                        <span class="pre">
                            CUBLASLT_MATMUL_DESC_SCALE_TYPE
                        </span>
                        of
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        . Usually same as computeType.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        Atype, Btype, Ctype, and Dtype
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Datatype precision for the input and output matrices. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cudadatatype-t">
                            cudaDataType_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        algoId
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Specifies the algorithm being initialized. Should be a valid
                        <span class="pre">
                            algoId
                        </span>
                        returned by the
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgogetids">
                            cublasLtMatmulAlgoGetIds()
                        </a>
                        function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        algo
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the opaque structure to be initialized. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulalgo-t">
                            cublasLtMatmulAlgo_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            algo
                        </span>
                        is NULL or
                        <span class="pre">
                            algoId
                        </span>
                        is outside the recognized range.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_SUPPORTED
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            algoId
                        </span>
                        is not supported for given combination of data types.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the structure was successfully initialized.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.25.
            </span>
            cublasLtMatmulDescCreate()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesccreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulDescCreate</span><span class="p">(</span><span class="n">cublasLtMatmulDesc_t</span><span class="o">*</span><span class="n">matmulDesc</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">scaleType</span><span class="p">);</span>
</pre>
        <p>
            This function creates a matrix multiply descriptor by allocating the memory needed to hold its opaque
            structure.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matmulDesc
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix multiply descriptor created by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix multiply descriptor this function
                        creates. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                            cublasComputeType_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        scaleType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix transform descriptor this function
                        creates. See
                        <span class="pre">
                            cudaDataType
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.26.
            </span>
            cublasLtMatmulDescInit()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescinit"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulDescInit</span><span class="p">(</span><span class="n">cublasLtMatmulDesc_t</span><span class="n">matmulDesc</span><span class="p">,</span>
<span class="n">cublasComputeType_t</span><span class="n">computeType</span><span class="p">,</span>
<span class="n">cudaDataType_t</span><span class="n">scaleType</span><span class="p">);</span>
</pre>
        <p>
            This function initializes a matrix multiply descriptor in a previously allocated one.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matmulDesc
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix multiply descriptor initialized by this function.
                        See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        computeType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix multiply descriptor this function
                        initializes. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublascomputetype-t">
                            cublasComputeType_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        scaleType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix transform descriptor this function
                        initializes. See
                        <span class="pre">
                            cudaDataType
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.27.
            </span>
            cublasLtMatmulDescDestroy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescdestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulDescDestroy</span><span class="p">(</span>
<span class="n">cublasLtMatmulDesc_t</span><span class="n">matmulDesc</span><span class="p">);</span>
</pre>
        <p>
            This function destroys a previously created matrix multiply descriptor object.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matmulDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix multiply descriptor that should be destroyed by this
                        function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If operation was successful.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.28.
            </span>
            cublasLtMatmulDescGetAttribute()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescgetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulDescGetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatmulDesc_t</span><span class="n">matmulDesc</span><span class="p">,</span>
<span class="n">cublasLtMatmulDescAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">sizeWritten</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the queried attribute belonging to a previously created matrix multiply
            descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matmulDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix multiply descriptor queried by
                        this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be retrieved by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Memory address containing the attribute value retrieved by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        sizeWritten
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Valid only when the return value is CUBLAS_STATUS_SUCCESS. If
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is non-zero: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes actually written; if
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is 0: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes needed to write full contents.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is 0 and
                                <span class="pre">
                                    sizeWritten
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is non-zero and
                                <span class="pre">
                                    buf
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                doesnt match size of internal storage for the selected attribute
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attributes value was successfully written to user memory.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.29.
            </span>
            cublasLtMatmulDescSetAttribute()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescsetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulDescSetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatmulDesc_t</span><span class="n">matmulDesc</span><span class="p">,</span>
<span class="n">cublasLtMatmulDescAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">);</span>
</pre>
        <p>
            This function sets the value of the specified attribute belonging to a previously created matrix multiply
            descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matmulDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix multiply descriptor queried by
                        this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldesc-t">
                            cublasLtMatmulDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be set by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmuldescattributes-t">
                            cublasLtMatmulDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The value to which the specified attribute should be set.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            buf
                        </span>
                        is NULL or
                        <span class="pre">
                            sizeInBytes
                        </span>
                        doesnt match the size of the internal storage for the selected attribute.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the attribute was set successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.30.
            </span>
            cublasLtMatmulPreferenceCreate()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencecreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulPreferenceCreate</span><span class="p">(</span>
<span class="n">cublasLtMatmulPreference_t</span><span class="o">*</span><span class="n">pref</span><span class="p">);</span>
</pre>
        <p>
            This function creates a matrix multiply heuristic search preferences descriptor by allocating the memory
            needed to hold its opaque structure.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        pref
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix multiply preferences descriptor created by this
                        function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.31.
            </span>
            cublasLtMatmulPreferenceInit()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceinit"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulPreferenceInit</span><span class="p">(</span>
<span class="n">cublasLtMatmulPreference_t</span><span class="n">pref</span><span class="p">);</span>
</pre>
        <p>
            This function initializes a matrix multiply heuristic search preferences descriptor in a previously
            allocated one.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        pref
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix multiply preferences descriptor created by this
                        function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.32.
            </span>
            cublasLtMatmulPreferenceDestroy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencedestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulPreferenceDestroy</span><span class="p">(</span>
<span class="n">cublasLtMatmulPreference_t</span><span class="n">pref</span><span class="p">);</span>
</pre>
        <p>
            This function destroys a previously created matrix multiply preferences descriptor object.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        pref
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix multiply preferences descriptor that should be
                        destroyed by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t">
                            cublasLtMatmulPreference_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the operation was successful.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.33.
            </span>
            cublasLtMatmulPreferenceGetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencegetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulPreferenceGetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatmulPreference_t</span><span class="n">pref</span><span class="p">,</span>
<span class="n">cublasLtMatmulPreferenceAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">sizeWritten</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the queried attribute belonging to a previously created matrix multiply
            heuristic search preferences descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        pref
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix multiply heuristic search
                        preferences descriptor queried by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t">
                            cublasLtMatmulPreference_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be queried by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceattributes-t">
                            cublasLtMatmulPreferenceAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Memory address containing the attribute value retrieved by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        sizeWritten
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Valid only when the return value is CUBLAS_STATUS_SUCCESS. If
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is non-zero: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes actually written; if
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is 0: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes needed to write full contents.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is 0 and
                                <span class="pre">
                                    sizeWritten
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is non-zero and
                                <span class="pre">
                                    buf
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                doesnt match size of internal storage for the selected attribute
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attributes value was successfully written to user memory.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.34.
            </span>
            cublasLtMatmulPreferenceSetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferencesetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatmulPreferenceSetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatmulPreference_t</span><span class="n">pref</span><span class="p">,</span>
<span class="n">cublasLtMatmulPreferenceAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">);</span>
</pre>
        <p>
            This function sets the value of the specified attribute belonging to a previously created matrix multiply
            preferences descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        pref
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix multiply preferences descriptor
                        queried by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreference-t">
                            cublasLtMatmulPreference_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be set by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatmulpreferenceattributes-t">
                            cublasLtMatmulPreferenceAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The value to which the specified attribute should be set.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If buf is NULL or
                        <span class="pre">
                            sizeInBytes
                        </span>
                        doesnt match the size of the internal storage for the selected attribute.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the attribute was set successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.35.
            </span>
            cublasLtMatrixLayoutCreate()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutcreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixLayoutCreate</span><span class="p">(</span><span class="n">cublasLtMatrixLayout_t</span><span class="o">*</span><span class="n">matLayout</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">type</span><span class="p">,</span>
<span class="kt">uint64_t</span><span class="n">rows</span><span class="p">,</span>
<span class="kt">uint64_t</span><span class="n">cols</span><span class="p">,</span>
<span class="kt">int64_t</span><span class="n">ld</span><span class="p">);</span>
</pre>
        <p>
            This function creates a matrix layout descriptor by allocating the memory needed to hold its opaque
            structure.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matLayout
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix layout descriptor created by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        type
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix layout descriptor this function
                        creates. See
                        <span class="pre">
                            cudaDataType
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        rows, cols
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows and columns of the matrix.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ld
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The leading dimension of the matrix. In column major layout, this is the number of elements to
                        jump to reach the next column. Thus ld &gt;= m (number of rows).
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If the memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.36.
            </span>
            cublasLtMatrixLayoutInit()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutinit"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixLayoutInit</span><span class="p">(</span><span class="n">cublasLtMatrixLayout_t</span><span class="n">matLayout</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">type</span><span class="p">,</span>
<span class="kt">uint64_t</span><span class="n">rows</span><span class="p">,</span>
<span class="kt">uint64_t</span><span class="n">cols</span><span class="p">,</span>
<span class="kt">int64_t</span><span class="n">ld</span><span class="p">);</span>
</pre>
        <p>
            This function initializes a matrix layout descriptor in a previously allocated one.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matLayout
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix layout descriptor initialized by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        type
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix layout descriptor this function
                        initializes. See
                        <span class="pre">
                            cudaDataType
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        rows, cols
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Number of rows and columns of the matrix.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ld
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The leading dimension of the matrix. In column major layout, this is the number of elements to
                        jump to reach the next column. Thus ld &gt;= m (number of rows).
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If the memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.37.
            </span>
            cublasLtMatrixLayoutDestroy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutdestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixLayoutDestroy</span><span class="p">(</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">matLayout</span><span class="p">);</span>
</pre>
        <p>
            This function destroys a previously created matrix layout descriptor object.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matLayout
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix layout descriptor that should be destroyed by this
                        function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <td>
                    <p>
                        Return Value
                    </p>
                </td>
                <td>
                    <p>
                        Description
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the operation was successful.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.38.
            </span>
            cublasLtMatrixLayoutGetAttribute()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutgetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixLayoutGetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">matLayout</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayoutAttribute_t</span><span class="n">attr</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">sizeWritten</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the queried attribute belonging to the specified matrix layout
            descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matLayout
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix layout descriptor queried by this
                        function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute being queried for. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutattribute-t">
                            cublasLtMatrixLayoutAttribute_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        The attribute value returned by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        sizeWritten
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Valid only when the return value is CUBLAS_STATUS_SUCCESS. If
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is non-zero: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes actually written; if
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is 0: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes needed to write full contents.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is 0 and
                                <span class="pre">
                                    sizeWritten
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is non-zero and
                                <span class="pre">
                                    buf
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                doesnt match size of internal storage for the selected attribute
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attributes value was successfully written to user memory.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.39.
            </span>
            cublasLtMatrixLayoutSetAttribute()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutsetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixLayoutSetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">matLayout</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayoutAttribute_t</span><span class="n">attr</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">);</span>
</pre>
        <p>
            This function sets the value of the specified attribute belonging to a previously created matrix layout
            descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        matLayout
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix layout descriptor queried by this
                        function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be set by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayoutattribute-t">
                            cublasLtMatrixLayoutAttribute_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The value to which the specified attribute should be set.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        , the attribute buffer.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            buf
                        </span>
                        is NULL or
                        <span class="pre">
                            sizeInBytes
                        </span>
                        doesnt match size of internal storage for the selected attribute.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attribute was set successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.40.
            </span>
            cublasLtMatrixTransform()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransform"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixTransform</span><span class="p">(</span>
<span class="n">cublasLtHandle_t</span><span class="n">lightHandle</span><span class="p">,</span>
<span class="n">cublasLtMatrixTransformDesc_t</span><span class="n">transformDesc</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">A</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Adesc</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Bdesc</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="n">cublasLtMatrixLayout_t</span><span class="n">Cdesc</span><span class="p">,</span>
<span class="n">cudaStream_t</span><span class="n">stream</span><span class="p">);</span>
</pre>
        <p>
            This function computes the matrix transformation operation on the input matrices A and B, to produce the
            output matrix C, according to the below operation:
        </p>
        <p>
            <span class="pre">
                C
            </span>
            <span class="pre">
                =
            </span>
            <span class="pre">
                alpha*transformation(A)
            </span>
            <span class="pre">
                +
            </span>
            <span class="pre">
                beta*transformation(B),
            </span>
        </p>
        <p>
            where
            <span class="pre">
                A
            </span>
            ,
            <span class="pre">
                B
            </span>
            are input matrices, and
            <span class="pre">
                alpha
            </span>
            and
            <span class="pre">
                beta
            </span>
            are input scalars. The transformation operation is defined by the
            <span class="pre">
                transformDesc
            </span>
            pointer. This function can be used to change the memory order of data or to scale and shift the values.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lightHandle
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the allocated cuBLASLt handle for the cuBLASLt context. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublaslthandle-t">
                            cublasLtHandle_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transformDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the opaque descriptor holding the matrix transformation operation. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                            cublasLtMatrixTransformDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha, beta
                    </p>
                </td>
                <td>
                    <p>
                        Device or host
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointers to the scalars used in the multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A, B, and C
                    </p>
                </td>
                <td>
                    <p>
                        Device
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointers to the GPU memory associated with the corresponding descriptors
                        <span class="pre">
                            Adesc
                        </span>
                        ,
                        <span class="pre">
                            Bdesc
                        </span>
                        and
                        <span class="pre">
                            Cdesc
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        Adesc, Bdesc and Cdesc.
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Handles to the previous created descriptors of the type
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixlayout-t">
                            cublasLtMatrixLayout_t
                        </a>
                        .
                    </p>
                    <p>
                        <span class="pre">
                            Adesc
                        </span>
                        or
                        <span class="pre">
                            Bdesc
                        </span>
                        can be NULL if corresponding pointer is NULL and corresponding scalar is zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        stream
                    </p>
                </td>
                <td>
                    <p>
                        Host
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The CUDA stream where all the GPU work will be submitted.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_INITIALIZED
                    </p>
                </td>
                <td>
                    <p>
                        If cuBLASLt handle has not been initialized.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If the parameters are in conflict or in an impossible configuration. For example, when
                        <span class="pre">
                            A
                        </span>
                        is not NULL, but
                        <span class="pre">
                            Adesc
                        </span>
                        is NULL.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_NOT_SUPPORTED
                    </p>
                </td>
                <td>
                    <p>
                        If the current implementation on the selected device does not support the configured operation.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_ARCH_MISMATCH
                    </p>
                </td>
                <td>
                    <p>
                        If the configured operation cannot be run using the selected device.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_EXECUTION_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If CUDA reported an execution error from the device.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the operation completed successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.41.
            </span>
            cublasLtMatrixTransformDescCreate()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesccreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixTransformDescCreate</span><span class="p">(</span>
<span class="n">cublasLtMatrixTransformDesc_t</span><span class="o">*</span><span class="n">transformDesc</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">scaleType</span><span class="p">);</span>
</pre>
        <p>
            This function creates a matrix transform descriptor by allocating the memory needed to hold its opaque
            structure.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transformDesc
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix transform descriptor created by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                            cublasLtMatrixTransformDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        scaleType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix transform descriptor this function
                        creates. See
                        <span class="pre">
                            cudaDataType
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.42.
            </span>
            cublasLtMatrixTransformDescInit()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescinit"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixTransformDescInit</span><span class="p">(</span>
<span class="n">cublasLtMatrixTransformDesc_t</span><span class="n">transformDesc</span><span class="p">,</span>
<span class="n">cudaDataType</span><span class="n">scaleType</span><span class="p">);</span>
</pre>
        <p>
            This function initializes a matrix transform descriptor in a previously allocated one.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transformDesc
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix transform descriptor initialized by this function.
                        See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                            cublasLtMatrixTransformDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        scaleType
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Enumerant that specifies the data precision for the matrix transform descriptor this function
                        initializes. See
                        <span class="pre">
                            cudaDataType
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_ALLOC_FAILED
                    </p>
                </td>
                <td>
                    <p>
                        If memory could not be allocated.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the descriptor was created successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.43.
            </span>
            cublasLtMatrixTransformDescDestroy()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescdestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixTransformDescDestroy</span><span class="p">(</span>
<span class="n">cublasLtMatrixTransformDesc_t</span><span class="n">transformDesc</span><span class="p">);</span>
</pre>
        <p>
            This function destroys a previously created matrix transform descriptor object.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transformDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the structure holding the matrix transform descriptor that should be destroyed by
                        this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                            cublasLtMatrixTransformDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the operation was successful.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.44.
            </span>
            cublasLtMatrixTransformDescGetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescgetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixTransformDescGetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatrixTransformDesc_t</span><span class="n">transformDesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixTransformDescAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">sizeWritten</span><span class="p">);</span>
</pre>
        <p>
            This function returns the value of the queried attribute belonging to a previously created matrix transform
            descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transformDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix transform descriptor queried by
                        this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                            cublasLtMatrixTransformDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be retrieved by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescattributes-t">
                            cublasLtMatrixTransformDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Memory address containing the attribute value retrieved by this function.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        sizeWritten
                    </p>
                </td>
                <td>
                    <p>
                        Output
                    </p>
                </td>
                <td>
                    <p>
                        Valid only when the return value is CUBLAS_STATUS_SUCCESS. If
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is non-zero: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes actually written; if
                        <span class="pre">
                            sizeInBytes
                        </span>
                        is 0: then
                        <span class="pre">
                            sizeWritten
                        </span>
                        is the number of bytes needed to write full contents.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <ul class="simple">
                        <li>
                            <p>
                                If
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is 0 and
                                <span class="pre">
                                    sizeWritten
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                if
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                is non-zero and
                                <span class="pre">
                                    buf
                                </span>
                                is NULL, or
                            </p>
                        </li>
                        <li>
                            <p>
                                <span class="pre">
                                    sizeInBytes
                                </span>
                                doesnt match size of internal storage for the selected attribute
                            </p>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If attributes value was successfully written to user memory.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h3>
            <span class="section-number">
                3.4.45.
            </span>
            cublasLtMatrixTransformDescSetAttribute()
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescsetattribute"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasLtMatrixTransformDescSetAttribute</span><span class="p">(</span>
<span class="n">cublasLtMatrixTransformDesc_t</span><span class="n">transformDesc</span><span class="p">,</span>
<span class="n">cublasLtMatrixTransformDescAttributes_t</span><span class="n">attr</span><span class="p">,</span>
<span class="k">const</span><span class="kt">void</span><span class="o">*</span><span class="n">buf</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">sizeInBytes</span><span class="p">);</span>
</pre>
        <p>
            This function sets the value of the specified attribute belonging to a previously created matrix transform
            descriptor.
        </p>
        <p>
            Parameters
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Parameter
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        Input / Output
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transformDesc
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Pointer to the previously created structure holding the matrix transform descriptor queried by
                        this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdesc-t">
                            cublasLtMatrixTransformDesc_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        attr
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The attribute that will be set by this function. See
                        <a class="reference internal"
                            href="https://docs.nvidia.com/cuda/cublas/index.html#cublasltmatrixtransformdescattributes-t">
                            cublasLtMatrixTransformDescAttributes_t
                        </a>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        buf
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        The value to which the specified attribute should be set.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        sizeInBytes
                    </p>
                </td>
                <td>
                    <p>
                        Input
                    </p>
                </td>
                <td>
                    <p>
                        Size of
                        <span class="pre">
                            buf
                        </span>
                        buffer (in bytes) for verification.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            Returns
            :
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Description
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        CUBLAS_STATUS_INVALID_VALUE
                    </p>
                </td>
                <td>
                    <p>
                        If
                        <span class="pre">
                            buf
                        </span>
                        is NULL or
                        <span class="pre">
                            sizeInBytes
                        </span>
                        does not match size of the internal storage for the selected attribute.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        CUBLAS_STATUS_SUCCESS
                    </p>
                </td>
                <td>
                    <p>
                        If the attribute was set successfully.
                    </p>
                </td>
            </tr>
        </table>
        <p>
            See
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            for a complete list of valid return codes.
        </p>
        <h1>
            <span class="section-number">
                4.
            </span>
            Using the cuBLASXt API
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublasxt-api"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <h2>
            <span class="section-number">
                4.1.
            </span>
            General description
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id93"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The cuBLASXt API of cuBLAS exposes a multi-GPU capable host interface: when using this API the application
            only needs to allocate the required matrices on the host memory space. Additionally, the current
            implementation supports managed memory on Linux with GPU devices that have compute capability 6.x or greater
            but treats it as host memory. Managed memory is not supported on Windows. There are no restriction on the
            sizes of the matrices as long as they can fit into the host memory. The cuBLASXt API takes care of
            allocating the memory across the designated GPUs and dispatched the workload between them and finally
            retrieves the results back to the host. The cuBLASXt API supports only the compute-intensive BLAS3 routines
            (e.g matrix-matrix operations) where the PCI transfers back and forth from the GPU can be amortized. The
            cuBLASXt API has its own header file
            <span class="pre">
                cublasXt.h
            </span>
            .
        </p>
        <p>
            Starting with release 8.0, cuBLASXt API allows any of the matrices to be located on a GPU device.
        </p>
        <p>
            Note : The cuBLASXt API is only supported on 64-bit platforms.
        </p>
        <h3>
            <span class="section-number">
                4.1.1.
            </span>
            Tiling design approach
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#tiling-design-approach"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            To be able to share the workload between multiples GPUs, the cuBLASXt API uses a tiling strategy : every
            matrix is divided in square tiles of user-controllable dimension BlockDim x BlockDim. The resulting matrix
            tiling defines the static scheduling policy : each resulting tile is affected to a GPU in a round robin
            fashion One CPU thread is created per GPU and is responsible to do the proper memory transfers and cuBLAS
            operations to compute all the tiles that it is responsible for. From a performance point of view, due to
            this static scheduling strategy, it is better that compute capabilites and PCI bandwidth are the same for
            every GPU. The figure below illustrates the tiles distribution between 3 GPUs. To compute the first tile G0
            from C, the CPU thread 0 responsible of GPU0, have to load 3 tiles from the first row of A and tiles from
            the first columun of B in a pipeline fashion in order to overlap memory transfer and computations and sum
            the results into the first tile G0 of C before to move on to the next tile G0.
        </p>
        <p>
            <span class="caption-text">
                Example of
                <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-gemm">
                    cublasXt&lt;t&gt;gemm
                </a>
                tiling for 3 Gpus
            </span>
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#design-approach-example-of-xgemm-tiling-for-3-gpus"
                title="Permalink to this image">
                
            </a>
        </p>
        <p>
            When the tile dimension is not an exact multiple of the dimensions of C, some tiles are partially filled on
            the right border or/and the bottom border. The current implementation does not pad the incomplete tiles but
            simply keep track of those incomplete tiles by doing the right reduced cuBLAS opearations : this way, no
            extra computation is done. However it still can lead to some load unbalance when all GPUS do not have the
            same number of incomplete tiles to work on.
        </p>
        <p>
            When one or more matrices are located on some GPU devices, the same tiling approach and workload sharing is
            applied. The memory transfers are in this case done between devices. However, when the computation of a tile
            and some data are located on the same GPU device, the memory transfer to/from the local data into tiles is
            bypassed and the GPU operates directly on the local data. This can lead to a significant performance
            increase, especially when only one GPU is used for the computation.
        </p>
        <p>
            The matrices can be located on any GPU device, and do not have to be located on the same GPU device.
            Furthermore, the matrices can even be located on a GPU device that do not participate to the computation.
        </p>
        <p>
            On the contrary of the cuBLAS API, even if all matrices are located on the same device, the cuBLASXt API is
            still a blocking API from the host point of view : the data results wherever located will be valid on the
            call return and no device synchronization is required.
        </p>
        <h3>
            <span class="section-number">
                4.1.2.
            </span>
            Hybrid CPU-GPU computation
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#hybrid-cpu-gpu-computation"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            In the case of very large problems, the cuBLASXt API offers the possibility to offload some of the
            computation to the host CPU. This feature can be setup with the routines
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuroutine">
                cublasXtSetCpuRoutine()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuratio">
                cublasXtSetCpuRatio()
            </a>
            The workload affected to the CPU is put aside : it is simply a percentage of the resulting matrix taken from
            the bottom and the right side whichever dimension is bigger. The GPU tiling is done after that on the
            reduced resulting matrix.
        </p>
        <p>
            If any of the matrices is located on a GPU device, the feature is ignored and all computation will be done
            only on the GPUs
        </p>
        <p>
            This feature should be used with caution because it could interfere with the CPU threads responsible of
            feeding the GPUs.
        </p>
        <p>
            Currently, only the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-gemm">
                cublasXt&lt;t&gt;gemm
            </a>
            supports this feature.
        </p>
        <h3>
            <span class="section-number">
                4.1.3.
            </span>
            Results reproducibility
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id95"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            Currently all cuBLASXt API routines from a given toolkit version, generate the same bit-wise results when
            the following conditions are respected :
        </p>
        <ul class="simple">
            <li>
                <p>
                    all GPUs particating to the computation have the same compute capabilities and the same number of
                    SMs.
                </p>
            </li>
            <li>
                <p>
                    the tiles size is kept the same between run.
                </p>
            </li>
            <li>
                <p>
                    either the CPU hybrid computation is not used or the CPU Blas provided is also guaranteed to produce
                    reproducible results.
                </p>
            </li>
        </ul>
        <h2>
            <span class="section-number">
                4.2.
            </span>
            cuBLASXt API Datatypes Reference
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-api-datatypes-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <h3>
            <span class="section-number">
                4.2.1.
            </span>
            cublasXtHandle_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxthandle-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <span class="pre">
                cublasXtHandle_t
            </span>
            type is a pointer type to an opaque structure holding the cuBLASXt API context. The cuBLASXt API context
            must be initialized using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtcreate">
                cublasXtCreate()
            </a>
            and the returned handle must be passed to all subsequent cuBLASXt API function calls. The context should be
            destroyed at the end using
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtdestroy">
                cublasXtDestroy()
            </a>
            .
        </p>
        <h3>
            <span class="section-number">
                4.2.2.
            </span>
            cublasXtOpType_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtoptype-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <span class="pre">
                cublasOpType_t
            </span>
            enumerates the four possible types supported by BLAS routines. This enum is used as parameters of the
            routines
            <span class="pre">
                cublasXtSetCpuRoutine
            </span>
            and
            <span class="pre">
                cublasXtSetCpuRatio
            </span>
            to setup the hybrid configuration.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_FLOAT
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        float or single precision type
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_DOUBLE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        double precision type
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_COMPLEX
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        single precision complex
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_DOUBLECOMPLEX
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        double precision complex
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.2.3.
            </span>
            cublasXtBlasOp_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtblasop-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The
            <span class="pre">
                cublasXtBlasOp_t
            </span>
            type enumerates the BLAS3 or BLAS-like routine supported by cuBLASXt API. This enum is used as parameters of
            the routines
            <span class="pre">
                cublasXtSetCpuRoutine
            </span>
            and
            <span class="pre">
                cublasXtSetCpuRatio
            </span>
            to setup the hybrid configuration.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_GEMM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        GEMM routine
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_SYRK
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SYRK routine
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_HERK
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        HERK routine
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_SYMM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SYMM routine
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_HEMM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        HEMM routine
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_TRSM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        TRSM routine
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_SYR2K
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SYR2K routine
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_HER2K
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        HER2K routine
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_SPMM
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SPMM routine
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_SYRKX
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        SYRKX routine
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_HERKX
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        HERKX routine
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.2.4.
            </span>
            cublasXtPinningMemMode_t
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtpinningmemmode-t"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <p>
            The type is used to enable or disable the Pinning Memory mode through the routine
            <span class="pre">
                cubasMgSetPinningMemMode
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_PINNING_DISABLED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the Pinning Memory mode is disabled
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLASXT_PINNING_ENABLED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the Pinning Memory mode is enabled
                    </p>
                </td>
            </tr>
        </table>
        <h2>
            <span class="section-number">
                4.3.
            </span>
            cuBLASXt API Helper Function Reference
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-api-helper-function-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <h3>
            <span class="section-number">
                4.3.1.
            </span>
            cublasXtCreate()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtcreate"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasXtCreate</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="o">*</span><span class="n">handle</span><span class="p">)</span>
</pre>
        <p>
            This function initializes the cuBLASXt API and creates a handle to an opaque structure holding the cuBLASXt
            API context. It allocates hardware resources on the host and device and must be called prior to making any
            other cuBLASXt API calls.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the initialization succeeded
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the resources could not be allocated
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        cuBLASXt API is only supported on 64-bit platform
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.2.
            </span>
            cublasXtDestroy()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtdestroy"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span>
<span class="n">cublasXtDestroy</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">)</span>
</pre>
        <p>
            This function releases hardware resources used by the cuBLASXt API context. The release of GPU resources may
            be deferred until the application exits. This function is usually the last call with a particular handle to
            the cuBLASXt API.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the shut down succeeded
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.3.
            </span>
            cublasXtDeviceSelect()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtdeviceselect"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtDeviceSelect</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">nbDevices</span><span class="p">,</span><span class="kt">int</span><span class="n">deviceId</span><span class="p">[])</span>
</pre>
        <p>
            This function allows the user to provide the number of GPU devices and their respective Ids that will
            participate to the subsequent cuBLASXt API Math function calls. This function will create a cuBLAS context
            for every GPU provided in that list. Currently the device configuration is static and cannot be changed
            between Math function calls. In that regard, this function should be called only once after
            <span class="pre">
                cublasXtCreate
            </span>
            . To be able to run multiple configurations, multiple cuBLASXt API contexts should be created.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        User call was sucessful
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Access to at least one of the device could not be done or a cuBLAS context could not be created
                        on at least one of the device
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        Some resources could not be allocated.
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.4.
            </span>
            cublasXtSetBlockDim()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetblockdim"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtSetBlockDim</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="n">blockDim</span><span class="p">)</span>
</pre>
        <p>
            This function allows the user to set the block dimension used for the tiling of the matrices for the
            subsequent Math function calls. Matrices are split in square tiles of blockDim x blockDim dimension. This
            function can be called anytime and will take effect for the following Math function calls. The block
            dimension should be chosen in a way to optimize the math operation and to make sure that the PCI transfers
            are well overlapped with the computation.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the call has been successful
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        blockDim &lt;= 0
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.5.
            </span>
            cublasXtGetBlockDim()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtgetblockdim"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtGetBlockDim</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">blockDim</span><span class="p">)</span>
</pre>
        <p>
            This function allows the user to query the block dimension used for the tiling of the matrices.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the call has been successful
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.6.
            </span>
            cublasXtSetCpuRoutine()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuroutine"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtSetCpuRoutine</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasXtBlasOp_t</span><span class="n">blasOp</span><span class="p">,</span><span class="n">cublasXtOpType_t</span><span class="n">type</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">blasFunctor</span><span class="p">)</span>
</pre>
        <p>
            This function allows the user to provide a CPU implementation of the corresponding BLAS routine. This
            function can be used with the function
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuratio">
                cublasXtSetCpuRatio()
            </a>
            to define an hybrid computation between the CPU and the GPUs. Currently the hybrid feature is only supported
            for the xGEMM routines.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the call has been successful
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        blasOp or type define an invalid combination
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        CPU-GPU Hybridization for that routine is not supported
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.7.
            </span>
            cublasXtSetCpuRatio()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuratio"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtSetCpuRatio</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasXtBlasOp_t</span><span class="n">blasOp</span><span class="p">,</span><span class="n">cublasXtOpType_t</span><span class="n">type</span><span class="p">,</span><span class="kt">float</span><span class="n">ratio</span><span class="p">)</span>
</pre>
        <p>
            This function allows the user to define the percentage of workload that should be done on a CPU in the
            context of an hybrid computation. This function can be used with the function
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetcpuroutine">
                cublasXtSetCpuRoutine()
            </a>
            to define an hybrid computation between the CPU and the GPUs. Currently the hybrid feature is only supported
            for the xGEMM routines.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the call has been successful
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        blasOp or type define an invalid combination
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        CPU-GPU Hybridization for that routine is not supported
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.8.
            </span>
            cublasXtSetPinningMemMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtsetpinningmemmode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtSetPinningMemMode</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasXtPinningMemMode_t</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            This function allows the user to enable or disable the Pinning Memory mode. When enabled, the matrices
            passed in subsequent cuBLASXt API calls will be pinned/unpinned using the CUDART routine
            <span class="pre">
                cudaHostRegister()
            </span>
            and
            <span class="pre">
                cudaHostUnregister()
            </span>
            respectively if the matrices are not already pinned. If a matrix happened to be pinned partially, it will
            also not be pinned. Pinning the memory improve PCI transfer performace and allows to overlap PCI memory
            transfer with computation. However pinning/unpinning the memory take some time which might not be amortized.
            It is advised that the user pins the memory on its own using
            <span class="pre">
                cudaMallocHost()
            </span>
            or
            <span class="pre">
                cudaHostRegister()
            </span>
            and unpin it when the computation sequence is completed. By default, the Pinning Memory mode is disabled.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The Pinning Memory mode should not enabled when matrices used for different calls to cuBLASXt API overlap.
            cuBLASXt determines that a matrix is pinned or not if the first address of that matrix is pinned using
            <span class="pre">
                cudaHostGetFlags()
            </span>
            , thus cannot know if the matrix is already partially pinned or not. This is especially true in
            multi-threaded application where memory could be partially or totally pinned or unpinned while another
            thread is accessing that memory.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the call has been successful
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the mode value is different from
                        <span class="pre">
                            CUBLASXT_PINNING_DISABLED
                        </span>
                        and
                        <span class="pre">
                            CUBLASXT_PINNING_ENABLED
                        </span>
                    </p>
                </td>
            </tr>
        </table>
        <h3>
            <span class="section-number">
                4.3.9.
            </span>
            cublasXtGetPinningMemMode()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxtgetpinningmemmode"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasXtGetPinningMemMode</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span><span class="n">cublasXtPinningMemMode_t</span><span class="o">*</span><span class="n">mode</span><span class="p">)</span>
</pre>
        <p>
            This function allows the user to query the Pinning Memory mode. By default, the Pinning Memory mode is
            disabled.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Return Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the call has been successful
                    </p>
                </td>
            </tr>
        </table>
        <h2>
            <span class="section-number">
                4.4.
            </span>
            cuBLASXt API Math Functions Reference
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-api-math-functions-reference"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            In this chapter we describe the actual Linear Agebra routines that cuBLASXt API supports. We will use
            abbreviations &lt;
            type
            &gt; for type and &lt;
            t
            &gt; for the corresponding short type to make a more concise and clear presentation of the implemented
            functions. Unless otherwise specified &lt;
            type
            &gt; and &lt;
            t
            &gt; have the following meanings:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        &lt;type&gt;
                    </p>
                </th>
                <th class="head">
                    <p>
                        &lt;t&gt;
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            float
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        s or S
                    </p>
                </td>
                <td>
                    <p>
                        real single-precision
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            double
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        d or D
                    </p>
                </td>
                <td>
                    <p>
                        real double-precision
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cuComplex
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        c or C
                    </p>
                </td>
                <td>
                    <p>
                        complex single-precision
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cuDoubleComplex
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        z or Z
                    </p>
                </td>
                <td>
                    <p>
                        complex double-precision
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The abbreviation
            <span class="math notranslate nohighlight">
                \(\mathbf{Re}(\cdot)\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{Im}(\cdot)\)
            </span>
            will stand for the real and imaginary part of a number, respectively. Since imaginary part of a real number
            does not exist, we will consider it to be zero and can usually simply discard it from the equation where it
            is being used. Also, the
            <span class="math notranslate nohighlight">
                \(\bar{\alpha}\)
            </span>
            will denote the complex conjugate of
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            .
        </p>
        <p>
            In general throughout the documentation, the lower case Greek symbols
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            will denote scalars, lower case English letters in bold type
            <span class="math notranslate nohighlight">
                \(\mathbf{x}\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\mathbf{y}\)
            </span>
            will denote vectors and capital English letters
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            will denote matrices.
        </p>
        <h3>
            <span class="section-number">
                4.4.1.
            </span>
            cublasXt&lt;t&gt;gemm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id96"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtSgemm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDgemm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCgemm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZgemm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">transa</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">transb</span><span class="p">,</span>
<span class="kt">int</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">int</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are matrices stored in column-major format with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times k\)
            </span>
            ,
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(k \times n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            is defined similarly for matrix
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        transa
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        transb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            B
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of op(
                        <span class="pre">
                            A
                        </span>
                        ) and rows of op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store the matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication. If
                        <span class="pre">
                            beta==0
                        </span>
                        ,
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of a two-dimensional array used to store the matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/sgemm.f">
                sgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dgemm.f">
                dgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/cgemm.f">
                cgemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zgemm.f">
                zgemm
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.2.
            </span>
            cublasXt&lt;t&gt;hemm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-hemm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtChemm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZhemm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the Hermitian matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha AB + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha BA + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a Hermitian matrix stored in lower or upper mode,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side==CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise. The imaginary parts of the diagonal elements are assumed to be zero.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/chemm.f">
                chemm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zhemm.f">
                zhemm
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.3.
            </span>
            cublasXt&lt;t&gt;symm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-symm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtSsymm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDsymm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCsymm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZsymm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the symmetric matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha AB + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha BA + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a symmetric matrix stored in lower or upper mode,
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            A
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssymm.f">
                ssymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsymm.f">
                dsymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csymm.f">
                csymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsymm.f">
                zsymm
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.4.
            </span>
            cublasXt&lt;t&gt;syrk()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-syrk"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtSsyrk</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDsyrk</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCsyrk</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZsyrk</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the symmetric rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{T} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            trans
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix A.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyrk.f">
                ssyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyrk.f">
                dsyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyrk.f">
                csyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyrk.f">
                zsyrk
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.5.
            </span>
            cublasXt&lt;t&gt;syr2k()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-syr2k"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtSsyr2k</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDsyr2k</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCsyr2k</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZsyr2k</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the symmetric rank-
            <span class="math notranslate nohighlight">
                \(2k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha(\text{op}(A)\text{op}(B)^{T} + \text{op}(B)\text{op}(A)^{T}) + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{T}\text{ and }B^{T}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part, is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        , then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyr2k.f">
                ssyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyr2k.f">
                dsyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyr2k.f">
                csyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyr2k.f">
                zsyr2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.6.
            </span>
            cublasXt&lt;t&gt;syrkx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-syrkx"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtSsyrkx</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDsyrkx</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCsyrkx</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZsyrkx</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs a variation of the symmetric rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha(\text{op}(A)\text{op}(B)^{T} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a symmetric matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{T}\text{ and }B^{T}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_T}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            This routine can be used when B is in such way that the result is guaranteed to be symmetric. An usual
            example is when the matrix B is a scaled form of the matrix A : this is equivalent to B being the product of
            the matrix A and a diagonal matrix.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part, is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        , then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimensions
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyrk.f">
                ssyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyrk.f">
                dsyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyrk.f">
                csyrk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyrk.f">
                zsyrk
            </a>
            and
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssyr2k.f">
                ssyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsyr2k.f">
                dsyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csyr2k.f">
                csyr2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsyr2k.f">
                zsyr2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.7.
            </span>
            cublasXt&lt;t&gt;herk()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-herk"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtCherk</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZherk</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">int</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">int</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(A)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a matrix with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            . Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cherk.f">
                cherk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zherk.f">
                zherk
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.8.
            </span>
            cublasXt&lt;t&gt;her2k()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-her2k"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtCher2k</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZher2k</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(2k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B)^{H} + \overset{}{\alpha}\text{op}(B)\text{op}(A)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{H}\text{ and }B^{H}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cher2k.f">
                cher2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zher2k.f">
                zher2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.9.
            </span>
            cublasXt&lt;t&gt;herkx()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-herkx"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtCherkx</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZherkx</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span><span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span><span class="kt">size_t</span><span class="n">k</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs a variation of the Hermitian rank-
            <span class="math notranslate nohighlight">
                \(k\)
            </span>
            update
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \alpha\text{op}(A)\text{op}(B)^{H} + \beta C\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars,
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            is a Hermitian matrix stored in lower or upper mode, and
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are matrices with dimensions
            <span class="math notranslate nohighlight">
                \(\text{op}(A)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\text{op}(B)\)
            </span>
            <span class="math notranslate nohighlight">
                \(n \times k\)
            </span>
            , respectively. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op(}A\text{) and op(}B\text{)} = \left\{ \begin{matrix}
                {A\text{ and }B} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_N}$}} \\
                {A^{H}\text{ and }B^{H}} &amp; {\text{if }\textsf{trans == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            This routine can be used when the matrix B is in such way that the result is guaranteed to be hermitian. An
            usual example is when the matrix B is a scaled form of the matrix A : this is equivalent to B being the
            product of the matrix A and a diagonal matrix. For an efficient computation of the product of a regular
            matrix with a diagonal matrix, refer to the routine
            <a class="reference external" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-dgmm">
                cublasXt&lt;t&gt;dgmm
            </a>
            .
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            C
                        </span>
                        lower or upper part is stored, the other Hermitian part is not referenced.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ), op(
                        <span class="pre">
                            B
                        </span>
                        ) and
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        k
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix op(
                        <span class="pre">
                            A
                        </span>
                        ) and op(
                        <span class="pre">
                            B
                        </span>
                        ).
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transa
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            k
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,n)
                        </span>
                        if
                        <span class="pre">
                            transb
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_OP_N
                        </span>
                        and
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,k)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        real scalar used for multiplication, if
                        <span class="pre">
                            beta==0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        , with
                        <span class="pre">
                            ldc&gt;=max(1,n)
                        </span>
                        . The imaginary parts of the diagonal elements are assumed and set to zero.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            n,k&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cherk.f">
                cherk
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zherk.f">
                zherk
            </a>
            and
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/cher2k.f">
                cher2k
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zher2k.f">
                zher2k
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.10.
            </span>
            cublasXt&lt;t&gt;trsm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-trsm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtStrsm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasXtDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDtrsm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasXtDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCtrsm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasXtDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZtrsm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasXtDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">)</span>
</pre>
        <p>
            This function solves the triangular linear system with multiple right-hand-sides
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\left\{ \begin{matrix}
                {\text{op}(A)X = \alpha B} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {X\text{op}(A) = \alpha B} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal,
            <span class="math notranslate nohighlight">
                \(X\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            The solution
            <span class="math notranslate nohighlight">
                \(X\)
            </span>
            overwrites the right-hand-sides
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            on exit.
        </p>
        <p>
            No test for singularity or near-singularity is included in this function.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            X
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        is sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            alpha==0
                        </span>
                        then
                        <span class="pre">
                            A
                        </span>
                        is not referenced and
                        <span class="pre">
                            B
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array. It has dimensions
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strsm.f">
                strsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrsm.f">
                dtrsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrsm.f">
                ctrsm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrsm.f">
                ztrsm
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.11.
            </span>
            cublasXt&lt;t&gt;trmm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-trmm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="n">cublasXtStrmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtDtrmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtCtrmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
<span class="n">cublasStatus_t</span><span class="n">cublasXtZtrmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span><span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="n">cublasOperation_t</span><span class="n">trans</span><span class="p">,</span><span class="n">cublasDiagType_t</span><span class="n">diag</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span><span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="kt">size_t</span><span class="n">lda</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="kt">size_t</span><span class="n">ldc</span><span class="p">)</span>
</pre>
        <p>
            This function performs the triangular matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha\text{op}(A)B} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha B\text{op}(A)} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a triangular matrix stored in lower or upper mode with or without the main diagonal,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrix, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            is a scalar. Also, for matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(\text{op}(A) = \left\{ \begin{matrix}
                A &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_N}$}} \\
                A^{T} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_T}$}} \\
                A^{H} &amp; {\text{if }\textsf{transa == $\mathrm{CUBLAS\_OP\_C}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            Notice that in order to achieve better parallelism, similarly to the cublas API, cuBLASXt API differs from
            the BLAS API for this routine. The BLAS API assumes an in-place implementation (with results written back to
            B), while the cuBLASXt API assumes an out-of-place implementation (with results written into C). The
            application can still obtain the in-place functionality of BLAS in the cuBLASXt API by passing the address
            of the matrix B in place of the matrix C. No other overlapping in the input parameters is supported.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other part is not referenced and is inferred from the stored
                        elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        trans
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        operation op(
                        <span class="pre">
                            A
                        </span>
                        ) that is non- or (conj.) transpose.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        diag
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if the elements on the main diagonal of matrix
                        <span class="pre">
                            A
                        </span>
                        are unity and should not be accessed.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            alpha==0
                        </span>
                        then
                        <span class="pre">
                            A
                        </span>
                        is not referenced and
                        <span class="pre">
                            B
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        A
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            m
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,m)
                        </span>
                        if
                        <span class="pre">
                            side
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            CUBLAS_SIDE_LEFT
                        </span>
                        and
                        <span class="pre">
                            lda
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            lda&gt;=max(1,n)
                        </span>
                        otherwise.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        lda
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            A
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/strmm.f">
                strmm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dtrmm.f">
                dtrmm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ctrmm.f">
                ctrmm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/ztrmm.f">
                ztrmm
            </a>
        </p>
        <h3>
            <span class="section-number">
                4.4.12.
            </span>
            cublasXt&lt;t&gt;spmm()
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasxt-t-spmm"
                title="Permalink to this headline">
                
            </a>
        </h3>
        <pre><span class="n">cublasStatus_t</span><span class="nf">cublasXtSspmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">float</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">float</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldc</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasXtDspmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="kt">double</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="kt">double</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldc</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasXtCspmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldc</span><span class="p">);</span>

<span class="n">cublasStatus_t</span><span class="nf">cublasXtZspmm</span><span class="p">(</span><span class="n">cublasXtHandle_t</span><span class="n">handle</span><span class="p">,</span>
<span class="n">cublasSideMode_t</span><span class="n">side</span><span class="p">,</span>
<span class="n">cublasFillMode_t</span><span class="n">uplo</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">m</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">n</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">alpha</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">AP</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">B</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldb</span><span class="p">,</span>
<span class="k">const</span><span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">beta</span><span class="p">,</span>
<span class="n">cuDoubleComplex</span><span class="o">*</span><span class="n">C</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">ldc</span><span class="p">);</span>
</pre>
        <p>
            This function performs the symmetric packed matrix-matrix multiplication
        </p>
        <p>
            <span class="math notranslate nohighlight">
                \(C = \left\{ \begin{matrix}
                {\alpha AB + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_LEFT}$}} \\
                {\alpha BA + \beta C} &amp; {\text{if }\textsf{side == $\mathrm{CUBLAS\_SIDE\_RIGHT}$}} \\
                \end{matrix} \right.\)
            </span>
        </p>
        <p>
            where
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            is a
            <span class="math notranslate nohighlight">
                \(n \times n\)
            </span>
            symmetric matrix stored in packed format,
            <span class="math notranslate nohighlight">
                \(B\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(C\)
            </span>
            are
            <span class="math notranslate nohighlight">
                \(m \times n\)
            </span>
            matrices, and
            <span class="math notranslate nohighlight">
                \(\alpha\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(\beta\)
            </span>
            are scalars.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_LOWER
            </span>
            then the elements in the lower triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+((2*n-j+1)*j)/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \geq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p>
            If
            <span class="pre">
                uplo
            </span>
            <span class="pre">
                ==
            </span>
            <span class="pre">
                CUBLAS_FILL_MODE_UPPER
            </span>
            then the elements in the upper triangular part of the symmetric matrix
            <span class="math notranslate nohighlight">
                \(A\)
            </span>
            are packed together column by column without gaps, so that the element
            <span class="math notranslate nohighlight">
                \(A(i,j)\)
            </span>
            is stored in the memory location
            <span class="pre">
                AP[i+(j*(j+1))/2]
            </span>
            for
            <span class="math notranslate nohighlight">
                \(j = 1,\ldots,n\)
            </span>
            and
            <span class="math notranslate nohighlight">
                \(i \leq j\)
            </span>
            . Consequently, the packed format requires only
            <span class="math notranslate nohighlight">
                \(\frac{n(n + 1)}{2}\)
            </span>
            elements for storage.
        </p>
        <p class="admonition-title">
            Note
        </p>
        <p>
            The packed matrix AP must be located on the host or managed memory whereas the other matrices can be located
            on the host or any GPU device
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Param.
                    </p>
                </th>
                <th class="head">
                    <p>
                        Memory
                    </p>
                </th>
                <th class="head">
                    <p>
                        In/out
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        handle
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        handle to the cuBLASXt API context.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        side
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        is on the left or right of
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        uplo
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        indicates if matrix
                        <span class="pre">
                            A
                        </span>
                        lower or upper part is stored, the other symmetric part is not referenced and is inferred from
                        the stored elements.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        m
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of rows of matrix
                        <span class="pre">
                            A
                        </span>
                        and
                        <span class="pre">
                            B
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        n
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        number of columns of matrix
                        <span class="pre">
                            C
                        </span>
                        and
                        <span class="pre">
                            A
                        </span>
                        , with matrix
                        <span class="pre">
                            A
                        </span>
                        sized accordingly.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        alpha
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        AP
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array with
                        <span class="math notranslate nohighlight">
                            \(A\)
                        </span>
                        stored in packed format.
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        B
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldb
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldb&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        ldb
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            B
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        beta
                    </p>
                </td>
                <td>
                    <p>
                        host
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; scalar used for multiplication, if
                        <span class="pre">
                            beta
                        </span>
                        <span class="pre">
                            ==
                        </span>
                        <span class="pre">
                            0
                        </span>
                        then
                        <span class="pre">
                            C
                        </span>
                        does not have to be a valid input.
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        C
                    </p>
                </td>
                <td>
                    <p>
                        host or device
                    </p>
                </td>
                <td>
                    <p>
                        in/out
                    </p>
                </td>
                <td>
                    <p>
                        &lt;type&gt; array of dimension
                        <span class="pre">
                            ldc
                        </span>
                        <span class="pre">
                            x
                        </span>
                        <span class="pre">
                            n
                        </span>
                        with
                        <span class="pre">
                            ldc&gt;=max(1,m)
                        </span>
                        .
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        ldc
                    </p>
                </td>
                <td>
                    <p>
                        input
                    </p>
                </td>
                <td>
                    <p>
                        leading dimension of two-dimensional array used to store matrix
                        <span class="pre">
                            C
                        </span>
                        .
                    </p>
                </td>
            </tr>
        </table>
        <p>
            The possible error values returned by this function and their meanings are listed below.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Error Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the parameters
                        <span class="pre">
                            m,n&lt;0
                        </span>
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the matrix AP is located on a GPU device
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the function failed to launch on the GPU
                    </p>
                </td>
            </tr>
        </table>
        <p>
            For references please refer to:
        </p>
        <p>
            <a class="reference external" href="http://www.netlib.org/blas/ssymm.f">
                ssymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/dsymm.f">
                dsymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/csymm.f">
                csymm
            </a>
            ,
            <a class="reference external" href="http://www.netlib.org/blas/zsymm.f">
                zsymm
            </a>
        </p>
        <h1>
            <span class="section-number">
                5.
            </span>
            Using the cuBLASDx API
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublasdx-api"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <p>
            The cuBLASDx library (preview) is a device side API extension for performing BLAS calculations inside CUDA
            kernels.
            By fusing numerical operations you can decrease latency and further improve performance of your
            applications.
        </p>
        <ul class="simple">
            <li>
                <p>
                    You can access cuBLASDx documentation
                    <a class="reference external" href="https://docs.nvidia.com/cuda/cublasdx">
                        here
                    </a>
                    .
                </p>
            </li>
            <li>
                <p>
                    cuBLASDx is not a part of the CUDA Toolkit. You can download cuBLASDx separately from
                    <a class="reference external" href="https://developer.nvidia.com/cublasdx-downloads">
                        here
                    </a>
                    .
                </p>
            </li>
        </ul>
        <h1>
            <span class="section-number">
                6.
            </span>
            Using the cuBLAS Legacy API
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#using-the-cublas-legacy-api"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <p>
            This section does not provide a full reference of each Legacy API datatype and entry point. Instead, it
            describes how to use the API, especially where this is different from the regular cuBLAS API.
        </p>
        <p>
            Note that in this section, all references to the cuBLAS Library refer to the Legacy cuBLAS API only.
        </p>
        <p class="admonition-title">
            Warning
        </p>
        <p>
            The legacy cuBLAS API is deprecated and will be removed in future release.
        </p>
        <h2>
            <span class="section-number">
                6.1.
            </span>
            Error Status
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id99"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The
            <span class="pre">
                cublasStatus
            </span>
            type is used for function status returns. The cuBLAS Library helper functions return status directly, while
            the status of core functions can be retrieved using
            <span class="pre">
                cublasGetError()
            </span>
            . Notice that reading the error status via
            <span class="pre">
                cublasGetError()
            </span>
            , resets the internal error state to
            <span class="pre">
                CUBLAS_STATUS_SUCCESS
            </span>
            . Currently, the following values for are defined:
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Value
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_SUCCESS
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the operation completed successfully
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_INITIALIZED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the library was not initialized
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ALLOC_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the resource allocation failed
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INVALID_VALUE
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        an invalid numerical value was used as an argument
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_ARCH_MISMATCH
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        an absent device architectural feature is required
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_MAPPING_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        an access to GPU memory space failed
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_EXECUTION_FAILED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the GPU program failed to execute
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_INTERNAL_ERROR
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        an internal operation failed
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            CUBLAS_STATUS_NOT_SUPPORTED
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        the feature required is not supported
                    </p>
                </td>
            </tr>
        </table>
        <p>
            This legacy type corresponds to type
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                cublasStatus_t
            </a>
            in the cuBLAS library API.
        </p>
        <h2>
            <span class="section-number">
                6.2.
            </span>
            Initialization and Shutdown
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#initialization-and-shutdown"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The functions
            <span class="pre">
                cublasInit()
            </span>
            and
            <span class="pre">
                cublasShutdown()
            </span>
            are used to initialize and shutdown the cuBLAS library. It is recommended for
            <span class="pre">
                cublasInit()
            </span>
            to be called before any other function is invoked. It allocates hardware resources on the GPU device that is
            currently bound to the host thread from which it was invoked.
        </p>
        <p>
            The legacy initialization and shutdown functions are similar to the cuBLAS library API routines
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                cublasCreate()
            </a>
            and
            <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                cublasDestroy()
            </a>
            .
        </p>
        <h2>
            <span class="section-number">
                6.3.
            </span>
            Thread Safety
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id100"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The legacy API is not thread safe when used with multiple host threads and devices. It is recommended to be
            used only when utmost compatibility with Fortran is required and when a single host thread is used to setup
            the library and make all the functions calls.
        </p>
        <h2>
            <span class="section-number">
                6.4.
            </span>
            Memory Management
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#memory-management"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The memory used by the legacy cuBLAS library API is allocated and released using functions
            <span class="pre">
                cublasAlloc()
            </span>
            and
            <span class="pre">
                cublasFree()
            </span>
            , respectively. These functions create and destroy an object in the GPU memory space capable of holding an
            array of
            <span class="pre">
                n
            </span>
            elements, where each element requires
            <span class="pre">
                elemSize
            </span>
            bytes of storage. Please see the legacy cuBLAS API header file cublas.h for the prototypes of these
            functions.
        </p>
        <p>
            The function
            <span class="pre">
                cublasAlloc()
            </span>
            is a wrapper around the function
            <span class="pre">
                cudaMalloc()
            </span>
            , therefore device pointers returned by
            <span class="pre">
                cublasAlloc()
            </span>
            can be passed to any CUDA device kernel functions. However, these device pointers can not be dereferenced
            in the host code. The function
            <span class="pre">
                cublasFree()
            </span>
            is a wrapper around the function
            <span class="pre">
                cudaFree()
            </span>
            .
        </p>
        <h2>
            <span class="section-number">
                6.5.
            </span>
            Scalar Parameters
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#id101"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            In the legacy cuBLAS API, scalar parameters are passed by value from the host. Also, the few functions that
            do return a scalar result, such as dot() and nrm2(), return the resulting value on the host, and hence these
            routines will wait for kernel execution on the device to complete before returning, which makes parallelism
            with streams impractical. However, the majority of functions do not return any value, in order to be more
            compatible with Fortran and the existing BLAS libraries.
        </p>
        <h2>
            <span class="section-number">
                6.6.
            </span>
            Helper Functions
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#helper-functions"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            In this section we list the helper functions provided by the legacy cuBLAS API and their functionality. For
            the exact prototypes of these functions please refer to the legacy cuBLAS API header file cublas.h.
        </p>
        <table class="table-no-stripes docutils align-default">
            <tr class="row-odd">
                <th class="head">
                    <p>
                        Helper function
                    </p>
                </th>
                <th class="head">
                    <p>
                        Meaning
                    </p>
                </th>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasInit()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        initialize the library
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasShutdown()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        shuts down the library
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasGetError()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        retrieves the error status of the library
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasSetKernelStream()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        sets the stream to be used by the library
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasAlloc()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        allocates the device memory for the library
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasFree()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        releases the device memory allocated for the library
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasSetVector()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        copies a vector
                        <span class="pre">
                            x
                        </span>
                        on the host to a vector on the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasGetVector()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        copies a vector
                        <span class="pre">
                            x
                        </span>
                        on the GPU to a vector on the host
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasSetMatrix()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        copies a
                        <span class="math notranslate nohighlight">
                            \(m \times n\)
                        </span>
                        tile from a matrix on the host to the GPU
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasGetMatrix()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        copies a
                        <span class="math notranslate nohighlight">
                            \(m \times n\)
                        </span>
                        tile from a matrix on the GPU to the host
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasSetVectorAsync()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        similar to
                        <span class="pre">
                            cublasSetVector()
                        </span>
                        , but the copy is asynchronous
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasGetVectorAsync()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        similar to
                        <span class="pre">
                            cublasGetVector()
                        </span>
                        , but the copy is asynchronous
                    </p>
                </td>
            </tr>
            <tr class="row-even">
                <td>
                    <p>
                        <span class="pre">
                            cublasSetMatrixAsync()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        similar to
                        <span class="pre">
                            cublasSetMatrix()
                        </span>
                        , but the copy is asynchronous
                    </p>
                </td>
            </tr>
            <tr class="row-odd">
                <td>
                    <p>
                        <span class="pre">
                            cublasGetMatrixAsync()
                        </span>
                    </p>
                </td>
                <td>
                    <p>
                        similar to
                        <span class="pre">
                            cublasGetMatrix()
                        </span>
                        , but the copy is asynchronous
                    </p>
                </td>
            </tr>
        </table>
        <h2>
            <span class="section-number">
                6.7.
            </span>
            Level-1,2,3 Functions
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#level-1-2-3-functions"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            The Level-1,2,3 cuBLAS functions (also called core functions) have the same name and behavior as the ones
            listed in the chapters 3, 4 and 5 in this document. Please refer to the legacy cuBLAS API header file
            cublas.h for their exact prototype. Also, the next section talks a bit more about the differences
            between the legacy and the cuBLAS API prototypes, more specifically how to convert the function calls from
            one API to another.
        </p>
        <h2>
            <span class="section-number">
                6.8.
            </span>
            Converting Legacy to the cuBLAS API
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#converting-legacy-to-the-cublas-api"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            There are a few general rules that can be used to convert from legacy to the cuBLAS API:
        </p>
        <ul class="simple">
            <li>
                <p>
                    Exchange the header file cublas.h for cublas_v2.h.
                </p>
            </li>
            <li>
                <p>
                    Exchange the type
                    <span class="pre">
                        cublasStatus
                    </span>
                    for
                    <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus-t">
                        cublasStatus_t
                    </a>
                    .
                </p>
            </li>
            <li>
                <p>
                    Exchange the function
                    <span class="pre">
                        cublasSetKernelStream()
                    </span>
                    for
                    <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublassetstream">
                        cublasSetStream()
                    </a>
                    .
                </p>
            </li>
            <li>
                <p>
                    Exchange the function
                    <span class="pre">
                        cublasAlloc()
                    </span>
                    and
                    <span class="pre">
                        cublasFree()
                    </span>
                    for
                    <span class="pre">
                        cudaMalloc()
                    </span>
                    and
                    <span class="pre">
                        cudaFree()
                    </span>
                    , respectively. Notice that
                    <span class="pre">
                        cudaMalloc()
                    </span>
                    expects the size of the allocated memory to be provided in bytes (usually simply provide
                    <span class="pre">
                        n
                    </span>
                    <span class="pre">
                        x
                    </span>
                    <span class="pre">
                        elemSize
                    </span>
                    to allocate
                    <span class="pre">
                        n
                    </span>
                    elements, each of size
                    <span class="pre">
                        elemSize
                    </span>
                    bytes).
                </p>
            </li>
            <li>
                <p>
                    Declare the
                    <span class="pre">
                        cublasHandle_t
                    </span>
                    cuBLAS library handle.
                </p>
            </li>
            <li>
                <p>
                    Initialize the handle using
                    <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublascreate">
                        cublasCreate()
                    </a>
                    . Also, release the handle once finished using
                    <a class="reference internal" href="https://docs.nvidia.com/cuda/cublas/index.html#cublasdestroy">
                        cublasDestroy()
                    </a>
                    .
                </p>
            </li>
            <li>
                <p>
                    Add the handle as the first parameter to all the cuBLAS library function calls.
                </p>
            </li>
            <li>
                <p>
                    Change the scalar parameters to be passed by reference, instead of by value (usually simply adding
                    &amp; symbol in C/C++ is enough, because the parameters are passed by reference on the host by
                    default
                    ). However, note that if the routine is running asynchronously, then the variable holding the scalar
                    parameter cannot be changed until the kernels that the routine dispatches are completed. See the
                    CUDA C++ Programming Guide for a detailed discussion of how to use streams.
                </p>
            </li>
            <li>
                <p>
                    Change the parameter characters
                    <span class="pre">
                        N
                    </span>
                    or
                    <span class="pre">
                        n
                    </span>
                    (non-transpose operation),
                    <span class="pre">
                        T
                    </span>
                    or
                    <span class="pre">
                        t
                    </span>
                    (transpose operation) and
                    <span class="pre">
                        C
                    </span>
                    or
                    <span class="pre">
                        c
                    </span>
                    (conjugate transpose operation) to
                    <span class="pre">
                        CUBLAS_OP_N
                    </span>
                    ,
                    <span class="pre">
                        CUBLAS_OP_T
                    </span>
                    and
                    <span class="pre">
                        CUBLAS_OP_C
                    </span>
                    , respectively.
                </p>
            </li>
            <li>
                <p>
                    Change the parameter characters
                    <span class="pre">
                        L
                    </span>
                    or
                    <span class="pre">
                        l
                    </span>
                    (lower part filled) and
                    <span class="pre">
                        U
                    </span>
                    or
                    <span class="pre">
                        u
                    </span>
                    (upper part filled) to
                    <span class="pre">
                        CUBLAS_FILL_MODE_LOWER
                    </span>
                    and
                    <span class="pre">
                        CUBLAS_FILL_MODE_UPPER
                    </span>
                    , respectively.
                </p>
            </li>
            <li>
                <p>
                    Change the parameter characters
                    <span class="pre">
                        N
                    </span>
                    or
                    <span class="pre">
                        n
                    </span>
                    (non-unit diagonal) and
                    <span class="pre">
                        U
                    </span>
                    or
                    <span class="pre">
                        u
                    </span>
                    (unit diagonal) to
                    <span class="pre">
                        CUBLAS_DIAG_NON_UNIT
                    </span>
                    and
                    <span class="pre">
                        CUBLAS_DIAG_UNIT
                    </span>
                    , respectively.
                </p>
            </li>
            <li>
                <p>
                    Change the parameter characters
                    <span class="pre">
                        L
                    </span>
                    or
                    <span class="pre">
                        l
                    </span>
                    (left side) and
                    <span class="pre">
                        R
                    </span>
                    or
                    <span class="pre">
                        r
                    </span>
                    (right side) to
                    <span class="pre">
                        CUBLAS_SIDE_LEFT
                    </span>
                    and
                    <span class="pre">
                        CUBLAS_SIDE_RIGHT
                    </span>
                    , respectively.
                </p>
            </li>
            <li>
                <p>
                    If the legacy API function returns a scalar value, add an extra scalar parameter of the same type
                    passed by reference, as the last parameter to the same function.
                </p>
            </li>
            <li>
                <p>
                    Instead of using
                    <span class="pre">
                        cublasGetError()
                    </span>
                    , use the return value of the function itself to check for errors.
                </p>
            </li>
            <li>
                <p>
                    Finally, please use the function prototypes in the header files
                    <span class="pre">
                        cublas.h
                    </span>
                    and
                    <span class="pre">
                        cublas_v2.h
                    </span>
                    to check the code for correctness.
                </p>
            </li>
        </ul>
        <h2>
            <span class="section-number">
                6.9.
            </span>
            Examples
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#examples"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            For sample code references that use the legacy cuBLAS API please see the two examples below. They show an
            application written in C using the legacy cuBLAS library API with two indexing styles (Example A.1.
            Application Using C and cuBLAS: 1-based indexing and Example A.2. Application Using C and cuBLAS:
            0-based Indexing). This application is analogous to the one using the cuBLAS library API that is shown in
            the Introduction chapter.
        </p>
        <p>
            Example A.1. Application Using C and cuBLAS: 1-based indexing
        </p>
        <pre><span class="c1">//-----------------------------------------------------------</span>
<span class="cp">#include</span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="cpf">"cublas.h"</span>
<span class="cp">#define M 6</span>
<span class="cp">#define N 5</span>
<span class="cp">#define IDX2F(i,j,ld) ((((j)-1)*(ld))+((i)-1))</span>

<span class="k">static</span><span class="n">__inline__</span><span class="kt">void</span><span class="n">modify</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">ldm</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">p</span><span class="p">,</span><span class="kt">int</span><span class="n">q</span><span class="p">,</span><span class="kt">float</span><span class="n">alpha</span><span class="p">,</span><span class="kt">float</span><span class="n">beta</span><span class="p">){</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">q</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="n">ldm</span><span class="p">);</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">ldm</span><span class="o">-</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">beta</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="kt">int</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">;</span>
<span class="n">cublasStatus</span><span class="n">stat</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">devPtrA</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="n">a</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">));</span>
<span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">a</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"host memory allocation failed"</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;=</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">a</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="p">)((</span><span class="n">i</span><span class="mi">-1</span><span class="p">)</span><span class="o">*</span><span class="n">M</span><span class="o">+</span><span class="n">j</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
<span class="n">cublasInit</span><span class="p">();</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasAlloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="p">(</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">cuBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"device memory allocation failed"</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasSetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">cuBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data download failed"</span><span class="p">);</span>
<span class="n">cublasFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">modify</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mf">16.0f</span><span class="p">,</span><span class="mf">12.0f</span><span class="p">);</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasGetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">cuBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data upload failed"</span><span class="p">);</span>
<span class="n">cublasFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">cublasFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;=</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;=</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"%7.0f"</span><span class="p">,</span><span class="n">a</span><span class="p">[</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]);</span>
<span class="p">}</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre>
        <p>
            Example A.2. Application Using C and cuBLAS: 0-based indexing
        </p>
        <pre><span class="c1">//-----------------------------------------------------------</span>
<span class="cp">#include</span><span class="cpf">&lt;stdio.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;stdlib.h&gt;</span>
<span class="cp">#include</span><span class="cpf">&lt;math.h&gt;</span>
<span class="cp">#include</span><span class="cpf">"cublas.h"</span>
<span class="cp">#define M 6</span>
<span class="cp">#define N 5</span>
<span class="cp">#define IDX2C(i,j,ld) (((j)*(ld))+(i))</span>

<span class="k">static</span><span class="n">__inline__</span><span class="kt">void</span><span class="n">modify</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="n">m</span><span class="p">,</span><span class="kt">int</span><span class="n">ldm</span><span class="p">,</span><span class="kt">int</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="n">p</span><span class="p">,</span><span class="kt">int</span><span class="n">q</span><span class="p">,</span><span class="kt">float</span><span class="n">alpha</span><span class="p">,</span><span class="kt">float</span><span class="n">beta</span><span class="p">){</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">q</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="n">ldm</span><span class="p">);</span>
<span class="n">cublasSscal</span><span class="p">(</span><span class="n">ldm</span><span class="o">-</span><span class="n">p</span><span class="p">,</span><span class="n">beta</span><span class="p">,</span><span class="o">&amp;</span><span class="n">m</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)],</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span><span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">){</span>
<span class="kt">int</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">;</span>
<span class="n">cublasStatus</span><span class="n">stat</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">devPtrA</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span><span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>
<span class="n">a</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">));</span>
<span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">a</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"host memory allocation failed"</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">a</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]</span><span class="o">=</span><span class="p">(</span><span class="kt">float</span><span class="p">)(</span><span class="n">i</span><span class="o">*</span><span class="n">M</span><span class="o">+</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span>
<span class="n">cublasInit</span><span class="p">();</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasAlloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="p">(</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">cuBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"device memory allocation failed"</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasSetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">cuBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data download failed"</span><span class="p">);</span>
<span class="n">cublasFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">modify</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">16.0f</span><span class="p">,</span><span class="mf">12.0f</span><span class="p">);</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublasGetMatrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">),</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">cuBLAS_STATUS_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"data upload failed"</span><span class="p">);</span>
<span class="n">cublasFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">return</span><span class="n">EXIT_FAILURE</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">cublasFree</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">);</span>
<span class="n">cublasShutdown</span><span class="p">();</span>
<span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">j</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">M</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"%7.0f"</span><span class="p">,</span><span class="n">a</span><span class="p">[</span><span class="n">IDX2C</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">M</span><span class="p">)]);</span>
<span class="p">}</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">free</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="k">return</span><span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre>
        <h1>
            <span class="section-number">
                7.
            </span>
            cuBLAS Fortran Bindings
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#cublas-fortran-bindings"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <p>
            The cuBLAS library is implemented using the C-based CUDA toolchain. Thus, it provides a C-style API. This
            makes interfacing to applications written in C and C++ trivial, but the library can also be used by
            applications written in Fortran. In particular, the cuBLAS library uses 1-based indexing and Fortran-style
            column-major storage for multidimensional data to simplify interfacing to Fortran applications.
            Unfortunately, Fortran-to-C calling conventions are not standardized and differ by platform and toolchain.
            In particular, differences may exist in the following areas:
        </p>
        <ul class="simple">
            <li>
                <p>
                    symbol names (capitalization, name decoration)
                </p>
            </li>
            <li>
                <p>
                    argument passing (by value or reference)
                </p>
            </li>
            <li>
                <p>
                    passing of string arguments (length information)
                </p>
            </li>
            <li>
                <p>
                    passing of pointer arguments (size of the pointer)
                </p>
            </li>
            <li>
                <p>
                    returning floating-point or compound data types (for example single-precision or complex data types)
                </p>
            </li>
        </ul>
        <p>
            To provide maximum flexibility in addressing those differences, the cuBLAS Fortran interface is provided in
            the form of wrapper functions and is part of the Toolkit delivery. The C source code of those wrapper
            functions is located in the
            <span class="pre">
                src
            </span>
            directory and provided in two different forms:
        </p>
        <ul class="simple">
            <li>
                <p>
                    the thunking wrapper interface located in the file
                    <span class="pre">
                        fortran_thunking.c
                    </span>
                </p>
            </li>
            <li>
                <p>
                    the direct wrapper interface located in the file
                    <span class="pre">
                        fortran.c
                    </span>
                </p>
            </li>
        </ul>
        <p>
            The code of one of those two files needs to be compiled into an application for it to call the cuBLAS API
            functions. Providing source code allows users to make any changes necessary for a particular platform and
            toolchain.
        </p>
        <p>
            The code in those two C files has been used to demonstrate interoperability with the compilers g77 3.2.3 and
            g95 0.91 on 32-bit Linux, g77 3.4.5 and g95 0.91 on 64-bit Linux, Intel Fortran 9.0 and Intel Fortran 10.0
            on 32-bit and 64-bit Microsoft Windows XP, and g77 3.4.0 and g95 0.92 on Mac OS X.
        </p>
        <p>
            Note that for g77, use of the compiler flag
            <span class="pre">
                -fno-second-underscore
            </span>
            is required to use these wrappers as provided. Also, the use of the default calling conventions with regard
            to argument and return value passing is expected. Using the flag -fno-f2c changes the default calling
            convention with respect to these two items.
        </p>
        <p>
            The thunking wrappers allow interfacing to existing Fortran applications without any changes to the
            application. During each call, the wrappers allocate GPU memory, copy source data from CPU memory space to
            GPU memory space, call cuBLAS, and finally copy back the results to CPU memory space and deallocate the GPU
            memory. As this process causes very significant call overhead, these wrappers are intended for light
            testing, not for production code. To use the thunking wrappers, the application needs to be compiled with
            the file
            <span class="pre">
                fortran_thunking.c
            </span>
            .
        </p>
        <p>
            The direct wrappers, intended for production code, substitute device pointers for vector and matrix
            arguments in all BLAS functions. To use these interfaces, existing applications need to be modified slightly
            to allocate and deallocate data structures in GPU memory space (using
            <span class="pre">
                cuBLAS_ALLOC
            </span>
            and
            <span class="pre">
                cuBLAS_FREE
            </span>
            ) and to copy data between GPU and CPU memory spaces (using
            <span class="pre">
                cuBLAS_SET_VECTOR
            </span>
            ,
            <span class="pre">
                cuBLAS_GET_VECTOR
            </span>
            ,
            <span class="pre">
                cuBLAS_SET_MATRIX
            </span>
            , and
            <span class="pre">
                cuBLAS_GET_MATRIX
            </span>
            ). The sample wrappers provided in
            <span class="pre">
                fortran.c
            </span>
            map device pointers to the OS-dependent type
            <span class="pre">
                size_t
            </span>
            , which is 32-bit wide on 32-bit platforms and 64-bit wide on a 64-bit platforms.
        </p>
        <p>
            One approach to deal with index arithmetic on device pointers in Fortran code is to use C-style macros, and
            use the C preprocessor to expand these, as shown in the example below. On Linux and Mac OS X, one way of
            pre-processing is to use the option
            <span class="pre">
                -E
            </span>
            <span class="pre">
                -x
            </span>
            <span class="pre">
                f77-cpp-input
            </span>
            when using g77 compiler, or simply the option
            <span class="pre">
                -cpp
            </span>
            when using g95 or gfortran. On Windows platforms with Microsoft Visual C/C++, using cl -EP achieves
            similar results.
        </p>
        <pre><span class="c">! Example B.1. Fortran 77 Application Executing on the Host</span>
<span class="c">! ----------------------------------------------------------</span>
<span class="k">subroutine </span><span class="n">modify</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">ldm</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">beta</span><span class="p">)</span>
<span class="k">implicit none</span>
<span class="kt">integer </span><span class="n">ldm</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">q</span>
<span class="kt">real</span><span class="o">*</span><span class="mi">4</span><span class="n">m</span><span class="p">(</span><span class="n">ldm</span><span class="p">,</span><span class="o">*</span><span class="p">)</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">beta</span>
<span class="k">external </span><span class="n">cublas_sscal</span>
<span class="k">call </span><span class="n">cublas_sscal</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">m</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">),</span><span class="n">ldm</span><span class="p">)</span>
<span class="k">call </span><span class="n">cublas_sscal</span><span class="p">(</span><span class="n">ldm</span><span class="o">-</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">beta</span><span class="p">,</span><span class="n">m</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
<span class="k">return</span>
<span class="k">    end</span>

<span class="k">    program </span><span class="n">matrixmod</span>
<span class="k">implicit none</span>
<span class="kt">integer </span><span class="n">M</span><span class="p">,</span><span class="n">N</span>
<span class="k">parameter</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="kt">real</span><span class="o">*</span><span class="mi">4</span><span class="n">a</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="kt">integer </span><span class="n">i</span><span class="p">,</span><span class="n">j</span>
<span class="k">external </span><span class="n">cublas_init</span>
<span class="k">external </span><span class="n">cublas_shutdown</span>

<span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span>
<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span>
<span class="n">a</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span><span class="o">=</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">M</span><span class="o">+</span><span class="n">j</span>
<span class="k">enddo</span>
<span class="k">    enddo</span>
<span class="k">    call </span><span class="n">cublas_init</span>
<span class="k">call </span><span class="n">modify</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="mf">6.0</span><span class="p">,</span><span class="mi">1</span><span class="mf">2.0</span><span class="p">)</span>
<span class="k">call </span><span class="n">cublas_shutdown</span>
<span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span>
<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span>
<span class="k">write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="s2">"(F7.0$)"</span><span class="p">)</span><span class="n">a</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
<span class="k">enddo</span>
<span class="k">        write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="o">*</span><span class="p">)</span><span class="s2">""</span>
<span class="k">enddo</span>
<span class="k">    stop</span>
<span class="k">    end</span>
</pre>
        <p>
            When traditional fixed-form Fortran 77 code is ported to use the cuBLAS library, line length often increases
            when the BLAS calls are exchanged for cuBLAS calls. Longer function names and possible macro expansion are
            contributing factors. Inadvertently exceeding the maximum line length can lead to run-time errors that are
            difficult to find, so care should be taken not to exceed the 72-column limit if fixed form is retained.
        </p>
        <p>
            The examples in this chapter show a small application implemented in Fortran 77 on the host and the same
            application with the non-thunking wrappers after it has been ported to use the cuBLAS library.
        </p>
        <p>
            The second example should be compiled with ARCH_64 defined as 1 on 64-bit OS system and as 0 on 32-bit OS
            system. For example for g95 or gfortran, this can be done directly on the command line by using the option
            <span class="pre">
                -cpp
            </span>
            <span class="pre">
                -DARCH_64=1
            </span>
            .
        </p>
        <pre><span class="c">! Example B.2. Same Application Using Non-thunking cuBLAS Calls</span>
<span class="c">!-------------------------------------------------------------</span>
<span class="cp">#define IDX2F (i,j,ld) ((((j)-1)*(ld))+((i)-1))</span>
<span class="k">subroutine </span><span class="n">modify</span><span class="p">(</span><span class="n">devPtrM</span><span class="p">,</span><span class="n">ldm</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span><span class="n">beta</span><span class="p">)</span>
<span class="k">implicit none</span>
<span class="kt">integer </span><span class="n">sizeof_real</span>
<span class="k">parameter</span><span class="p">(</span><span class="n">sizeof_real</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="kt">integer </span><span class="n">ldm</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">q</span>
<span class="cp">#if ARCH_64</span>
<span class="kt">integer</span><span class="o">*</span><span class="mi">8</span><span class="n">devPtrM</span>
<span class="cp">#else</span>
<span class="kt">integer</span><span class="o">*</span><span class="mi">4</span><span class="n">devPtrM</span>
<span class="cp">#endif</span>
<span class="kt">real</span><span class="o">*</span><span class="mi">4</span><span class="n">alpha</span><span class="p">,</span><span class="n">beta</span>
<span class="k">call </span><span class="n">cublas_sscal</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">alpha</span><span class="p">,</span>
<span class="mi">1</span><span class="n">devPtrM</span><span class="o">+</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)</span><span class="o">*</span><span class="n">sizeof_real</span><span class="p">,</span>
<span class="mi">2</span><span class="n">ldm</span><span class="p">)</span>
<span class="k">call </span><span class="n">cublas_sscal</span><span class="p">(</span><span class="n">ldm</span><span class="o">-</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">beta</span><span class="p">,</span>
<span class="mi">1</span><span class="n">devPtrM</span><span class="o">+</span><span class="n">IDX2F</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">ldm</span><span class="p">)</span><span class="o">*</span><span class="n">sizeof_real</span><span class="p">,</span>
<span class="mi">2</span><span class="mi">1</span><span class="p">)</span>
<span class="k">return</span>
<span class="k">    end</span>
<span class="k">    program </span><span class="n">matrixmod</span>
<span class="k">implicit none</span>
<span class="kt">integer </span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">sizeof_real</span>
<span class="cp">#if ARCH_64</span>
<span class="kt">integer</span><span class="o">*</span><span class="mi">8</span><span class="n">devPtrA</span>
<span class="cp">#else</span>
<span class="kt">integer</span><span class="o">*</span><span class="mi">4</span><span class="n">devPtrA</span>
<span class="cp">#endif</span>
<span class="k">parameter</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">sizeof_real</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="kt">real</span><span class="o">*</span><span class="mi">4</span><span class="n">a</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="kt">integer </span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="nb">stat</span>
<span class="k">external </span><span class="n">cublas_init</span><span class="p">,</span><span class="n">cublas_set_matrix</span><span class="p">,</span><span class="n">cublas_get_matrix</span>
<span class="k">external </span><span class="n">cublas_shutdown</span><span class="p">,</span><span class="n">cublas_alloc</span>
<span class="kt">integer </span><span class="n">cublas_alloc</span><span class="p">,</span><span class="n">cublas_set_matrix</span><span class="p">,</span><span class="n">cublas_get_matrix</span>
<span class="k">do </span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span>
<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span>
<span class="n">a</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span><span class="o">=</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">M</span><span class="o">+</span><span class="n">j</span>
<span class="k">enddo</span>
<span class="k">    enddo</span>
<span class="k">    call </span><span class="n">cublas_init</span>
<span class="nb">stat</span><span class="o">=</span><span class="n">cublas_alloc</span><span class="p">(</span><span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="n">sizeof_real</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">)</span>
<span class="k">if</span><span class="p">(</span><span class="nb">stat</span><span class="p">.</span><span class="n">NE</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="k">then</span>
<span class="k">        write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="o">*</span><span class="p">)</span><span class="s2">"device memory allocation failed"</span>
<span class="k">call </span><span class="n">cublas_shutdown</span>
<span class="k">stop</span>
<span class="k">    endif</span>
<span class="nb">stat</span><span class="o">=</span><span class="n">cublas_set_matrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">sizeof_real</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">)</span>
<span class="k">if</span><span class="p">(</span><span class="nb">stat</span><span class="p">.</span><span class="n">NE</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span><span class="k">then</span>
<span class="k">        call </span><span class="n">cublas_free</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">)</span>
<span class="k">write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="o">*</span><span class="p">)</span><span class="s2">"data download failed"</span>
<span class="k">call </span><span class="n">cublas_shutdown</span>
<span class="k">stop</span>
<span class="k">    endif</span>
</pre>
        <p>
            
        </p>
        <p>
             Code block continues below. Space added for formatting purposes. 
        </p>
        <p>
            
        </p>
        <pre><span class="n">call</span><span class="n">modify</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mf">16.0</span><span class="p">,</span><span class="mf">12.0</span><span class="p">)</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cublas_get_matrix</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">sizeof_real</span><span class="p">,</span><span class="n">devPtrA</span><span class="p">,</span><span class="n">M</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">M</span><span class="p">)</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="p">.</span><span class="n">NE</span><span class="mf">.0</span><span class="p">)</span><span class="n">then</span>
<span class="n">call</span><span class="n">cublas_free</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">)</span>
<span class="n">write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="o">*</span><span class="p">)</span><span class="s">"data upload failed"</span>
<span class="n">call</span><span class="n">cublas_shutdown</span>
<span class="n">stop</span>
<span class="n">endif</span>
<span class="n">call</span><span class="n">cublas_free</span><span class="p">(</span><span class="n">devPtrA</span><span class="p">)</span>
<span class="n">call</span><span class="n">cublas_shutdown</span>
<span class="k">do</span><span class="n">j</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span>
<span class="k">do</span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span>
<span class="n">write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="s">"(F7.0$)"</span><span class="p">)</span><span class="n">a</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>
<span class="n">enddo</span>
<span class="n">write</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="o">*</span><span class="p">)</span><span class="s">""</span>
<span class="n">enddo</span>
<span class="n">stop</span>
<span class="n">end</span>
</pre>
        <h1>
            <span class="section-number">
                8.
            </span>
            Interaction with Other Libraries and Tools
            <a class="headerlink"
                href="https://docs.nvidia.com/cuda/cublas/index.html#interaction-with-other-libraries-and-tools"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <p>
            This section describes important requirements and recommendations that ensure correct use of cuBLAS with
            other libraries and utilities.
        </p>
        <h2>
            <span class="section-number">
                8.1.
            </span>
            nvprune
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#nvprune"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            <span class="pre">
                nvprune
            </span>
            enables pruning relocatable host objects and static libraries to only contain device code for the specific
            target architectures. In case of cuBLAS, particular care must be taken if using
            <span class="pre">
                nvprune
            </span>
            with compute capabilities, whose minor revision number is different than 0. To reduce binary size, cuBLAS
            may only store major revision equivalents of CUDA binary files for kernels reused between different minor
            revision versions. Therefore, to ensure that a pruned library does not fail for arbitrary problems, the user
            must keep binaries for a selected architecture and all prior minor architectures in its major architecture.
        </p>
        <p>
            For example, the following call prunes
            <span class="pre">
                libcublas_static.a
            </span>
            to contain only sm_75 (Turing) and sm_70 (Volta) cubins:
        </p>
        <pre><span class="n">nvprune</span><span class="o">--</span><span class="n">generate</span><span class="o">-</span><span class="n">code</span><span class="n">code</span><span class="o">=</span><span class="n">sm_70</span><span class="o">--</span><span class="n">generate</span><span class="o">-</span><span class="n">code</span><span class="n">code</span><span class="o">=</span><span class="n">sm_75</span><span class="n">libcublasLt_static</span><span class="p">.</span><span class="n">a</span><span class="o">-</span><span class="n">o</span><span class="n">libcublasLt_static_sm70_sm75</span><span class="p">.</span><span class="n">a</span>
</pre>
        <p>
            which should be used instead of:
        </p>
        <pre><span class="n">nvprune</span><span class="o">-</span><span class="n">arch</span><span class="o">=</span><span class="n">sm_75</span><span class="n">libcublasLt_static</span><span class="p">.</span><span class="n">a</span><span class="o">-</span><span class="n">o</span><span class="n">libcublasLt_static_sm75</span><span class="p">.</span><span class="n">a</span>
</pre>
        <h1>
            <span class="section-number">
                9.
            </span>
            Acknowledgements
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#acknowledgements"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <p>
            NVIDIA would like to thank the following individuals and institutions for their contributions:
        </p>
        <ul class="simple">
            <li>
                <p>
                    Portions of the SGEMM, DGEMM, CGEMM and ZGEMM library routines were written by Vasily Volkov of the
                    University of California.
                </p>
            </li>
            <li>
                <p>
                    Portions of the SGEMM, DGEMM and ZGEMM library routines were written by Davide Barbieri of the
                    University of Rome Tor Vergata.
                </p>
            </li>
            <li>
                <p>
                    Portions of the DGEMM and SGEMM library routines optimized for Fermi architecture were developed by
                    the University of Tennessee. Subsequently, several other routines that are optimized for the Fermi
                    architecture have been derived from these initial DGEMM and SGEMM implementations.
                </p>
            </li>
            <li>
                <p>
                    The substantial optimizations of the STRSV, DTRSV, CTRSV and ZTRSV library routines were developed
                    by Jonathan Hogg of The Science and Technology Facilities Council (STFC). Subsequently, some
                    optimizations of the STRSM, DTRSM, CTRSM and ZTRSM have been derived from these TRSV
                    implementations.
                </p>
            </li>
            <li>
                <p>
                    Substantial optimizations of the SYMV and HEMV library routines were developed by Ahmad Abdelfattah,
                    David Keyes and Hatem Ltaief of King Abdullah University of Science and Technology (KAUST).
                </p>
            </li>
            <li>
                <p>
                    Substantial optimizations of the TRMM and TRSM library routines were developed by Ali Charara, David
                    Keyes and Hatem Ltaief of King Abdullah University of Science and Technology (KAUST).
                </p>
            </li>
            <li>
                <p>
                    This product includes {fmt} - A modern formatting library
                    <a class="reference external" href="https://fmt.dev/">
                        https://fmt.dev
                    </a>
                    Copyright (c) 2012 - present, Victor Zverovich.
                </p>
            </li>
            <li>
                <p>
                    This product includes spdlog - Fast C++ logging library.
                    <a class="reference external" href="https://github.com/gabime/spdlog">
                        https://github.com/gabime/spdlog
                    </a>
                    The MIT License (MIT).
                </p>
            </li>
            <li>
                <p>
                    This product includes SIMD Library for Evaluating Elementary Functions, vectorized libm and DFT
                    <a class="reference external" href="https://sleef.org/">
                        https://sleef.org
                    </a>
                    Boost Software License - Version 1.0 - August 17th, 2003.
                </p>
            </li>
            <li>
                <p>
                    This product includes Frozen - a header-only, constexpr alternative to gperf for C++14 users.
                    <a class="reference external" href="https://github.com/serge-sans-paille/frozen">
                        https://github.com/serge-sans-paille/frozen
                    </a>
                    Apache License - Version 2.0, January 2004.
                </p>
            </li>
            <li>
                <p>
                    This product includes Boost C++ Libraries - free peer-reviewed portable C++ source libraries
                    <a class="reference external" href="https://www.boost.org/">
                        https://www.boost.org/
                    </a>
                    Boost Software License - Version 1.0 - August 17th, 2003.
                </p>
            </li>
            <li>
                <p>
                    This product includes Zstandard - a fast lossless compression algorithm, targeting real-time
                    compression scenarios at zlib-level and better compression ratios.
                    <a class="reference external" href="https://github.com/facebook/zstd">
                        https://github.com/facebook/zstd
                    </a>
                    The BSD License.
                </p>
            </li>
        </ul>
        <h1>
            <span class="section-number">
                10.
            </span>
            Notices
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#notices"
                title="Permalink to this headline">
                
            </a>
        </h1>
        <h2>
            <span class="section-number">
                10.1.
            </span>
            Notice
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#notice"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            This document is provided for information purposes only and shall not be regarded as a warranty of a certain
            functionality, condition, or quality of a product. NVIDIA Corporation (NVIDIA) makes no
            representations or warranties, expressed or implied, as to the accuracy or completeness of the information
            contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have
            no liability for the consequences or use of such information or for any infringement of patents or other
            rights of third parties that may result from its use. This document is not a commitment to develop, release,
            or deliver any Material (defined below), code, or functionality.
        </p>
        <p>
            NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other
            changes to this document, at any time without notice.
        </p>
        <p>
            Customer should obtain the latest relevant information before placing orders and should verify that such
            information is current and complete.
        </p>
        <p>
            NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of
            order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized
            representatives of NVIDIA and customer (Terms of Sale). NVIDIA hereby expressly objects to applying
            any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in
            this document. No contractual obligations are formed either directly or indirectly by this document.
        </p>
        <p>
            NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military,
            aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA
            product can reasonably be expected to result in personal injury, death, or property or environmental damage.
            NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications
            and therefore such inclusion and/or use is at customers own risk.
        </p>
        <p>
            NVIDIA makes no representation or warranty that products based on this document will be suitable for any
            specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is
            customers sole responsibility to evaluate and determine the applicability of any information contained in
            this document, ensure the product is suitable and fit for the application planned by customer, and perform
            the necessary testing for the application in order to avoid a default of the application or the product.
            Weaknesses in customers product designs may affect the quality and reliability of the NVIDIA product and
            may result in additional or different conditions and/or requirements beyond those contained in this
            document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based
            on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or
            (ii) customer product designs.
        </p>
        <p>
            No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other
            NVIDIA intellectual property right under this document. Information published by NVIDIA regarding
            third-party products or services does not constitute a license from NVIDIA to use such products or services
            or a warranty or endorsement thereof. Use of such information may require a license from a third party under
            the patents or other intellectual property rights of the third party, or a license from NVIDIA under the
            patents or other intellectual property rights of NVIDIA.
        </p>
        <p>
            Reproduction of information in this document is permissible only if approved in advance by NVIDIA in
            writing, reproduced without alteration and in full compliance with all applicable export laws and
            regulations, and accompanied by all associated conditions, limitations, and notices.
        </p>
        <p>
            THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS,
            AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, MATERIALS) ARE BEING PROVIDED AS IS. NVIDIA MAKES
            NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY
            DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE.
            TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT
            LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND
            REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN
            ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any
            reason whatsoever, NVIDIAs aggregate and cumulative liability towards customer for the products described
            herein shall be limited in accordance with the Terms of Sale for the product.
        </p>
        <h2>
            <span class="section-number">
                10.2.
            </span>
            OpenCL
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#opencl"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc.
        </p>
        <h2>
            <span class="section-number">
                10.3.
            </span>
            Trademarks
            <a class="headerlink" href="https://docs.nvidia.com/cuda/cublas/index.html#trademarks"
                title="Permalink to this headline">
                
            </a>
        </h2>
        <p>
            NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and
            other countries. Other company and product names may be trademarks of the respective companies with which
            they are associated.
        </p>
        <p class="notices">
            <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
                Privacy Policy
            </a>
            |
            <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">
                Manage My Privacy
            </a>
            |
            <a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">
                Do Not Sell or Share My Data
            </a>
            |
            <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
                Terms of Service
            </a>
            |
            <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
                Accessibility
            </a>
            |
            <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
                Corporate Policies
            </a>
            |
            <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
                Product Security
            </a>
            |
            <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
                Contact
            </a>
        </p>
        <p>
            Copyright  2012-2024, NVIDIA Corporation &amp; affiliates. All rights reserved.
        </p>
        <p>
            <span class="lastupdated">
                Last updated on Jul 1, 2024.
            </span>
        </p>
    </body>
</body>

</html>