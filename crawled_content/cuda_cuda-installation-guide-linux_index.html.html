<html><head><title>CUDA Installation Guide for Linux</title></head><body><body class="wy-body-for-nav">
 <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/contents.html">
 </a>
 <ul class="current">
  <li class="toctree-l1 current">
   <a class="current reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">
    1. Introduction
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#system-requirements">
      1.1. System Requirements
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#os-support-policy">
      1.2. OS Support Policy
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#host-compiler-support-policy">
      1.3. Host Compiler Support Policy
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#supported-c-dialects">
        1.3.1. Supported C++ Dialects
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#about-this-document">
      1.4. About This Document
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
    2. Pre-installation Actions
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-you-have-a-cuda-capable-gpu">
      2.1. Verify You Have a CUDA-Capable GPU
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-you-have-a-supported-version-of-linux">
      2.2. Verify You Have a Supported Version of Linux
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-system-has-gcc-installed">
      2.3. Verify the System Has gcc Installed
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-system-has-the-correct-kernel-headers-and-development-packages-installed">
      2.4. Verify the System has the Correct Kernel Headers and Development Packages Installed
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-gpudirect-storage">
      2.5. Install GPUDirect Storage
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#choose-an-installation-method">
      2.6. Choose an Installation Method
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#download-the-nvidia-cuda-toolkit">
      2.7. Download the NVIDIA CUDA Toolkit
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#address-custom-xorg-conf-if-applicable">
      2.8. Address Custom xorg.conf, If Applicable
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#handle-conflicting-installation-methods">
      2.9. Handle Conflicting Installation Methods
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-installation">
    3. Package Manager Installation
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#overview">
      3.1. Overview
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-rocky-8">
      3.2. RHEL 8 / Rocky 8
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-rhel-8-rocky-8">
        3.2.1. Prepare RHEL 8 / Rocky 8
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-rhel-8-rocky-8">
        3.2.2. Local Repo Installation for RHEL 8 / Rocky 8
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-rhel-8-rocky-8">
        3.2.3. Network Repo Installation for RHEL 8 / Rocky 8
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-instructions-for-rhel-8-rocky-8">
        3.2.4. Common Instructions for RHEL 8 / Rocky 8
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-rocky-9">
      3.3. RHEL 9 / Rocky 9
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-rhel-9-rocky-9">
        3.3.1. Prepare RHEL 9 / Rocky 9
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-rhel-9-rocky-9">
        3.3.2. Local Repo Installation for RHEL 9 / Rocky 9
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-rhel-9-rocky-9">
        3.3.3. Network Repo Installation for RHEL 9 / Rocky 9
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-instructions-for-rhel-9-rocky-9">
        3.3.4. Common Instructions for RHEL 9 / Rocky 9
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kylinos-10">
      3.4. KylinOS 10
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-kylinos-10">
        3.4.1. Prepare KylinOS 10
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-kylinos">
        3.4.2. Local Repo Installation for KylinOS
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-kylinos">
        3.4.3. Network Repo Installation for KylinOS
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-instructions-for-kylinos-10">
        3.4.4. Common Instructions for KylinOS 10
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#fedora">
      3.5. Fedora
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-fedora">
        3.5.1. Prepare Fedora
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-fedora">
        3.5.2. Local Repo Installation for Fedora
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-fedora">
        3.5.3. Network Repo Installation for Fedora
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-fedora">
        3.5.4. Common Installation Instructions for Fedora
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#sles">
      3.6. SLES
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-sles">
        3.6.1. Prepare SLES
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-sles">
        3.6.2. Local Repo Installation for SLES
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-sles">
        3.6.3. Network Repo Installation for SLES
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-sles">
        3.6.4. Common Installation Instructions for SLES
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opensuse">
      3.7. OpenSUSE
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-opensuse">
        3.7.1. Prepare OpenSUSE
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-opensuse">
        3.7.2. Local Repo Installation for OpenSUSE
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-opensuse">
        3.7.3. Network Repo Installation for OpenSUSE
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-opensuse">
        3.7.4. Common Installation Instructions for OpenSUSE
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#wsl">
      3.8. WSL
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-wsl">
        3.8.1. Prepare WSL
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-wsl">
        3.8.2. Local Repo Installation for WSL
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-wsl">
        3.8.3. Network Repo Installation for WSL
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-wsl">
        3.8.4. Common Installation Instructions for WSL
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">
      3.9. Ubuntu
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-ubuntu">
        3.9.1. Prepare Ubuntu
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-ubuntu">
        3.9.2. Local Repo Installation for Ubuntu
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-ubuntu">
        3.9.3. Network Repo Installation for Ubuntu
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-ubuntu">
        3.9.4. Common Installation Instructions for Ubuntu
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#debian">
      3.10. Debian
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-debian">
        3.10.1. Prepare Debian
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-debian">
        3.10.2. Local Repo Installation for Debian
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-debian">
        3.10.3. Network Repo Installation for Debian
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-debian">
        3.10.4. Common Installation Instructions for Debian
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#amazon-linux-2023">
      3.11. Amazon Linux 2023
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-amazon-linux-2023">
        3.11.1. Prepare Amazon Linux 2023
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-amazon-linux">
        3.11.2. Local Repo Installation for Amazon Linux
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-amazon-linux">
        3.11.3. Network Repo Installation for Amazon Linux
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-amazon-linux">
        3.11.4. Common Installation Instructions for Amazon Linux
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#additional-package-manager-capabilities">
      3.12. Additional Package Manager Capabilities
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#available-packages">
        3.12.1. Available Packages
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#meta-packages">
        3.12.2. Meta Packages
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#optional-32-bit-packages-for-linux-x86-64-deb-rpm">
        3.12.3. Optional 32-bit Packages for Linux x86_64 .deb/.rpm
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-upgrades">
        3.12.4. Package Upgrades
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#driver-installation">
    4. Driver Installation
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#nvidia-open-gpu-kernel-modules">
    5. NVIDIA Open GPU Kernel Modules
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-runfile">
      5.1. CUDA Runfile
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-debian-installation">
      5.2. Debian
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-fedora-installation">
      5.3. Fedora
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kylinos10-installation">
      5.4. KylinOS 10
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-and-rocky-9">
      5.5. RHEL 9 and Rocky 9
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-and-rocky-8">
      5.6. RHEL 8 and Rocky 8
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opensuse-and-sles">
      5.7. OpenSUSE and SLES
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-ubuntu-installation">
      5.8. Ubuntu
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#precompiled-streams">
    6. Precompiled Streams
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#precompiled-streams-support-matrix">
      6.1. Precompiled Streams Support Matrix
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#modularity-profiles">
      6.2. Modularity Profiles
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kickstart-installation">
    7. Kickstart Installation
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-rocky-linux-8">
      7.1. RHEL 8 / Rocky Linux 8
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-rocky-linux-9">
      7.2. RHEL 9 / Rocky Linux 9
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-installation">
    8. Runfile Installation
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-overview">
      8.1. Runfile Overview
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installation">
      8.2. Installation
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#disabling-nouveau">
      8.3. Disabling Nouveau
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-fedora">
        8.3.1. Fedora
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-rocky-and-kylinos">
        8.3.2. RHEL / Rocky and KylinOS
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-suse">
        8.3.3. OpenSUSE
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-sles">
        8.3.4. SLES
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-wsl">
        8.3.5. WSL
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-ubuntu">
        8.3.6. Ubuntu
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-debian">
        8.3.7. Debian
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#device-node-verification">
      8.4. Device Node Verification
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-options">
      8.5. Advanced Options
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#uninstallation">
      8.6. Uninstallation
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#conda-installation">
    9. Conda Installation
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#conda-overview">
      9.1. Conda Overview
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installing-cuda-using-conda">
      9.2. Installing CUDA Using Conda
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#uninstalling-cuda-using-conda">
      9.3. Uninstalling CUDA Using Conda
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installing-previous-cuda-releases">
      9.4. Installing Previous CUDA Releases
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#upgrading-from-cudatoolkit-package">
      9.5. Upgrading from cudatoolkit Package
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pip-wheels">
    10. Pip Wheels
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#tarball-and-zip-archive-deliverables">
    11. Tarball and Zip Archive Deliverables
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#parsing-redistrib-json">
      11.1. Parsing Redistrib JSON
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#importing-tarballs-into-cmake">
      11.2. Importing Tarballs into CMake
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#importing-tarballs-into-bazel">
      11.3. Importing Tarballs into Bazel
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-environment">
    12. CUDA Cross-Platform Environment
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation">
      12.1. CUDA Cross-Platform Installation
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-samples">
      12.2. CUDA Cross-Platform Samples
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
    13. Post-installation Actions
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#mandatory-actions">
      13.1. Mandatory Actions
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#environment-setup">
        13.1.1. Environment Setup
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#recommended-actions">
      13.2. Recommended Actions
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-persistence-daemon">
        13.2.1. Install Persistence Daemon
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-writable-samples">
        13.2.2. Install Writable Samples
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-installation">
        13.2.3. Verify the Installation
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-driver-version">
          13.2.3.1. Verify the Driver Version
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-the-binaries">
          13.2.3.2. Running the Binaries
         </a>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-nsight-eclipse-plugins">
        13.2.4. Install Nsight Eclipse Plugins
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-removal">
        13.2.5. Local Repo Removal
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#optional-actions">
      13.3. Optional Actions
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-third-party-libraries">
        13.3.1. Install Third-party Libraries
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-the-source-code-for-cuda-gdb">
        13.3.2. Install the Source Code for cuda-gdb
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#select-the-active-version-of-cuda">
        13.3.3. Select the Active Version of CUDA
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-setup">
    14. Advanced Setup
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#frequently-asked-questions">
    15. Frequently Asked Questions
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-install-the-toolkit-in-a-different-location">
      15.1. How do I install the Toolkit in a different location?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-do-i-see-nvcc-no-such-file-or-directory-when-i-try-to-build-a-cuda-application">
      15.2. Why do I see ânvcc: No such file or directoryâ when I try to build a CUDA application?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-do-i-see-error-while-loading-shared-libraries-lib-name-cannot-open-shared-object-file-no-such-file-or-directory-when-i-try-to-run-a-cuda-application-that-uses-a-cuda-library">
      15.3. Why do I see âerror while loading shared libraries: &lt;lib name&gt;: cannot open shared object file: No such file or directoryâ when I try to run a CUDA application that uses a CUDA library?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-do-i-see-multiple-404-not-found-errors-when-updating-my-repository-meta-data-on-ubuntu">
      15.4. Why do I see multiple â404 Not Foundâ errors when updating my repository meta-data on Ubuntu?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-can-i-tell-x-to-ignore-a-gpu-for-compute-only-use">
      15.5. How can I tell X to ignore a GPU for compute-only use?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-doesn-t-the-cuda-repo-package-install-the-cuda-toolkit-and-drivers">
      15.6. Why doesnât the cuda-repo package install the CUDA Toolkit and Drivers?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-get-cuda-to-work-on-a-laptop-with-an-igpu-and-a-dgpu-running-ubuntu14-04">
      15.7. How do I get CUDA to work on a laptop with an iGPU and a dGPU running Ubuntu14.04?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#what-do-i-do-if-the-display-does-not-load-or-cuda-does-not-work-after-performing-a-system-update">
      15.8. What do I do if the display does not load, or CUDA does not work, after performing a system update?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-install-a-cuda-driver-with-a-version-less-than-367-using-a-network-repo">
      15.9. How do I install a CUDA driver with a version less than 367 using a network repo?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-install-an-older-cuda-version-using-a-network-repo">
      15.10. How do I install an older CUDA version using a network repo?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-does-the-installation-on-suse-install-the-mesa-dri-nouveau-dependency">
      15.11. Why does the installation on SUSE install the Mesa-dri-nouveau dependency?
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-handle-errors-were-encountered-while-processing-glx-diversions">
      15.12. How do I handle âErrors were encountered while processing: glx-diversionsâ?
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#additional-considerations">
    16. Additional Considerations
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#switching-between-driver-module-flavors">
    17. Switching between Driver Module Flavors
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-toolkit-and-driver">
    18. Removing CUDA Toolkit and Driver
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#notices">
    19. Notices
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#notice">
      19.1. Notice
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opencl">
      19.2. OpenCL
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#trademarks">
      19.3. Trademarks
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#copyright">
    20. Copyright
   </a>
  </li>
 </ul>
 <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/contents.html">
  Installation Guide for Linux
 </a>
 <ul class="wy-breadcrumbs">
  <li>
   <a class="icon icon-home" href="https://docs.nvidia.com/cuda/index.html">
   </a>
   Â»
  </li>
  <li>
   <span class="section-number">
    1.
   </span>
   Introduction
  </li>
  <li class="wy-breadcrumbs-aside">
   <span>
    v12.5 |
   </span>
   <a class="reference external" href="https://docs.nvidia.com/cuda/pdf/CUDA_Installation_Guide_Linux.pdf">
    PDF
   </a>
   <span>
    |
   </span>
   <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit-archive">
    Archive
   </a>
   <span>
    Â
   </span>
  </li>
 </ul>
 <p class="rubric-h1 rubric">
  NVIDIA CUDA Installation Guide for Linux
 </p>
 <p>
  The installation instructions for the CUDA Toolkit on Linux.
 </p>
 <h1>
  <span class="section-number">
   1.
  </span>
  Introduction
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#introduction" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  CUDA
  Â®
  is a parallel computing platform and programming model invented by NVIDIA
  Â®
  . It enables dramatic increases in computing performance by harnessing the power of the graphics processing unit (GPU).
 </p>
 <p>
  CUDA was developed with several design goals in mind:
 </p>
 <ul class="simple">
  <li>
   <p>
    Provide a small set of extensions to standard programming languages, like C, that enable a straightforward implementation of parallel algorithms. With CUDA C/Cï»¿+ï»¿+, programmers can focus on the task of parallelization of the algorithms rather than spending time on their implementation.
   </p>
  </li>
  <li>
   <p>
    Support heterogeneous computation where applications use both the CPU and GPU. Serial portions of applications are run on the CPU, and parallel portions are offloaded to the GPU. As such, CUDA can be incrementally applied to existing applications. The CPU and GPU are treated as separate devices that have their own memory spaces. This configuration also allows simultaneous computation on the CPU and GPU without contention for memory resources.
   </p>
  </li>
 </ul>
 <p>
  CUDA-capable GPUs have hundreds of cores that can collectively run thousands of computing threads. These cores have shared resources including a register file and a shared memory. The on-chip shared memory allows parallel tasks running on these cores to share data without sending it over the system memory bus.
 </p>
 <p>
  This guide will show you how to install and check the correct operation of the CUDA development tools.
 </p>
 <h2>
  <span class="section-number">
   1.1.
  </span>
  System Requirements
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#system-requirements" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To use NVIDIA CUDA on your system, you will need the following installed:
 </p>
 <ul class="simple">
  <li>
   <p>
    CUDA-capable GPU
   </p>
  </li>
  <li>
   <p>
    A supported version of Linux with a gcc compiler and toolchain
   </p>
  </li>
  <li>
   <p>
    CUDA Toolkit (available at
    <a class="reference external" href="https://developer.nvidia.com/cuda-downloads">
     https://developer.nvidia.com/cuda-downloads
    </a>
    )
   </p>
  </li>
 </ul>
 <p>
  The CUDA development environment relies on tight integration with the host development environment, including the host compiler and C runtime libraries, and is therefore only supported on distribution versions that have been qualified for this CUDA Toolkit release.
 </p>
 <p>
  The following table lists the supported Linux distributions. Please review the footnotes associated with the table.
 </p>
 <table class="table-no-stripes longtable docutils align-default" id="id14">
  <span class="caption-number">
   Table 1
  </span>
  <span class="caption-text">
   Native Linux Distribution Support in CUDA 12.5 Update 1
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id14" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Distribution
    </p>
   </th>
   <th class="head">
    <p>
     Kernel
     1
    </p>
   </th>
   <th class="head">
    <p>
     Default GCC
    </p>
   </th>
   <th class="head">
    <p>
     GLIBC
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td colspan="4">
    <p>
     x86_64
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     RHEL 9.y (y &lt;= 4)
    </p>
   </td>
   <td>
    <p>
     5.14.0-427
    </p>
   </td>
   <td>
    <p>
     11.4.1
    </p>
   </td>
   <td>
    <p>
     2.34
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     RHEL 8.y (y &lt;= 10)
    </p>
   </td>
   <td>
    <p>
     4.18.0-553
    </p>
   </td>
   <td>
    <p>
     8.5.0
    </p>
   </td>
   <td>
    <p>
     2.28
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     OpenSUSE Leap 15.y (y &lt;= 5)
    </p>
   </td>
   <td>
    <p>
     5.14.21-150500
    </p>
   </td>
   <td>
    <p>
     7.5.0
    </p>
   </td>
   <td>
    <p>
     2.31
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Rocky Linux 8.y (y&lt;=10)
    </p>
   </td>
   <td>
    <p>
     4.18.0-553
    </p>
   </td>
   <td>
    <p>
     8.5.0
    </p>
   </td>
   <td>
    <p>
     2.28
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Rocky Linux 9.y (y&lt;=4)
    </p>
   </td>
   <td>
    <p>
     5.14.0-427
    </p>
   </td>
   <td>
    <p>
     11.4.1
    </p>
   </td>
   <td>
    <p>
     2.34
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     SUSE SLES 15.y (y &lt;= 5)
    </p>
   </td>
   <td>
    <p>
     5.14.21-150500
    </p>
   </td>
   <td>
    <p>
     7.5.0
    </p>
   </td>
   <td>
    <p>
     2.31
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Ubuntu 24.04 LTS
    </p>
   </td>
   <td>
    <p>
     6.8.0-31
    </p>
   </td>
   <td>
    <p>
     13.2.0
    </p>
   </td>
   <td>
    <p>
     2.39
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Ubuntu 22.04.z (z &lt;= 4) LTS
    </p>
   </td>
   <td>
    <p>
     6.5.0-27
    </p>
   </td>
   <td>
    <p>
     12.3.0
    </p>
   </td>
   <td>
    <p>
     2.35
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Ubuntu 20.04.z (z &lt;= 6) LTS
    </p>
   </td>
   <td>
    <p>
     5.15.0-67
    </p>
   </td>
   <td>
    <p>
     9.4.0
    </p>
   </td>
   <td>
    <p>
     2.31
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Debian 12.x (x&lt;=5)
    </p>
   </td>
   <td>
    <p>
     6.1.76-1
    </p>
   </td>
   <td>
    <p>
     12.2.0
    </p>
   </td>
   <td>
    <p>
     2.36
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Debian 11.y (y&lt;=9)
    </p>
   </td>
   <td>
    <p>
     5.10.209-2
    </p>
   </td>
   <td>
    <p>
     10.2.1
    </p>
   </td>
   <td>
    <p>
     2.31
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Debian 10.z (z&lt;=13)
    </p>
   </td>
   <td>
    <p>
     4.19.0-21
    </p>
   </td>
   <td>
    <p>
     8.3.0
    </p>
   </td>
   <td>
    <p>
     2.28
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Fedora 39
    </p>
   </td>
   <td>
    <p>
     6.5.6-300
    </p>
   </td>
   <td>
    <p>
     13.2.1
    </p>
   </td>
   <td>
    <p>
     2.38
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     KylinOS V10 SP2
    </p>
   </td>
   <td>
    <p>
     4.19.90-25.14.v2101.ky10
    </p>
   </td>
   <td>
    <p>
     7.3.0
    </p>
   </td>
   <td>
    <p>
     2.28
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Amazon Linux 2023
    </p>
   </td>
   <td>
    <p>
     6.1.82-99.168
    </p>
   </td>
   <td>
    <p>
     11.4.1
    </p>
   </td>
   <td>
    <p>
     2.34
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td colspan="4">
    <p>
     Arm64 sbsa
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     RHEL 9.y (y &lt;= 4)
    </p>
   </td>
   <td>
    <p>
     5.14.0-427
    </p>
   </td>
   <td>
    <p>
     11.4.1
    </p>
   </td>
   <td>
    <p>
     2.34
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     RHEL 8.y (y &lt;= 10)
    </p>
   </td>
   <td>
    <p>
     4.18.0-553
    </p>
   </td>
   <td>
    <p>
     8.5.0
    </p>
   </td>
   <td>
    <p>
     2.28
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     SUSE SLES 15.y (y &lt;= 5)
    </p>
   </td>
   <td>
    <p>
     5.14.21-150500
    </p>
   </td>
   <td>
    <p>
     7.5.0
    </p>
   </td>
   <td>
    <p>
     2.32
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Ubuntu 24.04 LTS
    </p>
   </td>
   <td>
    <p>
     6.8.0-31
    </p>
   </td>
   <td>
    <p>
     13.2.0
    </p>
   </td>
   <td>
    <p>
     2.39
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Ubuntu 22.04 LTS (z &lt;= 5) LTS
    </p>
   </td>
   <td>
    <p>
     5.15.0-102
    </p>
   </td>
   <td>
    <p>
     11.4.0
    </p>
   </td>
   <td>
    <p>
     2.35
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Ubuntu 20.04.z (z &lt;= 5) LTS
    </p>
   </td>
   <td>
    <p>
     5.4.0-174
    </p>
   </td>
   <td>
    <p>
     9.4.0
    </p>
   </td>
   <td>
    <p>
     2.31
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td colspan="4">
    <p>
     Arm64 sbsa Jetson (dGPU)
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     20.04.06 LTS Rel35 JP 5.x
    </p>
   </td>
   <td>
    <p>
     5.10.192-tegra
    </p>
   </td>
   <td>
    <p>
     9.4.0
    </p>
   </td>
   <td>
    <p>
     2.31
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     22.04.4 LTS Rel36 - JP6.x
    </p>
   </td>
   <td>
    <p>
     5.15.136-tegra
    </p>
   </td>
   <td>
    <p>
     11.4.0
    </p>
   </td>
   <td>
    <p>
     2.35
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td colspan="4">
    <p>
     Aarch64 Jetson (iGPU)
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     L4T Ubuntu 22.04 Rel36 - JP6.x
    </p>
   </td>
   <td>
    <p>
     6.1.80-tegra
    </p>
   </td>
   <td>
    <p>
     11.4.0
    </p>
   </td>
   <td>
    <p>
     2.3.5
    </p>
   </td>
  </tr>
 </table>
 <ol class="arabic simple">
  <li>
   <p>
    The following notes apply to the kernel versions supported by CUDA:
   </p>
  </li>
 </ol>
 <ul class="simple">
  <li>
   <p>
    For specific kernel versions supported on Red Hat Enterprise Linux (RHEL), visit
    <a class="reference external" href="https://access.redhat.com/articles/3078">
     https://access.redhat.com/articles/3078
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    A list of kernel versions including the release dates for SUSE Linux Enterprise Server (SLES) is available at
    <a class="reference external" href="https://www.suse.com/support/kb/doc/?id=000019587">
     https://www.suse.com/support/kb/doc/?id=000019587
    </a>
    .
   </p>
  </li>
 </ul>
 <ol class="arabic simple" start="2">
  <li>
   <p>
    L4T provides a Linux kernel and a sample root filesystem derived from Ubuntu 20.04. For more details, visit
    <a class="reference external" href="https://developer.nvidia.com/embedded/jetson-linux">
     https://developer.nvidia.com/embedded/jetson-linux
    </a>
    .
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   1.2.
  </span>
  OS Support Policy
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#os-support-policy" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ul class="simple">
  <li>
   <p>
    CUDA support for Ubuntu 20.04.x, Ubuntu 22.04.x, RHEL 8.x, RHEL 9.x, Rocky Linux 8.x, Rocky Linux 9.x, SUSE SLES 15.x and OpenSUSE Leap 15.x will be until the standard EOSS as defined for each OS. Please refer to the support lifecycle for these OSes to know their support timelines.
   </p>
  </li>
  <li>
   <p>
    CUDA supports the latest Fedora release version. For Fedora release timelines, visit
    <a class="reference external" href="https://docs.fedoraproject.org/en-US/releases/">
     https://docs.fedoraproject.org/en-US/releases/
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    CUDA supports a single KylinOS release version. For details, visit
    <a class="reference external" href="https://www.kylinos.cn/">
     https://www.kylinos.cn/
    </a>
    .
   </p>
  </li>
 </ul>
 <p>
  Refer to the support lifecycle for these supported OSes to know their support timelines and plan to move to newer releases accordingly.
 </p>
 <h2>
  <span class="section-number">
   1.3.
  </span>
  Host Compiler Support Policy
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#host-compiler-support-policy" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  In order to compile the CPU âHostâ code in the CUDA source, the CUDA compiler NVCC requires a compatible host compiler to be installed on the system. The version of the host compiler supported on Linux platforms is tabulated as below. NVCC performs a version check on the host compilerâs major version and so newer minor versions of the compilers listed below will be supported, but major versions falling outside the range will not be supported.
 </p>
 <table class="table-no-stripes docutils align-default" id="id15">
  <span class="caption-number">
   Table 2
  </span>
  <span class="caption-text">
   Supported Compilers
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id15" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Distribution
    </p>
   </th>
   <th class="head">
    <p>
     GCC
    </p>
   </th>
   <th class="head">
    <p>
     Clang
    </p>
   </th>
   <th class="head">
    <p>
     NVHPC
    </p>
   </th>
   <th class="head">
    <p>
     XLC
    </p>
   </th>
   <th class="head">
    <p>
     ArmC/C++
    </p>
   </th>
   <th class="head">
    <p>
     ICC
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     x86_64
    </p>
   </td>
   <td>
    <p>
     6.x - 13.2
    </p>
   </td>
   <td>
    <p>
     7.x - 17.0
    </p>
   </td>
   <td>
    <p>
     23.x
    </p>
   </td>
   <td>
    <p>
     No
    </p>
   </td>
   <td>
    <p>
     No
    </p>
   </td>
   <td>
    <p>
     2021.7
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Arm64 sbsa
    </p>
   </td>
   <td>
    <p>
     6.x - 13.2
    </p>
   </td>
   <td>
    <p>
     7.x - 17.0
    </p>
   </td>
   <td>
    <p>
     22.x
    </p>
   </td>
   <td>
    <p>
     No
    </p>
   </td>
   <td>
    <p>
     23.04.1
    </p>
   </td>
   <td>
    <p>
     No
    </p>
   </td>
  </tr>
 </table>
 <p>
  For GCC and Clang, the preceding table indicates the minimum version and the latest version supported. If you are on a Linux distribution that may use an older version of GCC toolchain as default than what is listed above, it is recommended to upgrade to a newer toolchain CUDA 11.0 or later toolkit. Newer GCC toolchains are available with the Red Hat Developer Toolset for example. For platforms that ship a compiler version older than GCC 6 by default, linking to static or dynamic libraries that are shipped with the CUDA Toolkit is not supported. We only support libstdc++ (GCCâs implementation) for all the supported host compilers for the platforms listed above.
 </p>
 <h3>
  <span class="section-number">
   1.3.1.
  </span>
  Supported C++ Dialects
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#supported-c-dialects" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  NVCC and NVRTC (CUDA Runtime Compiler) support the following C++ dialect: C++11, C++14, C++17, C++20 on supported host compilers. The default C++ dialect of NVCC  is determined by the default dialect of the host compiler used for compilation. Refer to host compiler documentation and the
  CUDA Programming Guide
  for more details on language support.
 </p>
 <p>
  C++20 is supported with the following flavors of host compiler in both host and device code.
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Distribution
    </p>
   </th>
   <th class="head">
    <p>
     GCC
    </p>
   </th>
   <th class="head">
    <p>
     Clang
    </p>
   </th>
   <th class="head">
    <p>
     NVHPC
    </p>
   </th>
   <th class="head">
    <p>
     Arm C/C++
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     x86_64
    </p>
   </td>
   <td>
    <p>
     &gt;=10.x
    </p>
   </td>
   <td>
    <p>
     &gt;=11.x
    </p>
   </td>
   <td>
    <p>
     &gt;=22.x
    </p>
   </td>
   <td>
    <p>
     22.x
    </p>
   </td>
  </tr>
 </table>
 <h2>
  <span class="section-number">
   1.4.
  </span>
  About This Document
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#about-this-document" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This document is intended for readers familiar with the Linux environment and the compilation of C programs from the command line. You do not need previous experience with CUDA or experience with parallel computation. Note: This guide covers installation only on systems with X Windows installed.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Many commands in this document might require
  superuser
  privileges. On most distributions of Linux, this will require you to log in as root. For systems that have enabled the sudo package, use the sudo prefix for all necessary commands.
 </p>
 <h1>
  <span class="section-number">
   2.
  </span>
  Pre-installation Actions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Some actions must be taken before the CUDA Toolkit and Driver can be installed on Linux:
 </p>
 <ul class="simple">
  <li>
   <p>
    Verify the system has a CUDA-capable GPU.
   </p>
  </li>
  <li>
   <p>
    Verify the system is running a supported version of Linux.
   </p>
  </li>
  <li>
   <p>
    Verify the system has gcc installed.
   </p>
  </li>
  <li>
   <p>
    Verify the system has the correct kernel headers and development packages installed.
   </p>
  </li>
  <li>
   <p>
    Download the NVIDIA CUDA Toolkit.
   </p>
  </li>
  <li>
   <p>
    Handle conflicting installation methods.
   </p>
  </li>
 </ul>
 <p class="admonition-title">
  Note
 </p>
 <p>
  You can override the install-time prerequisite checks by running the installer with the
  <span class="pre">
   -override
  </span>
  flag. Remember that the prerequisites will still be required to use the NVIDIA CUDA Toolkit.
 </p>
 <h2>
  <span class="section-number">
   2.1.
  </span>
  Verify You Have a CUDA-Capable GPU
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-you-have-a-cuda-capable-gpu" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To verify that your GPU is CUDA-capable, go to your distributionâs equivalent of System Properties, or, from the command line, enter:
 </p>
 <pre>lspci | grep -i nvidia
</pre>
 <p>
  If you do not see any settings, update the PCI hardware database that Linux maintains by entering
  <span class="pre">
   update-pciids
  </span>
  (generally found in
  <span class="pre">
   /sbin
  </span>
  ) at the command line and rerun the previous
  <span class="pre">
   lspci
  </span>
  command.
 </p>
 <p>
  If your graphics card is from NVIDIA and it is listed in
  <a class="reference external" href="https://developer.nvidia.com/cuda-gpus">
   https://developer.nvidia.com/cuda-gpus
  </a>
  , your GPU is CUDA-capable.
 </p>
 <p>
  The Release Notes for the CUDA Toolkit also contain a list of supported products.
 </p>
 <h2>
  <span class="section-number">
   2.2.
  </span>
  Verify You Have a Supported Version of Linux
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-you-have-a-supported-version-of-linux" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The CUDA Development Tools are only supported on some specific distributions of Linux. These are listed in the CUDA Toolkit release notes.
 </p>
 <p>
  To determine which distribution and release number youâre running, type the following at the command line:
 </p>
 <pre>uname -m &amp;&amp; cat /etc/*release
</pre>
 <p>
  You should see output similar to the following, modified for your particular system:
 </p>
 <pre>x86_64
Red Hat Enterprise Linux Workstation release 6.0 (Santiago)
</pre>
 <p>
  The
  <span class="pre">
   x86_64
  </span>
  line indicates you are running on a 64-bit system. The remainder gives information about your distribution.
 </p>
 <h2>
  <span class="section-number">
   2.3.
  </span>
  Verify the System Has gcc Installed
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-system-has-gcc-installed" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The
  <span class="pre">
   gcc
  </span>
  compiler is required for development using the CUDA Toolkit. It is not required for running CUDA applications. It is generally installed as part of the Linux installation, and in most cases the version of gcc installed with a supported version of Linux will work correctly.
 </p>
 <p>
  To verify the version of gcc installed on your system, type the following on the command line:
 </p>
 <pre>gcc --version
</pre>
 <p>
  If an error message displays, you need to install the development tools from your Linux distribution or obtain a version of
  <span class="pre">
   gcc
  </span>
  and its accompanying toolchain from the Web.
 </p>
 <h2>
  <span class="section-number">
   2.4.
  </span>
  Verify the System has the Correct Kernel Headers and Development Packages Installed
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-system-has-the-correct-kernel-headers-and-development-packages-installed" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The CUDA Driver requires that the kernel headers and development packages for the running version of the kernel be installed at the time of the driver installation, as well whenever the driver is rebuilt. For example, if your system is running kernel version 3.17.4-301, the 3.17.4-301 kernel headers and development packages must also be installed.
 </p>
 <p>
  While the Runfile installation performs no package validation, the RPM and Deb installations of the driver will make an attempt to install the kernel header and development packages if no version of these packages is currently installed. However, it will install the latest version of these packages, which may or may not match the version of the kernel your system is using.
  Therefore, it is best to manually ensure the correct version of the kernel headers and development packages are installed prior to installing the CUDA Drivers, as well as whenever you change the kernel version.
 </p>
 <p>
  The version of the kernel your system is running can be found by running the following command:
 </p>
 <pre>uname -r
</pre>
 <p>
  This is the version of the kernel headers and development packages that must be installed prior to installing the CUDA Drivers. This command will be used multiple times below to specify the version of the packages to install. Note that below are the common-case scenarios for kernel usage. More advanced cases, such as custom kernel branches, should ensure that their kernel headers and sources match the kernel build they are running.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  If you perform a system update which changes the version of the Linux kernel being used, make sure to rerun the commands below to ensure you have the correct kernel headers and kernel development packages installed. Otherwise, the CUDA Driver will fail to work with the new kernel.
 </p>
 <h2>
  <span class="section-number">
   2.5.
  </span>
  Install GPUDirect Storage
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-gpudirect-storage" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  If you intend to use GPUDirectStorage (GDS), you must install the CUDA package and MLNX_OFED package.
 </p>
 <p>
  GDS packages can be installed using the CUDA packaging guide. Follow the instructions in
  <a class="reference external" href="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#mofed-req-install">
   MLNX_OFED Requirements and Installation
  </a>
  .
 </p>
 <p>
  GDS is supported in two different modes: GDS (default/full perf mode) and Compatibility mode. Installation instructions for them differ slightly. Compatibility mode is the only mode that is supported on certain distributions due to software dependency limitations.
 </p>
 <p>
  Full GDS support is restricted to the following Linux distros:
 </p>
 <ul class="simple">
  <li>
   <p>
    Ubuntu 20.04, Ubuntu 22.04
   </p>
  </li>
  <li>
   <p>
    RHEL 8.3, RHEL 8.4, RHEL 9.0
   </p>
  </li>
 </ul>
 <p>
  Starting with CUDA toolkit 12.2.2, GDS kernel driver package nvidia-gds version 12.2.2-1 (provided by nvidia-fs-dkms 2.17.5-1) and above is only supported with the NVIDIA open kernel driver. Follow the instructions in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-tk-and-driver">
   Removing CUDA Toolkit and Driver
  </a>
  to remove existing NVIDIA driver packages and then follow instructions in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-gpu-kernel-modules">
   NVIDIA Open GPU Kernel Modules
  </a>
  to install NVIDIA open kernel driver packages.
 </p>
 <h2>
  <span class="section-number">
   2.6.
  </span>
  Choose an Installation Method
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#choose-an-installation-method" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The CUDA Toolkit can be installed using either of two different installation mechanisms: distribution-specific packages (RPM and Deb packages), or a distribution-independent package (runfile packages).
 </p>
 <p>
  The distribution-independent package has the advantage of working across a wider set of Linux distributions, but does not update the distributionâs native package management system. The distribution-specific packages interface with the distributionâs native package management system. It is recommended to use the distribution-specific packages, where possible.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  For both native as well as cross development, the toolkit must be installed using the distribution-specific installer. See the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation">
   CUDA Cross-Platform Installation
  </a>
  section for more details.
 </p>
 <h2>
  <span class="section-number">
   2.7.
  </span>
  Download the NVIDIA CUDA Toolkit
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#download-the-nvidia-cuda-toolkit" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The NVIDIA CUDA Toolkit is available at
  <a class="reference external" href="https://developer.nvidia.com/cuda-downloads">
   https://developer.nvidia.com/cuda-downloads
  </a>
  .
 </p>
 <p>
  Choose the platform you are using and download the NVIDIA CUDA Toolkit.
 </p>
 <p>
  The CUDA Toolkit contains the CUDA driver and tools needed to create, build and run a CUDA application as well as libraries, header files, and other resources.
 </p>
 <p>
  Download Verification
 </p>
 <p>
  The download can be verified by comparing the MD5 checksum posted at
  <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/12.5.1/docs/sidebar/md5sum.txt">
   https://developer.download.nvidia.com/compute/cuda/12.5.1/docs/sidebar/md5sum.txt
  </a>
  with that of the downloaded file. If either of the checksums differ, the downloaded file is corrupt and needs to be downloaded again.
 </p>
 <p>
  To calculate the MD5 checksum of the downloaded file, run the following:
 </p>
 <pre>md5sum &lt;file&gt;
</pre>
 <h2>
  <span class="section-number">
   2.8.
  </span>
  Address Custom xorg.conf, If Applicable
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#address-custom-xorg-conf-if-applicable" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The driver relies on an automatically generated
  <span class="pre">
   xorg.conf
  </span>
  file at
  <span class="pre">
   /etc/X11/xorg.conf
  </span>
  . If a custom-built
  <span class="pre">
   xorg.conf
  </span>
  file is present, this functionality will be disabled and the driver may not work. You can try removing the existing
  <span class="pre">
   xorg.conf
  </span>
  file, or adding the contents of
  <span class="pre">
   /etc/X11/xorg.conf.d/00-nvidia.conf
  </span>
  to the
  <span class="pre">
   xorg.conf
  </span>
  file. The
  <span class="pre">
   xorg.conf
  </span>
  file will most likely need manual tweaking for systems with a non-trivial GPU configuration.
 </p>
 <h2>
  <span class="section-number">
   2.9.
  </span>
  Handle Conflicting Installation Methods
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#handle-conflicting-installation-methods" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Before installing CUDA, any previous installations that could conflict should be uninstalled. This will not affect systems which have not had CUDA installed previously, or systems where the installation method has been preserved (RPM/Deb vs. Runfile). See the following charts for specifics.
 </p>
 <table class="table-no-stripes docutils align-default" id="id16">
  <span class="caption-number">
   Table 3
  </span>
  <span class="caption-text">
   CUDA Toolkit Installation Compatibility Matrix
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id16" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <td colspan="2">
    <p>
     Installed Toolkit Version == X.Y
    </p>
   </td>
   <td colspan="2">
    <p>
     Installed Toolkit Version != X.Y
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     RPM/Deb
    </p>
   </td>
   <td>
    <p>
     run
    </p>
   </td>
   <td>
    <p>
     RPM/Deb
    </p>
   </td>
   <td>
    <p>
     run
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td rowspan="2">
    <p>
     Installing Toolkit Version X.Y
    </p>
   </td>
   <td>
    <p>
     RPM/Deb
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
   <td>
    <p>
     Uninstall Run
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     run
    </p>
   </td>
   <td>
    <p>
     Uninstall RPM/Deb
    </p>
   </td>
   <td>
    <p>
     Uninstall Run
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
  </tr>
 </table>
 <table class="table-no-stripes docutils align-default" id="id17">
  <span class="caption-number">
   Table 4
  </span>
  <span class="caption-text">
   NVIDIA Driver Installation Compatibility Matrix
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id17" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <td colspan="2">
    <p>
     Installed Driver Version == X.Y
    </p>
   </td>
   <td colspan="2">
    <p>
     Installed Driver Version != X.Y
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     RPM/Deb
    </p>
   </td>
   <td>
    <p>
     run
    </p>
   </td>
   <td>
    <p>
     RPM/Deb
    </p>
   </td>
   <td>
    <p>
     run
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td rowspan="2">
    <p>
     Installing Driver Version X.Y
    </p>
   </td>
   <td>
    <p>
     RPM/Deb
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
   <td>
    <p>
     Uninstall Run
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
   <td>
    <p>
     Uninstall Run
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     run
    </p>
   </td>
   <td>
    <p>
     Uninstall RPM/Deb
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
   <td>
    <p>
     Uninstall RPM/Deb
    </p>
   </td>
   <td>
    <p>
     No Action
    </p>
   </td>
  </tr>
 </table>
 <p>
  Use the following command to uninstall a Toolkit runfile installation:
 </p>
 <pre>sudo /usr/local/cuda-X.Y/bin/cuda-uninstaller
</pre>
 <p>
  Use the following command to uninstall a Driver runfile installation:
 </p>
 <pre>sudo /usr/bin/nvidia-uninstall
</pre>
 <p>
  Use the following commands to uninstall an RPM/Deb installation:
 </p>
 <pre>sudo dnf remove &lt;package_name&gt;                      # RHEL 8 / Rocky Linux 8
</pre>
 <pre>sudo dnf remove &lt;package_name&gt;                      # Fedora
</pre>
 <pre>sudo zypper remove &lt;package_name&gt;                   # OpenSUSE / SLES
</pre>
 <pre>sudo apt-get --purge remove &lt;package_name&gt;          # Ubuntu
</pre>
 <h1>
  <span class="section-number">
   3.
  </span>
  Package Manager Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-installation" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Basic instructions can be found in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#linux">
   Quick Start Guide
  </a>
  . Read on for more detailed instructions.
 </p>
 <h2>
  <span class="section-number">
   3.1.
  </span>
  Overview
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#overview" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Installation using RPM or Debian packages interfaces with your systemâs package management system. When using RPM or Debian local repo installers, the downloaded package contains a repository snapshot stored on the local filesystem in /var/. Such a package only informs the package manager where to find the actual installation packages, but will not install them.
 </p>
 <p>
  If the online network repository is enabled, RPM or Debian packages will be automatically downloaded at installation time using the package manager: apt-get, dnf, yum, or zypper.
 </p>
 <p>
  Distribution-specific instructions detail how to install CUDA:
 </p>
 <ul class="simple">
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-rocky-8">
     RHEL 8 / Rocky Linux 8
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-rocky-9">
     RHEL 9 / Rocky Linux 9
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kylinos-10">
     KylinOS 10
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#fedora">
     Fedora
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#sles">
     SLES
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opensuse">
     OpenSUSE
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#wsl">
     WSL
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">
     Ubuntu
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#debian">
     Debian
    </a>
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#amazon">
     Amazon Linux 2023
    </a>
   </p>
  </li>
 </ul>
 <p>
  Finally, some helpful
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#additional-package-manager-capabilities">
   package manager capabilities
  </a>
  are detailed.
 </p>
 <p>
  These instructions are for native development only. For cross-platform development, see the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cross-platform">
   CUDA Cross-Platform Environment
  </a>
  section.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Optional components such as
  <span class="pre">
   nvidia-fs
  </span>
  ,
  <span class="pre">
   libnvidia_nscq
  </span>
  , and
  <span class="pre">
   fabricmanager
  </span>
  are not installed by default and will have to be installed separately as needed.
 </p>
 <h2>
  <span class="section-number">
   3.2.
  </span>
  RHEL 8 / Rocky 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-rocky-8" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.2.1.
  </span>
  Prepare RHEL 8 / Rocky 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-rhel-8-rocky-8" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r)
</pre>
   <p>
    If matching kernel-headers and kernel-devel packages are not available for the currently running kernel version, you may need to use the previously shipped version of these packages. See
    <a class="reference external" href="https://bugzilla.redhat.com/show_bug.cgi?id=1986132">
     https://bugzilla.redhat.com/show_bug.cgi?id=1986132
    </a>
    for more information.
   </p>
  </li>
  <li>
   <p>
    Satisfy third-party package dependency:
   </p>
   <ul>
    <li>
     <p>
      Satisfy DKMS dependency
      : The NVIDIA driver RPM packages depend on other external packages, such as DKMS and
      <span class="pre">
       libvdpau
      </span>
      . Those packages are only available on third-party repositories, such as
      <a class="reference external" href="http://fedoraproject.org/wiki/EPEL">
       EPEL
      </a>
      . Any such third-party repositories must be added to the package manager repository database before installing the NVIDIA driver RPM packages, or missing dependencies will prevent the installation from proceeding.
     </p>
     <p>
      To enable EPEL:
     </p>
     <pre>sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm
</pre>
    </li>
    <li>
     <p>
      Enable optional repos:
     </p>
     <p>
      On
      RHEL 8 Linux
      only, execute the following steps to enable optional repositories.
     </p>
     <ul>
      <li>
       <p>
        On x86_64 systems:
       </p>
       <pre>subscription-manager repos --enable=rhel-8-for-x86_64-appstream-rpms
subscription-manager repos --enable=rhel-8-for-x86_64-baseos-rpms
subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms
</pre>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo rpm --erase gpg-pubkey-7fa2af80*
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-rhel-8-rocky-8">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-rhel-8-rocky-8">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.2.2.
  </span>
  Local Repo Installation for RHEL 8 / Rocky 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-rhel-8-rocky-8" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic simple">
  <li>
   <p>
    Install local repository on file system:
   </p>
  </li>
 </ol>
 <pre>sudo rpm --install cuda-repo-&lt;distro&gt;-X-Y-local-&lt;version&gt;*.&lt;arch&gt;.rpm
</pre>
 <h3>
  <span class="section-number">
   3.2.3.
  </span>
  Network Repo Installation for RHEL 8 / Rocky 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-rhel-8-rocky-8" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repo:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-$distro.repo
</pre>
   <p>
    where
    <span class="pre">
     $distro/$arch
    </span>
    should be replaced by one of the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      <span class="pre">
       rhel8/cross-linux-sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       rhel8/sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       rhel8/x86_64
      </span>
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Install the new CUDA public GPG key:
   </p>
   <p>
    The new GPG public key for the CUDA repository (RPM-based distros) is
    <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/fedora32/x86_64/D42D0685.pub">
     d42d0685
    </a>
    .
   </p>
   <p>
    On a fresh installation of RHEL, the dnf package manager will prompt the user to accept new keys when installing packages the first time. Indicate you accept the change when prompted.
   </p>
   <p>
    For upgrades, you must also also fetch an updated .repo entry:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-$distro.repo
</pre>
  </li>
  <li>
   <p>
    Clean Yum repository cache:
   </p>
   <pre>sudo dnf clean expire-cache
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.2.4.
  </span>
  Common Instructions for RHEL 8 / Rocky 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-instructions-for-rhel-8-rocky-8" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo dnf module install nvidia-driver:latest-dkms
sudo dnf install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Install GPUDirect Filesystem:
   </p>
   <pre>sudo dnf install nvidia-gds
</pre>
  </li>
  <li>
   <p>
    Add libcuda.so symbolic link, if necessary
   </p>
   <p>
    The
    <span class="pre">
     libcuda.so
    </span>
    library is installed in the
    <span class="pre">
     /usr/lib{,64}/nvidia
    </span>
    directory. For pre-existing projects which use
    <span class="pre">
     libcuda.so
    </span>
    , it may be useful to add a symbolic link from
    <span class="pre">
     libcuda.so
    </span>
    in the
    <span class="pre">
     /usr/lib{,64}
    </span>
    directory.
   </p>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.3.
  </span>
  RHEL 9 / Rocky 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-rocky-9" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.3.1.
  </span>
  Prepare RHEL 9 / Rocky 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-rhel-9-rocky-9" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r)
</pre>
  </li>
  <li>
   <p>
    Satisfy third-party package dependency:
   </p>
   <ul>
    <li>
     <p>
      Satisfy DKMS dependency
      : The NVIDIA driver RPM packages depend on other external packages, such as DKMS and
      <span class="pre">
       libvdpau
      </span>
      . Those packages are only available on third-party repositories, such as
      <a class="reference external" href="http://fedoraproject.org/wiki/EPEL">
       EPEL
      </a>
      . Any such third-party repositories must be added to the package manager repository database before installing the NVIDIA driver RPM packages, or missing dependencies will prevent the installation from proceeding.
     </p>
     <p>
      To enable EPEL:
     </p>
     <pre>sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm
</pre>
    </li>
    <li>
     <p>
      Enable optional repos:
     </p>
     <p>
      On
      RHEL 9 Linux
      only, execute the following steps to enable optional repositories.
     </p>
     <ul>
      <li>
       <p>
        On x86_64 systems:
       </p>
       <pre>subscription-manager repos --enable=rhel-9-for-x86_64-appstream-rpms
subscription-manager repos --enable=rhel-9-for-x86_64-baseos-rpms
subscription-manager repos --enable=codeready-builder-for-rhel-9-x86_64-rpms
</pre>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo rpm --erase gpg-pubkey-7fa2af80*
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-rhel-9-rocky-9">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-rhel-9-rocky-9">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.3.2.
  </span>
  Local Repo Installation for RHEL 9 / Rocky 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-rhel-9-rocky-9" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo rpm --install cuda-repo-&lt;distro&gt;-X-Y-local-&lt;version&gt;*.&lt;arch&gt;.rpm
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.3.3.
  </span>
  Network Repo Installation for RHEL 9 / Rocky 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-rhel-9-rocky-9" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repo:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-$distro.repo
</pre>
   <p>
    where
    <span class="pre">
     $distro/$arch
    </span>
    should be replaced by one of the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      <span class="pre">
       rhel9/cross-linux-sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       rhel9/sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       rhel9/x86_64
      </span>
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Install the new CUDA public GPG key:
   </p>
   <p>
    The new GPG public key for the CUDA repository (RPM-based distros) is
    <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/fedora32/x86_64/D42D0685.pub">
     d42d0685
    </a>
    .
   </p>
   <p>
    On a fresh installation of RHEL, the dnf package manager will prompt the user to accept new keys when installing packages the first time. Indicate you accept the change when prompted.
   </p>
   <p>
    For upgrades, you must also also fetch an updated .repo entry:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-$distro.repo
</pre>
  </li>
  <li>
   <p>
    Clean Yum repository cache:
   </p>
   <pre>sudo dnf clean expire-cache
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.3.4.
  </span>
  Common Instructions for RHEL 9 / Rocky 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-instructions-for-rhel-9-rocky-9" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo dnf module install nvidia-driver:latest-dkms
sudo dnf install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Install GPUDirect Filesystem:
   </p>
   <pre>sudo dnf install nvidia-gds
</pre>
  </li>
  <li>
   <p>
    Add libcuda.so symbolic link, if necessary
   </p>
   <p>
    The
    <span class="pre">
     libcuda.so
    </span>
    library is installed in the
    <span class="pre">
     /usr/lib{,64}/nvidia
    </span>
    directory. For pre-existing projects which use
    <span class="pre">
     libcuda.so
    </span>
    , it may be useful to add a symbolic link from
    <span class="pre">
     libcuda.so
    </span>
    in the
    <span class="pre">
     /usr/lib{,64}
    </span>
    directory.
   </p>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.4.
  </span>
  KylinOS 10
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kylinos-10" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.4.1.
  </span>
  Prepare KylinOS 10
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-kylinos-10" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r)
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-kylinos">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-kylinos">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.4.2.
  </span>
  Local Repo Installation for KylinOS
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-kylinos" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo rpm --install cuda-repo-kylin10-X-Y-local-&lt;version&gt;*.&lt;arch&gt;.rpm
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.4.3.
  </span>
  Network Repo Installation for KylinOS
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-kylinos" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repo:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/kylin10/x86_64/cuda-$distro.repo
</pre>
  </li>
  <li>
   <p>
    Install the new CUDA public GPG key:
   </p>
   <p>
    The new GPG public key for the CUDA repository (RPM-based distros) is
    <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/fedora32/x86_64/D42D0685.pub">
     d42d0685
    </a>
    .
   </p>
   <p>
    On a fresh installation of RHEL, the dnf package manager will prompt the user to accept new keys when installing packages the first time. Indicate you accept the change when prompted.
   </p>
  </li>
  <li>
   <p>
    Clean Yum repository cache:
   </p>
   <pre>sudo dnf clean expire-cache
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.4.4.
  </span>
  Common Instructions for KylinOS 10
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-instructions-for-kylinos-10" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo dnf module install nvidia-driver:latest-dkms
sudo dnf install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Install GPUDirect Filesystem:
   </p>
   <pre>sudo dnf install nvidia-gds
</pre>
  </li>
  <li>
   <p>
    Add libcuda.so symbolic link, if necessary
   </p>
   <p>
    The
    <span class="pre">
     libcuda.so
    </span>
    library is installed in the
    <span class="pre">
     /usr/lib{,64}/nvidia
    </span>
    directory. For pre-existing projects which use
    <span class="pre">
     libcuda.so
    </span>
    , it may be useful to add a symbolic link from
    <span class="pre">
     libcuda.so
    </span>
    in the
    <span class="pre">
     /usr/lib{,64}
    </span>
    directory.
   </p>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.5.
  </span>
  Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#fedora" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.5.1.
  </span>
  Prepare Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-fedora" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r)
</pre>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo rpm --erase gpg-pubkey-7fa2af80*
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-fedora">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-fedora">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.5.2.
  </span>
  Local Repo Installation for Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-fedora" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo rpm --install cuda-repo-&lt;distro&gt;-X-Y-local-&lt;version&gt;*.x86_64.rpm
</pre>
   <p>
    where
    <span class="pre">
     distro
    </span>
    is
    <span class="pre">
     fedora37
    </span>
    or
    <span class="pre">
     fedora39
    </span>
    , for example.
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.5.3.
  </span>
  Network Repo Installation for Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-fedora" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repo:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$distro/x86_64/cuda-$distro.repo
</pre>
   <p>
    where
    <span class="pre">
     $distro
    </span>
    should be replaced by one of the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      <span class="pre">
       fedora37
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       fedora39
      </span>
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Install the new CUDA public GPG key:
   </p>
   <p>
    The new GPG public key for the CUDA repository (RPM-based distros) is
    <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/fedora32/x86_64/D42D0685.pub">
     d42d0685
    </a>
    .
   </p>
   <p>
    On a fresh installation of Fedora, the dnf package manager will prompt the user to accept new keys when installing packages the first time. Indicate you accept the change when prompted.
   </p>
   <p>
    For upgrades, you must also fetch an updated
    <span class="pre">
     .repo
    </span>
    entry:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/$distro/x86_64/cuda-$distro.repo
</pre>
  </li>
  <li>
   <p>
    Clean DNF repository cache:
   </p>
   <pre>sudo dnf clean expire-cache
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.5.4.
  </span>
  Common Installation Instructions for Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-fedora" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for Fedora.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo dnf module install nvidia-driver:latest-dkms
sudo dnf install cuda-toolkit
</pre>
   <p class="admonition-title">
    Note
   </p>
   <p>
    The CUDA driver installation may fail if the RPMFusion non-free repository is enabled. In this case, CUDA installations should temporarily disable the RPMFusion non-free repository.
   </p>
   <pre>sudo dnf --disablerepo="rpmfusion-nonfree*" install cuda
</pre>
   <p>
    It may be necessary to rebuild the grub configuration files, particularly if you use a non-default partition scheme. If so, then run this below command, and reboot the system:
   </p>
   <pre>sudo grub2-mkconfig -o /boot/grub2/grub.cfg
</pre>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Add libcuda.so symbolic link, if necessary:
   </p>
   <p>
    The
    <span class="pre">
     libcuda.so
    </span>
    library is installed in the
    <span class="pre">
     /usr/lib{,64}/nvidia
    </span>
    directory. For pre-existing projects which use
    <span class="pre">
     libcuda.so
    </span>
    , it may be useful to add a symbolic link from
    <span class="pre">
     libcuda.so
    </span>
    in the
    <span class="pre">
     /usr/lib{,64}
    </span>
    directory.
   </p>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.6.
  </span>
  SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#sles" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.6.1.
  </span>
  Prepare SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-sles" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo zypper install -y kernel-&lt;variant&gt;-devel=&lt;version&gt;
</pre>
   <p>
    To run the above command, you will need the variant and version of the currently running kernel. Use the output of the
    <span class="pre">
     uname
    </span>
    command to determine the currently running kernelâs variant and version:
   </p>
   <pre>$ uname -r
3.16.6-2-default
</pre>
   <p>
    In the above example, the variant is
    <span class="pre">
     default
    </span>
    and version is
    <span class="pre">
     3.16.6-2
    </span>
    .
   </p>
   <p>
    The kernel development packages for the default kernel variant can be installed with:
   </p>
   <pre>sudo zypper install -y kernel-default-devel=$(uname -r | sed 's/\-default//')
</pre>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo zypper install -y kernel-&lt;variant&gt;-devel=&lt;version&gt;
</pre>
  </li>
  <li>
   <p>
    On SLES12 SP4, install the Mesa-libgl-devel Linux packages before proceeding. See
    <a class="reference external" href="https://pkgs.org/download/Mesa-libGL-devel">
     Mesa-libGL-devel.
    </a>
   </p>
  </li>
  <li>
   <p>
    Add the user to the video group:
   </p>
   <pre>sudo usermod -a -G video &lt;username&gt;
</pre>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo rpm --erase gpg-pubkey-7fa2af80*
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-sles">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-sles">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.6.2.
  </span>
  Local Repo Installation for SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-sles" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic simple">
  <li>
   <p>
    Install local repository on file system:
   </p>
  </li>
 </ol>
 <pre>sudo rpm --install cuda-repo-sles15-X-Y-local-&lt;version&gt;*.x86_64.rpm
</pre>
 <h3>
  <span class="section-number">
   3.6.3.
  </span>
  Network Repo Installation for SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-sles" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repo:
   </p>
   <pre>sudo zypper addrepo https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-$distro.repo
</pre>
   <p>
    where
    <span class="pre">
     $distro/$arch
    </span>
    should be replaced by one of the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      <span class="pre">
       sles15/cross-linux-sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       sles15/sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       sles15/x86_64
      </span>
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    Install the new CUDA public GPG key:
   </p>
   <p>
    The new GPG public key for the CUDA repository (RPM-based distros) is
    <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/fedora32/x86_64/D42D0685.pub">
     d42d0685
    </a>
    .
   </p>
   <p>
    On a fresh installation of SLES, the zypper package manager will prompt the user to accept new keys when installing packages the first time. Indicate you accept the change when prompted.
   </p>
   <p>
    For upgrades, you must also also fetch an updated .repo entry:
   </p>
   <pre>sudo zypper removerepo cuda-$distro-$arch
sudo zypper addrepo https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-$distro.repo
</pre>
  </li>
  <li>
   <p>
    Refresh Zypper repository cache:
   </p>
   <pre>sudo SUSEConnect --product PackageHub/15/&lt;architecture&gt;
sudo zypper refresh
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.6.4.
  </span>
  Common Installation Instructions for SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-sles" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for SLES.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo zypper install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Install CUDA Samples GL dependencies:
   </p>
   <p>
    Refer to
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-samples">
     CUDA Cross-Platform Samples
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.7.
  </span>
  OpenSUSE
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opensuse" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.7.1.
  </span>
  Prepare OpenSUSE
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-opensuse" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo zypper install -y kernel-&lt;variant&gt;-devel=&lt;version&gt;
</pre>
   <p>
    To run the above command, you will need the variant and version of the currently running kernel. Use the output of the
    <span class="pre">
     uname
    </span>
    command to determine the currently running kernelâs variant and version:
   </p>
   <pre>$ uname -r
3.16.6-2-default
</pre>
   <p>
    In the above example, the variant is
    <span class="pre">
     default
    </span>
    and version is
    <span class="pre">
     3.16.6-2
    </span>
    .
   </p>
   <p>
    The kernel development packages for the default kernel variant can be installed with:
   </p>
   <pre>sudo zypper install -y kernel-default-devel=$(uname -r | sed 's/\-default//')
</pre>
  </li>
  <li>
   <p>
    Add the user to the video group:
   </p>
   <pre>sudo usermod -a -G video &lt;username&gt;
</pre>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo rpm --erase gpg-pubkey-7fa2af80*
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-opensuse">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-opensuse">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.7.2.
  </span>
  Local Repo Installation for OpenSUSE
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-opensuse" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo rpm --install cuda-repo-opensuse15-&lt;version&gt;.x86_64.rpm
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.7.3.
  </span>
  Network Repo Installation for OpenSUSE
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-opensuse" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repo:
   </p>
   <pre>sudo zypper addrepo https://developer.download.nvidia.com/compute/cuda/repos/opensuse15/x86_64/cuda-opensuse15.repo
</pre>
  </li>
  <li>
   <p>
    Install the new CUDA public GPG key:
   </p>
   <p>
    The new GPG public key for the CUDA repository (RPM-based distros) is
    <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/fedora32/x86_64/D42D0685.pub">
     d42d0685
    </a>
    . On fresh installation of openSUSE, the zypper package manager will prompt the user to accept new keys when installing packages the first time. Indicate you accept the change when prompted.
   </p>
   <p>
    For upgrades, you must also also fetch an updated .repo entry:
   </p>
   <pre>sudo zypper removerepo cuda-opensuse15-x86_64
sudo zypper addrepo https://developer.download.nvidia.com/compute/cuda/repos/opensuse15/x86_64/cuda-opensuse15.repo
</pre>
  </li>
  <li>
   <p>
    Refresh Zypper repository cache:
   </p>
   <pre>sudo zypper refresh
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.7.4.
  </span>
  Common Installation Instructions for OpenSUSE
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-opensuse" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for OpenSUSE.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo zypper install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.8.
  </span>
  WSL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#wsl" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  These instructions must be used if you are installing in a WSL environment. Do not use the Ubuntu instructions in this case; it is important to not install the
  <span class="pre">
   cuda-drivers
  </span>
  packages within the WSL environment.
 </p>
 <h3>
  <span class="section-number">
   3.8.1.
  </span>
  Prepare WSL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-wsl" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo apt-key del 7fa2af80
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-wsl">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-wsl">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.8.2.
  </span>
  Local Repo Installation for WSL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-wsl" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repositiry on file system:
   </p>
   <pre>sudo dpkg -i cuda-repo-wsl-ubuntu-X-Y-local_&lt;version&gt;*_x86_64.deb
</pre>
  </li>
  <li>
   <p>
    Enroll ephemeral public GPG key:
   </p>
   <pre>sudo cp /var/cuda-repo-wsl-ubuntu-X-Y-local/cuda-*-keyring.gpg /usr/share/keyrings/
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.8.3.
  </span>
  Network Repo Installation for WSL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-wsl" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The new GPG public key for the CUDA repository (Debian-based distros) is
  <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/3bf863cc.pub">
   3bf863cc
  </a>
  . This must be enrolled on the system, either using the
  <span class="pre">
   cuda-keyring
  </span>
  package or manually; the
  <span class="pre">
   apt-key
  </span>
  command is deprecated and not recommended.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the newcuda-keyring package:
   </p>
   <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
</pre>
   <p>
    Or if you are unable to install the cuda-keyring package, you can optionally:
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      Enroll the new signing key manually:
     </p>
     <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-archive-keyring.gpg
sudo mv cuda-archive-keyring.gpg /usr/share/keyrings/cuda-archive-keyring.gpg
</pre>
    </li>
    <li>
     <p>
      Enable the network repository:
     </p>
     <pre>echo "deb [signed-by=/usr/share/keyrings/cuda-archive-keyring.gpg] https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/ /" | sudo tee /etc/apt/sources.list.d/cuda-wsl-ubuntu-x86_64.list
</pre>
    </li>
    <li>
     <p>
      Add pin file to prioritize CUDA repository:
     </p>
     <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin
sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600
</pre>
    </li>
   </ol>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.8.4.
  </span>
  Common Installation Instructions for WSL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-wsl" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for WSL.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Update the Apt repository cache:
   </p>
   <pre>sudo apt-get update
</pre>
  </li>
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo apt-get install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.9.
  </span>
  Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.9.1.
  </span>
  Prepare Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo apt-get install linux-headers-$(uname -r)
</pre>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo apt-key del 7fa2af80
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-ubuntu">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-ubuntu">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.9.2.
  </span>
  Local Repo Installation for Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo dpkg -i cuda-repo-&lt;distro&gt;_&lt;version&gt;_&lt;architecture&gt;.deb
</pre>
  </li>
  <li>
   <p>
    Enroll ephemeral public GPG key:
   </p>
   <pre>sudo cp /var/cuda-repo-&lt;distro&gt;-X-Y-local/cuda-*-keyring.gpg /usr/share/keyrings/
</pre>
  </li>
  <li>
   <p>
    Add pin file to prioritize CUDA repository:
   </p>
   <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/x86_64/cuda-&lt;distro&gt;.pin
 sudo mv cuda-&lt;distro&gt;.pin /etc/apt/preferences.d/cuda-repository-pin-600
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.9.3.
  </span>
  Network Repo Installation for Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The new GPG public key for the CUDA repository is
  <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/3bf863cc.pub">
   3bf863cc
  </a>
  . This must be enrolled on the system, either using the
  <span class="pre">
   cuda-keyring
  </span>
  package or manually; the
  <span class="pre">
   apt-key
  </span>
  command is deprecated and not recommended.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the new cuda-keyring package:
   </p>
   <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
</pre>
   <p>
    where
    <span class="pre">
     $distro/$arch
    </span>
    should be replaced by one of the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      <span class="pre">
       ubuntu1604/x86_64
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu1804/cross-linux-sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu1804/sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu1804/x86_64
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2004/cross-linux-aarch64
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2004/arm64
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2004/cross-linux-sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2004/sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2004/x86_64
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2204/sbsa
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       ubuntu2204/x86_64
      </span>
     </p>
    </li>
   </ul>
   <p class="admonition-title">
    Note
   </p>
   <p>
    arm64-Jetson repos:
   </p>
   <ul class="simple">
    <li>
     <p>
      native:
      <span class="pre">
       $distro/arm64
      </span>
     </p>
    </li>
    <li>
     <p>
      cross:
      <span class="pre">
       $distro/cross-linux-aarch64
      </span>
     </p>
    </li>
   </ul>
   <pre>sudo dpkg -i cuda-keyring_1.1-1_all.deb
</pre>
  </li>
  <li>
   <p>
    Or if you are unable to install the
    <span class="pre">
     cuda-keyring
    </span>
    package, you can optionally:
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      Enroll the new signing key manually:
     </p>
     <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/&lt;arch&gt;/cuda-archive-keyring.gpg
sudo mv cuda-archive-keyring.gpg /usr/share/keyrings/cuda-archive-keyring.gpg
</pre>
    </li>
    <li>
     <p>
      Enable the network repository:
     </p>
     <pre>echo "deb [signed-by=/usr/share/keyrings/cuda-archive-keyring.gpg] https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/&lt;arch&gt;/ /" | sudo tee /etc/apt/sources.list.d/cuda-&lt;distro&gt;-&lt;arch&gt;.list
</pre>
    </li>
    <li>
     <p>
      Add pin file to prioritize CUDA repository:
     </p>
     <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/&lt;arch&gt;/cuda-&lt;distro&gt;.pin
sudo mv cuda-&lt;distro&gt;.pin /etc/apt/preferences.d/cuda-repository-pin-600
</pre>
    </li>
   </ol>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.9.4.
  </span>
  Common Installation Instructions for Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for Ubuntu.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Update the Apt repository cache:
   </p>
   <pre>sudo apt-get update
</pre>
  </li>
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <p class="admonition-title">
    Note
   </p>
   <p>
    These two commands must be executed separately.
   </p>
   <pre>sudo apt-get install cuda-toolkit
</pre>
   <p>
    To include all GDS packages:
   </p>
   <pre>sudo apt-get install nvidia-gds
</pre>
  </li>
  <li>
   <p>
    Reboot the system
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     Post-installation Actions
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.10.
  </span>
  Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#debian" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.10.1.
  </span>
  Prepare Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-debian" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo apt-get install linux-headers-$(uname -r)
</pre>
  </li>
  <li>
   <p>
    Enable the contrib repository:
   </p>
   <pre>sudo add-apt-repository contrib
</pre>
  </li>
  <li>
   <p>
    Remove Outdated Signing Key:
   </p>
   <pre>sudo apt-key del 7fa2af80
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-debian">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-debian">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.10.2.
  </span>
  Local Repo Installation for Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-debian" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo dpkg -i cuda-repo-&lt;distro&gt;-X-Y-local_&lt;version&gt;*_x86_64.deb
</pre>
  </li>
  <li>
   <p>
    Enroll ephemeral public GPG key:
   </p>
   <pre>sudo cp /var/cuda-repo-&lt;distro&gt;-X-Y-local/cuda-*-keyring.gpg /usr/share/keyrings/
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.10.3.
  </span>
  Network Repo Installation for Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-debian" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The new GPG public key for the CUDA repository (Debian-based distros) is
  <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/3bf863cc.pub">
   3bf863cc
  </a>
  . This must be enrolled on the system, either using the cuda-keyring package or manually; the
  <span class="pre">
   apt-key
  </span>
  command is deprecated and not recommended.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the new cuda-keyring package:
   </p>
   <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/&lt;arch&gt;/cuda-keyring_1.1-1_all.deb
</pre>
   <p>
    where
    <span class="pre">
     $distro/$arch
    </span>
    should be replaced by one of the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      <span class="pre">
       debian10/x86_64
      </span>
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       debian11/x86_64
      </span>
     </p>
    </li>
   </ul>
   <pre>sudo dpkg -i cuda-keyring_1.1-1_all.deb
</pre>
  </li>
  <li>
   <p>
    Or if you are unable to install the
    <span class="pre">
     cuda-keyring
    </span>
    package, you can optionally:
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      Enroll the new signing key manually:
     </p>
     <pre>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/x86_64/cuda-archive-keyring.gpg
sudo mv cuda-archive-keyring.gpg /usr/share/keyrings/cuda-archive-keyring.gpg
</pre>
    </li>
    <li>
     <p>
      Enable the network repository:
     </p>
     <pre>echo "deb [signed-by=/usr/share/keyrings/cuda-archive-keyring.gpg] https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/x86_64/ /" | sudo tee /etc/apt/sources.list.d/cuda-&lt;distro&gt;-x86_64.list
</pre>
    </li>
   </ol>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.10.4.
  </span>
  Common Installation Instructions for Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-debian" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for Debian.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Update the Apt repository cache:
   </p>
   <pre>sudo apt-get update
</pre>
   <p class="admonition-title">
    Note
   </p>
   <p>
    If you are using Debian 10, you may instead need to run:
   </p>
   <pre>sudo apt-get --allow-releaseinfo-change update
</pre>
  </li>
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo apt-get -y install cuda
</pre>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.11.
  </span>
  Amazon Linux 2023
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#amazon-linux-2023" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.11.1.
  </span>
  Prepare Amazon Linux 2023
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#prepare-amazon-linux-2023" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    The kernel headers and development packages for the currently running kernel can be installed with:
   </p>
   <pre>sudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r) kernel-modules-extra-$(uname -r)
</pre>
  </li>
  <li>
   <p>
    Choose an installation method:
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-amazon">
     local repo
    </a>
    or
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-amazon">
     network repo
    </a>
    .
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.11.2.
  </span>
  Local Repo Installation for Amazon Linux
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-installation-for-amazon-linux" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Install local repository on file system:
   </p>
   <pre>sudo rpm --install cuda-repo-amzn2023-X-Y-local-&lt;version&gt;*.x86_64.rpm
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.11.3.
  </span>
  Network Repo Installation for Amazon Linux
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#network-repo-installation-for-amazon-linux" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Enable the network repository:
   </p>
   <pre>sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/amzn2023/x86_64/cuda-amzn2023.repo
</pre>
  </li>
  <li>
   <p>
    Clean DNF repository cache:
   </p>
   <pre>sudo dnf clean expire-cache
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   3.11.4.
  </span>
  Common Installation Instructions for Amazon Linux
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#common-installation-instructions-for-amazon-linux" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These instructions apply to both local and network installation for Amazon Linux.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install CUDA SDK:
   </p>
   <pre>sudo dnf module install nvidia-driver:latest-dkms
sudo dnf install cuda-toolkit
</pre>
  </li>
  <li>
   <p>
    Install GPUDirect Filesystem:
   </p>
   <pre>sudo dnf install nvidia-gds
</pre>
  </li>
  <li>
   <p>
    Add libcuda.so symbolic link, if necessary:
   </p>
   <p>
    The
    <span class="pre">
     libcuda.so
    </span>
    library is installed in the
    <span class="pre">
     /usr/lib{,64}/nvidia
    </span>
    directory. For pre-existing projects which use
    <span class="pre">
     libcuda.so
    </span>
    , it may be useful to add a symbolic link from
    <span class="pre">
     libcuda.so
    </span>
    in the
    <span class="pre">
     /usr/lib{,64}
    </span>
    directory.
   </p>
  </li>
  <li>
   <p>
    Reboot the system:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   3.12.
  </span>
  Additional Package Manager Capabilities
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#additional-package-manager-capabilities" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Below are some additional capabilities of the package manager that users can take advantage of.
 </p>
 <h3>
  <span class="section-number">
   3.12.1.
  </span>
  Available Packages
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#available-packages" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The recommended installation package is the
  <span class="pre">
   cuda
  </span>
  package. This package will install the full set of other CUDA packages required for native development and should cover most scenarios.
 </p>
 <p>
  The
  <span class="pre">
   cuda
  </span>
  package installs all the available packages for native developments. That includes the compiler, the debugger, the profiler, the math libraries, and so on. For x86_64 platforms, this also includes Nsight Eclipse Edition and the visual profilers. It also includes the NVIDIA driver package.
 </p>
 <p>
  On supported platforms, the
  <span class="pre">
   cuda-cross-aarch64
  </span>
  and
  <span class="pre">
   cuda-cross-sbsa
  </span>
  packages install all the packages required for cross-platform development to arm64-Jetson and arm64-Server, respectively. The libraries and header files of the target architectureâs display driver package are also installed to enable the cross compilation of driver applications. The
  <span class="pre">
   cuda-cross-&lt;arch&gt;
  </span>
  packages do not install the native display driver.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  32-bit compilation native and cross-compilation is removed from CUDA 12.0 and later Toolkit. Use the CUDA Toolkit from earlier releases for 32-bit compilation. CUDA Driver will continue to support running existing 32-bit applications on existing GPUs except Hopper. Hopper does not support 32-bit applications. Ada will be the last architecture with driver support for 32-bit applications.
 </p>
 <p>
  The packages installed by the packages above can also be installed individually by specifying their names explicitly. The list of available packages be can obtained with:
 </p>
 <pre>yum --disablerepo="*" --enablerepo="cuda*" list available    # RedHat
</pre>
 <pre>dnf --disablerepo="*" --enablerepo="cuda*" list available    # Fedora
</pre>
 <pre>zypper packages -r cuda                                      # OpenSUSE &amp; SLES
</pre>
 <pre>cat /var/lib/apt/lists/*cuda*Packages | grep "Package:"      # Ubuntu
</pre>
 <h3>
  <span class="section-number">
   3.12.2.
  </span>
  Meta Packages
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#meta-packages" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Meta packages are RPM/Deb/Conda packages which contain no (or few) files but have multiple dependencies. They are used to install many CUDA packages when you may not know the details of the packages you want. The following table lists the meta packages.
 </p>
 <table class="table-no-stripes docutils align-default" id="id18">
  <span class="caption-number">
   Table 5
  </span>
  <span class="caption-text">
   Meta Packages Available for CUDA 12.4
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id18" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Meta Package
    </p>
   </th>
   <th class="head">
    <p>
     Purpose
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     cuda
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA Toolkit and Driver packages. Handles upgrading to the next version of the
     <span class="pre">
      cuda
     </span>
     package when itâs released.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     cuda-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA Toolkit and Driver packages. Remains at version 12.5 until an additional version of CUDA is installed.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     cuda-toolkit-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA Toolkit packages required to develop CUDA applications. Does not include the driver.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     cuda-toolkit-15
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA Toolkit packages required to develop applications. Will not upgrade beyond the 12.x series toolkits. Does not include the driver.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     cuda-toolkit
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA Toolkit packages required to develop applications. Handles upgrading to the next 12.x version of CUDA when itâs released. Does not include the driver.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     cuda-tools-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA command line and visual tools.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     cuda-runtime-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA Toolkit packages required to run CUDA applications, as well as the Driver packages.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     cuda-compiler-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all CUDA compiler packages.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     cuda-libraries-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all runtime CUDA Library packages.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     cuda-libraries-dev-12-5
    </p>
   </td>
   <td>
    <p>
     Installs all development CUDA Library packages.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     cuda-drivers
    </p>
   </td>
   <td>
    <p>
     Installs all NVIDIA Driver packages with proprietary kernel modules. Handles upgrading to the next version of the Driver packages when theyâre released.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     cuda-drivers-555
    </p>
   </td>
   <td>
    <p>
     Installs all NVIDIA Driver packages with proprietary kernel modules. Will not upgrade beyond the 555 branch drivers.
    </p>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.12.3.
  </span>
  Optional 32-bit Packages for Linux x86_64 .deb/.rpm
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#optional-32-bit-packages-for-linux-x86-64-deb-rpm" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  These packages provide 32-bit driver libraries needed for things such as Steam (popular game app store/launcher), older video games, and some compute applications.
 </p>
 <p>
  For Debian 10 and Debian 11:
 </p>
 <pre>sudo dpkg --add-architecture i386
sudo apt-get update
sudo apt-get install libcuda1-i386 nvidia-driver-libs-i386
</pre>
 <p>
  For Debian 12:
 </p>
 <pre>sudo dpkg --add-architecture i386
sudo apt-get update
apt install nvidia-driver-libs:i386
</pre>
 <p>
  For Ubuntu:
 </p>
 <pre>sudo dpkg --add-architecture i386
sudo apt-get update
sudo apt-get install libnvidia-compute-&lt;branch&gt;:i386 libnvidia-decode-&lt;branch&gt;:i386 \
 libnvidia-encode-&lt;branch&gt;:i386 libnvidia-extra-&lt;branch&gt;:i386 libnvidia-fbc1-&lt;branch&gt;:i386 \
 libnvidia-gl-&lt;branch&gt;:i386
</pre>
 <p>
  Where
  <span class="pre">
   &lt;branch&gt;
  </span>
  is the driver version, for example 495.
 </p>
 <p>
  For Fedora and RHEL8+:
 </p>
 <pre>sudo dnf install nvidia-driver-cuda-libs.i686 nvidia-driver-devel.i686 \
 nvidia-driver-libs.i686 nvidia-driver-NvFBCOpenGL.i686 nvidia-driver-NVML.i686
</pre>
 <p class="admonition-title">
  Note
 </p>
 <p>
  There is no modularity profile support.
 </p>
 <p>
  For openSUSE/SLES:
 </p>
 <pre>sudo zypper install nvidia-compute-G06-32bit nvidia-gl-G06-32bit nvidia-video-G06-32bit
</pre>
 <h3>
  <span class="section-number">
   3.12.4.
  </span>
  Package Upgrades
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-upgrades" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  <span class="pre">
   cuda
  </span>
  package points to the latest stable release of the CUDA Toolkit. When a new version is available, use the following commands to upgrade the toolkit and driver:
 </p>
 <pre>sudo dnf install cuda-toolkit                                # Fedora, RHEL9, RHEL8, and KylinOS
</pre>
 <pre>sudo zypper install cuda-toolkit                             # OpenSUSE and SLES
</pre>
 <pre>sudo apt-get install cuda-toolkit                            # Ubuntu and Debian
</pre>
 <p>
  The
  <span class="pre">
   cuda-cross-&lt;arch&gt;
  </span>
  packages can also be upgraded in the same manner.
 </p>
 <p>
  The cuda-drivers package points to the latest driver release available in the CUDA repository. When a new version is available, use the following commands to upgrade the driver:
 </p>
 <pre>sudo dnf module install nvidia-driver:latest-dkms             # Fedora, RHEL9, RHEL8, and KylinOS
</pre>
 <pre>sudo zypper install cuda-drivers nvidia-gfxG04-kmp-default   # OpenSUSE and SLES
</pre>
 <pre>sudo apt-get install cuda-drivers                            # Ubuntu and Debian
</pre>
 <p>
  Some desktop environments, such as GNOME or KDE, will display a notification alert when new packages are available.
 </p>
 <p>
  To avoid any automatic upgrade, and lock down the toolkit installation to the X.Y release, install the
  <span class="pre">
   cuda-X-Y
  </span>
  or
  <span class="pre">
   cuda-cross-&lt;arch&gt;-X-Y
  </span>
  package.
 </p>
 <p>
  Side-by-side installations are supported. For instance, to install both the X.Y CUDA Toolkit and the X.Y+1 CUDA Toolkit, install the
  <span class="pre">
   cuda-X.Y
  </span>
  and
  <span class="pre">
   cuda-X.Y+1
  </span>
  packages.
 </p>
 <h1>
  <span class="section-number">
   4.
  </span>
  Driver Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#driver-installation" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  This section is for users who want to install a specific driver version.
 </p>
 <p>
  For Debian and Ubuntu:
 </p>
 <pre>sudo apt-get install cuda-drivers-&lt;driver_branch&gt;
</pre>
 <p>
  For example:
 </p>
 <pre>sudo apt-get install cuda-drivers-535
</pre>
 <p>
  For OpenSUSE and SLES:
 </p>
 <pre>sudo zypper -v install cuda-drivers-&lt;driver_branch&gt;
</pre>
 <p>
  For example:
 </p>
 <pre>sudo zypper -v install cuda-drivers-550
</pre>
 <p>
  This allows you to get the highest version in the specified branch.
 </p>
 <p>
  For Fedora and RHEL8+:
 </p>
 <pre>sudo dnf module install nvidia-driver:&lt;stream&gt;/&lt;profile&gt;
</pre>
 <p>
  where profile by default is â
  <span class="pre">
   default
  </span>
  â and does not need to be specified.
 </p>
 <ul class="simple">
  <li>
   <p>
    Example dkms streams:
    <span class="pre">
     450-dkms
    </span>
    or
    <span class="pre">
     latest-dkms
    </span>
   </p>
  </li>
  <li>
   <p>
    Example precompiled streams:
    <span class="pre">
     450
    </span>
    or
    <span class="pre">
     latest
    </span>
   </p>
  </li>
 </ul>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Precompiled streams are only supported on RHEL8 x86_64 and RHEL9 x86_64.
 </p>
 <p>
  To uninstall or change streams on Fedora and RHEL8:
 </p>
 <pre>sudo dnf module remove --all nvidia-driver
sudo dnf module reset nvidia-driver
</pre>
 <h1>
  <span class="section-number">
   5.
  </span>
  NVIDIA Open GPU Kernel Modules
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#nvidia-open-gpu-kernel-modules" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  The NVIDIA Linux GPU Driver contains several kernel modules:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     nvidia.ko
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     nvidia-modeset.ko
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     nvidia-uvm.ko
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     nvidia-drm.ko
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     nvidia-peermem.ko
    </span>
   </p>
  </li>
 </ul>
 <p>
  Starting in the 515 driver release series, two âflavorsâ of these kernel modules are provided:
 </p>
 <ul class="simple">
  <li>
   <p>
    Proprietary
    - this is the flavor that NVIDIA has historically shipped.
   </p>
  </li>
  <li>
   <p>
    Open-source
    - published kernel modules that are dual licensed MIT/GPLv2. These are new starting in release 515. With every driver release, the source code to the open kernel modules will be published on
    <a class="reference external" href="https://github.com/NVIDIA/open-gpu-kernel-modules">
     https://github.com/NVIDIA/open-gpu-kernel-modules
    </a>
    and a tarball will be provided on
    <a class="reference external" href="https://download.nvidia.com/XFree86/">
     https://download.nvidia.com/XFree86/
    </a>
    .
   </p>
  </li>
 </ul>
 <p>
  Verify that your NVIDIA GPU is at least Turing or newer generation.
 </p>
 <pre>lspci | grep VGA
</pre>
 <p>
  Experimental support for GeForce and Quadro SKUs can be enabled with:
 </p>
 <pre>echo "options nvidia NVreg_OpenRmEnableUnsupportedGpus=1" | sudo tee /etc/modprobe.d/nvidia-gsp.conf
</pre>
 <p>
  To install NVIDIA Open GPU Kernel Modules, follow the instructions below.
 </p>
 <h2>
  <span class="section-number">
   5.1.
  </span>
  CUDA Runfile
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-runfile" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Pass the CLI argument to the CUDA runfile to opt in to NVIDIA Open GPU Kernel Modules:
 </p>
 <pre>sh cuda_&lt;release&gt;_&lt;version&gt;_linux.run -m=kernel-open
</pre>
 <h2>
  <span class="section-number">
   5.2.
  </span>
  Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-debian-installation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package:
   </p>
   <pre>sudo apt-get install nvidia-kernel-open-dkms
</pre>
  </li>
  <li>
   <p>
    Install the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo apt-get install cuda-drivers
</pre>
  </li>
 </ol>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package:
   </p>
   <pre>sudo apt-get install -v nvidia-kernel-open-dkms=&lt;version&gt;-1
</pre>
  </li>
  <li>
   <p>
    Install the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo apt-get install -v cuda-drivers-&lt;driver_branch&gt;
</pre>
   <p>
    For example:
   </p>
   <pre>sudo apt-get install -v nvidia-kernel-open-dkms=550.90.07-1
sudo apt-get install -v cuda-drivers-550
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   5.3.
  </span>
  Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-fedora-installation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:open-dkms
</pre>
  </li>
 </ol>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:&lt;driver_branch&gt;-open
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   5.4.
  </span>
  KylinOS 10
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kylinos10-installation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:open-dkms
</pre>
  </li>
 </ol>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:&lt;driver_branch&gt;-open
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   5.5.
  </span>
  RHEL 9 and Rocky 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-and-rocky-9" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:open-dkms
</pre>
  </li>
 </ol>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:&lt;driver_branch&gt;-open
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   5.6.
  </span>
  RHEL 8 and Rocky 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-and-rocky-8" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:open-dkms
</pre>
  </li>
 </ol>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package and the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo dnf module install nvidia-driver:&lt;driver_branch&gt;-open
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   5.7.
  </span>
  OpenSUSE and SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opensuse-and-sles" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package:
   </p>
   <pre>sudo zypper install nvidia-open-driver-G06-kmp-default
</pre>
  </li>
  <li>
   <p>
    Install the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo zypper install cuda-drivers
</pre>
  </li>
 </ol>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package:
   </p>
   <pre>sudo zypper -v install $(zypper search -s nvidia-open-driver-G06-kmp-&lt;flavor&gt; | sed 's| ||g' | awk -F '|' '/&lt;driver_branch&gt;/ {print $2"="$4}')
</pre>
  </li>
  <li>
   <p>
    Install the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo zypper -v install cuda-drivers-&lt;driver_branch&gt;
</pre>
   <p>
    For example:
   </p>
   <pre>sudo zypper -v install $(zypper search -s nvidia-open-driver-G06-kmp-default | sed 's| ||g' | awk -F '|' '/550/ {print $2"="$4}')
sudo zypper -v install cuda-drivers-550
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   5.8.
  </span>
  Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#open-ubuntu-installation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package:
   </p>
   <pre>sudo apt-get install nvidia-driver-&lt;driver_branch&gt;-open
</pre>
  </li>
  <li>
   <p>
    Install the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo apt-get install cuda-drivers-&lt;driver_branch&gt;
</pre>
  </li>
 </ol>
 <p class="admonition-title">
  Note
 </p>
 <p>
  End-users on Ubuntu should upgrade their NVIDIA Open GPU kernel modules using the following:
 </p>
 <pre>sudo apt-get install --verbose-versions nvidia-kernel-source-550-open cuda-drivers-550
</pre>
 <p>
  OR to install a specific driver version
 </p>
 <ol class="arabic">
  <li>
   <p>
    Install the NVIDIA Open GPU Kernel Modules package:
   </p>
   <pre>sudo apt-get install -v nvidia-driver-&lt;driver_branch&gt;-open
</pre>
  </li>
  <li>
   <p>
    Install the rest of the NVIDIA driver packages:
   </p>
   <pre>sudo apt-get install -v cuda-drivers-&lt;driver_branch&gt;
</pre>
   <p>
    For example:
   </p>
   <pre>sudo apt-get install -v nvidia-driver-550-open
sudo apt-get install -v cuda-drivers-550
</pre>
  </li>
 </ol>
 <h1>
  <span class="section-number">
   6.
  </span>
  Precompiled Streams
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#precompiled-streams" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Precompiled streams offer an optional method of streamlining the installation process.
 </p>
 <p>
  The advantages of precompiled streams:
 </p>
 <ul class="simple">
  <li>
   <p>
    Precompiled: faster boot up after driver and/or kernel updates
   </p>
  </li>
  <li>
   <p>
    Pre-tested: kernel and driver combination has been validated
   </p>
  </li>
  <li>
   <p>
    Removes gcc dependency: no compiler installation required
   </p>
  </li>
  <li>
   <p>
    Removes dkms dependency: enabling EPEL repository not required
   </p>
  </li>
  <li>
   <p>
    Removes kernel-devel and kernel-headers dependencies: no black screen if matching packages are missing
   </p>
  </li>
 </ul>
 <p>
  When using precompiled drivers, a plugin for the dnf package manager is enabled that cleans up stale .ko files. To prevent system breakages, the NVIDIA dnf plugin also prevents upgrading to a kernel for which no precompiled driver yet exists. This can delay the application of security fixes but ensures that a tested kernel and driver combination is always used. A warning is displayed by
  <span class="pre">
   dnf
  </span>
  during that upgrade situation:
 </p>
 <pre>NOTE:  Skipping kernel installation since no NVIDIA driver kernel module package
 kmod-nvidia-${driver}-${kernel} ... could be found
</pre>
 <p>
  Packaging templates and instructions are provided on GitHub to allow you to maintain your own precompiled kernel module packages for custom kernels and derivative Linux distros:
  <a class="reference external" href="https://github.com/NVIDIA/yum-packaging-precompiled-kmod">
   NVIDIA/yum-packaging-precompiled-kmod
  </a>
 </p>
 <p>
  To use the new driver packages on RHEL 8 or RHEL 9:
 </p>
 <ol class="arabic">
  <li>
   <p>
    First, ensure that the Red Hat repositories are enabled:
   </p>
   <p>
    RHEL 8:
   </p>
   <pre>subscription-manager repos --enable=rhel-8-for-x86_64-appstream-rpms
subscription-manager repos --enable=rhel-8-for-x86_64-baseos-rpms
</pre>
   <p>
    or
   </p>
   <p>
    RHEL 9:
   </p>
   <pre>subscription-manager repos --enable=rhel-9-for-x86_64-appstream-rpms
subscription-manager repos --enable=rhel-9-for-x86_64-baseos-rpms
</pre>
  </li>
  <li>
   <p>
    Choose
    one
    of the four options below depending on the desired driver:
   </p>
   <ul>
    <li>
     <p>
      <span class="pre">
       latest
      </span>
      always updates to the highest versioned driver (precompiled):
     </p>
     <pre>sudo dnf module install nvidia-driver:latest
</pre>
    </li>
    <li>
     <p>
      <span class="pre">
       &lt;id&gt;
      </span>
      locks the driver updates to the specified driver branch (precompiled):
     </p>
     <pre>sudo dnf module install nvidia-driver:&lt;id&gt;
</pre>
     <p class="admonition-title">
      Note
     </p>
     <p>
      Replace
      <span class="pre">
       &lt;id&gt;
      </span>
      with the appropriate driver branch streams, for example 520, 515, 470, or 450.
     </p>
    </li>
    <li>
     <p>
      latest-dkms
      always updates to the highest versioned driver (non-precompiled):
     </p>
     <pre>sudo dnf module install nvidia-driver:latest-dkms
</pre>
     <p class="admonition-title">
      Note
     </p>
     <p>
      This is the default stream.
     </p>
    </li>
    <li>
     <p>
      <span class="pre">
       &lt;id&gt;-dkms
      </span>
      locks the driver updates to the specified driver branch (non-precompiled):
     </p>
     <pre>sudo dnf module install nvidia-driver:&lt;id&gt;-dkms
</pre>
     <p class="admonition-title">
      Note
     </p>
     <p>
      Valid streams include
      <span class="pre">
       520-dkms
      </span>
      ,
      <span class="pre">
       515-dkms
      </span>
      ,
      <span class="pre">
       470-dkms
      </span>
      , and
      <span class="pre">
       450-dkms
      </span>
      .
     </p>
    </li>
   </ul>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   6.1.
  </span>
  Precompiled Streams Support Matrix
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#precompiled-streams-support-matrix" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This table shows the supported precompiled and legacy DKMS streams for each driver.
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     NVIDIA Driver
    </p>
   </th>
   <th class="head">
    <p>
     Precompiled Stream
    </p>
   </th>
   <th class="head">
    <p>
     Legacy DKMS Stream
    </p>
   </th>
   <th class="head">
    <p>
     Open DKMS Stream
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Highest version
    </p>
   </td>
   <td>
    <p>
     latest
    </p>
   </td>
   <td>
    <p>
     latest-dkms
    </p>
   </td>
   <td>
    <p>
     open-dkms
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Locked at 520.x
    </p>
   </td>
   <td>
    <p>
     520
    </p>
   </td>
   <td>
    <p>
     520-dkms
    </p>
   </td>
   <td>
    <p>
     520-open
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Locked at 515.x
    </p>
   </td>
   <td>
    <p>
     515
    </p>
   </td>
   <td>
    <p>
     515-dkms
    </p>
   </td>
   <td>
    <p>
     515-open
    </p>
   </td>
  </tr>
 </table>
 <p>
  Prior to switching between module streams, first reset:
 </p>
 <pre>sudo dnf module reset nvidia-driver
</pre>
 <p class="admonition-title">
  Note
 </p>
 <p>
  This is also required for upgrading between branch locked streams.
 </p>
 <p>
  Or alternatively:
 </p>
 <pre>sudo dnf module switch-to nvidia-driver:&lt;stream&gt;
</pre>
 <h2>
  <span class="section-number">
   6.2.
  </span>
  Modularity Profiles
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#modularity-profiles" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Modularity profiles work with any supported modularity stream and allow for additional use cases. These modularity profiles are available on RHEL8+ and Fedora.
 </p>
 <table class="table-no-stripes docutils align-default" id="id19">
  <span class="caption-number">
   Table 6
  </span>
  <span class="caption-text">
   Table 5. List of nvidia-driver Module Profiles
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id19" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Stream
    </p>
   </th>
   <th class="head">
    <p>
     Profile
    </p>
   </th>
   <th class="head">
    <p>
     Use Case
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Default
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      /default
     </span>
    </p>
   </td>
   <td>
    <p>
     Installs all the driver packages in a stream.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Kickstart
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      /ks
     </span>
    </p>
   </td>
   <td>
    <p>
     Performs unattended Linux OS installation using a config file.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     NVSwitch Fabric
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      /fm
     </span>
    </p>
   </td>
   <td>
    <p>
     Installs all the driver packages plus components required for bootstrapping an NVSwitch system (including the Fabric Manager and NSCQ telemetry).
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Source
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      /src
     </span>
    </p>
   </td>
   <td>
    <p>
     Source headers for compilation (precompiled streams only).
    </p>
   </td>
  </tr>
 </table>
 <p>
  For example:
 </p>
 <pre>sudo dnf module nvidia-driver:&lt;stream&gt;/default
sudo dnf module nvidia-driver:&lt;stream&gt;/ks
sudo dnf module nvidia-driver:&lt;stream&gt;/fm
sudo dnf module nvidia-driver:&lt;stream&gt;/src
</pre>
 <p>
  You can install multiple modularity profiles using BASH curly brace expansion, for example:
 </p>
 <pre>sudo dnf module install nvidia-driver:latest/{default,src}
</pre>
 <p>
  See
  <a class="reference external" href="https://developer.nvidia.com/blog/streamlining-nvidia-driver-deployment-on-rhel-8-with-modularity-streams">
   https://developer.nvidia.com/blog/streamlining-nvidia-driver-deployment-on-rhel-8-with-modularity-streams
  </a>
  in the Developer Blog and
  <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/precompiled/">
   https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/precompiled/
  </a>
  for more information.
 </p>
 <h1>
  <span class="section-number">
   7.
  </span>
  Kickstart Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#kickstart-installation" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <h2>
  <span class="section-number">
   7.1.
  </span>
  RHEL 8 / Rocky Linux 8
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-8-rocky-linux-8" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Enable the EPEL repository:
   </p>
   <pre>repo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/8/Everything/x86_64/
</pre>
  </li>
  <li>
   <p>
    Enable the CUDA repository:
   </p>
   <pre>repo --name=cuda-rhel8 --baseurl=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/
</pre>
  </li>
  <li>
   <p>
    In the packages section of the
    <span class="pre">
     ks.cfg
    </span>
    file, make sure you are using the
    /ks
    profile and
    :latest-dkms
    stream:
   </p>
   <pre>@nvidia-driver:latest-dkms/ks
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   7.2.
  </span>
  RHEL 9 / Rocky Linux 9
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-9-rocky-linux-9" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Enable the EPEL repository:
   </p>
   <pre>repo --name=epel --baseurl=http://download.fedoraproject.org/pub/epel/9/Everything/x86_64/
</pre>
  </li>
  <li>
   <p>
    Enable the CUDA repository:
   </p>
   <pre>repo --name=cuda-rhel9 --baseurl=https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/
</pre>
  </li>
  <li>
   <p>
    In the packages section of the
    <span class="pre">
     ks.cfg
    </span>
    file, make sure you are using the
    /ks
    profile and
    :latest-dkms
    stream:
   </p>
   <pre>@nvidia-driver:latest-dkms/ks
</pre>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h1>
  <span class="section-number">
   8.
  </span>
  Runfile Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-installation" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Basic instructions can be found in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#linux">
   Quick Start Guide
  </a>
  . Read on for more detailed instructions.
 </p>
 <p>
  This section describes the installation and configuration of CUDA when using the standalone installer. The standalone installer is a â.runâ file and is completely self-contained.
 </p>
 <h2>
  <span class="section-number">
   8.1.
  </span>
  Runfile Overview
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-overview" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The Runfile installation installs the NVIDIA Driver and CUDA Toolkit via an interactive ncurses-based interface.
 </p>
 <p>
  The
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installation">
   installation steps
  </a>
  are listed below. Distribution-specific instructions on
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#disabling-nouveau">
   disabling the Nouveau drivers
  </a>
  as well as steps for
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#device-node-runfile-verification">
   verifying device node creation
  </a>
  are also provided.
 </p>
 <p>
  Finally,
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-advanced">
   advanced options
  </a>
  for the installer and
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-uninstallation">
   uninstallation steps
  </a>
  are detailed below.
 </p>
 <p>
  The Runfile installation does not include support for cross-platform development. For cross-platform development, see the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cross-platform">
   CUDA Cross-Platform Environment
  </a>
  section.
 </p>
 <h2>
  <span class="section-number">
   8.2.
  </span>
  Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#disabling-nouveau">
     Disable the Nouveau drivers
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    Reboot into text mode (runlevel 3).
   </p>
   <p>
    This can usually be accomplished by adding the number â3â to the end of the systemâs kernel boot parameters.
   </p>
   <p>
    Since the NVIDIA drivers are not yet installed, the text terminals may not display correctly. Temporarily adding ânomodesetâ to the systemâs kernel boot parameters may fix this issue.
   </p>
   <p>
    Consult your systemâs bootloader documentation for information on how to make the above boot parameter changes.
   </p>
   <p>
    The reboot is required to completely unload the Nouveau drivers and prevent the graphical interface from loading. The CUDA driver cannot be installed while the Nouveau drivers are loaded or while the graphical interface is active.
   </p>
  </li>
  <li>
   <p>
    Verify that the Nouveau drivers are not loaded. If the Nouveau drivers are still loaded, consult your distributionâs documentation to see if further steps are needed to disable Nouveau.
   </p>
  </li>
  <li>
   <p>
    Run the installer and follow the on-screen prompts:
   </p>
   <pre>sudo sh cuda_&lt;version&gt;_linux.run
</pre>
   <p>
    The installer will prompt for the following:
   </p>
   <ul class="simple">
    <li>
     <p>
      EULA Acceptance
     </p>
    </li>
    <li>
     <p>
      CUDA Driver installation
     </p>
    </li>
    <li>
     <p>
      CUDA Toolkit installation, location, and
      <span class="pre">
       /usr/local/cuda
      </span>
      symbolic link
     </p>
    </li>
   </ul>
   <p>
    The default installation location for the toolkit is
    <span class="pre">
     /usr/local/cuda-12.4
    </span>
    :
   </p>
   <p>
    The
    <span class="pre">
     /usr/local/cuda
    </span>
    symbolic link points to the location where the CUDA Toolkit was installed. This link allows projects to use the latest CUDA Toolkit without any configuration file update.
   </p>
   <p>
    The installer must be executed with sufficient privileges to perform some actions. When the current privileges are insufficient to perform an action, the installer will ask for the userâs password to attempt to install with root privileges. Actions that cause the installer to attempt to install with root privileges are:
   </p>
   <ul class="simple">
    <li>
     <p>
      installing the CUDA Driver
     </p>
    </li>
    <li>
     <p>
      installing the CUDA Toolkit to a location the user does not have permission to write to
     </p>
    </li>
    <li>
     <p>
      creating the
      <span class="pre">
       /usr/local/cuda
      </span>
      symbolic link
     </p>
    </li>
   </ul>
   <p>
    Running the installer with
    sudo
    , as shown above, will give permission to install to directories that require root permissions. Directories and files created while running the installer with
    sudo
    will have root ownership.
   </p>
   <p>
    If installing the driver, the installer will also ask if the openGL libraries should be installed. If the GPU used for display is not an NVIDIA GPU, the NVIDIA openGL libraries should not be installed. Otherwise, the openGL libraries used by the graphics driver of the non-NVIDIA GPU will be overwritten and the GUI will not work. If performing a silent installation, the
    <span class="pre">
     --no-opengl-libs
    </span>
    option should be used to prevent the openGL libraries from being installed. See the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-options">
     Advanced Options
    </a>
    section for more details.
   </p>
   <p>
    If the GPU used for display is an NVIDIA GPU, the X server configuration file,
    <span class="pre">
     /etc/X11/xorg.conf
    </span>
    , may need to be modified. In some cases,
    <span class="pre">
     nvidia-xconfig
    </span>
    can be used to automatically generate an
    <span class="pre">
     xorg.conf
    </span>
    file that works for the system. For non-standard systems, such as those with more than one GPU, it is recommended to manually edit the
    <span class="pre">
     xorg.conf
    </span>
    file. Consult the
    <span class="pre">
     xorg.conf
    </span>
    documentation for more information.
   </p>
   <p class="admonition-title">
    Note
   </p>
   <p>
    Installing Mesa may overwrite the
    <span class="pre">
     /usr/lib/libGL.so
    </span>
    that was previously installed by the NVIDIA driver, so a reinstallation of the NVIDIA driver might be required after installing these libraries.
   </p>
  </li>
  <li>
   <p>
    Reboot the system to reload the graphical interface:
   </p>
   <pre>sudo reboot
</pre>
  </li>
  <li>
   <p>
    Verify the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#device-node-verification">
     device nodes
    </a>
    are created properly.
   </p>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions
    </a>
    .
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   8.3.
  </span>
  Disabling Nouveau
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#disabling-nouveau" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To install the Display Driver, the Nouveau drivers must first be disabled. Each distribution of Linux has a different method for disabling Nouveau.
 </p>
 <p>
  The Nouveau drivers are loaded if the following command prints anything:
 </p>
 <pre>lsmod | grep nouveau
</pre>
 <h3>
  <span class="section-number">
   8.3.1.
  </span>
  Fedora
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-fedora" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Create a file at
    <span class="pre">
     /usr/lib/modprobe.d/blacklist-nouveau.conf
    </span>
    with the following contents:
   </p>
   <pre>blacklist nouveau
options nouveau modeset=0
</pre>
  </li>
  <li>
   <p>
    Regenerate the kernel initramfs:
   </p>
   <pre>sudo dracut --force
</pre>
  </li>
  <li>
   <p>
    Run the following command:
   </p>
   <pre>sudo grub2-mkconfig -o /boot/grub2/grub.cfg
</pre>
  </li>
  <li>
   <p>
    Reboot the system.
   </p>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   8.3.2.
  </span>
  RHEL / Rocky and KylinOS
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#rhel-rocky-and-kylinos" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Create a file at
    <span class="pre">
     /etc/modprobe.d/blacklist-nouveau.conf
    </span>
    with the following contents:
   </p>
   <pre>blacklist nouveau
options nouveau modeset=0
</pre>
  </li>
  <li>
   <p>
    Regenerate the kernel initramfs:
   </p>
   <pre>sudo dracut --force
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   8.3.3.
  </span>
  OpenSUSE
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-suse" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Create a file at
    <span class="pre">
     /etc/modprobe.d/blacklist-nouveau.conf
    </span>
    with the following contents:
   </p>
   <pre>blacklist nouveau
options nouveau modeset=0
</pre>
  </li>
  <li>
   <p>
    Regenerate the kernel initrd:
   </p>
   <pre>sudo /sbin/mkinitrd
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   8.3.4.
  </span>
  SLES
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-sles" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  No actions to disable Nouveau are required as Nouveau is not installed on SLES.
 </p>
 <h3>
  <span class="section-number">
   8.3.5.
  </span>
  WSL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-wsl" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  No actions to disable Nouveau are required as Nouveau is not installed on WSL.
 </p>
 <h3>
  <span class="section-number">
   8.3.6.
  </span>
  Ubuntu
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Create a file at
    <span class="pre">
     /etc/modprobe.d/blacklist-nouveau.conf
    </span>
    with the following contents:
   </p>
   <pre>blacklist nouveau
options nouveau modeset=0
</pre>
  </li>
  <li>
   <p>
    Regenerate the kernel initramfs:
   </p>
   <pre>sudo update-initramfs -u
</pre>
  </li>
 </ol>
 <h3>
  <span class="section-number">
   8.3.7.
  </span>
  Debian
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-debian" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <ol class="arabic">
  <li>
   <p>
    Create a file at
    <span class="pre">
     /etc/modprobe.d/blacklist-nouveau.conf
    </span>
    with the following contents:
   </p>
   <pre>blacklist nouveau
options nouveau modeset=0
</pre>
  </li>
  <li>
   <p>
    Regenerate the kernel initramfs:
   </p>
   <pre>sudo update-initramfs -u
</pre>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   8.4.
  </span>
  Device Node Verification
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#device-node-verification" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Check that the device files
  <span class="pre">
   /dev/nvidia*
  </span>
  exist and have the correct (0666) file permissions. These files are used by the CUDA Driver to communicate with the kernel-mode portion of the NVIDIA Driver. Applications that use the NVIDIA driver, such as a CUDA application or the X server (if any), will normally automatically create these files if they are missing using the setuid
  <span class="pre">
   nvidia-modprobe
  </span>
  tool that is bundled with the NVIDIA Driver. However, some systems disallow setuid binaries, so if these files do not exist, you can create them manually by using a startup script such as the one below:
 </p>
 <pre>#!/bin/bash

/sbin/modprobe nvidia

if [ "$?" -eq 0 ]; then
  # Count the number of NVIDIA controllers found.
  NVDEVS=`lspci | grep -i NVIDIA`
  N3D=`echo "$NVDEVS" | grep "3D controller" | wc -l`
  NVGA=`echo "$NVDEVS" | grep "VGA compatible controller" | wc -l`

  N=`expr $N3D + $NVGA - 1`
  for i in `seq 0 $N`; do
    mknod -m 666 /dev/nvidia$i c 195 $i
  done

  mknod -m 666 /dev/nvidiactl c 195 255

else
  exit 1
fi

/sbin/modprobe nvidia-uvm

if [ "$?" -eq 0 ]; then
  # Find out the major device number used by the nvidia-uvm driver
  D=`grep nvidia-uvm /proc/devices | awk '{print $1}'`

  mknod -m 666 /dev/nvidia-uvm c $D 0
else
  exit 1
fi
</pre>
 <h2>
  <span class="section-number">
   8.5.
  </span>
  Advanced Options
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-options" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Action
    </p>
   </th>
   <th class="head">
    <p>
     Options Used
    </p>
   </th>
   <th class="head">
    <p>
     Explanation
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td rowspan="5">
    <p>
     Silent Installation
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --silent
     </span>
    </p>
   </td>
   <td>
    <p>
     Required for any silent installation. Performs an installation with no further user-input and minimal command-line output based on the options provided below. Silent installations are useful for scripting the installation of CUDA. Using this option implies acceptance of the EULA. The following flags can be used to customize the actions taken during installation. At least one of
     <span class="pre">
      --driver
     </span>
     ,
     <span class="pre">
      --uninstall
     </span>
     , and
     <span class="pre">
      --toolkit
     </span>
     must be passed if running with non-root permissions.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      --driver
     </span>
    </p>
   </td>
   <td>
    <p>
     Install the CUDA Driver.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      --toolkit
     </span>
    </p>
   </td>
   <td>
    <p>
     Install the CUDA Toolkit.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      --toolkitpath=&lt;path&gt;
     </span>
    </p>
   </td>
   <td>
    <p>
     Install the CUDA Toolkit to the &lt;path&gt; directory. If not provided, the default path of
     <span class="pre">
      /usr/local/cuda-12.4
     </span>
     is used.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      --defaultroot=&lt;path&gt;
     </span>
    </p>
   </td>
   <td>
    <p>
     Install libraries to the &lt;path&gt; directory. If the &lt;path&gt; is not provided, then the default path of your distribution is used.
     This only applies to the libraries installed outside of the CUDA Toolkit path.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Extraction
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --extract=&lt;path&gt;
     </span>
    </p>
   </td>
   <td>
    <p>
     Extracts to the &lt;path&gt; the following: the driver runfile, the raw files of the toolkit to &lt;path&gt;.
    </p>
    <p>
     This is especially useful when one wants to install the driver using one or more of the command-line options provided by the driver installer which are not exposed in this installer.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Overriding Installation Checks
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --override
     </span>
    </p>
   </td>
   <td>
    <p>
     Ignores compiler, third-party library, and toolkit detection checks which would prevent the CUDA Toolkit from installing.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     No OpenGL Libraries
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --no-opengl-libs
     </span>
    </p>
   </td>
   <td>
    <p>
     Prevents the driver installation from installing NVIDIAâs GL libraries. Useful for systems where the display is driven by a non-NVIDIA GPU. In such systems, NVIDIAâs GL libraries could prevent X from loading properly.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     No man pages
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --no-man-page
     </span>
    </p>
   </td>
   <td>
    <p>
     Do not install the man pages under
     <span class="pre">
      /usr/share/man
     </span>
     .
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Overriding Kernel Source
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --kernel-source-path=&lt;path&gt;
     </span>
    </p>
   </td>
   <td>
    <p>
     Tells the driver installation to use &lt;path&gt; as the kernel source directory when building the NVIDIA kernel module. Required for systems where the kernel source is installed to a non-standard location.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Running nvidia-xconfig
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --run-nvidia-xconfig
     </span>
    </p>
   </td>
   <td>
    <p>
     Tells the driver installation to run nvidia-xconfig to update the system X configuration file so that the NVIDIA X driver is used. The pre-existing X configuration file will be backed up.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     No nvidia-drm kernel module
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --no-drm
     </span>
    </p>
   </td>
   <td>
    <p>
     Do not install the nvidia-drm kernel module. This option should only be used to work around failures to build or install the nvidia-drm kernel module on systems that do not need the provided features.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Custom Temporary Directory Selection
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --tmpdir=&lt;path&gt;
     </span>
    </p>
   </td>
   <td>
    <p>
     Performs any temporary actions within &lt;path&gt; instead of
     <span class="pre">
      /tmp
     </span>
     . Useful in cases where
     <span class="pre">
      /tmp
     </span>
     cannot be used (doesnât exist, is full, is mounted with ânoexecâ, etc.).
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Show Installer Options
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      --help
     </span>
    </p>
   </td>
   <td>
    <p>
     Prints the list of command-line options to stdout.
    </p>
   </td>
  </tr>
 </table>
 <h2>
  <span class="section-number">
   8.6.
  </span>
  Uninstallation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#uninstallation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To uninstall the CUDA Toolkit, run the uninstallation script provided in the bin directory of the toolkit. By default, it is located in
  <span class="pre">
   /usr/local/cuda-12.4/bin
  </span>
  :
 </p>
 <pre>sudo /usr/local/cuda-12.4/bin/cuda-uninstaller
</pre>
 <p>
  To uninstall the NVIDIA Driver, run
  <span class="pre">
   nvidia-uninstall
  </span>
  :
 </p>
 <pre>sudo /usr/bin/nvidia-uninstall
</pre>
 <p>
  To enable the Nouveau drivers, remove the blacklist file created in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau">
   Disabling Nouveau
  </a>
  section, and regenerate the kernel initramfs/initrd again as described in that section.
 </p>
 <h1>
  <span class="section-number">
   9.
  </span>
  Conda Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#conda-installation" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  This section describes the installation and configuration of CUDA when using the Conda installer. The Conda packages are available at
  <a class="reference external" href="https://anaconda.org/nvidia">
   https://anaconda.org/nvidia
  </a>
  .
 </p>
 <h2>
  <span class="section-number">
   9.1.
  </span>
  Conda Overview
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#conda-overview" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The Conda installation installs the CUDA Toolkit. The installation steps are listed below.
 </p>
 <h2>
  <span class="section-number">
   9.2.
  </span>
  Installing CUDA Using Conda
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installing-cuda-using-conda" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To perform a basic install of all CUDA Toolkit components using Conda, run the following command:
 </p>
 <pre>conda install cuda -c nvidia
</pre>
 <h2>
  <span class="section-number">
   9.3.
  </span>
  Uninstalling CUDA Using Conda
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#uninstalling-cuda-using-conda" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To uninstall the CUDA Toolkit using Conda, run the following command:
 </p>
 <pre>conda remove cuda
</pre>
 <h2>
  <span class="section-number">
   9.4.
  </span>
  Installing Previous CUDA Releases
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#installing-previous-cuda-releases" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  All Conda packages released under a specific CUDA version are labeled with that release version. To install a previous version, include that label in the
  <span class="pre">
   install
  </span>
  command such as:
 </p>
 <pre>conda install cuda -c nvidia/label/cuda-11.3.0
</pre>
 <h2>
  <span class="section-number">
   9.5.
  </span>
  Upgrading from cudatoolkit Package
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#upgrading-from-cudatoolkit-package" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  If you had previously installed CUDA using the
  <span class="pre">
   cudatoolkit
  </span>
  package and want to maintain a similar install footprint, you can limit your installation to the following packages:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cuda-libraries-dev
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cuda-nvcc
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cuda-nvtx
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cuda-cupti
    </span>
   </p>
  </li>
 </ul>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Some extra files, such as headers, will be included in this installation which were not included in the
  <span class="pre">
   cudatoolkit
  </span>
  package. If you need to reduce your installation further, replace
  <span class="pre">
   cuda-libraries-dev
  </span>
  with the specific libraries you need.
 </p>
 <h1>
  <span class="section-number">
   10.
  </span>
  Pip Wheels
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pip-wheels" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  NVIDIA provides Python Wheels for installing CUDA through pip, primarily for using CUDA with Python. These packages are intended for runtime use and do not currently include developer tools (these can be installed separately).
 </p>
 <p>
  Please note that with this installation method, CUDA installation environment is managed via pip and additional care must be taken to set up your host environment to use CUDA outside the pip environment.
 </p>
 <p>
  Prerequisites
 </p>
 <p>
  To install Wheels, you must first install the
  <span class="pre">
   nvidia-pyindex
  </span>
  package, which is required in order to set up your pip installation to fetch additional Python modules from the NVIDIA NGC PyPI repo. If your pip and setuptools Python modules are not up-to-date, then use the following command to upgrade these Python modules. If these Python modules are out-of-date then the commands which follow later in this section may fail.
 </p>
 <pre>python3 -m pip install --upgrade setuptools pip wheel
</pre>
 <p>
  You should now be able to install the
  <span class="pre">
   nvidia-pyindex
  </span>
  module.
 </p>
 <pre>python3 -m pip install nvidia-pyindex
</pre>
 <p>
  If your project is using a
  <span class="pre">
   requirements.txt
  </span>
  file, then you can add the following line to your
  <span class="pre">
   requirements.txt
  </span>
  file as an alternative to installing the
  <span class="pre">
   nvidia-pyindex
  </span>
  package:
 </p>
 <pre>--extra-index-url https://pypi.org/simple
</pre>
 <p>
  Procedure
 </p>
 <p>
  Install the CUDA runtime package:
 </p>
 <pre>python3 -m pip install nvidia-cuda-runtime-cu12
</pre>
 <p>
  Optionally, install additional packages as listed below using the following command:
 </p>
 <pre>python3 -m pip install nvidia-&lt;library&gt;
</pre>
 <p>
  Metapackages
 </p>
 <p>
  The following metapackages will install the latest version of the named component on Linux for the indicated CUDA version. âcu12â should be read as âcuda12â.
 </p>
 <ul class="simple">
  <li>
   <p>
    nvidia-cuda-runtime-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-cccl-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-cupti-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-nvcc-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-opencl-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-nvrtc-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cublas-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-sanitizer-api-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cufft-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-curand-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cusolver-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-cusparse-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-npp-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-nvfatbin-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-nvjitlink-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-nvjpeg-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-nvml-dev-cu12
   </p>
  </li>
  <li>
   <p>
    nvidia-nvtx-cu12
   </p>
  </li>
 </ul>
 <p>
  These metapackages install the following packages:
 </p>
 <ul class="simple">
  <li>
   <p>
    nvidia-cuda-runtime-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-cccl-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-cupti-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-nvcc-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-opencl-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cublas-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-sanitizer-api-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cuda-nvrtc-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cufft-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-curand-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cusolver-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-cusparse-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-npp-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-nvfatbin-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-nvjitlink-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-nvjpeg-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-nvml-dev-cu125
   </p>
  </li>
  <li>
   <p>
    nvidia-nvtx-cu125
   </p>
  </li>
 </ul>
 <h1>
  <span class="section-number">
   11.
  </span>
  Tarball and Zip Archive Deliverables
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#tarball-and-zip-archive-deliverables" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  In an effort to meet the needs of a growing customer base requiring alternative installer packaging formats, as well as a means of input into community CI/CD systems, tarball and zip archives are available for each component.
 </p>
 <p>
  These tarball and zip archives, known as binary archives, are provided at
  <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/redist/">
   https://developer.download.nvidia.com/compute/cuda/redist/
  </a>
  .
 </p>
 <a class="reference internal image-reference" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/_images/tarball-archives.png">
 </a>
 <p>
  These component .tar.xz and .zip binary archives do not replace existing packages such as .deb, .rpm, runfile, conda, etc. and are not meant for general consumption, as they are not installers. However this standardized approach will replace existing .txz archives.
 </p>
 <p>
  For each release, a JSON manifest is provided such as
  redistrib_11.4.2.json
  , which corresponds to the CUDA 11.4.2 release label (CUDA 11.4 update 2) which includes the release date, the name of each component, license name, relative URL for each platform and checksums.
 </p>
 <p>
  Package maintainers are advised to check the provided LICENSE for each component prior to redistribution. Instructions for developers using CMake and Bazel build systems are provided in the next sections.
 </p>
 <h2>
  <span class="section-number">
   11.1.
  </span>
  Parsing Redistrib JSON
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#parsing-redistrib-json" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The following example of a JSON manifest contains keys for each component: name, license, version, and a platform array which includes relative_path, sha256, md5, and size (bytes) for each archive.
 </p>
 <pre>{
    "release_date": "2021-09-07",
    "cuda_cudart": {
        "name": "CUDA Runtime (cudart)",
        "license": "CUDA Toolkit",
        "version": "11.4.108",
        "linux-x86_64": {
            "relative_path": "cuda_cudart/linux-x86_64/cuda_cudart-linux-x86_64-11.4.108-archive.tar.xz",
            "sha256": "d08a1b731e5175aa3ae06a6d1c6b3059dd9ea13836d947018ea5e3ec2ca3d62b",
            "md5": "da198656b27a3559004c3b7f20e5d074",
            "size": "828300"
        },
        "linux-ppc64le": {
            "relative_path": "cuda_cudart/linux-ppc64le/cuda_cudart-linux-ppc64le-11.4.108-archive.tar.xz",
            "sha256": "831dffe062ae3ebda3d3c4010d0ee4e40a01fd5e6358098a87bb318ea7c79e0c",
            "md5": "ca73328e3f8e2bb5b1f2184c98c3a510",
            "size": "776840"
        },
        "linux-sbsa": {
            "relative_path": "cuda_cudart/linux-sbsa/cuda_cudart-linux-sbsa-11.4.108-archive.tar.xz",
            "sha256": "2ab9599bbaebdcf59add73d1f1a352ae619f8cb5ccec254093c98efd4c14553c",
            "md5": "aeb5c19661f06b6398741015ba368102",
            "size": "782372"
        },
        "windows-x86_64": {
            "relative_path": "cuda_cudart/windows-x86_64/cuda_cudart-windows-x86_64-11.4.108-archive.zip",
            "sha256": "b59756c27658d1ea87a17c06d064d1336576431cd64da5d1790d909e455d06d3",
            "md5": "7f6837a46b78198402429a3760ab28fc",
            "size": "2897751"
        }
    }
}
</pre>
 <p>
  A JSON schema is provided at
  <a class="reference external" href="https://developer.download.nvidia.com/compute/redist/redistrib-v2.schema.json">
   https://developer.download.nvidia.com/compute/redist/redistrib-v2.schema.json
  </a>
  .
 </p>
 <p>
  A sample script that parses these JSON manifests is available on
  <a class="reference external" href="https://github.com/NVIDIA/build-system-archive-import-examples/blob/main/parse_redist.py">
   GitHub
  </a>
  :
 </p>
 <ul class="simple">
  <li>
   <p>
    Downloads each archive
   </p>
  </li>
  <li>
   <p>
    Validates SHA256 checksums
   </p>
  </li>
  <li>
   <p>
    Extracts archives
   </p>
  </li>
  <li>
   <p>
    Flattens into a collapsed directory structure
   </p>
  </li>
 </ul>
 <table class="table-no-stripes colwidths-given docutils align-default" id="id20">
  <span class="caption-number">
   Table 7
  </span>
  <span class="caption-text">
   Available Tarball and Zip Archives
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id20" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Product
    </p>
   </th>
   <th class="head">
    <p>
     Example
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cuda/redist">
      CUDA Toolkit
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cuda
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      12.3.2
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cublasmp/redist/">
      cuBLASMp
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cublasmp
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      0.1.0
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cudnn/redist">
      cuDNN
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cudnn
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      8.9.6.50
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cudss/redist">
      cuDSS
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cudss
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      0.1.0
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cuquantum/redist">
      cuQuantum
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cuquantum
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      23.10.0
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cusparselt/redist">
      cuSPARSELt
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cusparselt
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      0.5.2
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/cutensor/redist">
      cuTENSOR
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      cutensor
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      1.7.0
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/nvidia-driver/redist">
      NVIDIA driver
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      nvidia-driver
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      535.129.03
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/nvjpeg2000/redist">
      nvJPEG2000
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      nvjpeg2000
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      0.7.5
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/nvpl/redist">
      NVPL
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      nvpl
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      23.11
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <a class="reference external" href="https://developer.download.nvidia.com/compute/nvtiff/redist">
      nvTIFF
     </a>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      ./parse_redist.py
     </span>
     <span class="pre">
      --product
     </span>
     <span class="pre">
      nvtiff
     </span>
     <span class="pre">
      --label
     </span>
     <span class="pre">
      0.3.0
     </span>
    </p>
   </td>
  </tr>
 </table>
 <h2>
  <span class="section-number">
   11.2.
  </span>
  Importing Tarballs into CMake
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#importing-tarballs-into-cmake" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The recommended module for importing these tarballs into the CMake build system is via
  <a class="reference external" href="https://cmake.org/cmake/help/latest/module/FindCUDAToolkit.html">
   FindCUDAToolkit
  </a>
  (3.17 and newer).
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  The FindCUDA module is deprecated.
 </p>
 <p>
  The path to the extraction location can be specified with the
  <span class="pre">
   CUDAToolkit_ROOT
  </span>
  environmental variable. For example
  <span class="pre">
   CMakeLists.txt
  </span>
  and commands, see
  <a class="reference external" href="https://github.com/NVIDIA/build-system-archive-import-examples/blob/main/cmake/1_FindCUDAToolkit">
   cmake/1_FindCUDAToolkit/
  </a>
  .
 </p>
 <p>
  For older versions of CMake, the
  <a class="reference external" href="https://cmake.org/cmake/help/latest/module/ExternalProject.html">
   ExternalProject_Add
  </a>
  module is an alternative method. For example
  <span class="pre">
   CMakeLists.txt
  </span>
  file and commands, see
  <a class="reference external" href="https://github.com/NVIDIA/build-system-archive-import-examples/tree/main/cmake/2_ExternalProject">
   cmake/2_ExternalProject/
  </a>
  .
 </p>
 <h2>
  <span class="section-number">
   11.3.
  </span>
  Importing Tarballs into Bazel
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#importing-tarballs-into-bazel" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The recommended method of importing these tarballs into the Bazel build system is using
  <a class="reference external" href="https://docs.bazel.build/versions/main/repo/http.html">
   http_archive
  </a>
  and
  <a class="reference external" href="https://docs.bazel.build/versions/main/be/pkg.html#pkg_tar">
   pkg_tar
  </a>
  .
 </p>
 <p>
  For an example, see
  <a class="reference external" href="https://github.com/NVIDIA/build-system-archive-import-examples/blob/main/bazel/1_pkg_tar">
   bazel/1_pkg_tar/
  </a>
  .
 </p>
 <h1>
  <span class="section-number">
   12.
  </span>
  CUDA Cross-Platform Environment
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-environment" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Cross development for arm64-sbsa is supported on Ubuntu 20.04, Ubuntu 22.04, RHEL 8, RHEL 9, and SLES 15.
 </p>
 <p>
  Cross development for arm64-Jetson is only supported on Ubuntu 20.04
 </p>
 <p>
  We recommend selecting a host development environment that matches the supported cross-target environment. This selection helps prevent possible host/target incompatibilities, such as GCC or GLIBC version mismatches.
 </p>
 <h2>
  <span class="section-number">
   12.1.
  </span>
  CUDA Cross-Platform Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Some of the following steps may have already been performed as part of the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">
   native Ubuntu installation
  </a>
  . Such steps can safely be skipped.
 </p>
 <p>
  These steps should be performed on the x86_64 host system, rather than the target system. To install the native CUDA Toolkit on the target system, refer to the native
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">
   Ubuntu
  </a>
  installation section.
 </p>
 <ol class="arabic">
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#pre-installation-actions">
     pre-installation actions.
    </a>
   </p>
  </li>
  <li>
   <p>
    Install repository meta-data package with:
   </p>
   <pre>sudo dpkg -i cuda-repo-cross-&lt;identifier&gt;_all.deb
</pre>
   <p>
    where
    <span class="pre">
     &lt;identifier&gt;
    </span>
    indicates the operating system, architecture, and/or the version of the package.
   </p>
  </li>
  <li>
   <p>
    Update the Apt repository cache:
   </p>
   <pre>sudo apt-get update
</pre>
  </li>
  <li>
   <p>
    Install the appropriate cross-platform CUDA Toolkit:
   </p>
   <ol class="loweralpha">
    <li>
     <p>
      For aarch64:
     </p>
     <pre>sudo apt-get install cuda-cross-aarch64
</pre>
    </li>
    <li>
     <p>
      For QNX:
     </p>
     <pre>sudo apt-get install cuda-cross-qnx
</pre>
    </li>
   </ol>
  </li>
  <li>
   <p>
    Perform the
    <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions">
     post-installation actions.
    </a>
   </p>
  </li>
 </ol>
 <h2>
  <span class="section-number">
   12.2.
  </span>
  CUDA Cross-Platform Samples
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-samples" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  CUDA Samples are now located in
  <a class="reference external" href="https://github.com/nvidia/cuda-samples">
   https://github.com/nvidia/cuda-samples
  </a>
  , which includes instructions for obtaining, building, and running the samples.
 </p>
 <h1>
  <span class="section-number">
   13.
  </span>
  Post-installation Actions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  The post-installation actions must be manually performed. These actions are split into mandatory, recommended, and optional sections.
 </p>
 <h2>
  <span class="section-number">
   13.1.
  </span>
  Mandatory Actions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#mandatory-actions" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Some actions must be taken after the installation before the CUDA Toolkit and Driver can be used.
 </p>
 <h3>
  <span class="section-number">
   13.1.1.
  </span>
  Environment Setup
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#environment-setup" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  <span class="pre">
   PATH
  </span>
  variable needs to include
  <span class="pre">
   export
  </span>
  <span class="pre">
   PATH=/usr/local/cuda-12.4/bin${PATH:+:${PATH}}
  </span>
  . Nsight Compute has moved to
  <span class="pre">
   /opt/nvidia/nsight-compute/
  </span>
  only in rpm/deb installation method. When using
  <span class="pre">
   .run
  </span>
  installer it is still located under
  <span class="pre">
   /usr/local/cuda-12.4/
  </span>
  .
 </p>
 <p>
  To add this path to the
  <span class="pre">
   PATH
  </span>
  variable:
 </p>
 <pre>export PATH=/usr/local/cuda-12.4/bin${PATH:+:${PATH}}
</pre>
 <p>
  In addition, when using the runfile installation method, the
  <span class="pre">
   LD_LIBRARY_PATH
  </span>
  variable needs to contain
  <span class="pre">
   /usr/local/cuda-12.4/lib64
  </span>
  on a 64-bit system, or
  <span class="pre">
   /usr/local/cuda-12.4/lib
  </span>
  on a 32-bit system
 </p>
 <ul>
  <li>
   <p>
    To change the environment variables for 64-bit operating systems:
   </p>
   <pre>export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64\
                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</pre>
  </li>
  <li>
   <p>
    To change the environment variables for 32-bit operating systems:
   </p>
   <pre>export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib\
                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</pre>
  </li>
 </ul>
 <p>
  Note that the above paths change when using a custom install path with the runfile installation method.
 </p>
 <h2>
  <span class="section-number">
   13.2.
  </span>
  Recommended Actions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#recommended-actions" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Other actions are recommended to verify the integrity of the installation.
 </p>
 <h3>
  <span class="section-number">
   13.2.1.
  </span>
  Install Persistence Daemon
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-persistence-daemon" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  NVIDIA is providing a user-space daemon on Linux to support persistence of driver state across CUDA job runs. The daemon approach provides a more elegant and robust solution to this problem than persistence mode. For more details on the NVIDIA Persistence Daemon, see the documentation
  <a class="reference external" href="http://docs.nvidia.com/deploy/driver-persistence/index.html#persistence-daemon">
   here
  </a>
  .
 </p>
 <p>
  The NVIDIA Persistence Daemon can be started as the root user by running:
 </p>
 <pre>/usr/bin/nvidia-persistenced --verbose
</pre>
 <p>
  This command should be run on boot. Consult your Linux distributionâs init documentation for details on how to automate this.
 </p>
 <h3>
  <span class="section-number">
   13.2.2.
  </span>
  Install Writable Samples
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-writable-samples" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  CUDA Samples are now located in
  <a class="reference external" href="https://github.com/nvidia/cuda-samples">
   https://github.com/nvidia/cuda-samples
  </a>
  , which includes instructions for obtaining, building, and running the samples.
 </p>
 <h3>
  <span class="section-number">
   13.2.3.
  </span>
  Verify the Installation
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-installation" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Before continuing, it is important to verify that the CUDA toolkit can find and communicate correctly with the CUDA-capable hardware. To do this, you need to compile and run some of the sample programs, located in
  <a class="reference external" href="https://github.com/nvidia/cuda-samples">
   https://github.com/nvidia/cuda-samples
  </a>
  .
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Ensure the PATH and, if using the runfile installation method, LD_LIBRARY_PATH variables are
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#environment-setup">
   set correctly
  </a>
  .
 </p>
 <h4>
  <span class="section-number">
   13.2.3.1.
  </span>
  Verify the Driver Version
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-driver-version" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  If you installed the driver, verify that the correct version of it is loaded. If you did not install the driver, or are using an operating system where the driver is not loaded via a kernel module, such as L4T, skip this step.
 </p>
 <p>
  When the driver is loaded, the driver version can be found by executing the command
 </p>
 <pre>cat /proc/driver/nvidia/version
</pre>
 <p>
  Note that this command will not work on an iGPU/dGPU system.
 </p>
 <h4>
  <span class="section-number">
   13.2.3.2.
  </span>
  Running the Binaries
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-the-binaries" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  After compilation, find and run
  <span class="pre">
   deviceQuery
  </span>
  from
  <a class="reference external" href="https://github.com/nvidia/cuda-samples">
   https://github.com/nvidia/cuda-samples
  </a>
  . If the CUDA software is installed and configured correctly, the output for
  <span class="pre">
   deviceQuery
  </span>
  should look similar to that shown in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-binaries-valid-results-from-sample-cuda-devicequery-program">
   Figure 1
  </a>
  .
 </p>
 <a class="reference internal image-reference" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/_images/valid-results-from-sample-cuda-devicequery-program.png">
 </a>
 <p>
  <span class="caption-number">
   Figure 1
  </span>
  <span class="caption-text">
   Figure 1. Valid Results from deviceQuery CUDA Sample
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-binaries-valid-results-from-sample-cuda-devicequery-program" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  The exact appearance and the output lines might be different on your system. The important outcomes are that a device was found (the first highlighted line), that the device matches the one on your system (the second highlighted line), and that the test passed (the final highlighted line).
 </p>
 <p>
  If a CUDA-capable device and the CUDA Driver are installed but
  <span class="pre">
   deviceQuery
  </span>
  reports that no CUDA-capable devices are present, this likely means that the
  <span class="pre">
   /dev/nvidia*
  </span>
  files are missing or have the wrong permissions.
 </p>
 <p>
  On systems where
  <span class="pre">
   SELinux
  </span>
  is enabled, you might need to temporarily disable this security feature to run
  <span class="pre">
   deviceQuery
  </span>
  . To do this, type:
 </p>
 <pre>setenforce 0
</pre>
 <p>
  from the command line as the superuser.
 </p>
 <p>
  Running the
  <span class="pre">
   bandwidthTest
  </span>
  program ensures that the system and the CUDA-capable device are able to communicate correctly. Its output is shown in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-binaries__valid-results-from-sample-cuda-bandwidthtest-program">
   Figure 2
  </a>
  .
 </p>
 <a class="reference internal image-reference" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/_images/valid-results-from-sample-cuda-bandwidthtest-program.png">
 </a>
 <p>
  <span class="caption-number">
   Figure 2
  </span>
  <span class="caption-text">
   Figure 2. Valid Results from bandwidthTest CUDA Sample
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-binaries-valid-results-from-sample-cuda-bandwidthtest-program" title="Permalink to this image">
   ï
  </a>
 </p>
 <p>
  Note that the measurements for your CUDA-capable device description will vary from system to system. The important point is that you obtain measurements, and that the second-to-last line (in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#running-binaries-valid-results-from-sample-cuda-bandwidthtest-program">
   Figure 2
  </a>
  ) confirms that all necessary tests passed.
 </p>
 <p>
  Should the tests not pass, make sure you have a CUDA-capable NVIDIA GPU on your system and make sure it is properly installed.
 </p>
 <p>
  If you run into difficulties with the link step (such as libraries not being found), consult the Linux Release Notes found in
  <a class="reference external" href="https://github.com/nvidia/cuda-samples">
   https://github.com/nvidia/cuda-samples
  </a>
  .
 </p>
 <h3>
  <span class="section-number">
   13.2.4.
  </span>
  Install Nsight Eclipse Plugins
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-nsight-eclipse-plugins" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  To install Nsight Eclipse plugins, an installation script is provided:
 </p>
 <pre>/usr/local/cuda-12.4/bin/nsight_ee_plugins_manage.sh install &lt;eclipse-dir&gt;
</pre>
 <p>
  Refer to
  <a class="reference external" href="https://docs.nvidia.com/cuda/nsightee-plugins-install-guide/index.html">
   Nsight Eclipse Plugins Installation Guide
  </a>
  for more details.
 </p>
 <h3>
  <span class="section-number">
   13.2.5.
  </span>
  Local Repo Removal
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#local-repo-removal" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Removal of the local repo installer is recommended after installation of
  CUDA SDK
  .
 </p>
 <p>
  Ubuntu and Debian
 </p>
 <pre>sudo apt-get remove --purge "cuda-repo-&lt;distro&gt;-X-Y-local*"
</pre>
 <p>
  Fedora
 </p>
 <pre>sudo dnf remove "cuda-repo-&lt;distro&gt;-X-Y-local*"
</pre>
 <p>
  RHEL 9 / Rocky Linux 9 and RHEL 8 / Rocky Linux 8
 </p>
 <pre>sudo dnf remove "cuda-repo-&lt;distro&gt;-X-Y-local*"
</pre>
 <p>
  openSUSE 15 and SLES 15
 </p>
 <pre>sudo zypper remove "cuda-repo-&lt;distro&gt;-X-Y-local*"
</pre>
 <p>
  Removal of the local repo installer is recommended after installation of
  NVIDA driver
  .
 </p>
 <p>
  Ubuntu and Debian
 </p>
 <pre>sudo apt-get remove --purge "nvidia-driver-local-repo-&lt;distro&gt;*"
</pre>
 <p>
  Fedora
 </p>
 <pre>sudo dnf remove "nvidia-driver-local-repo-&lt;distro&gt;*"
</pre>
 <p>
  RHEL 9 / Rocky Linux 9 and RHEL 8 / Rocky Linux 8
 </p>
 <pre>sudo dnf remove "nvidia-driver-local-repo-&lt;distro&gt;*"
</pre>
 <p>
  openSUSE 15 and SLES 15
 </p>
 <pre>sudo zypper remove "nvidia-driver-local-repo-&lt;distro&gt;*"
</pre>
 <h2>
  <span class="section-number">
   13.3.
  </span>
  Optional Actions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#optional-actions" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Other options are not necessary to use the CUDA Toolkit, but are available to provide additional features.
 </p>
 <h3>
  <span class="section-number">
   13.3.1.
  </span>
  Install Third-party Libraries
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-third-party-libraries" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Some CUDA samples use third-party libraries which may not be installed by default on your system. These samples attempt to detect any required libraries when building.
 </p>
 <p>
  If a library is not detected, it waives itself and warns you which library is missing. To build and run these samples, you must install the missing libraries. In cases where these dependencies are not installed, follow the instructions below.
 </p>
 <p>
  RHEL 8 / Rocky Linux 8
 </p>
 <pre>sudo dnf install freeglut-devel libX11-devel libXi-devel libXmu-devel \
    make mesa-libGLU-devel freeimage-devel libglfw3-devel
</pre>
 <p>
  RHEL 9 / Rocky Linux 9
 </p>
 <pre>sudo dnf install freeglut-devel libX11-devel libXi-devel libXmu-devel \
                    make mesa-libGLU-devel freeimage-devel libglfw3-devel
</pre>
 <p>
  KylinOS 10
 </p>
 <pre>sudo dnf install freeglut-devel libX11-devel libXi-devel libXmu-devel \
                    make mesa-libGLU-devel freeimage-devel libglfw3-devel
</pre>
 <p>
  Fedora
 </p>
 <pre>sudo dnf install freeglut-devel libX11-devel libXi-devel libXmu-devel \
    make mesa-libGLU-devel freeimage-devel libglfw3-devel
</pre>
 <p>
  SLES
 </p>
 <pre>sudo zypper install libglut3 libX11-devel libXi6 libXmu6 libGLU1 make
</pre>
 <p>
  OpenSUSE
 </p>
 <pre>sudo zypper install freeglut-devel libX11-devel libXi-devel libXmu-devel \
    make Mesa-libGL-devel freeimage-devel
</pre>
 <p>
  Ubuntu
 </p>
 <pre>sudo apt-get install g++ freeglut3-dev build-essential libx11-dev \
    libxmu-dev libxi-dev libglu1-mesa-dev libfreeimage-dev libglfw3-dev
</pre>
 <p>
  Debian
 </p>
 <pre>sudo apt-get install g++ freeglut3-dev build-essential libx11-dev \
    libxmu-dev libxi-dev libglu1-mesa-dev libfreeimage-dev libglfw3-dev
</pre>
 <h3>
  <span class="section-number">
   13.3.2.
  </span>
  Install the Source Code for cuda-gdb
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#install-the-source-code-for-cuda-gdb" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  <span class="pre">
   cuda-gdb
  </span>
  source must be explicitly selected for installation with the runfile installation method. During the installation, in the component selection page, expand the component âCUDA Tools 12.4â and select
  <span class="pre">
   cuda-gdb-src
  </span>
  for installation. It is unchecked by default.
 </p>
 <p>
  To obtain a copy of the source code for
  <span class="pre">
   cuda-gdb
  </span>
  using the RPM and Debian installation methods, the
  <span class="pre">
   cuda-gdb-src
  </span>
  package must be installed.
 </p>
 <p>
  The source code is installed as a tarball in the
  <span class="pre">
   /usr/local/cuda-12.4/extras
  </span>
  directory.
 </p>
 <h3>
  <span class="section-number">
   13.3.3.
  </span>
  Select the Active Version of CUDA
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#select-the-active-version-of-cuda" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  For applications that rely on the symlinks
  <span class="pre">
   /usr/local/cuda
  </span>
  and
  <span class="pre">
   /usr/local/cuda-MAJOR
  </span>
  , you may wish to change to a different installed version of CUDA using the provided alternatives.
 </p>
 <p>
  To show the active version of CUDA and all available versions:
 </p>
 <pre>update-alternatives --display cuda
</pre>
 <p>
  To show the active minor version of a given major CUDA release:
 </p>
 <pre>update-alternatives --display cuda-12
</pre>
 <p>
  To update the active version of CUDA:
 </p>
 <pre>sudo update-alternatives --config cuda
</pre>
 <h1>
  <span class="section-number">
   14.
  </span>
  Advanced Setup
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-setup" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Below is information on some advanced setup scenarios which are not covered in the basic instructions above.
 </p>
 <table class="table-no-stripes docutils align-default" id="id21">
  <span class="caption-number">
   Table 8
  </span>
  <span class="caption-text">
   Advanced Setup Scenarios when Installing CUDA
  </span>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#id21" title="Permalink to this table">
   ï
  </a>
  <tr class="row-odd">
   <th class="head">
    <p>
     Scenario
    </p>
   </th>
   <th class="head">
    <p>
     Instructions
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Install CUDA using the Package Manager installation method without installing the NVIDIA GL libraries.
    </p>
   </td>
   <td>
    <p>
     Fedora
    </p>
    <p>
     Install CUDA using the following command:
    </p>
    <pre>sudo dnf install cuda-toolkit-12-4 \
    nvidia-driver-cuda akmod-nvidia
</pre>
    <p>
     Follow the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-fedora">
      here
     </a>
     to ensure that Nouveau is disabled.
    </p>
    <p>
     If performing an upgrade over a previous installation, the NVIDIA kernel module may need to be rebuilt by following the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#faq8">
      here
     </a>
     .
    </p>
    <p>
     OpenSUSE/SLES
    </p>
    <p>
     On some system configurations the NVIDIA GL libraries may need to be locked before installation using:
    </p>
    <pre>sudo zypper addlock nvidia-glG04
</pre>
    <p>
     Install CUDA using the following command:
    </p>
    <pre>sudo zypper install --no-recommends cuda-toolkit-12-4 \
    nvidia-computeG04 \
    nvidia-gfxG04-kmp-default
</pre>
    <p>
     Follow the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau-suse">
      here
     </a>
     to ensure that Nouveau is disabled.
    </p>
    <p>
     Ubuntu
    </p>
    <p>
     This functionality isnât supported on Ubuntu. Instead, the driver packages integrate with the Bumblebee framework to provide a solution for users who wish to control what applications the NVIDIA drivers are used for. See Ubuntuâs
     <a class="reference external" href="https://wiki.ubuntu.com/Bumblebee">
      Bumblebee wiki
     </a>
     for more information.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Upgrade from a RPM/Deb driver installation which includes the diagnostic driver packages to a
    </p>
    <p>
     driver installation which does not include the diagnostic driver packages.
    </p>
   </td>
   <td>
    <p>
     RHEL/CentOS
    </p>
    <p>
     Remove diagnostic packages using the following command:
    </p>
    <pre>sudo yum remove cuda-drivers-diagnostic \
    xorg-x11-drv-nvidia-diagnostic
</pre>
    <p>
     Follow the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-upgrades">
      here
     </a>
     to continue installation as normal.
    </p>
    <p>
     Fedora
    </p>
    <p>
     Remove diagnostic packages using the following command:
    </p>
    <pre>sudo dnf remove cuda-drivers-diagnostic \
    xorg-x11-drv-nvidia-diagnostic
</pre>
    <p>
     Follow the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-upgrades">
      here
     </a>
     to continue installation as normal.
    </p>
    <p>
     OpenSUSE/SLES
    </p>
    <p>
     Remove diagnostic packages using the following command:
    </p>
    <pre>sudo zypper remove cuda-drivers-diagnostic \
    nvidia-diagnosticG04
</pre>
    <p>
     Follow the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-upgrades">
      here
     </a>
     to continue installation as normal.
    </p>
    <p>
     Ubuntu
    </p>
    <p>
     Remove diagnostic packages using the following command:
    </p>
    <pre>sudo apt-get purge cuda-drivers-diagnostic \
    nvidia-384-diagnostic
</pre>
    <p>
     Follow the instructions
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-upgrades">
      here
     </a>
     to continue installation as normal.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Use a specific GPU for rendering the display.
    </p>
   </td>
   <td>
    <p>
     Add or replace a
     Device
     entry in your
     <span class="pre">
      xorg.conf
     </span>
     file, located at
     <span class="pre">
      /etc/X11/xorg.conf
     </span>
     . The
     Device
     entry should resemble the following:
    </p>
    <pre>Section "Device"
    Identifier    "Device0"
    Driver        "driver_name"
    VendorName    "vendor_name"
    BusID         "bus_id"
EndSection
</pre>
    <p>
     The details will you will need to add differ on a case-by-case basis. For example, if you have two NVIDIA GPUs and you want the first GPU to be used for display, you would replace â
     <span class="pre">
      driver_name
     </span>
     â with â
     <span class="pre">
      nvidia
     </span>
     â, â
     <span class="pre">
      vendor_name
     </span>
     â with â
     <span class="pre">
      NVIDIA
     </span>
     <span class="pre">
      Corporation
     </span>
     â and â
     <span class="pre">
      bus_id
     </span>
     â with the Bus ID of the GPU.
The Bus ID will resemble âPCI:00:02.0â and can be found by running
     <span class="pre">
      lspci
     </span>
     .
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Install CUDA to a specific directory using the Package Manager installation method.
    </p>
   </td>
   <td>
    <p>
     RPM
    </p>
    <p>
     The RPM packages donât support custom install locations through the package managers (Yum and Zypper), but it is possible to install the RPM packages to a custom location using rpmâs
     <span class="pre">
      --relocate
     </span>
     parameter:
    </p>
    <pre>sudo rpm --install --relocate /usr/local/cuda-12.4=/new/toolkit package.rpm
</pre>
    <p>
     You will need to install the packages in the correct dependency order; this task is normally taken care of by the package managers. For example, if package âfooâ has a dependency on package âbarâ, you should install package âbarâ first, and package âfooâ second. You can check the dependencies of a RPM package as follows:
    </p>
    <pre>rpm -qRp package.rpm
</pre>
    <p>
     Note that the driver packages cannot be relocated.
    </p>
    <p>
     Deb
    </p>
    <p>
     The Deb packages do not support custom install locations. It is however possible to extract the contents of the Deb packages and move the files to the desired install location. See the next scenario for more details one xtracting Deb packages.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Extract the contents of the installers.
    </p>
   </td>
   <td>
    <p>
     Runfile
    </p>
    <p>
     The Runfile can be extracted into the standalone Toolkit and Driver Runfiles by using the
     <span class="pre">
      --extract
     </span>
     parameter. The Toolkit standalone Runfiles can be further extracted by running:
    </p>
    <pre>./runfile.run --tar mxvf
</pre>
    <p>
     The Driver Runfile can be extracted by running:
    </p>
    <pre>./runfile.run -x
</pre>
    <p>
     RPM
    </p>
    <p>
     The RPM packages can be extracted by running:
    </p>
    <pre>rpm2cpio package.rpm | cpio -idmv
</pre>
    <p>
     Deb
    </p>
    <p>
     The Deb packages can be extracted by running:
    </p>
    <pre>dpkg-deb -x package.deb output_dir
</pre>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Modify Ubuntuâs apt package manager to query specific architectures for specific repositories.
    </p>
    <p>
     This is useful when a foreign architecture has been added, causing â404 Not Foundâ errors to appear when the repository meta-data is updated.
    </p>
   </td>
   <td>
    <p>
     Each repository you wish to restrict to specific architectures must have its
     <span class="pre">
      sources.list
     </span>
     entry modified. This is done by modifying the
     <span class="pre">
      /etc/apt/sources.list
     </span>
     file and any files containing repositories you wish to restrict under the
     <span class="pre">
      /etc/apt/sources.list.d/
     </span>
     directory. Normally, it is sufficient to modify only the entries in
     <span class="pre">
      /etc/apt/sources.list
     </span>
    </p>
    <p>
     An architecture-restricted repository entry looks like:
    </p>
    <pre>deb [arch=&lt;arch1&gt;,&lt;arch2&gt;] &lt;url&gt;
</pre>
    <p>
     For example, if you wanted to restrict a repository to only the amd64 and i386 architectures, it would look like:
    </p>
    <pre>deb [arch=amd64,i386] &lt;url&gt;
</pre>
    <p>
     It is not necessary to restrict the
     <span class="pre">
      deb-src
     </span>
     repositories, as these repositories donât provide architecture-specific packages.
    </p>
    <p>
     For more details, see the
     <span class="pre">
      sources.list
     </span>
     manpage.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     The nvidia.ko kernel module fails to load, saying some symbols are unknown.
    </p>
    <p>
     For example:
    </p>
    <pre>nvidia: Unknown symbol drm_open (err 0)
</pre>
   </td>
   <td>
    <p>
     Check to see if there are any optionally installable modules that might provide these symbols which are not currently installed.
    </p>
    <p>
     For the example of the
     <span class="pre">
      drm_open
     </span>
     symbol, check to see if there are any packages which provide drm_open and are not already installed. For instance, on Ubuntu 14.04, the
     <span class="pre">
      linux-image-extra
     </span>
     package provides the DRM kernel module (which provides
     <span class="pre">
      drm_open
     </span>
     ). This package is optional even though the kernel headers reflect the availability of DRM regardless of whether this package is installed or not.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     The runfile installer fails to extract due to limited space in the TMP directory.
    </p>
   </td>
   <td>
    <p>
     This can occur on systems with limited storage in the TMP directory (usually
     <span class="pre">
      /tmp
     </span>
     ), or on systems which use a tmpfs in memory to handle temporary storage. In this case, the
     <span class="pre">
      --tmpdir
     </span>
     command-line option should be used to instruct the runfile to use a directory with sufficient space to extract into. More information on this option can be found
     <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-advanced">
      here
     </a>
     .
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Re-enable Wayland after installing the RPM driver on Fedora.
    </p>
   </td>
   <td>
    <p>
     Wayland is disabled during installation of the Fedora driver RPM due to compatability issues. To re-enable Wayland, comment out this line in
     <span class="pre">
      /etc/gdm/custom.conf
     </span>
     :
    </p>
    <pre>WaylandEnable=false
</pre>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     In case of the error:
     <span class="pre">
      E:
     </span>
     <span class="pre">
      Failed
     </span>
     <span class="pre">
      to
     </span>
     <span class="pre">
      fetch
     </span>
     <span class="pre">
      file:/var/cuda-repo
     </span>
     <span class="pre">
      File
     </span>
     <span class="pre">
      not
     </span>
     <span class="pre">
      found
     </span>
    </p>
   </td>
   <td>
    <p>
     Debian and Ubuntu
    </p>
    <p>
     This can occur when installing CUDA after uninstalling a different version. Use the following command before installation:
    </p>
    <pre>sudo rm -v /var/lib/apt/lists/*cuda* /var/lib/apt/lists/*nvidia*
</pre>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Verbose installation on Debian and Ubuntu
    </p>
   </td>
   <td>
    <p>
     Use the
     <span class="pre">
      --verbose-versions
     </span>
     flag, for example:
    </p>
    <pre>sudo apt-get install --verbose-versions cuda
</pre>
   </td>
  </tr>
 </table>
 <h1>
  <span class="section-number">
   15.
  </span>
  Frequently Asked Questions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#frequently-asked-questions" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <h2>
  <span class="section-number">
   15.1.
  </span>
  How do I install the Toolkit in a different location?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-install-the-toolkit-in-a-different-location" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The Runfile installation asks where you wish to install the Toolkit during an interactive install. If installing using a non-interactive install, you can use the
  <span class="pre">
   --toolkitpath
  </span>
  parameter to change the install location:
 </p>
 <pre>./runfile.run --silent \
                --toolkit --toolkitpath=/my/new/toolkit
</pre>
 <p>
  The RPM and Deb packages cannot be installed to a custom install location directly using the package managers. See the âInstall CUDA to a specific directory using the Package Manager installation methodâ scenario in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-setup">
   Advanced Setup
  </a>
  section for more information.
 </p>
 <h2>
  <span class="section-number">
   15.2.
  </span>
  Why do I see ânvcc: No such file or directoryâ when I try to build a CUDA application?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-do-i-see-nvcc-no-such-file-or-directory-when-i-try-to-build-a-cuda-application" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Your PATH environment variable is not set up correctly. Ensure that your PATH includes the bin directory where you installed the Toolkit, usually
  <span class="pre">
   /usr/local/cuda-12.4/bin
  </span>
  .
 </p>
 <pre>export PATH=/usr/local/cuda-12.4/bin${PATH:+:${PATH}}
</pre>
 <h2>
  <span class="section-number">
   15.3.
  </span>
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#faq3">
   Why do I see âerror while loading shared libraries: &lt;lib name&gt;: cannot open shared object file: No such file or directoryâ when I try to run a CUDA application that uses a CUDA library?
  </a>
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-do-i-see-error-while-loading-shared-libraries-lib-name-cannot-open-shared-object-file-no-such-file-or-directory-when-i-try-to-run-a-cuda-application-that-uses-a-cuda-library" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Your LD_LIBRARY_PATH environment variable is not set up correctly. Ensure that your LD_LIBRARY_PATH includes the lib and/or lib64 directory where you installed the Toolkit, usually
  <span class="pre">
   /usr/local/cuda-12.4/lib{,64}
  </span>
  :
 </p>
 <pre>export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib\
                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</pre>
 <h2>
  <span class="section-number">
   15.4.
  </span>
  Why do I see multiple â404 Not Foundâ errors when updating my repository meta-data on Ubuntu?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-do-i-see-multiple-404-not-found-errors-when-updating-my-repository-meta-data-on-ubuntu" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  These errors occur after adding a foreign architecture because apt is attempting to query for each architecture within each repository listed in the systemâs sources.list file. Repositories that do not host packages for the newly added architecture will present this error. While noisy, the error itself does no harm. Please see the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-setup">
   Advanced Setup
  </a>
  section for details on how to modify your
  <span class="pre">
   sources.list
  </span>
  file to prevent these errors.
 </p>
 <h2>
  <span class="section-number">
   15.5.
  </span>
  How can I tell X to ignore a GPU for compute-only use?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-can-i-tell-x-to-ignore-a-gpu-for-compute-only-use" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To make sure X doesnât use a certain GPU for display, you need to specify which
  other
  GPU to use for display. For more information, please refer to the âUse a specific GPU for rendering the displayâ scenario in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#advanced-setup">
   Advanced Setup
  </a>
  section.
 </p>
 <h2>
  <span class="section-number">
   15.6.
  </span>
  Why doesnât the cuda-repo package install the CUDA Toolkit and Drivers?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-doesn-t-the-cuda-repo-package-install-the-cuda-toolkit-and-drivers" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  When using RPM or Deb, the downloaded package is a repository package. Such a package only informs the package manager where to find the actual installation packages, but will not install them.
 </p>
 <p>
  See the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-installation">
   Package Manager Installation
  </a>
  section for more details.
 </p>
 <h2>
  <span class="section-number">
   15.7.
  </span>
  How do I get CUDA to work on a laptop with an iGPU and a dGPU running Ubuntu14.04?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-get-cuda-to-work-on-a-laptop-with-an-igpu-and-a-dgpu-running-ubuntu14-04" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  After installing CUDA, set the driver value for the
  <span class="pre">
   intel
  </span>
  device in
  <span class="pre">
   /etc/X11/xorg.conf
  </span>
  to â
  <span class="pre">
   modesetting
  </span>
  â as shown below:
 </p>
 <pre>Section "Device"
    Identifier "intel"
    Driver "modesetting"
    ...
EndSection
</pre>
 <p>
  To prevent Ubuntu from reverting the change in xorg.conf, edit
  <span class="pre">
   /etc/default/grub
  </span>
  to add â
  <span class="pre">
   nogpumanager
  </span>
  â to GRUB_CMDLINE_LINUX_DEFAULT.
 </p>
 <p>
  Run the following command to update grub before rebooting:
 </p>
 <pre>sudo update-grub
</pre>
 <h2>
  <span class="section-number">
   15.8.
  </span>
  What do I do if the display does not load, or CUDA does not work, after performing a system update?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#what-do-i-do-if-the-display-does-not-load-or-cuda-does-not-work-after-performing-a-system-update" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  System updates may include an updated Linux kernel. In many cases, a new Linux kernel will be installed without properly updating the required Linux kernel headers and development packages. To ensure the CUDA driver continues to work when performing a system update, rerun the commands in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-the-system-has-the-correct-kernel-headers-and-development-packages-installed">
   Kernel Headers and Development Packages
  </a>
  section.
 </p>
 <p>
  Additionally, on Fedora, the Akmods framework will sometimes fail to correctly rebuild the NVIDIA kernel module packages when a new Linux kernel is installed. When this happens, it is usually sufficient to invoke Akmods manually and regenerate the module mapping files by running the following commands in a virtual console, and then rebooting:
 </p>
 <pre>sudo akmods --force
sudo depmod
</pre>
 <p>
  You can reach a virtual console by hitting
  <span class="pre">
   ctrl+alt+f2
  </span>
  at the same time.
 </p>
 <h2>
  <span class="section-number">
   15.9.
  </span>
  How do I install a CUDA driver with a version less than 367 using a network repo?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-install-a-cuda-driver-with-a-version-less-than-367-using-a-network-repo" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  To install a CUDA driver at a version earlier than 367 using a network repo, the required packages will need to be explicitly installed at the desired version. For example, to install 352.99, instead of installing the cuda-drivers metapackage at version 352.99, you will need to install all required packages of cuda-drivers at version 352.99.
 </p>
 <h2>
  <span class="section-number">
   15.10.
  </span>
  How do I install an older CUDA version using a network repo?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-install-an-older-cuda-version-using-a-network-repo" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Depending on your system configuration, you may not be able to install old versions of CUDA using the cuda metapackage. In order to install a specific version of CUDA, you may need to specify all of the packages that would normally be installed by the cuda metapackage at the version you want to install.
 </p>
 <p>
  If you are using yum to install certain packages at an older version, the dependencies may not resolve as expected. In this case you may need to pass â
  <span class="pre">
   --setopt=obsoletes=0
  </span>
  â to yum to allow an install of packages which are obsoleted at a later version than you are trying to install.
 </p>
 <h2>
  <span class="section-number">
   15.11.
  </span>
  Why does the installation on SUSE install the Mesa-dri-nouveau dependency?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#why-does-the-installation-on-suse-install-the-mesa-dri-nouveau-dependency" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This dependency comes from the SUSE repositories and shouldnât affect the use of the NVIDIA driver or the CUDA Toolkit. To disable this dependency, you can lock that package with the following command:
 </p>
 <pre>sudo zypper al Mesa-dri-nouveau
</pre>
 <h2>
  <span class="section-number">
   15.12.
  </span>
  How do I handle âErrors were encountered while processing: glx-diversionsâ?
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#how-do-i-handle-errors-were-encountered-while-processing-glx-diversions" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This sometimes occurs when trying to uninstall CUDA after a clean .deb installation. Run the following commands:
 </p>
 <pre>sudo apt-get install glx-diversions --reinstall
sudo apt-get remove nvidia-alternative
</pre>
 <p>
  Then re-run the commands from
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-tk-and-driver">
   Removing CUDA Toolkit and Driver
  </a>
  .
 </p>
 <h1>
  <span class="section-number">
   16.
  </span>
  Additional Considerations
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#additional-considerations" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Now that you have CUDA-capable hardware and the NVIDIA CUDA Toolkit installed, you can examine and enjoy the numerous included programs. To begin using CUDA to accelerate the performance of your own applications, consult the CUDA C++ Programming Guide, located in
  <span class="pre">
   /usr/local/cuda-12.4/doc
  </span>
  .
 </p>
 <p>
  A number of helpful development tools are included in the CUDA Toolkit to assist you as you develop your CUDA programs, such as NVIDIA
  Â®
  Nsightâ¢ Eclipse Edition, NVIDIA Visual Profiler, CUDA-GDB, and CUDA-MEMCHECK.
 </p>
 <p>
  For technical support on programming questions, consult and participate in the developer forums at
  <a class="reference external" href="https://forums.developer.nvidia.com/c/accelerated-computing/cuda/206">
   https://forums.developer.nvidia.com/c/accelerated-computing/cuda/206
  </a>
  .
 </p>
 <h1>
  <span class="section-number">
   17.
  </span>
  Switching between Driver Module Flavors
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#switching-between-driver-module-flavors" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Use the following steps to switch between the NVIDIA driver legacy and open module flavors on your system.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  If switching to open module, experimental support for GeForce and Quadro SKUs can be enabled with:
 </p>
 <pre>echo "options nvidia NVreg_OpenRmEnableUnsupportedGpus=1" | sudo tee /etc/modprobe.d/nvidia-gsp.conf
</pre>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Replace
  XXX
  with the NVIDIA driver branch number such as 550.
 </p>
 <p>
  Fedora, RHEL 9 / Rocky Linux 9, RHEL 8 / Rocky Linux 8
 </p>
 <p>
  To switch between legacy and open: uninstall, then reinstall.
 </p>
 <p>
  Kylin OS
 </p>
 <p>
  To switch between legacy and open: uninstall, then reinstall.
 </p>
 <p>
  Ubuntu
 </p>
 <p>
  To switch from legacy to open:
 </p>
 <pre>sudo apt-get --purge remove nvidia-kernel-source-XXX
sudo apt-get install --verbose-versions nvidia-kernel-open-XXX
sudo apt-get install --verbose-versions cuda-drivers-XXX
</pre>
 <p>
  To switch from open to legacy:
 </p>
 <pre>sudo apt-get remove --purge nvidia-kernel-open-XXX
sudo apt-get install --verbose-versions cuda-drivers-XXX
</pre>
 <p>
  Debian
 </p>
 <p>
  To switch from legacy to open:
 </p>
 <pre>sudo apt-get --purge remove nvidia-kernel-dkms
sudo apt-get install --verbose-versions nvidia-kernel-open-dkms
sudo apt-get install --verbose-versions cuda-drivers-XXX
</pre>
 <p>
  To switch from open to legacy:
 </p>
 <pre>sudo apt-get remove --purge nvidia-kernel-open-dkms
sudo apt-get install --verbose-versions cuda-drivers-XXX
</pre>
 <p>
  OpenSUSE
 </p>
 <p>
  To switch from legacy to open:
 </p>
 <pre>sudo zypper remove nvidia-driver-G06-kmp-default
sudo zypper install --details nvidia-open-driver-G06-kmp-default
sudo zypper install --details cuda-drivers-XXX
</pre>
 <p>
  To switch from open to legacy:
 </p>
 <pre>sudo zypper remove nvidia-open-driver-G06-kmp-default
sudo zypper install --details cuda-drivers-XXX
</pre>
 <p>
  SLES
 </p>
 <p>
  To switch from legacy to open:
 </p>
 <pre>sudo zypper remove nvidia-driver-G06-kmp-default nvidia-driver-G06-kmp-azure
sudo zypper install --details nvidia-open-driver-G06-kmp-default nvidia-open-driver-G06-kmp-azure
sudo zypper install --details cuda-drivers-XXX
</pre>
 <p>
  To switch from open to legacy:
 </p>
 <pre>sudo zypper remove nvidia-open-driver-G06-kmp-default nvidia-driver-G06-open-kmp-azure
sudo zypper install --details cuda-drivers-XXX
</pre>
 <p class="admonition-title">
  Note
 </p>
 <p>
  The Azure package is only available for SLES (x86_64).
 </p>
 <h1>
  <span class="section-number">
   18.
  </span>
  Removing CUDA Toolkit and Driver
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#removing-cuda-toolkit-and-driver" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Follow the below steps to properly uninstall the CUDA Toolkit and NVIDIA Drivers from your system. These steps will ensure that the uninstallation will be clean.
 </p>
 <p>
  KylinOS 10
 </p>
 <p>
  To remove CUDA Toolkit:
 </p>
 <pre>sudo dnf remove "cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
                    "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"
</pre>
 <p>
  To remove NVIDIA Drivers:
 </p>
 <pre>sudo dnf module remove --all nvidia-driver
</pre>
 <p>
  To reset the module stream:
 </p>
 <pre>sudo dnf module reset nvidia-driver
</pre>
 <p>
  RHEL 9 / Rocky Linux 9
 </p>
 <p>
  To remove CUDA Toolkit:
 </p>
 <pre>sudo dnf remove "cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
 "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"
</pre>
 <p>
  To remove NVIDIA Drivers:
 </p>
 <pre>sudo dnf module remove --all nvidia-driver
</pre>
 <p>
  To reset the module stream:
 </p>
 <pre>sudo dnf module reset nvidia-driver
</pre>
 <p>
  RHEL 8 / Rocky Linux 8
 </p>
 <p>
  To remove CUDA Toolkit:
 </p>
 <pre>sudo dnf remove "cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
 "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"
</pre>
 <p>
  To remove NVIDIA Drivers:
 </p>
 <pre>sudo dnf module remove --all nvidia-driver
</pre>
 <p>
  To reset the module stream:
 </p>
 <pre>sudo dnf module reset nvidia-driver
</pre>
 <p>
  Fedora
 </p>
 <p>
  To remove CUDA Toolkit:
 </p>
 <pre>sudo dnf remove "cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
 "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"
</pre>
 <p>
  To remove NVIDIA Drivers:
 </p>
 <pre>sudo dnf module remove --all nvidia-driver
</pre>
 <p>
  To reset the module stream:
 </p>
 <pre>sudo dnf module reset nvidia-driver
</pre>
 <p>
  To remove 3rd party NVIDIA Drivers:
 </p>
 <pre>sudo dnf remove "*nvidia*"
</pre>
 <p>
  OpenSUSE / SLES
 </p>
 <p>
  To remove CUDA Toolkit:
 </p>
 <pre>sudo zypper remove "cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
 "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"
</pre>
 <p>
  To remove NVIDIA Drivers:
 </p>
 <pre>sudo zypper remove "*nvidia*"
</pre>
 <p>
  Ubuntu and Debian
 </p>
 <p>
  To remove CUDA Toolkit:
 </p>
 <pre>sudo apt-get --purge remove "*cuda*" "*cublas*" "*cufft*" "*cufile*" "*curand*" \
 "*cusolver*" "*cusparse*" "*gds-tools*" "*npp*" "*nvjpeg*" "nsight*" "*nvvm*"
</pre>
 <p>
  To remove NVIDIA Drivers:
 </p>
 <pre>sudo apt-get --purge remove "*nvidia*" "libxnvctrl*"
</pre>
 <p>
  To clean up the uninstall:
 </p>
 <pre>sudo apt-get autoremove
</pre>
 <h1>
  <span class="section-number">
   19.
  </span>
  Notices
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#notices" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <h2>
  <span class="section-number">
   19.1.
  </span>
  Notice
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#notice" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product. NVIDIA Corporation (âNVIDIAâ) makes no representations or warranties, expressed or implied, as to the accuracy or completeness of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use. This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality.
 </p>
 <p>
  NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any time without notice.
 </p>
 <p>
  Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete.
 </p>
 <p>
  NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (âTerms of Saleâ). NVIDIA hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in this document. No contractual obligations are formed either directly or indirectly by this document.
 </p>
 <p>
  NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications and therefore such inclusion and/or use is at customerâs own risk.
 </p>
 <p>
  NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is customerâs sole responsibility to evaluate and determine the applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer, and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customerâs product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product designs.
 </p>
 <p>
  No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights of NVIDIA.
 </p>
 <p>
  Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices.
 </p>
 <p>
  THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, âMATERIALSâ) ARE BEING PROVIDED âAS IS.â NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any reason whatsoever, NVIDIAâs aggregate and cumulative liability towards customer for the products described herein shall be limited in accordance with the Terms of Sale for the product.
 </p>
 <h2>
  <span class="section-number">
   19.2.
  </span>
  OpenCL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#opencl" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc.
 </p>
 <h2>
  <span class="section-number">
   19.3.
  </span>
  Trademarks
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#trademarks" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.
 </p>
 <h1>
  <span class="section-number">
   20.
  </span>
  Copyright
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#copyright" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Â© 2009-2024 NVIDIA Corporation &amp; affiliates. All rights reserved.
 </p>
 <p>
  This product includes software developed by the Syncro Soft SRL (
  <a class="reference external" href="http://www.sync.ro/">
   http://www.sync.ro/
  </a>
  ).
 </p>
 <p class="notices">
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
   Privacy Policy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">
   Manage My Privacy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">
   Do Not Sell or Share My Data
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
   Terms of Service
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
   Accessibility
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
   Corporate Policies
  </a>
  |
  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
   Product Security
  </a>
  |
  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
   Contact
  </a>
 </p>
 <p>
  <a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/copyright.html">
   Copyright
  </a>
  Â© 2009-2024, NVIDIA Corporation &amp; affiliates. All rights reserved.
 </p>
 <p>
  <span class="lastupdated">
   Last updated on Jul 1, 2024.
  </span>
 </p>
</body>
</body></html>