<html><head><title>NVIDIA Multi-Instance GPU User Guide :: NVIDIA Data Center GPU Driver Documentation</title></head><body><body>
 <span id="company">
  NVIDIA
 </span>
 <span id="site-title">
  NVIDIA Data Center GPU Driver Documentation
 </span>
 Search In:
 Entire Site
 Just This Document
 clear search
 search
 <a href="https://docs.nvidia.com/datacenter/tesla/index.html" title="The root of the site.">
  NVIDIA Data Center GPU
 </a>
 <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html" title="NVIDIA Multi-Instance GPU User Guide">
  NVIDIA Multi-Instance GPU User Guide
 </a>
 <ul>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#introduction">
    1. Introduction
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-gpus">
    2. Supported GPUs
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-configs">
    3. Supported Configurations
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#virtualization">
    4. Virtualization
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#concepts">
    5. Concepts
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#terminology">
      5.1. Terminology
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#partitioning">
      5.2. Partitioning
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-concurrency">
      5.3. CUDA Concurrency Mechanisms
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#deployment">
    6. Deployment Considerations
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#system-considerations">
      6.1. System Considerations
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#app-considerations">
      6.2. Application Considerations
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-names">
    7. MIG Device Names
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-enum">
      7.1. Device Enumeration
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-visible-devices">
      7.2. CUDA Device Enumeration
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-profiles">
    8. Supported MIG Profiles
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#a30-profiles">
      8.1. A30 MIG Profiles
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#a100-profiles">
      8.2. A100 MIG Profiles
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#h100-profiles">
      8.3. H100 MIG Profiles
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#h200-profiles">
      8.4. H200 MIG Profiles
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#running-with-mig">
    9. Getting Started with MIG
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#prerequisites">
      9.1. Prerequisites
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#enable-mig-mode">
      9.2. Enable MIG Mode
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#reset-hopper">
        9.2.1. GPU Reset on Hopper+ GPUs
       </a>
      </li>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#reset-ampere">
        9.2.2. GPU Reset on Ampere GPUs
       </a>
      </li>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#driver-clients">
        9.2.3. Driver Clients
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#lgi">
      9.3. List GPU Instance Profiles
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#create-gi">
      9.4. Creating GPU Instances
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-baremetal">
      9.5. Running CUDA Applications on Bare-Metal
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-gi">
        9.5.1. GPU Instances
       </a>
      </li>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-ci">
        9.5.2. Compute Instances
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-destroy">
      9.6. Destroying GPU Instances
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#telemetry">
      9.7. Monitoring MIG Devices
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-mps">
      9.8. MIG with CUDA MPS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-containers">
      9.9. Running CUDA Applications as Containers
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#install-docker">
        9.9.1. Install Docker
       </a>
      </li>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#nvidia-docker">
        9.9.2. Install NVIDIA Container Toolkit
       </a>
      </li>
      <li>
       <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#running-containers">
        9.9.3. Running Containers
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#kubernetes">
      9.10. MIG with Kubernetes
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#slurm">
      9.11. MIG with Slurm
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes">
    10. Device Nodes and Capabilities
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes-devfs">
      10.1. /dev based nvidia-capabilities
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes-procfs">
      10.2. /proc based nvidia-capabilities (**Deprecated**)
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#changelog">
    11. Changelog
   </a>
  </li>
 </ul>
 <h2>
  Search Results
 </h2>
 NVIDIA Multi-Instance GPU User Guide
                  
                  
                  
                  
                  (
 <a href="https://docs.nvidia.com/datacenter/tesla/pdf/NVIDIA_MIG_User_Guide.pdf">
  PDF
 </a>
 )
                  -
                  
                  
                  
                  Last updated March 26, 2024
                  -
 <a name="abstract" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#abstract" name="abstract" shape="rect">
   NVIDIA Multi-Instance GPU User Guide
  </a>
 </h2>
 <p class="shortdesc">
  User guide for Multi-Instance GPU on the NVIDIAÂ® GPUs.
 </p>
 <p class="p">
  This edition of the user guide describes the Multi-Instance GPU feature first introduced
                        with the NVIDIAÂ® Ampere architecture.
 </p>
 <a name="introduction" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#introduction" name="introduction" shape="rect">
   Introduction
  </a>
 </h2>
 <p class="p">
  The new Multi-Instance GPU (MIG) feature allows GPUs (starting with NVIDIA Ampere 
                        architecture) to be securely partitioned into up to seven 
                        separate GPU Instances for CUDA applications, providing multiple users with separate 
                        GPU resources for optimal GPU utilization. This feature is particularly beneficial for 
                        workloads that do not fully saturate the GPU's compute capacity and therefore users may want to 
                        run different workloads in parallel to maximize utilization.
 </p>
 <p class="p">
  For Cloud Service Providers (CSPs), who have multi-tenant use cases, MIG ensures one client 
                        cannot impact the work or scheduling of other clients, in addition to providing enhanced isolation for customers.
 </p>
 <p class="p">
  With MIG, each instance's processors have separate and isolated paths through the entire
                        memory system - the on-chip crossbar ports, L2 cache banks, memory controllers, and DRAM
                        address busses are all assigned uniquely to an individual instance. This ensures that an
                        individual user's workload can run with predictable throughput and latency, with the same L2
                        cache allocation and DRAM bandwidth, even if other tasks are thrashing their own caches or
                        saturating their DRAM interfaces. MIG can partition available GPU compute resources (including 
                        streaming multiprocessors or SMs, and GPU engines such as copy engines or decoders), to provide 
                        a defined quality of service (QoS) with fault isolation for different clients such as VMs, 
                        containers or processes. MIG enables multiple GPU Instances to run in parallel on a single, physical 
                        NVIDIA Ampere GPU.
 </p>
 <p class="p">
  With MIG, users will be able to see and schedule jobs on their new virtual GPU Instances as 
                        if they were physical GPUs. MIG works with Linux operating systems, supports containers using Docker Engine, 
                        with support for Kubernetes and virtual machines using hypervisors such as Red Hat Virtualization and 
                        VMware vSphere.
 </p>
 MIG supports the following deployment configurations:
 <ul class="ul">
  <li class="li">
   <p class="p">
    Bare-metal, including containers
   </p>
  </li>
  <li class="li">
   <p class="p">
    GPU pass-through virtualization to Linux guests on top of supported hypervisors
   </p>
  </li>
  <li class="li">
   <p class="p">
    vGPU on top of supported hypervisors
   </p>
  </li>
 </ul>
 <p class="p">
  MIG allows multiple vGPUs (and thereby VMs) to run in parallel on a single GPU, while preserving the isolation guarantees
                        
                        that vGPU provides. For more information on GPU partitioning using vGPU and MIG, refer to the
  <a class="xref" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/TB-10226-001_v01.pdf" shape="rect" target="_blank">
   technical brief
  </a>
  .
 </p>
 <a name="introduction__gpu-mig-overview" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 1. MIG Overview
 </span>
 <p class="p">
  The purpose of this document is to introduce the concepts behind MIG, deployment considerations and 
                        provide examples of MIG management to demonstrate how users can run CUDA applications on MIG supported GPUs.
 </p>
 <a name="supported-gpus" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-gpus" name="supported-gpus" shape="rect">
   Supported GPUs
  </a>
 </h2>
 <p class="p">
  MIG is supported on GPUs starting with the NVIDIA Ampere generation (i.e. GPUs with
                        compute capability &gt;= 8.0). The following table provides a list of supported GPUs:
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 1. Supported GPU Products
  </span>
  <tr class="row">
   <th class="entry" colspan="1" id="d54e138" rowspan="1" valign="top" width="NaN%">
    Product
   </th>
   <th class="entry" colspan="1" id="d54e141" rowspan="1" valign="top" width="NaN%">
    Architecture
   </th>
   <th class="entry" colspan="1" id="d54e144" rowspan="1" valign="top" width="NaN%">
    Microarchitecture
   </th>
   <th class="entry" colspan="1" id="d54e147" rowspan="1" valign="top" width="NaN%">
    Compute Capability
   </th>
   <th class="entry" colspan="1" id="d54e150" rowspan="1" valign="top" width="NaN%">
    Memory Size
   </th>
   <th class="entry" colspan="1" id="d54e154" rowspan="1" valign="top" width="NaN%">
    Max Number of Instances
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    H100-SXM5
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    Hopper
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GH100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    9.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    80GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    H100-PCIE
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    Hopper
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GH100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    9.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    80GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    H100-SXM5
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    Hopper
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GH100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    9.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    94GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    H100-PCIE
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    Hopper
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GH100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    9.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    94GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    H100 on GH200
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    Hopper
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GH100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    9.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    96GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    A100-SXM4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    NVIDIA Ampere
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GA100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    8.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    40GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    A100-SXM4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    NVIDIA Ampere
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GA100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    8.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    80GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    A100-PCIE
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    NVIDIA Ampere
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GA100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    8.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    40GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    A100-PCIE
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    NVIDIA Ampere
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GA100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    8.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    80GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e138" rowspan="1" valign="top" width="NaN%">
    A30
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e141" rowspan="1" valign="middle" width="NaN%">
    NVIDIA Ampere
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e144" rowspan="1" valign="middle" width="NaN%">
    GA100
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e147" rowspan="1" valign="middle" width="NaN%">
    8.0
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e150" rowspan="1" valign="middle" width="NaN%">
    24GB
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e154" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
  </tr>
 </table>
 <p class="p">
  Additionally, MIG is supported on systems that include the supported products above such as 
                        DGX, DGX Station and HGX.
 </p>
 <a name="supported-configs" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-configs" name="supported-configs" shape="rect">
   Supported Configurations
  </a>
 </h2>
 Supported deployment configurations with MIG include
 <ul class="ul">
  <li class="li">
   <p class="p">
    Bare-metal, including
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#running-containers" shape="rect">
     containers
    </a>
    and
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#kubernetes" shape="rect">
     Kubernetes
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    GPU pass-through virtualization to Linux guests on top of supported hypervisors
   </p>
  </li>
  <li class="li">
   <p class="p">
    vGPU on top of supported hypervisors
   </p>
  </li>
 </ul>
 <a name="virtualization" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#virtualization" name="virtualization" shape="rect">
   Virtualization
  </a>
 </h2>
 MIG can be used with two types of virtualization:
 <ul class="ul">
  <li class="li">
   <p class="p">
    Under Linux guests on supported hypervisors, when MIG-supported GPUs are 
                                 in GPU pass-through, the same
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#running-with-mig" shape="rect">
     workflows
    </a>
    , tools 
                                 and
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-profiles" shape="rect">
     profiles
    </a>
    available 
                                 on bare-metal can be used.
   </p>
  </li>
  <li class="li">
   <p class="p">
    MIG allows multiple vGPUs (and thereby VMs) to run in parallel on a single 
                                 MIG-supported GPU, while preserving the isolation guarantees that vGPU provides.
                                 To configure a GPU for use with vGPU VMs, refer to the
    <a class="xref" href="https://docs.nvidia.com/grid/latest/grid-vgpu-user-guide/index.html#configuring-a-gpu-for-mig-backed-vgpus" shape="rect" target="_blank">
     chapter
    </a>
    in the vGPU Software User
                                 Guide.
                                 Refer also to the
    <a class="xref" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/TB-10226-001_v01.pdf" shape="rect" target="_blank">
     technical brief
    </a>
    for more information on GPU partitioning with vGPU.
   </p>
  </li>
 </ul>
 <a name="concepts" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#concepts" name="concepts" shape="rect">
   Concepts
  </a>
 </h2>
 <a name="terminology" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#terminology" name="terminology" shape="rect">
   Terminology
  </a>
 </h3>
 <p class="p">
  This section introduces some terminology used to describe the concepts behind MIG.
 </p>
 <h3 class="title sectiontitle">
  Streaming Multiprocessor
 </h3>
 <p class="p">
  A streaming multiprocessor (SM) executes compute instructions on the GPU.
 </p>
 <h3 class="title sectiontitle">
  GPU Context
 </h3>
 A GPU context is analogous to a CPU process. It encapsulates all the resources necessary 
                              to execute operations on the GPU, including a distinct address space, memory allocations, 
                              etc. A GPU context has the following properties:
 <a name="terminology__ul_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ul class="ul" id="terminology__ul_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    Fault isolation
   </p>
  </li>
  <li class="li">
   <p class="p">
    Individually scheduled
   </p>
  </li>
  <li class="li">
   <p class="p">
    Distinct address space
   </p>
  </li>
 </ul>
 <h3 class="title sectiontitle">
  GPU Engine
 </h3>
 <p class="p">
  A GPU engine is what executes work on the GPU. The most commonly used engine is the 
                              Compute/Graphics engine that executes the compute instructions. Other engines include the 
                              copy engine (CE) that is responsible for performing DMAs, NVDEC for video decoding, NVENC 
                              for encoding, etc. Each engine can be scheduled independently and execute work for different 
                              GPU contexts.
 </p>
 <h3 class="title sectiontitle">
  GPU Memory Slice
 </h3>
 <p class="p">
  A GPU memory slice is the smallest fraction of the GPU's memory, including the 
                              corresponding memory controllers and cache. A GPU memory slice is roughly one eighth of the 
                              total GPU memory resources, including both capacity and bandwidth.
 </p>
 <h3 class="title sectiontitle">
  GPU SM Slice
 </h3>
 <p class="p">
  A GPU SM slice is the smallest fraction of the SMs on the GPU. A GPU SM slice is 
                              roughly one seventh of the total number of SMs available in the GPU when configured in MIG mode.
 </p>
 <h3 class="title sectiontitle">
  GPU Slice
 </h3>
 <p class="p">
  A GPU slice is the smallest fraction of the GPU that combines a single GPU memory slice 
                              and a single GPU SM slice.
 </p>
 <h3 class="title sectiontitle">
  GPU Instance
 </h3>
 <p class="p">
  A GPU Instance (GI) is a combination of GPU slices and GPU engines (DMAs, NVDECs, etc.). 
                              Anything within a GPU instance always shares all the GPU memory slices and other GPU engines, 
                              but it's SM slices can be further subdivided into compute instances (CI). A GPU instance provides 
                              memory QoS. Each GPU slice includes dedicated GPU memory resources which limit both the available 
                              capacity and bandwidth, and provide memory QoS. Each GPU memory slice gets 1/8 of the total GPU 
                              memory resources and each GPU SM slice gets 1/7 of the total number of SMs.
 </p>
 <h3 class="title sectiontitle">
  Compute Instance
 </h3>
 <p class="p">
  A GPU instance can be subdivided into multiple compute instances. A Compute Instance (CI) contains 
                              a subset of the parent GPU instance's SM slices and other GPU engines (DMAs, NVDECs, etc.). 
                              The CIs share memory and engines.
 </p>
 <a name="partitioning" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#partitioning" name="partitioning" shape="rect">
   Partitioning
  </a>
 </h3>
 <p class="p">
  Using the concepts introduced above, this section provides an overview of how the user can 
                           create various partitions on the GPU. For illustration purposes, the document will use the 
                           A100-40GB as an example, but the process is similar for other GPUs that support MIG.
 </p>
 <h3 class="title sectiontitle">
  GPU Instance
 </h3>
 <p class="p">
  Partitioning of the GPU happens using memory slices, so the A100-40GB GPU can be thought 
                              of having 8x5GB memory slices and 7 SM slices as shown in the diagram below.
 </p>
 <a name="partitioning__mig-partitioning-ex1" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 2. Available Slices on A100
 </span>
 <p class="p">
  As explained above, then to create a GPU Instance (GI) requires combining some number of 
                              memory slices with some number of compute slices. In the diagram below, a 5GB memory 
                              slice is combined with 1 compute slice to create a
  1g.5gb
  GI profile:
 </p>
 <a name="partitioning__mig-partitioning-ex2" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 3. Combining Memory and Compute Slices
 </span>
 <p class="p">
  Similarly, 4x5GB memory slices can be combined with 4x1 compute slices to create the
  4g.5gb
  GI profile:
 </p>
 <a name="partitioning__mig-partitioning-ex3" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 4. Combining Memory and Compute Slices
 </span>
 <h3 class="title sectiontitle">
  Compute Instance
 </h3>
 <p class="p">
  The compute slices of a GPU Instance can be further subdivided into multiple 
                              Compute Instances (CI), with the CIs sharing the engines and memory of the parent GI, 
                              but each CI has dedicated SM resources.
 </p>
 <p class="p">
  Using the same
  4g.20gb
  example above, a CI may be created to consume only the first 
                              compute slice as shown below:
 </p>
 <a name="partitioning__mig-partitioning-ex4" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 5. Combining Memory and Compute Slices
 </span>
 <p class="p">
  In this case, 4 different CIs can be created by choosing any of the compute slices. Two compute 
                              slices can also be combined together to create a
  2c.4g.20gb
  profile:
 </p>
 <a name="partitioning__mig-partitioning-ex5" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 6. Combining Memory and Compute Slices
 </span>
 <p class="p">
  In this example, 3 compute slices can also be combined to create a
  3c.4g.20gb
  profile or all 4 can be combined to create a
  4c.4g.20gb
  profile. When all 4 
                              compute slices are combined, the profile is simply referred to as the
  4g.20gb
  profile.
 </p>
 <p class="p">
  Refer to the sections on the
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-names" shape="rect">
   canonical naming scheme
  </a>
  and 
                              the
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-visible-devices" shape="rect">
   CUDA device terminology
  </a>
  .
 </p>
 <h3 class="title sectiontitle">
  Profile Placement
 </h3>
 <p class="p">
  The number of slices that a GI can be created with is not arbitrary. The NVIDIA driver 
                              APIs provide a number of âGPU Instance Profilesâ and users can create GIs by specifying 
                              one of these profiles.
 </p>
 <p class="p">
  On a given GPU, multiple GIs can be created from a mix and match of these profiles, so long 
                              as enough slices are available to satisfy the request.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The table below shows the profile names on the A100-SXM4-40GB product. For A100-SXM4-80GB, the 
                                 profile names will change according to the memory proportion - for example,
  1g.10gb
  ,
  2g.20gb
  ,
  3g.40gb
  ,
  4g.40gb
  ,
  7g.80gb
  respectively.
 </p>
 <p class="p">
  For a list of all supported combinations of profiles on MIG-enabled GPUs, refer to the section on
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-names" shape="rect">
   supported profiles
  </a>
  .
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 2. GPU Instance Profiles on A100
  </span>
  <tr class="row">
   <th class="entry" colspan="1" id="d54e762" rowspan="1" valign="top" width="NaN%">
    Profile Name
   </th>
   <th class="entry" colspan="1" id="d54e765" rowspan="1" valign="top" width="NaN%">
    Fraction of Memory
   </th>
   <th class="entry" colspan="1" id="d54e768" rowspan="1" valign="top" width="NaN%">
    Fraction of SMs
   </th>
   <th class="entry" colspan="1" id="d54e771" rowspan="1" valign="top" width="NaN%">
    Hardware Units
   </th>
   <th class="entry" colspan="1" id="d54e774" rowspan="1" valign="top" width="NaN%">
    L2 Cache Size
   </th>
   <th class="entry" colspan="1" id="d54e778" rowspan="1" valign="top" width="NaN%">
    Copy Engines
   </th>
   <th class="entry" colspan="1" id="d54e781" rowspan="1" valign="top" width="NaN%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 1g.5gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    0 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 1g.5gb+me
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 1g.10gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 2g.10gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    2/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 3g.20gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    3/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 4g.20gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    4/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e762" rowspan="1" valign="top" width="NaN%">
    MIG 7g.40gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e765" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e768" rowspan="1" valign="middle" width="NaN%">
    7/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e771" rowspan="1" valign="middle" width="NaN%">
    5 NVDECs /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e774" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e778" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e781" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
 </table>
 <p class="p">
  The diagram below shows a pictorial representation of how to build all valid
                              combinations of GPU instances.
 </p>
 <a name="partitioning__mig-partitioning-ex6" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 7. MIG Profiles on A100
 </span>
 <p class="p">
  In this diagram, a valid combination can be built by starting with an instance
                              profile on the left and combining it with other instance profiles as you move to the
                              right, such that no two profiles overlap vertically.  For a list of all supported
                              combinations and placements of profiles on A100 and A30, refer to the section on
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-names" shape="rect">
   supported profiles
  </a>
  .
 </p>
 <p class="p">
  Note that prior to NVIDIA driver release R510, the combination of a (4 memory, 4
                              compute) and a (4 memory, 3 compute) profile was not supported. This restriction no
                              longer applies on newer drivers.
 </p>
 <a name="partitioning__mig-partitioning-ex7" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 8. Profile Placements on A100
 </span>
 <p class="p">
  Note that the diagram represents the physical layout of where the GPU Instances will exist once they 
                              are instantiated on the GPU. As GPU Instances are created and destroyed at different locations, 
                              fragmentation can occur, and the physical position of one GPU Instance will play a role in which other 
                              GPU Instances can be instantiated next to it.
 </p>
 <a name="cuda-concurrency" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-concurrency" name="cuda-concurrency" shape="rect">
   CUDA Concurrency Mechanisms
  </a>
 </h3>
 <p class="p">
  MIG has been designed to be largely transparent to CUDA applications - so that the 
                           CUDA programming model remains unchanged to minimize programming effort. CUDA already 
                           exposes multiple technologies for running work in parallel on the GPU and it is worthwhile 
                           showcasing how these technologies compare to MIG. Note that streams and MPS are part of the 
                           CUDA programming model and thus work when used with GPU Instances.
 </p>
 <p class="p">
  CUDA Streams are a CUDA Programming model feature where, in a CUDA application, different 
                           work can be submitted to independent queues and be processed independently by the GPU. 
                           CUDA streams can only be used within a single process and don't offer much isolation - the 
                           address space is shared, the SMs are shared, the GPU memory bandwidth, caches and capacity 
                           are shared. And lastly any errors affect all the streams and the whole process.
 </p>
 <p class="p">
  MPS is the CUDA Multi-Process service. It allows co-operative multi process applications to share 
                           compute resources on the GPU. It's commonly used by MPI jobs that cooperate, but it has also been 
                           used for sharing the GPU resources among unrelated applications, while accepting the challenges that 
                           such a solution brings. MPS currently does not offer error isolation between clients and while 
                           streaming multiprocessors used by each MPS client can be optionally limited to a percentage of all SMs, 
                           the scheduling hardware is still shared. Memory bandwidth, caches and capacity are all shared 
                           between MPS clients.
 </p>
 <p class="p">
  Lastly, MIG is the new form of concurrency offered by NVIDIA GPUs while addressing some of the 
                           limitations with the other CUDA technologies for running parallel work.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 3. CUDA Concurrency Mechanisms
  </span>
  <tr class="row">
   <th align="center" class="entry" colspan="1" id="d54e1042" rowspan="1" valign="middle" width="NaN%">
    Streams
   </th>
   <th align="center" class="entry" colspan="1" id="d54e1045" rowspan="1" valign="middle" width="NaN%">
    MPS
   </th>
   <th align="center" class="entry" colspan="1" id="d54e1048" rowspan="1" valign="middle" width="NaN%">
    MIG
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Partition Type
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    Single Process
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    Logical
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    Physical
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Max Partitions
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    Unlimited
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    48
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    SM Performance Isolation
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    No
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    Yes (by percentage, not partitioning)
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    Yes
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Memory Protection
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    No
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    Yes
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    Yes
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Memory Bandwidth QoS
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    No
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    No
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    Yes
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Error Isolation
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    No
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    No
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    Yes
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Cross-Partition Interop
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    Always
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    IPC
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    Limited IPC
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1040" rowspan="1" valign="top" width="NaN%">
    Reconfigure
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1042" rowspan="1" valign="middle" width="NaN%">
    Dynamic
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1045" rowspan="1" valign="middle" width="NaN%">
    Process Launch
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1048" rowspan="1" valign="middle" width="NaN%">
    When Idle
   </td>
  </tr>
 </table>
 <a name="deployment" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#deployment" name="deployment" shape="rect">
   Deployment Considerations
  </a>
 </h2>
 MIG functionality is provided as part of the NVIDIA GPU driver.
 <a name="deployment__ul_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ul class="ul" id="deployment__ul_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    H100 GPUs are supported starting with CUDA 12/R525 drivers.
   </p>
  </li>
  <li class="li">
   <p class="p">
    A100 and A30 GPUs are supported starting with CUDA 11/R450 drivers.
   </p>
  </li>
 </ul>
 <a name="system-considerations" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#system-considerations" name="system-considerations" shape="rect">
   System Considerations
  </a>
 </h3>
 <p class="p">
  The following system considerations are relevant for when the GPU is in MIG mode.
 </p>
 <a name="system-considerations__ul_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ul class="ul" id="system-considerations__ul_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    MIG is supported only on Linux operating system distributions supported by CUDA. It is also recommended to use 
                                 the latest NVIDIA Datacenter Linux. Refer to the
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html" shape="rect" target="_blank">
     quick start guide
    </a>
    .
   </p>
   <span class="notetitle">
    Note:
   </span>
   <p class="p">
    Also note the device nodes and
    nvidia-capabilities
    for exposing the MIG devices. The
    /proc
    mechanism 
                                    for system-level interfaces is deprecated as of 450.51.06 and it is recommended to use the
    /dev
    based system-level interface 
                                    for controlling access mechanisms of MIG devices through cgroups. This functionality is available starting with 450.80.02+
                                    drivers.
   </p>
  </li>
  <li class="li">
   Supported configurations include
   <ul class="ul">
    <li class="li">
     <p class="p">
      Bare-metal, including containers
     </p>
    </li>
    <li class="li">
     <p class="p">
      GPU pass-through virtualization to Linux guests on top of supported hypervisors
     </p>
    </li>
    <li class="li">
     <p class="p">
      vGPU on top of supported hypervisors
     </p>
    </li>
   </ul>
   <p class="p">
    MIG allows multiple vGPUs (and thereby VMs) to run in parallel on a single A100, while preserving the isolation guarantees
                                 
                                 that vGPU provides. For more information on GPU partitioning using vGPU and MIG, refer to the
    <a class="xref" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/TB-10226-001_v01.pdf" shape="rect" target="_blank">
     technical brief
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    Setting MIG mode on the A100/A30 requires a GPU reset (and thus super-user privileges). 
                                 Once the GPU is in MIG mode, instance management is then dynamic. Note 
                                 that the setting is on a per-GPU basis.
   </p>
  </li>
  <li class="li">
   <p class="p">
    On NVIDIA Ampere GPUs, similar to ECC mode, MIG mode setting is persistent across reboots until the user toggles the setting
                                 explicitly
   </p>
  </li>
  <li class="li">
   <p class="p">
    All daemons holding handles on driver modules need to be stopped before MIG enablement.
   </p>
  </li>
  <li class="li">
   <p class="p">
    This is true for systems such as DGX which may be running system health monitoring services 
                                 such as
    <a class="xref" href="https://docs.nvidia.com/datacenter/nvsm/index.html" shape="rect" target="_blank">
     nvsm
    </a>
    or GPU health monitoring or telemetry services such as
    <a class="xref" href="https://docs.nvidia.com/datacenter/dcgm/index.html" shape="rect" target="_blank">
     DCGM
    </a>
    .
   </p>
  </li>
  <li class="li">
   <p class="p">
    Toggling MIG mode requires the
    CAP_SYS_ADMIN
    capability. Other MIG management, such as creating and destroying instances, 
                                 requires superuser by default, but can be delegated to non-privileged users by adjusting permissions to MIG capabilities 
                                 in
    /proc/
    .
   </p>
  </li>
 </ul>
 <a name="app-considerations" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#app-considerations" name="app-considerations" shape="rect">
   Application Considerations
  </a>
 </h3>
 <p class="p">
  Users should note the following considerations when the A100 is in MIG mode:
 </p>
 <a name="app-considerations__ul_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ul class="ul" id="app-considerations__ul_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    No graphics APIs are supported (e.g. OpenGL, Vulkan etc.)
   </p>
  </li>
  <li class="li">
   <p class="p">
    No GPU to GPU P2P (either PCIe or NVLink) is supported
   </p>
  </li>
  <li class="li">
   <p class="p">
    CUDA applications treat a Compute Instance and its parent GPU Instance as a single CUDA device. 
                                 See
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-visible-devices" shape="rect">
     this
    </a>
    section on device enumeration by CUDA
   </p>
  </li>
  <li class="li">
   <p class="p">
    CUDA IPC across GPU instances is not supported. CUDA IPC across Compute instances is supported
   </p>
  </li>
  <li class="li">
   <p class="p">
    CUDA debugging (e.g. using cuda-gdb) and memory/race checking 
                                 (e.g. using cuda-memcheck or compute-sanitizer) is supported
   </p>
  </li>
  <li class="li">
   <p class="p">
    CUDA MPS is supported on top of MIG. The only limitation is that the maximum number of clients (48) is 
                                 lowered proportionally to the Compute Instance size
   </p>
  </li>
  <li class="li">
   <p class="p">
    GPUDirect RDMA is supported when used from GPU Instances
   </p>
  </li>
 </ul>
 <a name="device-names" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-names" name="device-names" shape="rect">
   MIG Device Names
  </a>
 </h2>
 <p class="p">
  By default, a MIG device consists of a single âGPU Instanceâ and a single âCompute Instanceâ. 
                        The table below highlights a naming convention to refer to a MIG device by its GPU Instance's 
                        compute slice count and its total memory in GB (rather than just its memory slice count).
 </p>
 <p class="p">
  When only a single CI is created (that consumes the entire compute capacity of the GI), 
                        then the CI sizing is implied in the device name.
 </p>
 <a name="device-names__mig-device-name" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 9. MIG Device Name
 </span>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The description below shows the profile names on the A100-SXM4-40GB product. For A100-SXM4-80GB, the 
                           profile names will change according to the memory proportion - for example,
  1g.10gb
  ,
  2g.20gb
  ,
  3g.40gb
  ,
  4g.40gb
  ,
  7g.80gb
  respectively.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 4. Device names when using a single CI
  </span>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    Memory
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    20gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    10gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    5gb
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    GPU Instance
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    3g
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    2g
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1g
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    Compute Instance
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    3c
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    2c
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    MIG Device
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    3g.20gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    2g.10gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1g.5gb
   </td>
  </tr>
  <tr class="row">
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
    GPC
    GPC
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
    GPC
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
   </td>
  </tr>
 </table>
 <p class="p">
  Each GI can be further sub-divided into multiple CIs as required by users depending on their workloads. The table 
                        below highlights what the name of a MIG device would look like in this case. The example shown is for 
                        subdividing a 3g.20gb device into a set of sub-devices with different Compute Instance slice counts.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 5. Device names when using multiple CIs
  </span>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    Memory
   </td>
   <td align="center" class="entry" colspan="3" rowspan="1" valign="middle">
    20gb
   </td>
   <td align="center" class="entry" colspan="3" rowspan="1" valign="middle">
    20gb
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    GPU Instance
   </td>
   <td align="center" class="entry" colspan="3" rowspan="1" valign="middle">
    3g
   </td>
   <td align="center" class="entry" colspan="3" rowspan="1" valign="middle">
    3g
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    Compute Instance
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c
   </td>
   <td align="center" class="entry" colspan="2" rowspan="1" valign="middle">
    2c
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" rowspan="1" valign="top" width="NaN%">
    MIG Device
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c.3g.20gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c.3g.20gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c.3g.20gb
   </td>
   <td align="center" class="entry" colspan="2" rowspan="1" valign="middle">
    2c.3g.20gb
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    1c.3g.20gb
   </td>
  </tr>
  <tr class="row">
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
   </td>
   <td align="center" class="entry" colspan="2" rowspan="1" valign="middle">
    GPC
    GPC
   </td>
   <td align="center" class="entry" colspan="1" rowspan="1" valign="middle" width="NaN%">
    GPC
   </td>
  </tr>
 </table>
 <a name="device-enum" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-enum" name="device-enum" shape="rect">
   Device Enumeration
  </a>
 </h3>
 <p class="p">
  GPU Instances (GIs) and Compute Instances (CIs) are enumerated in the new
  /proc
  filesystem layout for MIG
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ ls -l /proc/driver/nvidia-caps/
-r--r--r-- 1 root root 0 Nov 21 21:22 mig-minors
-r--r--r-- 1 root root 0 Nov 21 21:22 nvlink-minors
-r--r--r-- 1 root root 0 Nov 21 21:22 sys-minors

        </pre>
 <p class="p">
  The corresponding device nodes (in
  mig-minors
  ) are created under
  /dev/nvidia-caps
  .
                           Refer to the chapter on
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-visible-devices" shape="rect">
   device nodes and capabilities
  </a>
  for more information.
 </p>
 <a name="cuda-visible-devices" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-visible-devices" name="cuda-visible-devices" shape="rect">
   CUDA Device Enumeration
  </a>
 </h3>
 <p class="p">
  MIG supports running CUDA applications by specifying the CUDA device on which the application should be run. 
                           With CUDA 11/R450 and CUDA 12/R525, only enumeration of a single MIG instance is supported. In other words, 
                           regardless of how many MIG devices are created (or made available to a container), a single CUDA process 
                           can only enumerate a single MIG device.
 </p>
 CUDA applications treat a CI and its parent GI as a single CUDA device. CUDA is limited to use a single CI and 
                           will pick the first one available if several of them are visible. To summarize, there are two constraints:
 <a name="cuda-visible-devices__ol_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ol class="ol" id="cuda-visible-devices__ol_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    CUDA can only enumerate a single compute instance
   </p>
  </li>
  <li class="li">
   <p class="p">
    CUDA will not enumerate non-MIG GPU if any compute instance is enumerated on any other GPU
   </p>
  </li>
 </ol>
 <p class="p">
  Note that these constraints may be relaxed in future NVIDIA driver releases for MIG.
 </p>
 CUDA_VISIBLE_DEVICES
 has been extended to add support for MIG. Depending on the driver versions being used, 
                           two formats are supported:
 <ol class="ol">
  <li class="li">
   With drivers &gt;= R470 (
   470.42.01
   +), each MIG device is assigned a GPU UUID starting with
   MIG-&lt;UUID&gt;
   .
  </li>
  <li class="li">
   With drivers &lt; R470 (e.g. R450 and R460), each MIG device is enumerated by specifying the CI and the 
                                 corresponding parent GI. The format follows this convention:
   MIG-&lt;GPU-UUID&gt;/&lt;GPU instance ID&gt;/&lt;compute instance ID&gt;
   .
  </li>
 </ol>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  With the R470 NVIDIA datacenter drivers (
  470.42.01
  +), the example below shows 
                              how MIG devices are assigned GPU UUIDs in an 8-GPU system with each GPU configured differently.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi -L        

GPU 0: A100-SXM4-40GB (UUID: GPU-5d5ba0d6-d33d-2b2c-524d-9e3d8d2b8a77)
  MIG 1g.5gb      Device  0: (UUID: MIG-c6d4f1ef-42e4-5de3-91c7-45d71c87eb3f)
  MIG 1g.5gb      Device  1: (UUID: MIG-cba663e8-9bed-5b25-b243-5985ef7c9beb)
  MIG 1g.5gb      Device  2: (UUID: MIG-1e099852-3624-56c0-8064-c5db1211e44f)
  MIG 1g.5gb      Device  3: (UUID: MIG-8243111b-d4c4-587a-a96d-da04583b36e2)
  MIG 1g.5gb      Device  4: (UUID: MIG-169f1837-b996-59aa-9ed5-b0a3f99e88a6)
  MIG 1g.5gb      Device  5: (UUID: MIG-d5d0152c-e3f0-552c-abee-ebc0195e9f1d)
  MIG 1g.5gb      Device  6: (UUID: MIG-7df6b45c-a92d-5e09-8540-a6b389968c31)
GPU 1: A100-SXM4-40GB (UUID: GPU-0aa11ebd-627f-af3f-1a0d-4e1fd92fd7b0)
  MIG 2g.10gb     Device  0: (UUID: MIG-0c757cd7-e942-5726-a0b8-0e8fb7067135)
  MIG 2g.10gb     Device  1: (UUID: MIG-703fb6ed-3fa0-5e48-8e65-1c5bdcfe2202)
  MIG 2g.10gb     Device  2: (UUID: MIG-532453fc-0faa-5c3c-9709-a3fc2e76083d)
GPU 2: A100-SXM4-40GB (UUID: GPU-08279800-1cbe-a71d-f3e6-8f67e15ae54a)
  MIG 3g.20gb     Device  0: (UUID: MIG-aa232436-d5a6-5e39-b527-16f9b223cc46)
  MIG 3g.20gb     Device  1: (UUID: MIG-3b12da37-7fa2-596c-8655-62dab88f0b64)
GPU 3: A100-SXM4-40GB (UUID: GPU-71086aca-c858-d1e0-aae1-275bed1008b9)
  MIG 7g.40gb     Device  0: (UUID: MIG-3e209540-03e2-5edb-8798-51d4967218c9)
GPU 4: A100-SXM4-40GB (UUID: GPU-74fa9fb7-ccf6-8234-e597-7af8ace9a8f5)
  MIG 1c.3g.20gb  Device  0: (UUID: MIG-79c62632-04cc-574b-af7b-cb2e307120d8)
  MIG 1c.3g.20gb  Device  1: (UUID: MIG-4b3cc0fd-6876-50d7-a8ba-184a86e2b958)
  MIG 1c.3g.20gb  Device  2: (UUID: MIG-194837c7-0476-5b56-9c45-16bddc82e1cf)
  MIG 1c.3g.20gb  Device  3: (UUID: MIG-291820db-96a4-5463-8e7b-444c2d2e3dfa)
  MIG 1c.3g.20gb  Device  4: (UUID: MIG-5a97e28a-7809-5e93-abae-c3818c5ea801)
  MIG 1c.3g.20gb  Device  5: (UUID: MIG-3dfd5705-b18a-5a7c-bcee-d03a0ccb7a96)
GPU 5: A100-SXM4-40GB (UUID: GPU-3301e6dd-d38f-0eb5-4665-6c9659f320ff)
  MIG 4g.20gb     Device  0: (UUID: MIG-6d96b9f9-960e-5057-b5da-b8a35dc63aa8)
GPU 6: A100-SXM4-40GB (UUID: GPU-bb40ed7d-cbbb-d92c-50ac-24803cda52c5)
  MIG 1c.7g.40gb  Device  0: (UUID: MIG-66dd01d7-8cdb-5a13-a45d-c6eb0ee11810)
  MIG 2c.7g.40gb  Device  1: (UUID: MIG-03c649cb-e6ae-5284-8e94-4b1cf767e06c)
  MIG 3c.7g.40gb  Device  2: (UUID: MIG-8abf68e0-2808-525e-9133-ba81701ed6d3)
GPU 7: A100-SXM4-40GB (UUID: GPU-95fac899-e21a-0e44-b0fc-e4e3bf106feb)
  MIG 4g.20gb     Device  0: (UUID: MIG-219c765c-e07f-5b85-9c04-4afe174d83dd)
  MIG 2g.10gb     Device  1: (UUID: MIG-25884364-137e-52cc-a7e4-ecf3061c3ae1)
  MIG 1g.5gb      Device  2: (UUID: MIG-83e71a6c-f0c3-5dfc-8577-6e8b17885e1f)

        </pre>
 <a name="supported-profiles" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-profiles" name="supported-profiles" shape="rect">
   Supported MIG Profiles
  </a>
 </h2>
 <p class="p">
  This section provides an overview of the supported profiles and possible placements of the MIG profiles on 
                        supported GPUs.
 </p>
 <a name="a30-profiles" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#a30-profiles" name="a30-profiles" shape="rect">
   A30 MIG Profiles
  </a>
 </h3>
 <p class="p">
  The following diagram shows the profiles supported on the NVIDIA A30:
 </p>
 <a name="a30-profiles__a30-profiles" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 10. Profiles on A30
 </span>
 <p class="p">
  The table below shows the supported profiles on the A30-24GB product.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 6. GPU Instance Profiles on A30
  </span>
  <tr class="row">
   <th class="entry" colspan="1" id="d54e1820" rowspan="1" valign="top" width="NaN%">
    Profile Name
   </th>
   <th class="entry" colspan="1" id="d54e1823" rowspan="1" valign="top" width="NaN%">
    Fraction of Memory
   </th>
   <th class="entry" colspan="1" id="d54e1826" rowspan="1" valign="top" width="NaN%">
    Fraction of SMs
   </th>
   <th class="entry" colspan="1" id="d54e1829" rowspan="1" valign="top" width="NaN%">
    Hardware Units
   </th>
   <th class="entry" colspan="1" id="d54e1832" rowspan="1" valign="top" width="NaN%">
    L2 Cache Size
   </th>
   <th class="entry" colspan="1" id="d54e1836" rowspan="1" valign="top" width="NaN%">
    Copy Engines
   </th>
   <th class="entry" colspan="1" id="d54e1839" rowspan="1" valign="top" width="NaN%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1820" rowspan="1" valign="top" width="NaN%">
    MIG 1g.6gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1823" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1826" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1829" rowspan="1" valign="middle" width="NaN%">
    0 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1832" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1836" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1839" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1820" rowspan="1" valign="top" width="NaN%">
    MIG 1g.6gb+me
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1823" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1826" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1829" rowspan="1" valign="middle" width="NaN%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1832" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1836" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1839" rowspan="1" valign="middle" width="NaN%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1820" rowspan="1" valign="top" width="NaN%">
    MIG 2g.12gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1823" rowspan="1" valign="middle" width="NaN%">
    2/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1826" rowspan="1" valign="middle" width="NaN%">
    2/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1829" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1832" rowspan="1" valign="middle" width="NaN%">
    2/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1836" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1839" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1820" rowspan="1" valign="top" width="NaN%">
    MIG 2g.12gb+me
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1823" rowspan="1" valign="middle" width="NaN%">
    2/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1826" rowspan="1" valign="middle" width="NaN%">
    2/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1829" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1832" rowspan="1" valign="middle" width="NaN%">
    2/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1836" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1839" rowspan="1" valign="middle" width="NaN%">
    1 (A single 2g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e1820" rowspan="1" valign="top" width="NaN%">
    MIG 4g.24gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1823" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1826" rowspan="1" valign="middle" width="NaN%">
    4/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1829" rowspan="1" valign="middle" width="NaN%">
    4 NVDECs /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1832" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1836" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e1839" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
 </table>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The
  1g.6gb+me
  profile is only available starting with R470 drivers.
 </p>
 <p class="p">
  The
  2g.12gb+me
  profile is only available starting with R525 drivers.
 </p>
 <a name="a100-profiles" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#a100-profiles" name="a100-profiles" shape="rect">
   A100 MIG Profiles
  </a>
 </h3>
 <p class="p">
  The following diagram shows the profiles supported on the NVIDIA A100:
 </p>
 <a name="a100-profiles__a100-profiles" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 11. Profiles on A100
 </span>
 <p class="p">
  The table below shows the supported profiles on the A100-SXM4-40GB product. For A100-SXM4-80GB, the 
                           profile names will change according to the memory proportion - for example,
  1g.10gb
  ,
  1g.10gb+me
  ,
  1g.20gb
  ,
  2g.20gb
  ,
  3g.40gb
  ,
  4g.40gb
  ,
  7g.80gb
  respectively.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 7. GPU Instance Profiles on A100
  </span>
  <tr class="row">
   <th class="entry" colspan="1" id="d54e2060" rowspan="1" valign="top" width="NaN%">
    Profile Name
   </th>
   <th class="entry" colspan="1" id="d54e2063" rowspan="1" valign="top" width="NaN%">
    Fraction of Memory
   </th>
   <th class="entry" colspan="1" id="d54e2066" rowspan="1" valign="top" width="NaN%">
    Fraction of SMs
   </th>
   <th class="entry" colspan="1" id="d54e2069" rowspan="1" valign="top" width="NaN%">
    Hardware Units
   </th>
   <th class="entry" colspan="1" id="d54e2072" rowspan="1" valign="top" width="NaN%">
    L2 Cache Size
   </th>
   <th class="entry" colspan="1" id="d54e2076" rowspan="1" valign="top" width="NaN%">
    Copy Engines
   </th>
   <th class="entry" colspan="1" id="d54e2079" rowspan="1" valign="top" width="NaN%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 1g.5gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    0 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 1g.5gb+me
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 1g.10gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 2g.10gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    2/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 3g.20gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    3/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 4g.20gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    4/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /0 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2060" rowspan="1" valign="top" width="NaN%">
    MIG 7g.40gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2063" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2066" rowspan="1" valign="middle" width="NaN%">
    7/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2069" rowspan="1" valign="middle" width="NaN%">
    5 NVDECs /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2072" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2076" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2079" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
 </table>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The
  1g.5gb+me
  profile is only available starting with R470 drivers.
 </p>
 <p class="p">
  The
  1g.10gb
  profile is only available starting with R525 drivers.
 </p>
 <a name="h100-profiles" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#h100-profiles" name="h100-profiles" shape="rect">
   8.3. H100 MIG Profiles
  </a>
 </h3>
 <p class="p">
  The following diagram shows the profiles supported on the NVIDIA H100:
 </p>
 <a name="h100-profiles__h100-profiles" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 12. Profiles on H100
 </span>
 <p class="p">
  The table below shows the supported profiles on the H100 80GB product (PCIe and SXM5).
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 8. GPU Instance Profiles on H100
  </span>
  <tr class="row">
   <th class="entry" colspan="1" id="d54e2329" rowspan="1" valign="top" width="NaN%">
    Profile Name
   </th>
   <th class="entry" colspan="1" id="d54e2332" rowspan="1" valign="top" width="NaN%">
    Fraction of Memory
   </th>
   <th class="entry" colspan="1" id="d54e2335" rowspan="1" valign="top" width="NaN%">
    Fraction of SMs
   </th>
   <th class="entry" colspan="1" id="d54e2338" rowspan="1" valign="top" width="NaN%">
    Hardware Units
   </th>
   <th class="entry" colspan="1" id="d54e2341" rowspan="1" valign="top" width="NaN%">
    L2 Cache Size
   </th>
   <th class="entry" colspan="1" id="d54e2345" rowspan="1" valign="top" width="NaN%">
    Copy Engines
   </th>
   <th class="entry" colspan="1" id="d54e2348" rowspan="1" valign="top" width="NaN%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 1g.10gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 1g.10gb+me
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 1g.20gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 2g.20gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    2/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /2 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 3g.40gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    3/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    3 NVDECs /3 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 4g.40gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    4/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    4 NVDECs /4 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e2329" rowspan="1" valign="top" width="NaN%">
    MIG 7g.80gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2332" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2335" rowspan="1" valign="middle" width="NaN%">
    7/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2338" rowspan="1" valign="middle" width="NaN%">
    7 NVDECs /7 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2341" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2345" rowspan="1" valign="middle" width="NaN%">
    8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e2348" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
 </table>
 The table below shows the supported profiles on the H100 94GB product (PCIe and SXM5).
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <tr class="row">
   <th align="left" class="entry" colspan="1" id="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    Profile Name
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    Fraction of Memory
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    Fraction of SMs
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    Hardware Units
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    L2 Cache Size
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    Copy Engines
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 1g.11gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    1/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    7
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 1g.11gb+me
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    1/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 1g.22gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    1/4
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    1/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    4
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 2g.22gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    2/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    2/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    2 NVDECs /2 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    2/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    2
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    3
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 3g.44gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    3/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    3 NVDECs /3 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    3
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    2
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 4g.44gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    4/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    4 NVDECs /4 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    4
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2559" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 7g.88gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2562" rowspan="1" valign="top" width="14.285714285714285%">
    Full
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2565" rowspan="1" valign="top" width="14.285714285714285%">
    7/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2568" rowspan="1" valign="top" width="14.285714285714285%">
    7 NVDECs /7 JPEG /1 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2571" rowspan="1" valign="top" width="14.285714285714285%">
    Full
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2575" rowspan="1" valign="top" width="14.285714285714285%">
    8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2578" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
  </tr>
 </table>
 The table below shows the supported profiles on the H100 96GB product (H100 on
                           GH200).
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <tr class="row">
   <th align="left" class="entry" colspan="1" id="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    Profile Name
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    Fraction of Memory
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    Fraction of SMs
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    Hardware Units
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    L2 Cache Size
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    Copy Engines
   </th>
   <th align="left" class="entry" colspan="1" id="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 1g.12gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    1/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    7
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 1g.12gb+me
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    1/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 1g.24gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    1/4
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    1/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    1/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    4
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 2g.24gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    2/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    2/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    2 NVDECs /2 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    2/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    2
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    3
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 3g.48gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    3/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    3 NVDECs /3 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    3
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    2
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 4g.48gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    4/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    4 NVDECs /4 JPEG /0 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    4/8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    4
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
  </tr>
  <tr class="row">
   <td align="left" class="entry" colspan="1" headers="d54e2790" rowspan="1" valign="top" width="14.285714285714285%">
    MIG 7g.96gb
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2793" rowspan="1" valign="top" width="14.285714285714285%">
    Full
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2796" rowspan="1" valign="top" width="14.285714285714285%">
    7/7
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2799" rowspan="1" valign="top" width="14.285714285714285%">
    7 NVDECs /7 JPEG /1 OFA
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2802" rowspan="1" valign="top" width="14.285714285714285%">
    Full
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2806" rowspan="1" valign="top" width="14.285714285714285%">
    8
   </td>
   <td align="left" class="entry" colspan="1" headers="d54e2809" rowspan="1" valign="top" width="14.285714285714285%">
    1
   </td>
  </tr>
 </table>
 <a name="h200-profiles" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#h200-profiles" name="h200-profiles" shape="rect">
   8.4. H200 MIG Profiles
  </a>
 </h3>
 <p class="p">
  The following diagram shows the profiles supported on the NVIDIA H200:
 </p>
 <a name="h200-profiles__h200-profiles" shape="rect">
  <!-- -->
 </a>
 <span class="figcap">
  Figure 13. Profiles on H200
 </span>
 <p class="p">
  The table below shows the supported profiles on the H200 141GB product.
 </p>
 <table border="1" cellpadding="4" cellspacing="0" class="table" frame="border" rules="all" summary="">
  <span class="tablecap">
   Table 9. GPU Instance Profiles on H200
  </span>
  <tr class="row">
   <th class="entry" colspan="1" id="d54e3045" rowspan="1" valign="top" width="NaN%">
    Profile Name
   </th>
   <th class="entry" colspan="1" id="d54e3048" rowspan="1" valign="top" width="NaN%">
    Fraction of Memory
   </th>
   <th class="entry" colspan="1" id="d54e3051" rowspan="1" valign="top" width="NaN%">
    Fraction of SMs
   </th>
   <th class="entry" colspan="1" id="d54e3054" rowspan="1" valign="top" width="NaN%">
    Hardware Units
   </th>
   <th class="entry" colspan="1" id="d54e3057" rowspan="1" valign="top" width="NaN%">
    L2 Cache Size
   </th>
   <th class="entry" colspan="1" id="d54e3061" rowspan="1" valign="top" width="NaN%">
    Copy Engines
   </th>
   <th class="entry" colspan="1" id="d54e3064" rowspan="1" valign="top" width="NaN%">
    Number of Instances Available
   </th>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 1g.18gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    7
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 1g.18gb+me
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    1 NVDEC /1 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    1 (A single 1g profile can include media extensions)
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 1g.35gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    1/4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    1/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    1 NVDECs /1 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    1/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 2g.35gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    2/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    2 NVDECs /2 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    2/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 3g.71gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    3/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    3 NVDECs /3 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    3
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    2
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 4g.71gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    4/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    4 NVDECs /4 JPEG /0 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    4/8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    4
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
  <tr class="row">
   <td class="entry" colspan="1" headers="d54e3045" rowspan="1" valign="top" width="NaN%">
    MIG 7g.141gb
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3048" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3051" rowspan="1" valign="middle" width="NaN%">
    7/7
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3054" rowspan="1" valign="middle" width="NaN%">
    7 NVDECs /7 JPEG /1 OFA
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3057" rowspan="1" valign="middle" width="NaN%">
    Full
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3061" rowspan="1" valign="middle" width="NaN%">
    8
   </td>
   <td align="center" class="entry" colspan="1" headers="d54e3064" rowspan="1" valign="middle" width="NaN%">
    1
   </td>
  </tr>
 </table>
 <a name="running-with-mig" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#running-with-mig" name="running-with-mig" shape="rect">
   Getting Started with MIG
  </a>
 </h2>
 <a name="prerequisites" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#prerequisites" name="prerequisites" shape="rect">
   Prerequisites
  </a>
 </h3>
 <p class="p">
  The following prerequisites and minimum software versions are recommended when using supported GPUs in MIG mode.
 </p>
 <a name="prerequisites__ul_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ul class="ul" id="prerequisites__ul_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    MIG is supported only on GPUs and systems listed
    <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-gpus" shape="rect">
     here
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    It is recommended to install the latest NVIDIA datacenter driver. The minimum versions are provided below:
   </p>
   <ul class="ul">
    <li class="li">
     If using H100, then CUDA 12 and NVIDIA driver R525 (
     &gt;= 525.53
     ) or later
    </li>
    <li class="li">
     If using A100/A30, then CUDA 11 and NVIDIA driver R450 (
     &gt;= 450.80.02
     ) or later
    </li>
   </ul>
  </li>
  <li class="li">
   <p class="p">
    Linux operating system distributions supported by
    <a class="xref" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html" shape="rect" target="_blank">
     CUDA
    </a>
   </p>
  </li>
  <li class="li">
   <p class="p">
    If running containers or using Kubernetes, then:
   </p>
   <ul class="ul">
    <li class="li">
     NVIDIA Container Toolkit (
     nvidia-docker2
     ): v2.5.0 or later
    </li>
    <li class="li">
     NVIDIA K8s Device Plugin: v0.7.0 or later
    </li>
    <li class="li">
     NVIDIA gpu-feature-discovery: v0.2.0 or later
    </li>
   </ul>
  </li>
 </ul>
 <p class="p">
  MIG can be managed programmatically using NVIDIA Management Library (NVML) APIs or its 
                           command-line-interface,
  nvidia-smi
  . Note that for brevity, some of the
  nvidia-smi
  output in the following examples may be cropped to showcase the relevant sections of interest.
 </p>
 <p class="p">
  For more information on the MIG commands, see the
  nvidia-smi
  man page or
  nvidia-smi mig --help
  . 
                           For information on the MIG management APIs, see the NVML header (
  nvml.h
  ) included in the CUDA Toolkit packages 
                           (
  cuda-nvml-dev-*
  ; installed under
  /usr/local/cuda/include/nvml.h
  )
                           For automated tooling support with configuring MIG, refer to the 
                           NVIDIA MIG
  Part
  ition
  Ed
  itor (or
  mig-parted
  )
  <a class="xref" href="https://github.com/nvidia/mig-parted" shape="rect" target="_blank">
   tools
  </a>
  .
 </p>
 <a name="enable-mig-mode" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#enable-mig-mode" name="enable-mig-mode" shape="rect">
   Enable MIG Mode
  </a>
 </h3>
 <p class="p">
  By default, MIG mode is not enabled on the GPU. For example, running nvidia-smi shows that MIG mode is disabled:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ nvidia-smi -i 0
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-SXM4-40GB      Off  | 00000000:36:00.0 Off |                    0 |
| N/A   29C    P0    62W / 400W |      0MiB / 40537MiB |      6%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
        </pre>
 <p class="p">
  MIG mode can be enabled on a per-GPU basis with the following command:
  nvidia-smi -i &lt;GPU IDs&gt; -mig 1
  . The GPUs can be selected using comma separated 
                           GPU indexes, PCI Bus Ids or UUIDs. If no GPU ID is specified, then MIG mode is applied to all the GPUs on the system.
 </p>
 <p class="p">
  When MIG is enabled on the GPU, depending on the GPU product, the driver will attempt to reset the GPU so that MIG mode can
                           take effect.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi -i 0 -mig 1
Enabled MIG Mode for GPU 00000000:36:00.0
All done.


$ nvidia-smi -i 0 --query-gpu=pci.bus_id,mig.mode.current --format=csv
pci.bus_id, mig.mode.current
00000000:36:00.0, Enabled
        </pre>
 <a name="reset-hopper" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#reset-hopper" name="reset-hopper" shape="rect">
   GPU Reset on Hopper+ GPUs
  </a>
 </h3>
 <p class="p">
  Starting with the Hopper generation of GPUs, enabling MIG mode no longer requires a GPU reset to take 
                              effect (and thus the driver does not attempt to reset the GPU in the background).
 </p>
 <p class="p">
  Note that MIG mode (
  Disabled
  or
  Enabled
  states) is only 
                              persistent as long as the driver is resident in the system (i.e. the kernel modules are loaded). MIG mode is 
                              no longer persistent across system reboots (there is no longer a status bit stored in the GPU InfoROM).
 </p>
 <p class="p">
  Thus, an unload and reload of the driver kernel modules will disable MIG mode.
 </p>
 <a name="reset-ampere" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#reset-ampere" name="reset-ampere" shape="rect">
   GPU Reset on Ampere GPUs
  </a>
 </h3>
 <p class="p">
  On NVIDIA Ampere GPUs, when MIG mode is enabled, the driver will attempt to reset the 
                              GPU so that MIG mode can take effect.
 </p>
 <p class="p">
  Note that MIG mode (
  Disabled
  or
  Enabled
  states) 
                              is persistent across system reboots (there is a status bit stored in the GPU InfoROM). 
                              Thus MIG mode has to be explicitly disabled to return the GPU to its default state.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  If you are using MIG inside a VM with NVIDIA Ampere GPUs (A100 or A30) in passthrough, then you may need to reboot the VM
                                 to allow the GPU to be in MIG mode as in some cases, GPU reset is not 
                                 allowed via the hypervisor for security reasons. This can be seen in the following example:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi -i 0 -mig 1
Warning: MIG mode is in pending enable state for GPU 00000000:00:03.0:Not Supported
Reboot the system or try nvidia-smi --gpu-reset to make MIG mode effective on GPU 00000000:00:03.0
All done.


$ sudo nvidia-smi --gpu-reset
Resetting GPU 00000000:00:03.0 is not supported.
        </pre>
 <a name="driver-clients" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#driver-clients" name="driver-clients" shape="rect">
   Driver Clients
  </a>
 </h3>
 <p class="p">
  In some cases, if you have agents on the system (e.g. monitoring agents) that use the GPU, then you may not be able to initiate
                              a GPU reset. For example, on DGX systems, 
                              you may encounter the following message:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi -i 0 -mig 1
Warning: MIG mode is in pending enable state for GPU 00000000:07:00.0:In use by another client
00000000:07:00.0 is currently being used by one or more other processes (e.g. CUDA application or a monitoring application such as another instance of nvidia-smi). Please first kill all processes using the device and retry the command or reboot the system to make MIG mode effective.
All done.
        </pre>
 <p class="p">
  In this specific DGX example, you would have to stop the
  nvsm
  and
  dcgm
  services, enable MIG mode on the desired GPU and then restore the monitoring services:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo systemctl stop nvsm

$ sudo systemctl stop dcgm

$ sudo nvidia-smi -i 0 -mig 1
Enabled MIG Mode for GPU 00000000:07:00.0
All done.
        </pre>
 <p class="p">
  The examples shown in the document use super-user privileges. As described in the
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes-devfs" shape="rect">
   Device Nodes
  </a>
  section, granting read access to
  mig/config
  capabilities allows non-root users to manage instances once the GPU has been configured into MIG mode. 
                              The default file permissions on the
  mig/config
  file is shown below.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ ls -l /proc/driver/nvidia/capabilities/*
/proc/driver/nvidia/capabilities/mig:
total 0
-r-------- 1 root root 0 May 24 16:10 config
-r--r--r-- 1 root root 0 May 24 16:10 monitor
        </pre>
 <a name="lgi" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#lgi" name="lgi" shape="rect">
   List GPU Instance Profiles
  </a>
 </h3>
 <p class="p">
  The NVIDIA driver provides a number of profiles that users can opt-in for when configuring the MIG feature in A100. 
                           The profiles are the sizes and capabilities of the GPU instances that can be created by the user. 
                           The driver also provides information about the placements, which indicate the type and number of instances that can be created.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi mig -lgip
+-----------------------------------------------------------------------------+
| GPU instance profiles:                                                      |
| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |
|                              Free/Total   GiB              CE    JPEG  OFA  |
|=============================================================================|
|   0  MIG 1g.5gb        19     7/7        4.75       No     14     0     0   |
|                                                             1     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 1g.5gb+me     20     1/1        4.75       No     14     1     0   |
|                                                             1     1     1   |
+-----------------------------------------------------------------------------+
|   0  MIG 1g.10gb       15     4/4        9.62       No     14     1     0   |
|                                                             1     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 2g.10gb       14     3/3        9.62       No     28     1     0   |
|                                                             2     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 3g.20gb        9     2/2        19.50      No     42     2     0   |
|                                                             3     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 4g.20gb        5     1/1        19.50      No     56     2     0   |
|                                                             4     0     0   |
+-----------------------------------------------------------------------------+
|   0  MIG 7g.40gb        0     1/1        39.25      No     98     5     0   |
|                                                             7     1     1   |
+-----------------------------------------------------------------------------+
        </pre>
 <p class="p">
  List the possible placements available using the following command. The syntax of the placement is
  {&lt;index&gt;}:&lt;GPU Slice Count&gt;
  and shows the placement of the instances on the GPU.
                           The placement index shown indicates how the profiles are mapped on the GPU as shown in the
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-names" shape="rect">
   supported profiles tables
  </a>
  .
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi mig -lgipp
GPU  0 Profile ID 19 Placements: {0,1,2,3,4,5,6}:1
GPU  0 Profile ID 20 Placements: {0,1,2,3,4,5,6}:1
GPU  0 Profile ID 15 Placements: {0,2,4,6}:2
GPU  0 Profile ID 14 Placements: {0,2,4}:2
GPU  0 Profile ID  9 Placements: {0,4}:4
GPU  0 Profile ID  5 Placement : {0}:4
GPU  0 Profile ID  0 Placement : {0}:8

        </pre>
 <p class="p">
  The command shows that the user can create two instances of type
  3g.20gb
  (profile ID 9) or 
                           seven instances of
  1g.5gb
  (profile ID 19).
 </p>
 <a name="create-gi" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#create-gi" name="create-gi" shape="rect">
   Creating GPU Instances
  </a>
 </h3>
 Before starting to use MIG, the user needs to create GPU instances using the
 -cgi
 option. One of 
                           three options can be used to specify the instance profiles to be created:
 <ol class="ol">
  <li class="li">
   Profile ID (e.g. 9, 14, 5)
  </li>
  <li class="li">
   Short name of the profile (e.g.
   3g.20gb
  </li>
  <li class="li">
   Full profile name of the instance (e.g.
   MIG 3g.20gb
   )
  </li>
 </ol>
 <p class="p">
  Once the GPU instances are created, one needs to create the corresponding Compute Instances (CI). By using the
  -C
  option,
  nvidia-smi
  creates these instances.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Without creating GPU instances (and corresponding compute instances), CUDA workloads cannot be run on the GPU. In 
                              other words, simply enabling MIG mode on the GPU is not sufficient. Also note that, the created MIG devices are not 
                              persistent across system reboots. Thus, the user or system administrator needs to recreate the desired MIG configurations
                              
                              if the GPU or system is reset. For automated tooling support for this purpose, refer to the 
                              NVIDIA MIG
  Part
  ition
  Ed
  itor (or
  mig-parted
  )
  <a class="xref" href="https://github.com/nvidia/mig-parted" shape="rect" target="_blank">
   tool
  </a>
  , including creating a
  systemd
  service that could recreate the MIG geometry at system startup.
 </p>
 <p class="p">
  The following example shows how the user can create GPU instances (and corresponding compute instances). In this example,
                           the user can create 
                           two GPU instances (of type
  3g.20gb
  ), with each GPU instance having half of the available compute and memory capacity. In this 
                           example, we purposefully use profile ID and short profile name to showcase how either option can be used:
 </p>
 <pre class="pre screen" xml:space="preserve">
    
$ sudo nvidia-smi mig -cgi 9,3g.20gb -C
Successfully created GPU instance ID  2 on GPU  0 using profile MIG 3g.20gb (ID  9)
Successfully created compute instance ID  0 on GPU  0 GPU instance ID  2 using profile MIG 3g.20gb (ID  2)
Successfully created GPU instance ID  1 on GPU  0 using profile MIG 3g.20gb (ID  9)
Successfully created compute instance ID  0 on GPU  0 GPU instance ID  1 using profile MIG 3g.20gb (ID  2)
        </pre>
 <p class="p">
  Now list the available GPU instances:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -lgi
+----------------------------------------------------+
| GPU instances:                                     |
| GPU   Name          Profile  Instance   Placement  |
|                       ID       ID       Start:Size |
|====================================================|
|   0  MIG 3g.20gb       9        1          4:4     |
+----------------------------------------------------+
|   0  MIG 3g.20gb       9        2          0:4     |
+----------------------------------------------------+
        </pre>
 <p class="p">
  Now verify that the GIs and corresponding CIs are created:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi
+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |                      | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |     11MiB / 20224MiB | 42      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+
|  0    2   0   1  |     11MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
        </pre>
 <h3 class="title sectiontitle">
  Instance Geometry
 </h3>
 <p class="p">
  As described in the section on
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#partitioning" shape="rect" target="_blank">
   Partitioning
  </a>
  , the NVIDIA driver APIs provide a number of available GPU Instance profiles that can be chosen by the user.
 </p>
 <p class="p">
  If a mixed geometry of the profiles is specified by the user, then the NVIDIA driver chooses the placement of the various
                              profiles. This can be seen in the following 
                              examples.
 </p>
 <p class="p">
  Example 1: Creation of a 4-2-1 geometry. After the instances are created, the placement of the profiles can be observed:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -cgi 19,14,5
Successfully created GPU instance ID 13 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID  5 on GPU  0 using profile MIG 2g.10gb (ID 14)
Successfully created GPU instance ID  1 on GPU  0 using profile MIG 4g.20gb (ID  5)


$ sudo nvidia-smi mig -lgi
+----------------------------------------------------+
| GPU instances:                                     |
| GPU   Name          Profile  Instance   Placement  |
|                       ID       ID       Start:Size |
|====================================================|
|   0  MIG 1g.5gb       19       13          6:1     |
+----------------------------------------------------+
|   0  MIG 2g.10gb      14        5          4:2     |
+----------------------------------------------------+
|   0  MIG 4g.20gb       5        1          0:4     |
+----------------------------------------------------+
        </pre>
 <p class="p">
  Example 2: Creation of a 3-2-1-1 geometry.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  Due to a known issue with the APIs, the profile ID
  9
  or
  3g.20gb
  must be specified first in order. 
                                 Not doing so, will result in the following error.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -cgi 19,19,14,9
Successfully created GPU instance ID 13 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID 11 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID  3 on GPU  0 using profile MIG 2g.10gb (ID 14)
Unable to create a GPU instance on GPU  0 using profile 9: Insufficient Resources
Failed to create GPU instances: Insufficient Resources
                </pre>
 <p class="p">
  Specify the correct order for the
  3g.20gb
  profile. The remaining combinations of the profiles do not have this requirement.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -cgi 9,19,14,19
Successfully created GPU instance ID  2 on GPU  0 using profile MIG 3g.20gb (ID  9)
Successfully created GPU instance ID  7 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID  4 on GPU  0 using profile MIG 2g.10gb (ID 14)
Successfully created GPU instance ID  8 on GPU  0 using profile MIG 1g.5gb (ID 19)


$ sudo nvidia-smi mig -lgi
+----------------------------------------------------+
| GPU instances:                                     |
| GPU   Name          Profile  Instance   Placement  |
|                       ID       ID       Start:Size |
|====================================================|
|   0  MIG 1g.5gb       19        7          0:1     |
+----------------------------------------------------+
|   0  MIG 1g.5gb       19        8          1:1     |
+----------------------------------------------------+
|   0  MIG 2g.10gb      14        4          2:2     |
+----------------------------------------------------+
|   0  MIG 3g.20gb       9        2          4:4     |
+----------------------------------------------------+
        </pre>
 <p class="p">
  Example 3: Creation of a 2-1-1-1-1-1 geometry:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -cgi 14,19,19,19,19,19
Successfully created GPU instance ID  5 on GPU  0 using profile MIG 2g.10gb (ID 14)
Successfully created GPU instance ID 13 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID  7 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID  8 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID  9 on GPU  0 using profile MIG 1g.5gb (ID 19)
Successfully created GPU instance ID 10 on GPU  0 using profile MIG 1g.5gb (ID 19)


$ sudo nvidia-smi mig -lgi
+----------------------------------------------------+
| GPU instances:                                     |
| GPU   Name          Profile  Instance   Placement  |
|                       ID       ID       Start:Size |
|====================================================|
|   0  MIG 1g.5gb       19        7          0:1     |
+----------------------------------------------------+
|   0  MIG 1g.5gb       19        8          1:1     |
+----------------------------------------------------+
|   0  MIG 1g.5gb       19        9          2:1     |
+----------------------------------------------------+
|   0  MIG 1g.5gb       19       10          3:1     |
+----------------------------------------------------+
|   0  MIG 1g.5gb       19       13          6:1     |
+----------------------------------------------------+
|   0  MIG 2g.10gb      14        5          4:2     |
+----------------------------------------------------+
        </pre>
 <a name="cuda-baremetal" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-baremetal" name="cuda-baremetal" shape="rect">
   Running CUDA Applications on Bare-Metal
  </a>
 </h3>
 <a name="cuda-gi" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-gi" name="cuda-gi" shape="rect">
   GPU Instances
  </a>
 </h3>
 <p class="p">
  The following example shows how two CUDA applications can be run in parallel on two different GPU instances. In this example,
                              
                              the BlackScholes CUDA sample is run simultaneously on the two GIs created on the A100.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ nvidia-smi -L
GPU 0: A100-SXM4-40GB (UUID: GPU-e86cb44c-6756-fd30-cd4a-1e6da3caf9b0)
  MIG 3g.20gb Device 0: (UUID: MIG-c7384736-a75d-5afc-978f-d2f1294409fd)
  MIG 3g.20gb Device 1: (UUID: MIG-a28ad590-3fda-56dd-84fc-0a0b96edc58d)


$ CUDA_VISIBLE_DEVICES=MIG-c7384736-a75d-5afc-978f-d2f1294409fd ./BlackScholes &amp;
$ CUDA_VISIBLE_DEVICES=MIG-a28ad590-3fda-56dd-84fc-0a0b96edc58d ./BlackScholes &amp;
        </pre>
 <p class="p">
  Now verify the two CUDA applications are running on two separate GPU instances:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ nvidia-smi
+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |                      | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |    268MiB / 20224MiB | 42      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+
|  0    2   0   1  |    268MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    1    0      58866      C   ./BlackScholes                    253MiB |
|    0    2    0      58856      C   ./BlackScholes                    253MiB |
+-----------------------------------------------------------------------------+
        </pre>
 <h4 class="title sectiontitle">
  GPU Utilization Metrics
 </h4>
 <p class="p">
  NVML (and
  nvidia-smi
  ) does not support attribution of utilization metrics to MIG devices. From the previous example, 
                                 the utilization is displayed as
  N/A
  when running CUDA programs:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ nvidia-smi

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |    268MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
|                  |      4MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
|  0    2   0   1  |    268MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
|                  |      4MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    1    0       6217      C   ...inux/release/BlackScholes      253MiB |
|    0    2    0       6223      C   ...inux/release/BlackScholes      253MiB |
+-----------------------------------------------------------------------------+
        </pre>
 <p class="p">
  For monitoring MIG devices on MIG capable GPUs such as the A100, including attribution of GPU metrics 
                                 (including utilization and other profiling metrics), it is recommended to use
  <a class="xref" href="https://developer.nvidia.com/dcgm" shape="rect" target="_blank">
   NVIDIA DCGM
  </a>
  v2.0.13 or later. 
                                 See the
  <a class="xref" href="https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/feature-overview.html#profiling" shape="rect" target="_blank">
   Profiling Metrics
  </a>
  section in the DCGM User Guide for more details on getting started.
 </p>
 <a name="cuda-ci" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-ci" name="cuda-ci" shape="rect">
   Compute Instances
  </a>
 </h3>
 <p class="p">
  As explained earlier in this document, a further level of concurrency can be achieved by using Compute Instances (CIs). 
                              The following example shows how 3 CUDA processes (BlackScholes CUDA sample) can be run on the same GI.
 </p>
 <p class="p">
  First, list the available CI profiles available using our prior configuration of creating 2 GIs on the A100.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ sudo nvidia-smi mig -lcip -gi 1
+--------------------------------------------------------------------------------------+
| Compute instance profiles:                                                           |
| GPU     GPU       Name             Profile  Instances   Exclusive       Shared       |
|       Instance                       ID     Free/Total     SM       DEC   ENC   OFA  |
|         ID                                                          CE    JPEG       |
|======================================================================================|
|   0      1       MIG 1c.3g.20gb       0      0/3           14        2     0     0   |
|                                                                      3     0         |
+--------------------------------------------------------------------------------------+
|   0      1       MIG 2c.3g.20gb       1      0/1           28        2     0     0   |
|                                                                      3     0         |
+--------------------------------------------------------------------------------------+
|   0      1       MIG 3g.20gb          2*     0/1           42        2     0     0   |
|                                                                      3     0         |
+--------------------------------------------------------------------------------------+
        </pre>
 <p class="p">
  Create 3 CIs, each of type 1c compute capacity (profile ID 0) on the first GI.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ sudo nvidia-smi mig -cci 0,0,0 -gi 1
Successfully created compute instance on GPU  0 GPU instance ID  1 using profile MIG 1c.3g.20gb (ID  0)
Successfully created compute instance on GPU  0 GPU instance ID  1 using profile MIG 1c.3g.20gb (ID  0)
Successfully created compute instance on GPU  0 GPU instance ID  1 using profile MIG 1c.3g.20gb (ID  0)
        </pre>
 <p class="p">
  Using nvidia-smi, the following CIs are now created on GI 1.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -lci -gi 1
+-------------------------------------------------------+
| Compute instances:                                    |
| GPU     GPU       Name             Profile   Instance |
|       Instance                       ID        ID     |
|         ID                                            |
|=======================================================|
|   0      1       MIG 1c.3g.20gb       0         0     |
+-------------------------------------------------------+
|   0      1       MIG 1c.3g.20gb       0         1     |
+-------------------------------------------------------+
|   0      1       MIG 1c.3g.20gb       0         2     |
+-------------------------------------------------------+
        </pre>
 <p class="p">
  And the GIs and CIs created on the A100 are now enumerated by the driver:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi
+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |                      | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |     11MiB / 20224MiB | 14      0 |  3   0    2    0    0 |
+------------------+                      +-----------+-----------------------+
|  0    1   1   1  |                      | 14      0 |  3   0    2    0    0 |
+------------------+                      +-----------+-----------------------+
|  0    1   2   2  |                      | 14      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
        </pre>
 <p class="p">
  Now, three BlackScholes applications can be created and run in parallel:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ CUDA_VISIBLE_DEVICES=MIG-c7384736-a75d-5afc-978f-d2f1294409fd ./BlackScholes &amp;
$ CUDA_VISIBLE_DEVICES=MIG-c376546e-7559-5610-9721-124e8dbb1bc8 ./BlackScholes &amp;
$ CUDA_VISIBLE_DEVICES=MIG-928edfb0-898f-53bd-bf24-c7e5d08a6852 ./BlackScholes &amp;
        </pre>
 <p class="p">
  And seen using
  nvidia-smi
  as running processes on the three CIs:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi
+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |                      | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |    476MiB / 20224MiB | 14      0 |  3   0    2    0    0 |
+------------------+                      +-----------+-----------------------+
|  0    1   1   1  |                      | 14      0 |  3   0    2    0    0 |
+------------------+                      +-----------+-----------------------+
|  0    1   2   2  |                      | 14      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    1    0      59785      C   ./BlackScholes                    153MiB |
|    0    1    1      59796      C   ./BlackScholes                    153MiB |
|    0    1    2      59885      C   ./BlackScholes                    153MiB |
+-----------------------------------------------------------------------------+
        </pre>
 <a name="cuda-destroy" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-destroy" name="cuda-destroy" shape="rect">
   Destroying GPU Instances
  </a>
 </h3>
 <p class="p">
  Once the GPU is in MIG mode, GIs and CIs can be configured dynamically. 
                           The following example shows how the CIs and GIs created in the previous examples can be destroyed.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  If the intention is to destroy all the CIs and GIs, then this can be accomplished with 
                              the following commands:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ sudo nvidia-smi mig -dci &amp;&amp; sudo nvidia-smi mig -dgi
Successfully destroyed compute instance ID  0 from GPU  0 GPU instance ID  1
Successfully destroyed compute instance ID  1 from GPU  0 GPU instance ID  1
Successfully destroyed compute instance ID  2 from GPU  0 GPU instance ID  1
Successfully destroyed GPU instance ID  1 from GPU  0
Successfully destroyed GPU instance ID  2 from GPU  0
        </pre>
 <p class="p">
  In this example, we delete the specific CIs created under GI 1.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ sudo nvidia-smi mig -dci -ci 0,1,2 -gi 1
Successfully destroyed compute instance ID  0 from GPU  0 GPU instance ID  1
Successfully destroyed compute instance ID  1 from GPU  0 GPU instance ID  1
Successfully destroyed compute instance ID  2 from GPU  0 GPU instance ID  1
        </pre>
 <p class="p">
  It can be verified that the CI devices have now been torn down on the GPU:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ nvidia-smi
+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |                      | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  No MIG devices found                                                       |
+-----------------------------------------------------------------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
        </pre>
 <p class="p">
  Now the GIs have to be deleted:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo nvidia-smi mig -dgi
Successfully destroyed GPU instance ID  1 from GPU  0
Successfully destroyed GPU instance ID  2 from GPU  0

        </pre>
 <a name="telemetry" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#telemetry" name="telemetry" shape="rect">
   Monitoring MIG Devices
  </a>
 </h3>
 <p class="p">
  For monitoring MIG devices on including attribution of GPU metrics 
                           (including utilization and other profiling metrics), it is recommended to use
  <a class="xref" href="https://developer.nvidia.com/dcgm" shape="rect" target="_blank">
   NVIDIA DCGM
  </a>
  v3 or later. 
                           See the
  <a class="xref" href="https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/feature-overview.html#profiling" shape="rect" target="_blank">
   Profiling Metrics
  </a>
  section in the DCGM User Guide for more details on getting started.
 </p>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  On Ampere GPUs (A100 or A30), NVML (and
  nvidia-smi
  ) does not support attribution of utilization metrics to MIG devices. From the previous example, 
                              the utilization is displayed as
  N/A
  when running CUDA programs:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ nvidia-smi

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |    268MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
|                  |      4MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
|  0    2   0   1  |    268MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
|                  |      4MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    1    0       6217      C   ...inux/release/BlackScholes      253MiB |
|    0    2    0       6223      C   ...inux/release/BlackScholes      253MiB |
+-----------------------------------------------------------------------------+
        </pre>
 <a name="cuda-mps" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-mps" name="cuda-mps" shape="rect">
   MIG with CUDA MPS
  </a>
 </h3>
 <p class="p">
  As described in the
  <a class="xref" href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-concurrency" shape="rect">
   section
  </a>
  on CUDA concurrency mechanisms,
  <a class="xref" href="https://docs.nvidia.com/deploy/mps/index.html" shape="rect" target="_blank">
   CUDA Multi-Process 
                              Service
  </a>
  (MPS) enables co-operative multi-process CUDA applications to be processed 
                           concurrently on the GPU. MPS and MIG can work together, potentially achieving even higher levels of utilization 
                           for certain workloads.
 </p>
 <p class="p">
  Refer to the MPS documentation to understand the
  <a class="xref" href="https://docs.nvidia.com/deploy/mps/index.html#topic_6" shape="rect" target="_blank">
   architecture and provisioning sequence
  </a>
  for MPS.
 </p>
 <p class="p">
  In the following sections, we will walk through an example of running MPS on MIG devices.
 </p>
 <h3 class="title sectiontitle">
  Workflow
 </h3>
 In summary, the workflow for running with MPS is as follows:
 <ul class="ul">
  <li class="li">
   <p class="p">
    Configure the desired MIG geometry on the GPU.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Setup the
    CUDA_MPS_PIPE_DIRECTORY
    variable to point to unique directories 
                                       so that the multiple MPS servers and clients can communicate with each other using named pipes and 
                                       Unix domain sockets.
   </p>
  </li>
  <li class="li">
   <p class="p">
    Launch the application by specifying the MIG device using
    CUDA_VISIBLE_DEVICES
    .
   </p>
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The MPS documentation recommends setting up
  EXCLUSIVE_PROCESS
  mode to ensure that a single 
                                    MPS server is using the GPU. However, this mode is not supported when the GPU is in MIG mode as we use multiple 
                                    MPS servers (one per MIG GPU instance).
 </p>
 <h3 class="title sectiontitle">
  Configure GPU Instances
 </h3>
 <p class="p">
  Follow the steps outlined in the previous sections to configure the desired MIG geometry on the GPU. For this example,
                              we configure the GPU into a
  3g.20gb
  ,
  3g.2gb
  geometry:
 </p>
 <pre class="pre screen" xml:space="preserve">
            
$ nvidia-smi

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      On   | 00000000:65:00.0 Off |                   On |
| N/A   37C    P0    66W / 250W |    581MiB / 40536MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |    290MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
|                  |      8MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
|  0    2   0   1  |    290MiB / 20096MiB | 42      0 |  3   0    2    0    0 |
|                  |      8MiB / 32767MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
            </pre>
 <h3 class="title sectiontitle">
  Setup the MPS Control Daemons
 </h3>
 <p class="p">
  In this step, we start an MPS control daemon (with admin privileges) and ensure we use a different socket for each daemon:
 </p>
 <pre class="pre screen" xml:space="preserve">
            
export CUDA_MPS_PIPE_DIRECTORY=/tmp/&lt;MIG_UUID&gt;
mkdir -p $CUDA_MPS_PIPE_DIRECTORY

CUDA_VISIBLE_DEVICES=&lt;MIG_UUID&gt; \
CUDA_MPS_PIPE_DIRECTORY=/tmp/&lt;MIG_UUID&gt; \
nvidia-cuda-mps-control -d
    
            </pre>
 <h3 class="title sectiontitle">
  Launch the Application
 </h3>
 <p class="p">
  Now we can launch the application by specifying the desired MIG device using
  CUDA_VISIBLE_DEVICES
  :
 </p>
 <pre class="pre screen" xml:space="preserve">
            
CUDA_VISIBLE_DEVICES=&lt;MIG_UUID&gt; \
   my-cuda-app
    
            </pre>
 <h3 class="title sectiontitle">
  A Complete Example
 </h3>
 <p class="p">
  We now provide a script below where we attempt to run the
  BlackScholes
  from before on the two MIG devices 
                              created on the GPU:
 </p>
 <pre class="pre screen" xml:space="preserve">
            
#!/usr/bin/env bash

set -euo pipefail

#GPU 0: A100-PCIE-40GB (UUID: GPU-63feeb45-94c6-b9cb-78ea-98e9b7a5be6b)
#  MIG 3g.20gb Device 0: (UUID: MIG-GPU-63feeb45-94c6-b9cb-78ea-98e9b7a5be6b/1/0)
#  MIG 3g.20gb Device 1: (UUID: MIG-GPU-63feeb45-94c6-b9cb-78ea-98e9b7a5be6b/2/0)

GPU_UUID=GPU-63feeb45-94c6-b9cb-78ea-98e9b7a5be6b
for i in MIG-$GPU_UUID/1/0 MIG-$GPU_UUID/2/0; do

   # set the environment variable on each MPS 
   # control daemon and use different socket for each MIG instance
   export CUDA_MPS_PIPE_DIRECTORY=/tmp/$i
   mkdir -p $CUDA_MPS_PIPE_DIRECTORY
   sudo CUDA_VISIBLE_DEVICES=$i \
        CUDA_MPS_PIPE_DIRECTORY=/tmp/$i \
        nvidia-cuda-mps-control -d

   # now launch the job on the specific MIG device 
   # and select the appropriate MPS server on the device
   CUDA_MPS_PIPE_DIRECTORY=/tmp/$i \
   CUDA_VISIBLE_DEVICES=$i \
   ./bin/BlackScholes &amp;
done
    
            </pre>
 <p class="p">
  When running this script, we can observe the two MPS servers on each MIG device and the corresponding CUDA program started
                              as an 
                              MPS client when using
  nvidia-smi
  :
 </p>
 <pre class="pre screen" xml:space="preserve">
            
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0    1    0      46781    M+C   ./bin/BlackScholes                251MiB |
|    0    1    0      46784      C   nvidia-cuda-mps-server             29MiB |
|    0    2    0      46797    M+C   ./bin/BlackScholes                251MiB |
|    0    2    0      46798      C   nvidia-cuda-mps-server             29MiB |
+-----------------------------------------------------------------------------+
    
            </pre>
 <a name="cuda-containers" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#cuda-containers" name="cuda-containers" shape="rect">
   Running CUDA Applications as Containers
  </a>
 </h3>
 <p class="p">
  <a class="xref" href="https://github.com/NVIDIA/nvidia-docker" shape="rect" target="_blank">
   NVIDIA Container Toolkit
  </a>
  has been enhanced to provide support for MIG devices, allowing users to run 
                           GPU containers with runtimes such as Docker. This section provides an overview of running Docker containers on A100 with MIG.
 </p>
 <a name="install-docker" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#install-docker" name="install-docker" shape="rect">
   Install Docker
  </a>
 </h3>
 <p class="p">
  Many Linux distributions may come with Docker-CE pre-installed. 
                              If not, use the Docker installation script to install Docker.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ curl https://get.docker.com | sh \
    &amp;&amp; sudo systemctl start docker \
    &amp;&amp; sudo systemctl enable docker 
        </pre>
 <a name="nvidia-docker" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#nvidia-docker" name="nvidia-docker" shape="rect">
   Install NVIDIA Container Toolkit
  </a>
 </h3>
 <p class="p">
  Now install the NVIDIA Container Toolkit (previously known as
  nvidia-docker2
  ). 
                              MIG support is available starting with v2.3 of
  nvidia-docker2
  (or v1.1.1 of the
  nvidia-container-toolkit
  package).
 </p>
 <p class="p">
  To get access to the
  /dev nvidia capabilities
  , 
                              it is recommended to use at least v2.5.0 of
  nvidia-docker2
  . See the
  <a class="xref" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker" shape="rect" target="_blank">
   Installation Guide
  </a>
  for more information.
 </p>
 <p class="p">
  For brevity, the installation instructions provided here are for Ubuntu 18.04 LTS. 
                              Refer to the
  <a class="xref" href="https://github.com/NVIDIA/nvidia-docker" shape="rect" target="_blank">
   NVIDIA Container Toolkit
  </a>
  page for instructions on other Linux distributions.
 </p>
 <p class="p">
  Setup the repository and the GPG key:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
      &amp;&amp; curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
      &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list 
        </pre>
 <p class="p">
  Install the NVIDIA Container Toolkit packages (and their dependencies):
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo apt-get install -y nvidia-docker2 \
    &amp;&amp; sudo systemctl restart docker 
        </pre>
 <a name="running-containers" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#running-containers" name="running-containers" shape="rect">
   Running Containers
  </a>
 </h3>
 <p class="p">
  To run containers on specific MIG devices - whether these are GIs or specific underlying CIs, 
                              then the
  NVIDIA_VISIBLE_DEVICES
  variable (or the
  --gpus
  option 
                              with Docker 19.03+) can be used.
 </p>
 NVIDIA_VISIBLE_DEVICES
 supports the following formats to specify MIG devices:
 <a name="running-containers__ol_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ol class="ol" id="running-containers__ol_pfg_czt_4fb">
  <li class="li">
   <p class="p">
    MIG-&lt;GPU-UUID&gt;/&lt;GPU instance ID&gt;/&lt;compute instance ID&gt;
    when using R450 and R460 drivers or
    MIG-&lt;UUID&gt;
    starting with 
                                       R470 drivers.
   </p>
  </li>
  <li class="li">
   <p class="p">
    GPUDeviceIndex&gt;:&lt;MIGDeviceIndex&gt;
   </p>
  </li>
 </ol>
 <p class="p">
  If using Docker 19.03, the
  --gpus
  option can be used to specify MIG devices by 
                              using the following format:
  ââdevice=MIG-deviceââ
  , where MIG-device can follow 
                              either of the format specified above for
  NVIDIA_VISIBLE_DEVICES
  .
 </p>
 <p class="p">
  The following example shows running
  nvidia-smi
  from within a CUDA container using both formats. 
                              As can be seen in the example, only one MIG device as chosen is visible to the container when using either format.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo docker run --runtime=nvidia \
    -e NVIDIA_VISIBLE_DEVICES=MIG-c7384736-a75d-5afc-978f-d2f1294409fd \
    nvidia/cuda nvidia-smi        

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |                      | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |     11MiB / 20224MiB | 42      0 |  3   0    2    0    0 |
+------------------+----------------------+-----------+-----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+


# For Docker versions &lt; 19.03
$ sudo docker run --runtime=nvidia \
    -e NVIDIA_VISIBLE_DEVICES="0:0" \
    nvidia/cuda nvidia-smi -L
GPU 0: A100-SXM4-40GB (UUID: GPU-e86cb44c-6756-fd30-cd4a-1e6da3caf9b0)
  MIG 3g.20gb Device 0: (UUID: MIG-c7384736-a75d-5afc-978f-d2f1294409fd)


# For Docker versions &gt;= 19.03
$ sudo docker run --gpus '"device=0:0"' \
    nvidia/cuda nvidia-smi -L
GPU 0: A100-SXM4-40GB (UUID: GPU-e86cb44c-6756-fd30-cd4a-1e6da3caf9b0)
  MIG 3g.20gb Device 0: (UUID: MIG-c7384736-a75d-5afc-978f-d2f1294409fd)
        </pre>
 <p class="p">
  A more complex example is to run a TensorFlow container to do a training run using GPUs on the MNIST dataset. This is shown
                              below:
 </p>
 <pre class="pre screen" xml:space="preserve">
        
$ sudo docker run --gpus '"device=0:1"' \
    nvcr.io/nvidia/pytorch:20.11-py3 \
    /bin/bash -c 'cd /opt/pytorch/examples/upstream/mnist &amp;&amp; python main.py'

=============
== PyTorch ==
=============

NVIDIA Release 20.11 (build 17345815)
PyTorch Version 1.8.0a0+17f8c32

Container image Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.

Copyright (c) 2014-2020 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

NVIDIA Deep Learning Profiler (dlprof) Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
NVIDIA modifications are covered by the license terms that apply to the underlying project or file.

NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.

9920512it [00:01, 7880654.53it/s]
32768it [00:00, 129950.31it/s]
1654784it [00:00, 2353765.88it/s]
8192it [00:00, 41020.33it/s]
/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz
Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz
Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz
Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz
Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw
Processing...
Done!
Train Epoch: 1 [0/60000 (0%)]   Loss: 2.320747
Train Epoch: 1 [640/60000 (1%)] Loss: 1.278727
        </pre>
 <a name="kubernetes" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#kubernetes" name="kubernetes" shape="rect">
   MIG with Kubernetes
  </a>
 </h3>
 <p class="p">
  MIG support in Kubernetes is available starting with v0.7.0 of the
  <a class="xref" href="https://github.com/NVIDIA/k8s-device-plugin" shape="rect" target="_blank">
   NVIDIA Device Plugin for Kubernetes
  </a>
  .
                           Visit the
  <a class="xref" href="https://docs.nvidia.com/datacenter/cloud-native/kubernetes/mig-k8s.html" shape="rect" target="_blank">
   documentation
  </a>
  on getting started with MIG and Kubernetes.
 </p>
 <a name="slurm" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#slurm" name="slurm" shape="rect">
   MIG with Slurm
  </a>
 </h3>
 <p class="p">
  <a class="xref" href="https://slurm.schedmd.com/" shape="rect" target="_blank">
   Slurm
  </a>
  is a 
                           workload manager that is widely used at high performance computing centers such as government labs, universities.
 </p>
 <p class="p">
  Starting with 21.08, Slurm supports the usage of MIG devices. Refer to the official
  <a class="xref" href="https://slurm.schedmd.com/gres.html#MIG_Management" shape="rect" target="_blank">
   documentation
  </a>
  on getting started.
 </p>
 <a name="device-nodes" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes" name="device-nodes" shape="rect">
   Device Nodes and Capabilities
  </a>
 </h2>
 <p class="p">
  Currently, the NVIDIA kernel driver exposes its interfaces through a few system-wide device nodes. 
                        Each physical GPU is represented by its own device node - e.g. nvidia0, nvidia1 etc. 
                        This is shown below for a 2-GPU system.
 </p>
 <pre class="pre screen" xml:space="preserve">
        
        /dev
        âââ nvidiactl
        âââ nvidia-modeset
        âââ nvidia-uvm
        âââ nvidia-uvm-tools
        âââ nvidia-nvswitchctl
        âââ nvidia0
        âââ nvidia1   
        </pre>
 <p class="p">
  Starting with CUDA 11/R450, a new abstraction known as
  nvidia-capabilities
  has been introduced. 
                        The idea being that access to a specific
  capability
  is required to perform certain actions through the driver. If a user 
                        has access to the
  capability
  , the action will be carried out. If a user does not have access to the
  capability
  ,
                        the action will fail. The one exception being if you are the root-user (or any user with
  CAP_SYS_ADMIN
  privileges). 
                        With
  CAP_SYS_ADMIN
  privileges, you implicitly have access to all
  nvidia-capabilities
  .
 </p>
 <p class="p">
  For example, the
  mig-config
  capability allows one to create and destroy MIG instances on any MIG-capable GPU 
                        (e.g. the A100 GPU). Without this capability, all attempts to create or destroy a MIG instance will fail. Likewise, the
  fabric-mgmt
  capability allows one to run the Fabric Manager as a non-root but privileged daemon. Without this capability, all attempts
                        to launch the 
                        Fabric Manager as a non-root user will fail.
 </p>
 <p class="p">
  The following sections walk through the system level interface for managing these new
  nvidia-capabilities
  , including the 
                        steps necessary to grant and revoke access to them.
 </p>
 <h2 class="title sectiontitle">
  System Level Interface
 </h2>
 There are two different system-level interfaces available to work with
 nvidia-capabilities
 . The first is via
 /dev
 and the second is via
 /proc
 . The
 /proc
 based interface relies on user-permissions and mount namespaces to limit access 
                           to a particular capability, while the
 /dev
 based interface relies on
 cgroups
 . Technically, the
 /dev
 based interface 
                           also relies on user-permissions as a second-level access control mechanism (on the actual device node files themselves), but
                           the primary access control 
                           mechanism is cgroups. The current CUDA 11/R450 GA (Linux driver 450.51.06) supports both mechanisms, but going forward the
 /dev
 based interface 
                           is the preferred method and the
 /proc
 based interface is deprecated. For now, users can choose the desired interface by using the
 nv_cap_enable_devfs
 parameter on the
 nvidia.ko
 kernel module:
 <ul class="ul">
  <li class="li">
   When
   nv_cap_enable_devfs=0
   the
   /proc
   based interface is enabled.
  </li>
  <li class="li">
   When
   nv_cap_enable_devfs=1
   the
   /dev
   based interface is enabled.
  </li>
  <li class="li">
   A setting of
   nv_cap_enable_devfs=0
   is the default for the R450 driver (as of Linux 450.51.06).
  </li>
  <li class="li">
   All future NVIDIA datacenter drivers will have a default of nv_cap_enable_devfs=1.
  </li>
 </ul>
 <p class="p">
  An example of loading the nvidia kernel module with this parameter set can be seen below:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ modprobe nvidia nv_cap_enable_devfs=1 
                </pre>
 <a name="device-nodes-devfs" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes-devfs" name="device-nodes-devfs" shape="rect">
   /dev based nvidia-capabilities
  </a>
 </h3>
 <p class="p">
  The system level interface for interacting with
  /dev
  based capabilities is actually through a combination of
  /proc
  and
  /dev
  .
 </p>
 <p class="p">
  First, a new major device is now associated with
  nvidia-caps
  and can be read from the standard
  /proc/devices
  file.
 </p>
 <pre class="pre screen" xml:space="preserve">

$ cat /proc/devices | grep nvidia-caps 
508 nvidia-caps
        </pre>
 <p class="p">
  Second, the exact same set of files exist under
  /proc/driver/nvidia/capabilities
  . 
                           These files no longer control access to the capability directly and instead, the contents of 
                           these files point at a device node under
  /dev
  , through which 
                           cgroups can be used to control access to the capability.
 </p>
 <p class="p">
  This can be seen in the example below:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ cat /proc/driver/nvidia/capabilities/mig/config 
DeviceFileMinor: 1
DeviceFileMode: 256
DeviceFileModify: 1
        </pre>
 <p class="p">
  The combination of the device major for
  nvidia-caps
  and the value of
  DeviceFileMinor
  in this file indicate that the
  mig-config
  capability (which allows a user to create and destroy MIG devices) is controlled by the device node with a
  major:minor
  of
  238:1
  . 
                           As such, one will need to use
  cgroups
  to grant a process read access to this device in order to configure MIG devices. The purpose of the
  DeviceFileMode
  and
  DeviceFileModify
  fields in this file are explained later on in this section.
 </p>
 <p class="p">
  The standard location for these device nodes is under
  /dev/nvidia-caps
  as seen in the example below:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ ls -l /dev/nvidia-caps 
total 0
cr-------- 1 root root 508,  1 Nov 21 17:16 nvidia-cap1
cr--r--r-- 1 root root 508,  2 Nov 21 17:16 nvidia-cap2
...
        </pre>
 <p class="p">
  Unfortunately, these device nodes cannot be automatically created/deleted by the NVIDIA driver at the same time it creates/deletes
                           files underneath
  /proc/driver/nvidia/capabilities
  (due to GPL compliance issues). Instead, a user-level program called
  nvidia-modprobe
  is provided, that can be invoked from user-space in order to do this. For example:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ nvidia-modprobe \
    -f /proc/driver/nvidia/capabilities/mig/config \
    -f /proc/driver/nvidia/capabilities/mig/monitor 

$ ls -l /dev/nvidia-caps 
total 0
cr-------- 1 root root 508,  1 Nov 21 17:16 nvidia-cap1
cr--r--r-- 1 root root 508,  2 Nov 21 17:16 nvidia-cap2
        </pre>
 <p class="p">
  nvidia-modprobe
  looks at the
  DeviceFileMode
  in each capability file and creates the device node with the permissions indicated 
                           (e.g.
  +ur
  from a value of
  256 (o400)
  from our example for
  mig-config
  ).
 </p>
 <p class="p">
  Programs such as
  nvidia-smi
  will automatically invoke
  nvidia-modprobe
  (when available) to create these device nodes on your behalf. 
                           In other scenarios it is not necessarily required to use
  nvidia-modprobe
  to create these device nodes, but it does make the process simpler.
 </p>
 <p class="p">
  If you actually want to prevent
  nvidia-modprobe
  from ever creating a particular device node on your behalf, you can do the following:
 </p>
 <pre class="pre screen" xml:space="preserve">

# Give a user write permissions to the capability file under /proc
$ chmod +uw /proc/driver/nvidia/capabilities/mig/config 

# Update the file with a âDeviceFileModifyâ setting of 0
$ echo "DeviceFileModify: 0" &gt; /proc/driver/nvidia/capabilities/mig/config 
        </pre>
 <p class="p">
  You will then be responsible for managing creation of the device node referenced by
  /proc/driver/nvidia/capabilities/mig/config
  going forward. 
                           If you want to change that in the future, simply reset it to a value of
  "DeviceFileModify: 1"
  with the same command sequence.
 </p>
 <p class="p">
  This is important in the context of containers because we may want to give a container access to a certain capability even
                           if it doesn't exist in the
  /proc
  hierarchy yet.
 </p>
 <p class="p">
  For example, granting a container the
  mig-config
  capability implies that we should also grant it capabilities to access all possible gis and cis that could be created 
                           for any GPU on the system. Otherwise the container will have no way of working with those gis and cis once they have actually
                           been created.
 </p>
 <p class="p">
  One final thing to note about
  /dev
  based capabilities is that the minor numbers for all possible capabilities are predetermined and can be 
                           queried under various files of the form:
 </p>
 <pre class="pre screen" xml:space="preserve">

/proc/driver/nvidia-caps/*-minors 
        </pre>
 <p class="p">
  For example, all capabilities related to MIG can be looked up as:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ cat /proc/driver/nvidia-caps/mig-minors 
config 1
monitor 2
gpu0/gi0/access 3
gpu0/gi0/ci0/access 4
gpu0/gi0/ci1/access 5
gpu0/gi0/ci2/access 6
...
gpu31/gi14/ci6/access 4321
gpu31/gi14/ci7/access 4322

        </pre>
 <p class="p">
  The format of the content follows:
  GPU&lt;deviceMinor&gt;/gi&lt;GPU instance ID&gt;/ci&lt;compute instance ID&gt;
 </p>
 Note that the GPU device minor number can be obtained by using either of these mechanisms:
 <ul class="ul">
  <li class="li">
   The NVML API
   nvmlDeviceGetMinorNumber()
   so it returns the device minor number
  </li>
  <li class="li">
   Or use the PCI BDF available under
   /proc/driver/nvidia/gpus/domain:bus:device:function/information
   . 
                                 This file contains a "Device Minor" field.
  </li>
 </ul>
 <span class="notetitle">
  Note:
 </span>
 <p class="p">
  The NVML device numbering (e.g. through
  nvidia-smi
  ) is not the device minor number.
 </p>
 <p class="p">
  For example, if the MIG geometry was created as below:
 </p>
 <pre class="pre screen" xml:space="preserve">

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0    1   0   0  |     19MiB / 40192MiB | 14      0 |  3   0    3    0    3 |
|                  |      0MiB / 65535MiB |           |                       |
+------------------+                      +-----------+-----------------------+
|  0    1   1   1  |                      | 14      0 |  3   0    3    0    3 |
|                  |                      |           |                       |
+------------------+                      +-----------+-----------------------+
|  0    1   2   2  |                      | 14      0 |  3   0    3    0    3 |
|                  |                      |           |                       |
+------------------+----------------------+-----------+-----------------------+

        </pre>
 <p class="p">
  Then the corresponding device nodes:
  /dev/nvidia-cap12
  ,
  /dev/nvidia-cap13
  and
  /dev/nvidia-cap14
  and
  /dev/nvidia-cap15
  would be created.
 </p>
 <a name="device-nodes-procfs" shape="rect">
  <!-- -->
 </a>
 <h3 class="title topictitle2">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#device-nodes-procfs" name="device-nodes-procfs" shape="rect">
   /proc based nvidia-capabilities (
   **Deprecated**
   )
  </a>
 </h3>
 <p class="p">
  The system level interface for interacting with
  /proc
  based
  nvidia-capabilities
  is rooted at
  /proc/driver/nvidia/capabilities
  . Files underneath this hierarchy are used to represent each capability, with
  read
  access to these files controlling whether a user has a given capability or not. These files have
  no content
  and 
                           only exist to represent a given capability.
 </p>
 <p class="p">
  For example, the
  mig-config
  capability (which allows a user to create and destroy MIG devices) is represented as follows:
 </p>
 <pre class="pre screen" xml:space="preserve">

        /proc/driver/nvidia/capabilities
        âââ mig
            âââ config
        </pre>
 <p class="p">
  Likewise, the capabilities required to run workloads on a MIG device once it has been created are represented as follows 
                           (namely as access to the GPU Instance and Compute Instance that comprise the MIG device):
 </p>
 <pre class="pre screen" xml:space="preserve">

        /proc/driver/nvidia/capabilities
        âââ gpu0
            âââ mig
                âââ gi0
                â   âââ access
                â   âââ ci0
                â       âââ access
                âââ gi1
                â   âââ access
                â   âââ ci0
                â       âââ access
                âââ gi2
                    âââ access
                    âââ ci0
                        âââ access
        </pre>
 <p class="p">
  And the corresponding file system layout is shown below with read permissions:
 </p>
 <pre class="pre screen" xml:space="preserve">

$ ls -l /proc/driver/nvidia/capabilities/gpu0/mig/gi*
/proc/driver/nvidia/capabilities/gpu0/mig/gi1:
total 0
-r--r--r-- 1 root root 0 May 24 17:38 access
dr-xr-xr-x 2 root root 0 May 24 17:38 ci0

/proc/driver/nvidia/capabilities/gpu0/mig/gi2:
total 0
-r--r--r-- 1 root root 0 May 24 17:38 access
dr-xr-xr-x 2 root root 0 May 24 17:38 ci0
        </pre>
 <p class="p">
  For a CUDA process to be able to run on top of MIG, it needs access to the Compute Instance 
                           capability and its parent GPU Instance. Thus a MIG device is identified by the following format:
 </p>
 <pre class="pre screen" xml:space="preserve">

            MIG-&lt;GPU-UUID&gt;/&lt;GPU instance ID&gt;/&lt;compute instance ID&gt;
        </pre>
 <p class="p">
  As an example, having read access to the following paths would allow one to run workloads on the MIG device represented by
  &lt;gpu0, gi0, ci0&gt;
  :
 </p>
 <pre class="pre screen" xml:space="preserve">

        /proc/driver/nvidia/capabilities/gpu0/mig/gi0/access
        /proc/driver/nvidia/capabilities/gpu0/mig/gi0/ci0/access
        </pre>
 <p class="p">
  Note, that there is no access file representing a capability to run workloads on gpu0 (only on gi0 and ci0 that sit underneath
                           gpu0). 
                           This is because the traditional mechanism of using cgroups to control access to top level GPU devices (and any required meta
                           devices) is still required. 
                           As shown earlier in the document, the cgroups mechanism applies to:
 </p>
 <pre class="pre screen" xml:space="preserve">

        /dev/nvidia0
        /dev/nvidiactl
        /dev/nvidiactl-uvm
        ...
        </pre>
 <p class="p">
  In the context of containers, a new mount namespace should be overlaid on top of the path for
  /proc/driver/nvidia/capabilities
  , and only those 
                           capabilities a user wishes to grant to a container should be
  bind-mounted
  in. Since the hostâs user/group information is retained across the bind-mount, 
                           it must be ensured that the correct user permissions are set for these capabilities on the host before injecting them into
                           a container.
 </p>
 <a name="changelog" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#changelog" name="changelog" shape="rect">
   Changelog
  </a>
 </h2>
 <a name="changelog__ul_pfg_czt_4fb" shape="rect">
  <!-- -->
 </a>
 <ul class="ul" id="changelog__ul_pfg_czt_4fb">
  <li class="li">
   11/17/2022 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Updates for Hopper, CUDA 12.0/R525
    </li>
    <li class="li">
     Reorginzation of several chapters
    </li>
    <li class="li">
     Added more information on
     /dev
     based capabilities
    </li>
   </ul>
  </li>
  <li class="li">
   7/19/2022 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Added a chapter on virtualization.
    </li>
   </ul>
  </li>
  <li class="li">
   6/6/2022 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Fix table that lists A30 profiles.
    </li>
    <li class="li">
     Update Slurm documentation link.
    </li>
   </ul>
  </li>
  <li class="li">
   8/26/2021 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Improve explanation of GPU Partitioning.
    </li>
   </ul>
  </li>
  <li class="li">
   6/30/2021 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Add info on unique UUIDs for MIG devices.
    </li>
    <li class="li">
     Update supported profiles.
    </li>
   </ul>
  </li>
  <li class="li">
   4/22/2021 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Added information for Slurm and CUDA MPS.
    </li>
   </ul>
  </li>
  <li class="li">
   4/14/2021 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Add additional supported products.
    </li>
    <li class="li">
     Update diagrams.
    </li>
    <li class="li">
     Add link to vGPU documentation.
    </li>
   </ul>
  </li>
  <li class="li">
   2/17/2021 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Add note about persistence of MIG devices.
    </li>
    <li class="li">
     Add link to gathering telemetry for MIG.
    </li>
    <li class="li">
     Add link to K8s documentation.
    </li>
   </ul>
  </li>
  <li class="li">
   11/24/2020 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Fix broken container example.
    </li>
    <li class="li">
     Added link to Kubernetes documentation.
    </li>
    <li class="li">
     Added minimum required software versions.
    </li>
    <li class="li">
     Added MIG mode enablement example on DGX A100.
    </li>
   </ul>
  </li>
  <li class="li">
   11/06/2020 (author: PR):
                              Includes the following changes:
   <ul class="ul">
    <li class="li">
     Updated examples.
    </li>
    <li class="li">
     Added documentation for new CLI options.
    </li>
    <li class="li">
     Added doc links for vGPU.
    </li>
    <li class="li">
     Added doc links for Kubernetes support.
    </li>
    <li class="li">
     Fixed typos.
    </li>
   </ul>
  </li>
  <li class="li">
   8/7/2020 (author: PR):
   <ul class="ul">
    <li class="li">
     Added information on device nodes and nvidia-capabilities with CUDA 11.0 GA.
    </li>
   </ul>
  </li>
  <li class="li">
   5/28/2020 (author: PR):
   <ul class="ul">
    <li class="li">
     Initial Version.
    </li>
   </ul>
  </li>
 </ul>
 <a name="notices-header" shape="rect">
  <!-- -->
 </a>
 <h2 class="title topictitle1">
  <a href="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#notices-header" name="notices-header" shape="rect">
   Notices
  </a>
 </h2>
 <a name="notice" shape="rect">
  <!-- -->
 </a>
 <h3 class="title sectiontitle notices">
  Notice
 </h3>
 <p class="p" id="notice__notice-para-1">
  <a name="notice__notice-para-1" shape="rect">
   <!-- -->
  </a>
  This document is provided for information
                                 purposes only and shall not be regarded as a warranty of a
                                 certain functionality, condition, or quality of a product.
                                 NVIDIA Corporation (âNVIDIAâ) makes no representations or
                                 warranties, expressed or implied, as to the accuracy or
                                 completeness of the information contained in this document
                                 and assumes no responsibility for any errors contained
                                 herein. NVIDIA shall have no liability for the consequences
                                 or use of such information or for any infringement of
                                 patents or other rights of third parties that may result
                                 from its use. This document is not a commitment to develop,
                                 release, or deliver any Material (defined below), code, or
                                 functionality.
 </p>
 <p class="p" id="notice__notice-para-2">
  <a name="notice__notice-para-2" shape="rect">
   <!-- -->
  </a>
  NVIDIA reserves the right to make corrections, modifications,
                                 enhancements, improvements, and any other changes to this
                                 document, at any time without notice.
 </p>
 <p class="p" id="notice__notice-para-3">
  <a name="notice__notice-para-3" shape="rect">
   <!-- -->
  </a>
  Customer should obtain the latest relevant information before
                                 placing orders and should verify that such information is
                                 current and complete.
 </p>
 <p class="p" id="notice__notice-para-4">
  <a name="notice__notice-para-4" shape="rect">
   <!-- -->
  </a>
  NVIDIA products are sold subject to the NVIDIA standard terms and
                                 conditions of sale supplied at the time of order
                                 acknowledgement, unless otherwise agreed in an individual
                                 sales agreement signed by authorized representatives of
                                 NVIDIA and customer (âTerms of Saleâ). NVIDIA hereby
                                 expressly objects to applying any customer general terms and
                                 conditions with regards to the purchase of the NVIDIA
                                 product referenced in this document. No contractual
                                 obligations are formed either directly or indirectly by this
                                 document.
 </p>
 <p class="p" id="notice__notice-para-5">
  <a name="notice__notice-para-5" shape="rect">
   <!-- -->
  </a>
  NVIDIA products are not designed, authorized, or warranted to be
                                 suitable for use in medical, military, aircraft, space, or
                                 life support equipment, nor in applications where failure or
                                 malfunction of the NVIDIA product can reasonably be expected
                                 to result in personal injury, death, or property or
                                 environmental damage. NVIDIA accepts no liability for
                                 inclusion and/or use of NVIDIA products in such equipment or
                                 applications and therefore such inclusion and/or use is at
                                 customerâs own risk.
 </p>
 <p class="p" id="notice__notice-para-6">
  <a name="notice__notice-para-6" shape="rect">
   <!-- -->
  </a>
  NVIDIA makes no representation or warranty that products based on
                                 this document will be suitable for any specified use.
                                 Testing of all parameters of each product is not necessarily
                                 performed by NVIDIA. It is customerâs sole responsibility to
                                 evaluate and determine the applicability of any information
                                 contained in this document, ensure the product is suitable
                                 and fit for the application planned by customer, and perform
                                 the necessary testing for the application in order to avoid
                                 a default of the application or the product. Weaknesses in
                                 customerâs product designs may affect the quality and
                                 reliability of the NVIDIA product and may result in
                                 additional or different conditions and/or requirements
                                 beyond those contained in this document. NVIDIA accepts no
                                 liability related to any default, damage, costs, or problem
                                 which may be based on or attributable to: (i) the use of the
                                 NVIDIA product in any manner that is contrary to this
                                 document or (ii) customer product designs.
 </p>
 <p class="p" id="notice__notice-para-7">
  <a name="notice__notice-para-7" shape="rect">
   <!-- -->
  </a>
  No license, either expressed or implied, is granted under any NVIDIA
                                 patent right, copyright, or other NVIDIA intellectual
                                 property right under this document. Information published by
                                 NVIDIA regarding third-party products or services does not
                                 constitute a license from NVIDIA to use such products or
                                 services or a warranty or endorsement thereof. Use of such
                                 information may require a license from a third party under
                                 the patents or other intellectual property rights of the
                                 third party, or a license from NVIDIA under the patents or
                                 other intellectual property rights of NVIDIA.
 </p>
 <p class="p" id="notice__notice-para-8">
  <a name="notice__notice-para-8" shape="rect">
   <!-- -->
  </a>
  Reproduction of information in this document is permissible only if
                                 approved in advance by NVIDIA in writing, reproduced without
                                 alteration and in full compliance with all applicable export
                                 laws and regulations, and accompanied by all associated
                                 conditions, limitations, and notices.
 </p>
 <p class="p" id="notice__notice-para-9">
  <a name="notice__notice-para-9" shape="rect">
   <!-- -->
  </a>
  THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE
                                 BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER
                                 DOCUMENTS (TOGETHER AND SEPARATELY, âMATERIALSâ) ARE BEING
                                 PROVIDED âAS IS.â NVIDIA MAKES NO WARRANTIES, EXPRESSED,
                                 IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE
                                 MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF
                                 NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A
                                 PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN
                                 NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING
                                 WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL,
                                 INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER
                                 CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING
                                 OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN
                                 ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding
                                 any damages that customer might incur for any reason
                                 whatsoever, NVIDIAâs aggregate and cumulative liability
                                 towards customer for the products described herein shall be
                                 limited in accordance with the Terms of Sale for the
                                 product.
 </p>
 <a name="trademarks" shape="rect">
  <!-- -->
 </a>
 <h3 class="title sectiontitle notices">
  Trademarks
 </h3>
 <p class="p">
  NVIDIA and the NVIDIA logo are trademarks and/or registered trademarks of NVIDIA
                                 Corporation in the Unites States and other countries. Other company and product
                                 names may be trademarks of the respective companies with which they are
                                 associated.
 </p>
 <a name="copyright-present" shape="rect">
  <!-- -->
 </a>
 <h3 class="title sectiontitle">
  Copyright
 </h3>
 <p class="p">
  Â©
  <span class="ph">
   2020
  </span>
  -
  <span class="ph">
   2024
  </span>
  NVIDIA Corporation &amp; affiliates. All rights
                                 reserved.
 </p>
 <p>
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
   Privacy Policy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
   Manage My Privacy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
   Do Not Sell or Share My Data
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
   Terms of Service
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
   Accessibility
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
   Corporate Policies
  </a>
  |
  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
   Product Security
  </a>
  |
  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
   Contact
  </a>
 </p>
</body>
</body></html>