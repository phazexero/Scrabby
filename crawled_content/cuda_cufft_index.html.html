<html><head><title>cuFFT</title></head><body><body class="wy-body-for-nav">
 <a href="https://docs.nvidia.com/cuda/cufft/contents.html">
 </a>
 <ul class="current">
  <li class="toctree-l1 current">
   <a class="current reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html">
    1. Introduction
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#using-the-cufft-api">
    2. Using the cuFFT API
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#accessing-cufft">
      2.1. Accessing cuFFT
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#fourier-transform-setup">
      2.2. Fourier Transform Setup
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#free-memory-requirement">
        2.2.1. Free Memory Requirement
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#plan-initialization-time">
        2.2.2. Plan Initialization Time
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#fourier-transform-types">
      2.3. Fourier Transform Types
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#half-precision-cufft-transforms">
        2.3.1. Half-precision cuFFT Transforms
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#bfloat16-precision-cufft-transforms">
        2.3.2. Bfloat16-precision cuFFT Transforms
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#data-layout">
      2.4. Data Layout
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multidimensional-transforms">
      2.5. Multidimensional Transforms
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout">
      2.6. Advanced Data Layout
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#streamed-cufft-transforms">
      2.7. Streamed cuFFT Transforms
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-cufft-transforms">
      2.8. Multiple GPU cuFFT Transforms
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#plan-specification-and-work-areas">
        2.8.1. Plan Specification and Work Areas
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#helper-functions">
        2.8.2. Helper Functions
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-2d-and-3d-transforms-on-permuted-input">
        2.8.3. Multiple GPU 2D and 3D Transforms on Permuted Input
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#supported-functionality">
        2.8.4. Supported Functionality
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-callback-routines">
      2.9. cuFFT Callback Routines
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#overview-of-the-cufft-callback-routine-feature">
        2.9.1. Overview of the cuFFT Callback Routine Feature
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#specifying-load-and-store-callback-routines">
        2.9.2. Specifying Load and Store Callback Routines
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#callback-routine-function-details">
        2.9.3. Callback Routine Function Details
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#coding-considerations-for-the-cufft-callback-routine-feature">
        2.9.4. Coding Considerations for the cuFFT Callback Routine Feature
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#no-ordering-guarantees-within-a-kernel">
          2.9.4.1. No Ordering Guarantees Within a Kernel
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#thread-safety">
      2.10. Thread Safety
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cuda-graphs-support">
      2.11. CUDA Graphs Support
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#static-library-and-callback-support">
      2.12. Static Library and Callback Support
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#static-library-without-callback-support">
        2.12.1. Static library without callback support
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#accuracy-and-performance">
      2.13. Accuracy and Performance
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#caller-allocated-work-area-support">
      2.14. Caller Allocated Work Area Support
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-link-time-optimized-kernels">
      2.15. cuFFT Link-Time Optimized Kernels
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#id1">
        2.15.1. Overview of the cuFFT Callback Routine Feature
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-api-reference">
    3. cuFFT API Reference
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#return-value-cufftresult">
      3.1. Return value cufftResult
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-basic-plans">
      3.2. cuFFT Basic Plans
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplan1d">
        3.2.1. cufftPlan1d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplan2d">
        3.2.2. cufftPlan2d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplan3d">
        3.2.3. cufftPlan3d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplanmany">
        3.2.4. cufftPlanMany()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-extensible-plans">
      3.3. cuFFT Extensible Plans
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftcreate">
        3.3.1. cufftCreate()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftdestroy">
        3.3.2. cufftDestroy()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplan1d">
        3.3.3. cufftMakePlan1d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplan2d">
        3.3.4. cufftMakePlan2d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplan3d">
        3.3.5. cufftMakePlan3d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplanmany">
        3.3.6. cufftMakePlanMany()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplanmany64">
        3.3.7. cufftMakePlanMany64()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtmakeplanmany">
        3.3.8. cufftXtMakePlanMany()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-plan-properties">
      3.4. cuFFT Plan Properties
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetplanpropertyint64">
        3.4.1. cufftSetPlanPropertyInt64()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetplanpropertyint64">
        3.4.2. cufftGetPlanPropertyInt64()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftresetplanproperty">
        3.4.3. cufftResetPlanProperty()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-estimated-size-of-work-area">
      3.5. cuFFT Estimated Size of Work Area
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimate1d">
        3.5.1. cufftEstimate1d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimate2d">
        3.5.2. cufftEstimate2d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimate3d">
        3.5.3. cufftEstimate3d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimatemany">
        3.5.4. cufftEstimateMany()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-refined-estimated-size-of-work-area">
      3.6. cuFFT Refined Estimated Size of Work Area
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize1d">
        3.6.1. cufftGetSize1d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize2d">
        3.6.2. cufftGetSize2d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize3d">
        3.6.3. cufftGetSize3d()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsizemany">
        3.6.4. cufftGetSizeMany()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsizemany64">
        3.6.5. cufftGetSizeMany64()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtgetsizemany">
        3.6.6. cufftXtGetSizeMany()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize">
      3.7. cufftGetSize()
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-caller-allocated-work-area-support">
      3.8. cuFFT Caller Allocated Work Area Support
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetautoallocation">
        3.8.1. cufftSetAutoAllocation()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetworkarea">
        3.8.2. cufftSetWorkArea()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetworkareapolicy">
        3.8.3. cufftXtSetWorkAreaPolicy()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-execution">
      3.9. cuFFT Execution
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftexecc2c-and-cufftexecz2z">
        3.9.1. cufftExecC2C() and cufftExecZ2Z()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftexecr2c-and-cufftexecd2z">
        3.9.2. cufftExecR2C() and cufftExecD2Z()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftexecc2r-and-cufftexecz2d">
        3.9.3. cufftExecC2R() and cufftExecZ2D()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexec">
        3.9.4. cufftXtExec()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptor">
        3.9.5. cufftXtExecDescriptor()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-and-multiple-gpus">
      3.10. cuFFT and Multiple GPUs
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetgpus">
        3.10.1. cufftXtSetGPUs()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetworkarea">
        3.10.2. cufftXtSetWorkArea()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-multiple-gpu-execution">
        3.10.3. cuFFT Multiple GPU Execution
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptorc2c-and-cufftxtexecdescriptorz2z">
          3.10.3.1. cufftXtExecDescriptorC2C() and cufftXtExecDescriptorZ2Z()
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptorr2c-and-cufftxtexecdescriptord2z">
          3.10.3.2. cufftXtExecDescriptorR2C() and cufftXtExecDescriptorD2Z()
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptorc2r-and-cufftxtexecdescriptorz2d">
          3.10.3.3. cufftXtExecDescriptorC2R() and cufftXtExecDescriptorZ2D()
         </a>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#memory-allocation-and-data-movement-functions">
        3.10.4. Memory Allocation and Data Movement Functions
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtmalloc">
          3.10.4.1. cufftXtMalloc()
         </a>
         <ul>
          <li class="toctree-l5">
           <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#parameter-cufftxtsubformat">
            3.10.4.1.1. Parameter cufftXtSubFormat
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtfree">
          3.10.4.2. cufftXtFree()
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtmemcpy">
          3.10.4.3. cufftXtMemcpy()
         </a>
         <ul>
          <li class="toctree-l5">
           <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#parameter-cufftxtcopytype">
            3.10.4.3.1. Parameter cufftXtCopyType
           </a>
          </li>
         </ul>
        </li>
       </ul>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#general-multiple-gpu-descriptor-types">
        3.10.5. General Multiple GPU Descriptor Types
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cudaxtdesc">
          3.10.5.1. cudaXtDesc
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cudalibxtdesc">
          3.10.5.2. cudaLibXtDesc
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-callbacks">
      3.11. cuFFT Callbacks
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetcallback">
        3.11.1. cufftXtSetCallback()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtclearcallback">
        3.11.2. cufftXtClearCallback()
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetcallbacksharedsize">
        3.11.3. cufftXtSetCallbackSharedSize()
       </a>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetstream">
      3.12. cufftSetStream()
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetversion">
      3.13. cufftGetVersion()
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetproperty">
      3.14. cufftGetProperty()
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-types">
      3.15. cuFFT Types
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#parameter-cuffttype">
        3.15.1. Parameter cufftType
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#parameters-for-transform-direction">
        3.15.2. Parameters for Transform Direction
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#type-definitions-for-callbacks">
        3.15.3. Type definitions for callbacks
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#other-cufft-types">
        3.15.4. Other cuFFT Types
       </a>
       <ul>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cuffthandle">
          3.15.4.1. cufftHandle
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftreal">
          3.15.4.2. cufftReal
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftdoublereal">
          3.15.4.3. cufftDoubleReal
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftcomplex">
          3.15.4.4. cufftComplex
         </a>
        </li>
        <li class="toctree-l4">
         <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftdoublecomplex">
          3.15.4.5. cufftDoubleComplex
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#common-types">
      3.16. Common types
     </a>
     <ul>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cudadatatype">
        3.16.1. cudaDataType
       </a>
      </li>
      <li class="toctree-l3">
       <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#librarypropertytype">
        3.16.2. libraryPropertyType
       </a>
      </li>
     </ul>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-code-examples">
    4. cuFFT Code Examples
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization">
    5. Multiple GPU Data Organization
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization-for-batched-transforms">
      5.1. Multiple GPU Data Organization for Batched Transforms
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization-for-single-2d-and-3d-transforms">
      5.2. Multiple GPU Data Organization for Single 2D and 3D Transforms
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization-for-single-1d-transforms">
      5.3. Multiple-GPU Data Organization for Single 1D Transforms
     </a>
    </li>
   </ul>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#fftw-conversion-guide">
    6. FFTW Conversion Guide
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#fftw-interface-to-cufft">
    7. FFTW Interface to cuFFT
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#deprecated-functionality">
    8. Deprecated Functionality
   </a>
  </li>
  <li class="toctree-l1">
   <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#notices">
    9. Notices
   </a>
   <ul>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#notice">
      9.1. Notice
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#opencl">
      9.2. OpenCL
     </a>
    </li>
    <li class="toctree-l2">
     <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#trademarks">
      9.3. Trademarks
     </a>
    </li>
   </ul>
  </li>
 </ul>
 <a href="https://docs.nvidia.com/cuda/cufft/contents.html">
  cuFFT
 </a>
 <ul class="wy-breadcrumbs">
  <li>
   <a class="icon icon-home" href="https://docs.nvidia.com/cuda/index.html">
   </a>
   Â»
  </li>
  <li>
   <span class="section-number">
    1.
   </span>
   Introduction
  </li>
  <li class="wy-breadcrumbs-aside">
   <span>
    v12.5 |
   </span>
   <a class="reference external" href="https://docs.nvidia.com/cuda/pdf/CUFFT_Library.pdf">
    PDF
   </a>
   <span>
    |
   </span>
   <a class="reference external" href="https://developer.nvidia.com/cuda-toolkit-archive">
    Archive
   </a>
   <span>
    Â
   </span>
  </li>
 </ul>
 <p class="rubric-h1 rubric">
  cuFFT API Reference
 </p>
 <p>
  The API reference guide for cuFFT, the CUDA Fast Fourier Transform library.
 </p>
 <h1>
  <span class="section-number">
   1.
  </span>
  Introduction
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#introduction" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  This document describes cuFFT, the NVIDIAÂ® CUDAÂ® Fast Fourier Transform (FFT) product. It consists of two separate libraries: cuFFT and cuFFTW. The cuFFT library is designed to provide high performance on NVIDIA GPUs. The cuFFTW library is provided as a porting tool to enable users of FFTW to start using NVIDIA GPUs with a minimum amount of effort.
 </p>
 <p>
  The FFT is a divide-and-conquer algorithm for efficiently computing discrete Fourier transforms of complex or real-valued data sets. It is one of the most important and widely used numerical algorithms in computational physics and general signal processing. The cuFFT library provides a simple interface for computing FFTs on an NVIDIA GPU, which allows users to quickly leverage the floating-point power and parallelism of the GPU in a highly optimized and tested FFT library.
 </p>
 <p>
  The cuFFT product supports a wide range of FFT inputs and options efficiently on NVIDIA GPUs. This version of the cuFFT library supports the following features:
 </p>
 <ul class="simple">
  <li>
   <p>
    Algorithms highly optimized for input sizes that can be written in the form
    <span class="math notranslate nohighlight">
     \(2^{a} \times 3^{b} \times 5^{c} \times 7^{d}\)
    </span>
    . In general the smaller the prime factor, the better the performance, i.e., powers of two are fastest.
   </p>
  </li>
  <li>
   <p>
    An
    <span class="math notranslate nohighlight">
     \(O\left( n\log n \right)\)
    </span>
    algorithm for every input data size
   </p>
  </li>
  <li>
   <p>
    Half-precision (16-bit floating point), single-precision (32-bit floating point) and double-precision (64-bit floating point). Transforms of lower precision have higher performance.
   </p>
  </li>
  <li>
   <p>
    Complex and real-valued input and output. Real valued input or output require less computations and data than complex values and often have faster time to solution. Types supported are:
   </p>
   <ul>
    <li>
     <p>
      C2C - Complex input to complex output
     </p>
    </li>
    <li>
     <p>
      R2C - Real input to complex output
     </p>
    </li>
    <li>
     <p>
      C2R - Symmetric complex input to real output
     </p>
    </li>
   </ul>
  </li>
  <li>
   <p>
    1D, 2D and 3D transforms
   </p>
  </li>
  <li>
   <p>
    Execution of multiple 1D, 2D and 3D transforms simultaneously. These batched transforms have higher performance than single transforms.
   </p>
  </li>
  <li>
   <p>
    In-place and out-of-place transforms
   </p>
  </li>
  <li>
   <p>
    Arbitrary intra- and inter-dimension element strides (strided layout)
   </p>
  </li>
  <li>
   <p>
    FFTW compatible data layout
   </p>
  </li>
  <li>
   <p>
    Execution of transforms across multiple GPUs
   </p>
  </li>
  <li>
   <p>
    Streamed execution, enabling asynchronous computation and data movement
   </p>
  </li>
 </ul>
 <p>
  The cuFFTW library provides the FFTW3 API to facilitate porting of existing FFTW applications.
 </p>
 <p>
  Please note that starting from CUDA 11.0, the minimum supported GPU architecture is SM35. See
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#deprecated-functionality">
   Deprecated Functionality
  </a>
  .
 </p>
 <h1>
  <span class="section-number">
   2.
  </span>
  Using the cuFFT API
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#using-the-cufft-api" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  This chapter provides a general overview of the cuFFT library API. For more complete information on specific functions, see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-api-reference">
   cuFFT API Reference
  </a>
  . Users are encouraged to read this chapter before continuing with more detailed descriptions.
 </p>
 <p>
  The Discrete Fourier transform (DFT) maps a complex-valued vector
  <span class="math notranslate nohighlight">
   \(x_{k}\)
  </span>
  (
  time domain
  ) into its
  frequency domain representation
  given by:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(X_{k} = \sum\limits_{n = 0}^{N - 1}x_{n}e^{-2\pi i\frac{kn}{N}}\)
     </span>
    </p>
   </td>
  </tr>
 </table>
 <p>
  where
  <span class="math notranslate nohighlight">
   \(X_{k}\)
  </span>
  is a complex-valued vector of the same size. This is known as a
  forward
  DFT. If the sign on the exponent of e is changed to be positive, the transform is an
  inverse
  transform. Depending on
  <span class="math notranslate nohighlight">
   \(N\)
  </span>
  , different algorithms are deployed for the best performance.
 </p>
 <p>
  The cuFFT API is modeled after
  <a class="reference external" href="http://www.fftw.org">
   FFTW
  </a>
  , which is one of the most popular and efficient CPU-based FFT libraries. cuFFT provides a simple configuration mechanism called a
  plan
  that uses internal building blocks to optimize the transform for the given configuration and the particular GPU hardware selected. Then, when the
  execution
  function is called, the actual transform takes place following the plan of execution. The advantage of this approach is that once the user creates a plan, the library retains whatever state is needed to execute the plan multiple times without recalculation of the configuration. This model works well for cuFFT because different kinds of FFTs require different thread configurations and GPU resources, and the plan interface provides a simple way of reusing configurations.
 </p>
 <p>
  Computing a number
  <span class="pre">
   BATCH
  </span>
  of one-dimensional DFTs of size
  <span class="pre">
   NX
  </span>
  using cuFFT will typically look like this:
 </p>
 <pre><span class="cp">#define NX 256</span>
<span class="cp">#define BATCH 10</span>
<span class="cp">#define RANK 1</span>
<span class="p">...</span>
<span class="p">{</span>
<span class="n">cufftHandle</span><span class="n">plan</span><span class="p">;</span>
<span class="n">cufftComplex</span><span class="o">*</span><span class="n">data</span><span class="p">;</span>
<span class="p">...</span>
<span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="n">cufftComplex</span><span class="p">)</span><span class="o">*</span><span class="n">NX</span><span class="o">*</span><span class="n">BATCH</span><span class="p">);</span>
<span class="n">cufftPlanMany</span><span class="p">(</span><span class="o">&amp;</span><span class="n">plan</span><span class="p">,</span><span class="n">RANK</span><span class="p">,</span><span class="n">NX</span><span class="p">,</span><span class="o">&amp;</span><span class="n">iembed</span><span class="p">,</span><span class="n">istride</span><span class="p">,</span><span class="n">idist</span><span class="p">,</span>
<span class="o">&amp;</span><span class="n">oembed</span><span class="p">,</span><span class="n">ostride</span><span class="p">,</span><span class="n">odist</span><span class="p">,</span><span class="n">CUFFT_C2C</span><span class="p">,</span><span class="n">BATCH</span><span class="p">);</span>
<span class="p">...</span>
<span class="n">cufftExecC2C</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">data</span><span class="p">,</span><span class="n">CUFFT_FORWARD</span><span class="p">);</span>
<span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">...</span>
<span class="n">cufftDestroy</span><span class="p">(</span><span class="n">plan</span><span class="p">);</span>
<span class="n">cudaFree</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
<span class="p">}</span>
</pre>
 <h2>
  <span class="section-number">
   2.1.
  </span>
  Accessing cuFFT
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#accessing-cufft" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The cuFFT and cuFFTW libraries are available as shared libraries. They consist of compiled programs ready for users to incorporate into applications with the compiler and linker. cuFFT can be downloaded from
  <a class="reference external" href="https://developer.nvidia.com/cufft">
   https://developer.nvidia.com/cufft
  </a>
  . By selecting
  Download CUDA Production Release
  users are all able to install the package containing the CUDA Toolkit, SDK code samples and development drivers. The CUDA Toolkit contains cuFFT and the samples include
  <span class="pre">
   simplecuFFT
  </span>
  .
 </p>
 <p>
  The Linux release for
  <span class="pre">
   simplecuFFT
  </span>
  assumes that the root install directory is
  <span class="pre">
   /usr/local/cuda
  </span>
  and that the locations of the products are contained there as follows. Modify the Makefile as appropriate for your system.
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Product
    </p>
   </th>
   <th class="head">
    <p>
     Location and name
    </p>
   </th>
   <th class="head">
    <p>
     Include file
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      nvcc
     </span>
     compiler
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      /bin/nvcc
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      cuFFT
     </span>
     library
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      {lib,
     </span>
     <span class="pre">
      lib64}/libcufft.so
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      inc/cufft.h
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      cuFFT
     </span>
     library with Xt functionality
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      {lib,
     </span>
     <span class="pre">
      lib64}/libcufft.so
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      inc/cufftXt.h
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      cuFFTW
     </span>
     library
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      {lib,
     </span>
     <span class="pre">
      lib64}/libcufftw.so
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      inc/cufftw.h
     </span>
    </p>
   </td>
  </tr>
 </table>
 <p>
  The most common case is for developers to modify an existing CUDA routine (for example,
  <span class="pre">
   filename.cu
  </span>
  ) to call cuFFT routines. In this case the include file
  <span class="pre">
   cufft.h
  </span>
  or
  <span class="pre">
   cufftXt.h
  </span>
  should be inserted into
  <span class="pre">
   filename.cu
  </span>
  file and the library included in the link line. A single compile and link line might appear as
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     /usr/local/cuda/bin/nvcc
    </span>
    <span class="pre">
     [options]
    </span>
    <span class="pre">
     filename.cu
    </span>
    <span class="pre">
     â¦
    </span>
    <span class="pre">
     -I/usr/local/cuda/inc
    </span>
    <span class="pre">
     -L/usr/local/cuda/lib
    </span>
    <span class="pre">
     -lcufft
    </span>
   </p>
  </li>
 </ul>
 <p>
  Of course there will typically be many compile lines and the compiler
  <span class="pre">
   g++
  </span>
  may be used for linking so long as the library path is set correctly.
 </p>
 <p>
  Users of the FFTW interface (see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#fftw-supported-interface">
   FFTW Interface to cuFFT
  </a>
  ) should include
  <span class="pre">
   cufftw.h
  </span>
  and link with both cuFFT and cuFFTW libraries.
 </p>
 <p>
  Functions in the cuFFT and cuFFTW library assume that the data is in GPU visible memory. This means any memory allocated by
  <span class="pre">
   cudaMalloc
  </span>
  ,
  <span class="pre">
   cudaMallocHost
  </span>
  and
  <span class="pre">
   cudaMallocManaged
  </span>
  or registered with
  <span class="pre">
   cudaHostRegister
  </span>
  can be used as input, output or plan work area with cuFFT and cuFFTW functions. For the best performance input data, output data and plan work area should reside in device memory.
 </p>
 <p>
  cuFFTW library also supports input data and output data that is not GPU visible.
 </p>
 <h2>
  <span class="section-number">
   2.2.
  </span>
  Fourier Transform Setup
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#fourier-transform-setup" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The first step in using the cuFFT Library is to create a plan using one of the following:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cufftPlan1D()
    </span>
    <span class="pre">
     /
    </span>
    <span class="pre">
     cufftPlan2D()
    </span>
    <span class="pre">
     /
    </span>
    <span class="pre">
     cufftPlan3D()
    </span>
    - Create a simple plan for a 1D/2D/3D transform respectively.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftPlanMany()
    </span>
    - Creates a plan supporting batched input and strided data layouts.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMakePlanMany()
    </span>
    - Creates a plan supporting batched input and strided data layouts for any supported precision.
   </p>
  </li>
 </ul>
 <p>
  Among the plan creation functions,
  <span class="pre">
   cufftPlanMany()
  </span>
  allows use of more complicated data layouts and batched executions. Execution of a transform of a particular size and type may take several stages of processing. When a plan for the transform is generated, cuFFT derives the internal steps that need to be taken. These steps may include multiple kernel launches, memory copies, and so on. In addition, all the intermediate buffer allocations (on CPU/GPU memory) take place during planning. These buffers are released when the plan is destroyed. In the worst case, the cuFFT Library allocates space for
  <span class="pre">
   8*batch*n[0]*..*n[rank-1]
  </span>
  <span class="pre">
   cufftComplex
  </span>
  or
  <span class="pre">
   cufftDoubleComplex
  </span>
  elements (where
  <span class="pre">
   batch
  </span>
  denotes the number of transforms that will be executed in parallel,
  <span class="pre">
   rank
  </span>
  is the number of dimensions of the input data (see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#multi-dimensional">
   Multidimensional Transforms
  </a>
  ) and
  <span class="pre">
   n[]
  </span>
  is the array of transform dimensions) for single and double-precision transforms respectively. Depending on the configuration of the plan, less memory may be used. In some specific cases, the temporary space allocations can be as low as
  <span class="pre">
   1*batch*n[0]*..*n[rank-1]
  </span>
  <span class="pre">
   cufftComplex
  </span>
  or
  <span class="pre">
   cufftDoubleComplex
  </span>
  elements. This temporary space is allocated separately for each individual plan when it is created (i.e., temporary space is not shared between the plans).
 </p>
 <p>
  The next step in using the library is to call an execution function such as
  <span class="pre">
   cufftExecC2C()
  </span>
  (see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-transform-types">
   Parameter cufftType
  </a>
  ) which will perform the transform with the specifications defined at planning.
 </p>
 <p>
  One can create a cuFFT plan and perform multiple transforms on different data sets by providing different input and output pointers. Once the plan is no longer needed, the
  <span class="pre">
   cufftDestroy()
  </span>
  function should be called to release the resources allocated for the plan.
 </p>
 <h3>
  <span class="section-number">
   2.2.1.
  </span>
  Free Memory Requirement
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#free-memory-requirement" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The first program call to any cuFFT function causes the initialization of the cuFFT kernels. This can fail if there is not enough free memory on the GPU. It is advisable to initialize cufft first (e.g. by creating a plan) and then allocating memory.
 </p>
 <h3>
  <span class="section-number">
   2.2.2.
  </span>
  Plan Initialization Time
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#plan-initialization-time" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  During plan initialization, cuFFT conducts a series of steps, including heuristics to determine which kernels to be used as well as kernel module loads. Starting from CUDA 12.0, cuFFT delivers a larger portion of kernels using the CUDA Parallel Thread eXecution assembly form (PTX code), instead of the binary form (cubin object). The PTX code of cuFFT kernels are loaded and compiled further to the binary code by the CUDA device driver at runtime when a cuFFT plan is initialized. This is called
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#just-in-time-compilation">
   just-in-time (JIT) compilation
  </a>
  .
 </p>
 <p>
  JIT compilation slightly increases cuFFT plan initialization time, depending on the transform size and the speed of the host CPU (see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#module">
   Module load driver API
  </a>
  ) . But the JIT overhead occurs only when a binary code is generated for the first time during plan initialization using one of the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-setup">
   plan creation functions
  </a>
  . The device driver automatically caches a copy of the generated binary code to avoid repeating the compilation in subsequent invocations. If necessary,
  <span class="pre">
   CUDA_CACHE_PATH
  </span>
  or
  <span class="pre">
   CUDA_CACHE_MAXSIZE
  </span>
  can be customized to set the cache folder and max size (see detail in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars">
   CUDA Environmental Variables
  </a>
  ), but the default settings are fine in general.
 </p>
 <h2>
  <span class="section-number">
   2.3.
  </span>
  Fourier Transform Types
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#fourier-transform-types" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Apart from the general complex-to-complex (C2C) transform, cuFFT implements efficiently two other types: real-to-complex (R2C) and complex-to-real (C2R). In many practical applications the input vector is real-valued. It can be easily shown that in this case the output satisfies Hermitian symmetry (
  <span class="math notranslate nohighlight">
   \(X_{k} = X_{N - k}^{\ast}\)
  </span>
  , where the star denotes complex conjugation). The converse is also true: for complex-Hermitian input the inverse transform will be purely real-valued. cuFFT takes advantage of this redundancy and works only on the first half of the Hermitian vector.
 </p>
 <p>
  Transform execution functions for single and double-precision are defined separately as:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cufftExecC2C()
    </span>
    <span class="pre">
     /
    </span>
    <span class="pre">
     cufftExecZ2Z()
    </span>
    - complex-to-complex transforms for single/double precision.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftExecR2C()
    </span>
    <span class="pre">
     /
    </span>
    <span class="pre">
     cufftExecD2Z()
    </span>
    - real-to-complex forward transform for single/double precision.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftExecC2R()
    </span>
    <span class="pre">
     /
    </span>
    <span class="pre">
     cufftExecZ2D()
    </span>
    - complex-to-real inverse transform for single/double precision.
   </p>
  </li>
 </ul>
 <p>
  Each of those functions demands different input data layout (see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#data-layout">
   Data Layout
  </a>
  for details).
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Complex-to-real (C2R) transforms accept complex-Hermitian input. For one-dimensional signals, this requires the 0th element (and the
  <span class="math notranslate nohighlight">
   \(\frac{N}{2}\)
  </span>
  th input if N is even) to be real-valued, i.e. its imaginary part should be zero.
For d-dimension signals, this means
  <span class="math notranslate nohighlight">
   \(x_{(n_{1},n_{2},\ldots,n_{d})} = x_{(N_{1} - n_{1},N_{2} - n_{2},\ldots,N_{d} - n_{d})}^{\ast}\)
  </span>
  .
Otherwise, the behavior of the transform is undefined. Also see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#multidimensional-transforms">
   Multidimensional Transforms
  </a>
  .
 </p>
 <p>
  Functions
  <span class="pre">
   cufftXtExec()
  </span>
  and
  <span class="pre">
   cufftXtExecDescriptor()
  </span>
  can perform transforms on any of the supported types.
 </p>
 <h3>
  <span class="section-number">
   2.3.1.
  </span>
  Half-precision cuFFT Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#half-precision-cufft-transforms" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Half-precision transforms have the following limitations:
 </p>
 <ul class="simple">
  <li>
   <p>
    Minimum GPU architecture is SM_53
   </p>
  </li>
  <li>
   <p>
    Sizes are restricted to powers of two only
   </p>
  </li>
  <li>
   <p>
    Strides on the real part of real-to-complex and complex-to-real transforms are not supported
   </p>
  </li>
  <li>
   <p>
    More than one GPU is not supported
   </p>
  </li>
  <li>
   <p>
    Transforms spanning more than 4 billion elements are not supported
   </p>
  </li>
 </ul>
 <p>
  Please refer to
  <span class="pre">
   cufftXtMakePlanMany
  </span>
  function for plan creation details.
 </p>
 <p>
  The CUDA Toolkit provides the
  <span class="pre">
   cuda_fp16.h
  </span>
  header with types and intrinsic functions for handling half-precision arithmetic.
 </p>
 <h3>
  <span class="section-number">
   2.3.2.
  </span>
  Bfloat16-precision cuFFT Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#bfloat16-precision-cufft-transforms" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  cuFFT supports bfloat16 precision using the
  <span class="pre">
   nv_bfloat16
  </span>
  data type. Please note that cuFFT utilizes a combination of single- and bfloat16-precision arithmetic operations when computing the FFT in bfloat16 precision. Bfloat16-precision transforms have similar limitations to half-precision transforms:
 </p>
 <ul class="simple">
  <li>
   <p>
    Minimum GPU architecture is SM_80
   </p>
  </li>
  <li>
   <p>
    Sizes are restricted to powers of two only
   </p>
  </li>
  <li>
   <p>
    Strides on the real part of real-to-complex and complex-to-real transforms are not supported
   </p>
  </li>
  <li>
   <p>
    More than one GPU is not supported
   </p>
  </li>
  <li>
   <p>
    Transforms spanning more than 4 billion elements are not supported
   </p>
  </li>
 </ul>
 <p>
  Please refer to
  <span class="pre">
   cufftXtMakePlanMany
  </span>
  function for plan creation details.
 </p>
 <p>
  The CUDA Toolkit provides the
  <span class="pre">
   cuda_bf16.h
  </span>
  header with types and intrinsic functions for handling bfloat16-precision arithmetic.
 </p>
 <h2>
  <span class="section-number">
   2.4.
  </span>
  Data Layout
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#data-layout" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  In the cuFFT Library, data layout depends strictly on the configuration and the transform type. In the case of general complex-to-complex transform both the input and output data shall be a
  <span class="pre">
   cufftComplex
  </span>
  /
  <span class="pre">
   cufftDoubleComplex
  </span>
  array in single- and double-precision modes respectively. In C2R mode an input array
  <span class="math notranslate nohighlight">
   \((x_{1},x_{2},\ldots,x_{\lfloor\frac{N}{2}\rfloor + 1})\)
  </span>
  of only non-redundant complex elements is required. The output array
  <span class="math notranslate nohighlight">
   \((X_{1},X_{2},\ldots,X_{N})\)
  </span>
  consists of
  <span class="pre">
   cufftReal
  </span>
  /
  <span class="pre">
   cufftDouble
  </span>
  elements in this mode. Finally, R2C demands an input array
  <span class="math notranslate nohighlight">
   \((X_{1},X_{2},\ldots,X_{N})\)
  </span>
  of real values and returns an array
  <span class="math notranslate nohighlight">
   \((x_{1},x_{2},\ldots,x_{\lfloor\frac{N}{2}\rfloor + 1})\)
  </span>
  of non-redundant complex elements.
 </p>
 <p>
  In real-to-complex and complex-to-real transforms the size of input data and the size of output data differ. For out-of-place transforms a separate array of appropriate size is created. For in-place transforms the user should use
  <span class="pre">
   padded
  </span>
  data layout. This layout is FFTW compatibile.
 </p>
 <p>
  In the
  <span class="pre">
   padded
  </span>
  layout output signals begin at the same memory addresses as the input data. Therefore input data for real-to-complex and output data for complex-to-real must be padded.
 </p>
 <p>
  Expected sizes of input/output data for 1-d transforms are summarized in the table below:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     FFT type
    </p>
   </th>
   <th class="head">
    <p>
     input data size
    </p>
   </th>
   <th class="head">
    <p>
     output data size
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     C2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(x\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(x\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     C2R
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\left\lfloor \frac{x}{2} \right\rfloor + 1\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(x\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     R2C*
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(x\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\left\lfloor \frac{x}{2} \right\rfloor + 1\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
 </table>
 <p>
  The real-to-complex transform is implicitly a forward transform. For an in-place real-to-complex transform where FFTW compatible output is desired, the input size must be padded to
  <span class="math notranslate nohighlight">
   \(\left( {\lfloor\frac{N}{2}\rfloor + 1} \right)\)
  </span>
  complex elements. For out-of-place transforms, input and output sizes match the logical transform size
  <span class="math notranslate nohighlight">
   \(N\)
  </span>
  and the non-redundant size
  <span class="math notranslate nohighlight">
   \(\lfloor\frac{N}{2}\rfloor + 1\)
  </span>
  , respectively.
 </p>
 <p>
  The complex-to-real transform is implicitly inverse. For in-place complex-to-real FFTs where FFTW compatible output is selected (default padding mode), the input size is assumed to be
  <span class="math notranslate nohighlight">
   \(\lfloor\frac{N}{2}\rfloor + 1\)
  </span>
  <span class="pre">
   cufftComplex
  </span>
  elements. Note that in-place complex-to-real FFTs may
  overwrite
  arbitrary imaginary input point values when non-unit input and output strides are chosen. Out-of-place complex-to-real FFT will always
  overwrite
  input buffer. For out-of-place transforms, input and output sizes match the logical transform non-redundant size
  <span class="math notranslate nohighlight">
   \(\lfloor\frac{N}{2}\rfloor + 1\)
  </span>
  and size
  <span class="math notranslate nohighlight">
   \(N\)
  </span>
  , respectively.
 </p>
 <h2>
  <span class="section-number">
   2.5.
  </span>
  Multidimensional Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multidimensional-transforms" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Multidimensional DFT map a
  <span class="math notranslate nohighlight">
   \(d\)
  </span>
  -dimensional array
  <span class="math notranslate nohighlight">
   \(x_{\mathbf{n}}\)
  </span>
  , where
  <span class="math notranslate nohighlight">
   \(\mathbf{n} = (n_{1},n_{2},\ldots,n_{d})\)
  </span>
  into its frequency domain array given by:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(X_{\mathbf{k}} = \sum\limits_{n = 0}^{N - 1}x_{\mathbf{n}}e^{-2\pi i\frac{\mathbf{k}\mathbf{n}}{\mathbf{N}}}\)
     </span>
    </p>
   </td>
  </tr>
 </table>
 <p>
  where
  <span class="math notranslate nohighlight">
   \(\frac{\mathbf{n}}{\mathbf{N}} = (\frac{n_{1}}{N_{1}},\frac{n_{2}}{N_{2}},\ldots,\frac{n_{d}}{N_{d}})\)
  </span>
  , and the summation denotes the set of nested summations
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\sum\limits_{n_{1} = 0}^{N_{1} - 1}\sum\limits_{n_{2} = 0}^{N_{2} - 1}\ldots\sum\limits_{n_{d} = 0}^{N_{d} - 1}\)
     </span>
    </p>
   </td>
  </tr>
 </table>
 <p>
  cuFFT supports one-dimensional, two-dimensional and three-dimensional transforms, which can all be called by the same
  <span class="pre">
   cufftExec*
  </span>
  functions (see
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#fft-types">
   Fourier Transform Types
  </a>
  ).
 </p>
 <p>
  Similar to the one-dimensional case, the frequency domain representation of real-valued input data satisfies Hermitian symmetry, defined as:
  <span class="math notranslate nohighlight">
   \(x_{(n_{1},n_{2},\ldots,n_{d})} = x_{(N_{1} - n_{1},N_{2} - n_{2},\ldots,N_{d} - n_{d})}^{\ast}\)
  </span>
  .
 </p>
 <p>
  C2R and R2C algorithms take advantage of this fact by operating only on half of the elements of signal array, namely on:
  <span class="math notranslate nohighlight">
   \(x_{\mathbf{n}}\)
  </span>
  for
  <span class="math notranslate nohighlight">
   \(\mathbf{n} \in \{ 1,\ldots,N_{1}\} \times \ldots \times \{ 1,\ldots,N_{d - 1}\} \times \{ 1,\ldots,\lfloor\frac{N_{d}}{2}\rfloor + 1\}\)
  </span>
  .
 </p>
 <p>
  The general rules of data alignment described in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#data-layout">
   Data Layout
  </a>
  apply to higher-dimensional transforms. The following table summarizes input and output data sizes for multidimensional DFTs:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Dims
    </p>
   </th>
   <th class="head">
    <p>
     FFT type
    </p>
   </th>
   <th class="head">
    <p>
     Input data size
    </p>
   </th>
   <th class="head">
    <p>
     Output data size
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     1D
    </p>
   </td>
   <td>
    <p>
     C2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     1D
    </p>
   </td>
   <td>
    <p>
     C2R
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\lfloor\frac{\mathbf{N}_{1}}{2}\rfloor + 1\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     1D
    </p>
   </td>
   <td>
    <p>
     R2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\lfloor\frac{\mathbf{N}_{1}}{2}\rfloor + 1\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     2D
    </p>
   </td>
   <td>
    <p>
     C2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     2D
    </p>
   </td>
   <td>
    <p>
     C2R
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}(\lfloor\frac{\mathbf{N}_{2}}{2}\rfloor + 1)\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     2D
    </p>
   </td>
   <td>
    <p>
     R2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}(\lfloor\frac{\mathbf{N}_{2}}{2}\rfloor + 1)\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     3D
    </p>
   </td>
   <td>
    <p>
     C2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\mathbf{N}_{3}\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\mathbf{N}_{3}\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     3D
    </p>
   </td>
   <td>
    <p>
     C2R
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}(\lfloor\frac{\mathbf{N}_{3}}{2}\rfloor + 1)\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\mathbf{N}_{3}\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     3D
    </p>
   </td>
   <td>
    <p>
     R2C
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}\mathbf{N}_{3}\)
     </span>
     <span class="pre">
      cufftReal
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="math notranslate nohighlight">
      \(\mathbf{N}_{1}\mathbf{N}_{2}(\lfloor\frac{\mathbf{N}_{3}}{2}\rfloor + 1)\)
     </span>
     <span class="pre">
      cufftComplex
     </span>
    </p>
   </td>
  </tr>
 </table>
 <p>
  For example, static declaration of a three-dimensional array for the output of an out-of-place real-to-complex transform will look like this:
 </p>
 <pre><span class="n">cufftComplex</span><span class="n">odata</span><span class="p">[</span><span class="n">N1</span><span class="p">][</span><span class="n">N2</span><span class="p">][</span><span class="n">N3</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>
</pre>
 <h2>
  <span class="section-number">
   2.6.
  </span>
  Advanced Data Layout
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The advanced data layout feature allows transforming only a subset of an input array, or outputting to only a portion of a larger data structure. It can be set by calling function:
 </p>
 <pre><span class="n">cufftResult</span><span class="nf">cufftPlanMany</span><span class="p">(</span><span class="n">cufftHandle</span><span class="o">*</span><span class="n">plan</span><span class="p">,</span><span class="kt">int</span><span class="n">rank</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">n</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">inembed</span><span class="p">,</span>
<span class="kt">int</span><span class="n">istride</span><span class="p">,</span><span class="kt">int</span><span class="n">idist</span><span class="p">,</span><span class="kt">int</span><span class="o">*</span><span class="n">onembed</span><span class="p">,</span><span class="kt">int</span><span class="n">ostride</span><span class="p">,</span>
<span class="kt">int</span><span class="n">odist</span><span class="p">,</span><span class="n">cufftType</span><span class="n">type</span><span class="p">,</span><span class="kt">int</span><span class="n">batch</span><span class="p">);</span>
</pre>
 <p>
  Passing
  <span class="pre">
   inembed
  </span>
  or
  <span class="pre">
   onembed
  </span>
  set to
  <span class="pre">
   NULL
  </span>
  is a special case and is equivalent to passing
  <span class="pre">
   n
  </span>
  for each. This is same as the basic data layout and other advanced parameters such as
  <span class="pre">
   istride
  </span>
  are ignored.
 </p>
 <p>
  If the advanced parameters are to be used, then all of the advanced interface parameters must be specified correctly. Advanced parameters are defined in units of the relevant data type (
  <span class="pre">
   cufftReal
  </span>
  ,
  <span class="pre">
   cufftDoubleReal
  </span>
  ,
  <span class="pre">
   cufftComplex
  </span>
  , or
  <span class="pre">
   cufftDoubleComplex
  </span>
  ).
 </p>
 <p>
  Advanced layout can be perceived as an additional layer of abstraction above the access to input/output data arrays. An element of coordinates
  <span class="pre">
   [z][y][x]
  </span>
  in signal number
  <span class="pre">
   b
  </span>
  in the batch will be associated with the following addresses in the memory:
 </p>
 <ul>
  <li>
   <p>
    1D
   </p>
   <p>
    <span class="pre">
     input[
    </span>
    <span class="pre">
     b
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     idist
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     x
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     istride
    </span>
    <span class="pre">
     ]
    </span>
   </p>
   <p>
    <span class="pre">
     output[
    </span>
    <span class="pre">
     b
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     odist
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     x
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     ostride
    </span>
    <span class="pre">
     ]
    </span>
   </p>
  </li>
  <li>
   <p>
    2D
   </p>
   <p>
    <span class="pre">
     input[
    </span>
    <span class="pre">
     b
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     idist`
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     (x
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     inembed[1]
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     y)
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     istride
    </span>
    <span class="pre">
     ]
    </span>
   </p>
   <p>
    <span class="pre">
     output[
    </span>
    <span class="pre">
     b
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     odist
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     (x
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     onembed[1]
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     y)
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     ostride
    </span>
    <span class="pre">
     ]
    </span>
   </p>
  </li>
  <li>
   <p>
    3D
   </p>
   <p>
    <span class="pre">
     input[
    </span>
    <span class="pre">
     b
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     idist
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     ((x
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     inembed[1]
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     y)
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     inembed[2]
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     z)
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     istride
    </span>
    <span class="pre">
     ]
    </span>
   </p>
   <p>
    <span class="pre">
     output[
    </span>
    <span class="pre">
     b
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     odist
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     ((x
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     onembed[1]
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     y)
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     onembed[2]
    </span>
    <span class="pre">
     +
    </span>
    <span class="pre">
     z)
    </span>
    <span class="pre">
     *
    </span>
    <span class="pre">
     ostride
    </span>
    <span class="pre">
     ]
    </span>
   </p>
  </li>
 </ul>
 <p>
  The
  <span class="pre">
   istride
  </span>
  and
  <span class="pre">
   ostride
  </span>
  parameters denote the distance between two successive input and output elements in the least significant (that is, the innermost) dimension respectively. In a single 1D transform, if every input element is to be used in the transform,
  <span class="pre">
   istride
  </span>
  should be set to
  <span class="math notranslate nohighlight">
   \(1\)
  </span>
  ; if every other input element is to be used in the transform, then
  <span class="pre">
   istride
  </span>
  should be set to
  <span class="math notranslate nohighlight">
   \(2\)
  </span>
  . Similarly, in a single 1D transform, if it is desired to output final elements one after another compactly,
  <span class="pre">
   ostride
  </span>
  should be set to
  <span class="math notranslate nohighlight">
   \(1\)
  </span>
  ; if spacing is desired between the least significant dimension output data,
  <span class="pre">
   ostride
  </span>
  should be set to the distance between the elements.
 </p>
 <p>
  The
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  parameters define the number of elements in each dimension in the input array and the output array respectively. The
  <span class="pre">
   inembed[rank-1]
  </span>
  contains the number of elements in the least significant (innermost) dimension of the input data excluding the
  <span class="pre">
   istride
  </span>
  elements; the number of total elements in the least significant dimension of the input array is then
  <span class="pre">
   istride*inembed[rank-1]
  </span>
  . The
  <span class="pre">
   inembed[0]
  </span>
  or
  <span class="pre">
   onembed[0]
  </span>
  corresponds to the most significant (that is, the outermost) dimension and is effectively ignored since the
  <span class="pre">
   idist
  </span>
  or
  <span class="pre">
   odist
  </span>
  parameter provides this information instead. Note that the size of each dimension of the transform should be less than or equal to the
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  values for the corresponding dimension, that is
  <span class="pre">
   n[i]
  </span>
  â¤
  <span class="pre">
   inembed[i]
  </span>
  ,
  <span class="pre">
   n[i]
  </span>
  â¤
  <span class="pre">
   onembed[i]
  </span>
  , where
  <span class="math notranslate nohighlight">
   \(i \in \{ 0,\ldots,rank - 1\}\)
  </span>
  .
 </p>
 <p>
  The
  <span class="pre">
   idist
  </span>
  and
  <span class="pre">
   odist
  </span>
  parameters indicate the distance between the first element of two consecutive batches in the input and output data.
 </p>
 <h2>
  <span class="section-number">
   2.7.
  </span>
  Streamed cuFFT Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#streamed-cufft-transforms" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Every cuFFT plan may be associated with a CUDA stream. Once so associated, all launches of the internal stages of that plan take place through the specified stream. Streaming of cuFFT execution allows for potential overlap between transforms and memory copies. (See the
  NVIDIA CUDA Programming Guide
  for more information on streams.) If no stream is associated with a plan, launches take place in
  <span class="pre">
   stream(0)
  </span>
  , the default CUDA stream. Note that many plan executions require multiple kernel launches.
 </p>
 <p>
  cuFFT uses private streams internally to sort operations, including event syncrhonization. cuFFT does not guarantee ordering of internal operations, and the order is only preserved with respect to the streams set by the user.
 </p>
 <p>
  As of CUDA 11.2 (cuFFT 10.4.0),
  <span class="pre">
   cufftSetStream()
  </span>
  is supported in multiple GPU cases. However, calls to
  <span class="pre">
   cufftXtMemcpy()
  </span>
  are still synchronous across multiple GPUs when using streams. In previous versions of cuFFT,
  <span class="pre">
   cufftSetStream()
  </span>
  returns an error in the multiple GPU case. Likewise, calling certain multi-GPU functions such as
  <span class="pre">
   cufftXtSetCallback()
  </span>
  after setting a stream with
  <span class="pre">
   cufftSetStream()
  </span>
  will result in an error (see API functions for more details).
 </p>
 <p>
  Please note that in order to overlap plans using single plan handle user needs to manage work area buffers. Each concurrent plan execution needs itâs exclusive work area. Work area can be set by
  <span class="pre">
   cufftSetWorkArea
  </span>
  function.
 </p>
 <h2>
  <span class="section-number">
   2.8.
  </span>
  Multiple GPU cuFFT Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-cufft-transforms" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  cuFFT supports using up to sixteen GPUs connected to a CPU to perform Fourier Transforms whose calculations are distributed across the GPUs. An API has been defined to allow users to write new code or modify existing code to use this functionality.
 </p>
 <p>
  Some existing functions such as the creation of a plan using
  <span class="pre">
   cufftCreate()
  </span>
  also apply in the multiple GPU case. Multiple GPU routines contain
  <span class="pre">
   Xt
  </span>
  in their name.
 </p>
 <p>
  The memory on the GPUs is managed by helper functions
  <span class="pre">
   cufftXtMalloc()/cufftXtFree()
  </span>
  and
  <span class="pre">
   cufftXtMemcpy()
  </span>
  using the
  <span class="pre">
   cudaLibXtDesc
  </span>
  descriptor.
 </p>
 <p>
  Performance is a function of the bandwidth between the GPUs, the computational ability of the individual GPUs, and the type and number of FFT to be performed. The highest performance is obtained using NVLink interconnect (
  <a class="reference external" href="https://www.nvidia.com/object/nvlink.html">
   https://www.nvidia.com/object/nvlink.html
  </a>
  ). The second best option is using PCI Express 3.0 between the GPUs and ensuring that both GPUs are on the same switch. Note that multiple GPU execution is not guaranteed to solve a given size problem in a shorter time than single GPU execution.
 </p>
 <p>
  The multiple GPU extensions to cuFFT are built on the extensible cuFFT API. The general steps in defining and executing a transform with this API are:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cufftCreate()
    </span>
    - create an empty plan, as in the single GPU case
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtSetGPUs()
    </span>
    - define which GPUs are to be used
   </p>
  </li>
  <li>
   <p>
    Optional:
    <span class="pre">
     cufftEstimate{1d,2d,3d,Many}()
    </span>
    - estimate the sizes of the work areas required. These are the same functions used in the single GPU case although the definition of the argument
    <span class="pre">
     workSize
    </span>
    reflects the number of GPUs used.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftMakePlan{1d,2d,3d,Many}()
    </span>
    - create the plan. These are the same functions used in the single GPU case although the definition of the argument
    <span class="pre">
     workSize
    </span>
    reflects the number of GPUs used.
   </p>
  </li>
  <li>
   <p>
    Optional:
    <span class="pre">
     cufftGetSize{1d,2d,3d,Many}()
    </span>
    - refined estimate of the sizes of the work areas required. These are the same functions used in the single GPU case although the definition of the argument
    <span class="pre">
     workSize
    </span>
    reflects the number of GPUs used.
   </p>
  </li>
  <li>
   <p>
    Optional:
    <span class="pre">
     cufftGetSize()
    </span>
    - check workspace size. This is the same function used in the single GPU case although the definition of the argument
    <span class="pre">
     workSize
    </span>
    reflects the number of GPUs used.
   </p>
  </li>
  <li>
   <p>
    Optional:
    <span class="pre">
     cufftXtSetWorkArea()
    </span>
    - do your own workspace allocation.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMalloc()
    </span>
    - allocate descriptor and data on the GPUs
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMemcpy()
    </span>
    - copy data to the GPUs
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtExecDescriptorC2C()/cufftXtExecDescriptorZ2Z()
    </span>
    - execute the plan
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMemcpy()
    </span>
    - copy data from the GPUs
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtFree()
    </span>
    - free any memory allocated with
    <span class="pre">
     cufftXtMalloc()
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftDestroy()
    </span>
    - free cuFFT plan resources
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   2.8.1.
  </span>
  Plan Specification and Work Areas
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#plan-specification-and-work-areas" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  In the single GPU case a plan is created by a call to
  <span class="pre">
   cufftCreate()
  </span>
  followed by a call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  . For multiple GPUs, the GPUs to use for execution are identified by a call to
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  and this must occur after the call to
  <span class="pre">
   cufftCreate()
  </span>
  and prior to the call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  .
 </p>
 <p>
  Note that when
  <span class="pre">
   cufftMakePlan*()
  </span>
  is called for a single GPU, the work area is on that GPU. In a multiple GPU plan, the returned work area has multiple entries; one value per GPU. That is
  <span class="pre">
   workSize
  </span>
  points to a
  <span class="pre">
   size_t
  </span>
  array, one entry per GPU. Also the strides and batches apply to the entire plan across all GPUs associated with the plan.
 </p>
 <p>
  Once a plan is locked by a call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  , different descriptors may be specified in calls to
  <span class="pre">
   cufftXtExecDescriptor*()
  </span>
  to execute the plan on different data sets, but the new descriptors must use the same GPUs in the same order.
 </p>
 <p>
  As in the single GPU case,
  <span class="pre">
   cufftEstimateSize{Many,1d,2d,3d}()
  </span>
  and
  <span class="pre">
   cufftGetSize{Many,1d,2d,3d}()
  </span>
  give estimates of the work area sizes required for a multiple GPU plan and in this case
  <span class="pre">
   workSize
  </span>
  points to a
  <span class="pre">
   size_t
  </span>
  array, one entry per GPU.
 </p>
 <p>
  Similarly the actual work size returned by
  <span class="pre">
   cufftGetSize()
  </span>
  is a
  <span class="pre">
   size_t
  </span>
  array, one entry per GPU in the multiple GPU case.
 </p>
 <h3>
  <span class="section-number">
   2.8.2.
  </span>
  Helper Functions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#helper-functions" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Multiple GPU cuFFT execution functions assume a certain data layout in terms of what input data has been copied to which GPUs prior to execution, and what output data resides in which GPUs post execution. cuFFT provides functions to assist users in manipulating data on multiple GPUs. These must be called after the call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  .
 </p>
 <p>
  On a single GPU users may call
  <span class="pre">
   cudaMalloc()
  </span>
  and
  <span class="pre">
   cudaFree()
  </span>
  to allocate and free GPU memory. To provide similar functionality in the multiple GPU case, cuFFT includes
  <span class="pre">
   cufftXtMalloc()
  </span>
  and
  <span class="pre">
   cufftXtFree()
  </span>
  functions. The function
  <span class="pre">
   cufftXtMalloc()
  </span>
  returns a descriptor which specifies the location of these memories.
 </p>
 <p>
  On a single GPU users may call
  <span class="pre">
   cudaMemcpy()
  </span>
  to transfer data between host and GPU memory. To provide similar functionality in the multiple GPU case, cuFFT includes
  <span class="pre">
   cufftXtMemcpy()
  </span>
  which allows users to copy between host and multiple GPU memories or even between the GPU memories.
 </p>
 <p>
  All single GPU cuFFT FFTs return output the data in natural order, that is the ordering of the result is the same as if a DFT had been performed on the data. Some Fast Fourier Transforms produce intermediate results where the data is left in a permutation of the natural output. When batch is one, data is left in the GPU memory in a permutation of the natural output.
 </p>
 <p>
  When
  <span class="pre">
   cufftXtMemcpy()
  </span>
  is used to copy data from GPU memory back to host memory, the results are in natural order regardless of whether the data on the GPUs is in natural order or permuted. Using
  <span class="pre">
   CUFFT_COPY_DEVICE_TO_DEVICE
  </span>
  allows users to copy data from the permuted data format produced after a single transform to the natural order on GPUs.
 </p>
 <h3>
  <span class="section-number">
   2.8.3.
  </span>
  Multiple GPU 2D and 3D Transforms on Permuted Input
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-2d-and-3d-transforms-on-permuted-input" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  For single 2D or 3D transforms on multiple GPUs, when
  <span class="pre">
   cufftXtMemcpy()
  </span>
  distributes the data to the GPUs, the array is divided on the X axis. E.G. for two GPUs half of the X dimenson points, for all Y (and Z) values, are copied to each of the GPUs. When the transform is computed, the data are permuted such that they are divided on the Y axis. I.E. half of the Y dimension points, for all X (and Z) values are on each of the GPUs.
 </p>
 <p>
  When cuFFT creates a 2D or 3D plan for a single transform on multiple GPUs, it actually creates two plans. One plan expects input to be divided on the X axis. The other plan expects data to be divided on the Y axis. This is done because many algorithms compute a forward FFT, then perform some point-wise operation on the result, and then compute the inverse FFT. A memory copy to restore the data to the original order would be expensive. To avoid this,
  <span class="pre">
   cufftXtMemcpy
  </span>
  and
  <span class="pre">
   cufftXtExecDescriptor()
  </span>
  keep track of the data ordering so that the correct operation is used.
 </p>
 <p>
  The ability of cuFFT to process data in either order makes the following sequence possible.
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cufftCreate()
    </span>
    - create an empty plan, as in the single GPU case
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtSetGPUs()
    </span>
    - define which GPUs are to be used
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftMakePlan{1d,2d,3d,Many}()
    </span>
    - create the plan.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMalloc()
    </span>
    - allocate descriptor and data on the GPUs
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMemcpy()
    </span>
    - copy data to the GPUs
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtExecDescriptorC2C()/cufftXtExecDescriptorZ2Z()
    </span>
    - compute the forward FFT
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     userFunction()
    </span>
    - modify the data in the frequency domain
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtExecDescriptorC2C()/cufftXtExecDescriptorZ2Z()
    </span>
    - compute the inverse FFT
   </p>
  </li>
  <li>
   <p>
    Note that it was not necessary to copy/permute the data between execute calls
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtMemcpy()
    </span>
    - copy data to the host
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtFree()
    </span>
    - free any memory allocated with
    <span class="pre">
     cufftXtMalloc()
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftDestroy()
    </span>
    - free cuFFT plan resources
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   2.8.4.
  </span>
  Supported Functionality
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#supported-functionality" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Starting with cuFFT version 7.0, a subset of single GPU functionality is supported for multiple GPU execution.
 </p>
 <p>
  Requirements and limitations:
 </p>
 <ul class="simple">
  <li>
   <p>
    All GPUs must have the same CUDA architecture level and support Unified Virtual Address Space.
   </p>
  </li>
  <li>
   <p>
    On Windows, the GPU boards must be operating in Tesla Compute Cluster (TCC) mode.
   </p>
  </li>
  <li>
   <p>
    For an application that uses the CUDA Driver API, running cuFFT on multiple GPUs is only compatible with applications using the primary context on each GPU.
   </p>
  </li>
  <li>
   <p>
    Strided input and output are not supported.
   </p>
  </li>
  <li>
   <p>
    Running cuFFT on more than 8 GPUs (16 GPUs is max) is supported on machines with NVLink only.
   </p>
  </li>
 </ul>
 <p>
  While transforms with batch count greater than one do not impose additional constraints, those with a single batch have some restrictions. Single-batch FFTs support only in-place mode, and have additional constraints depending on the FFT type. This behavior is summarized in the following table:
 </p>
 <table class="table-no-stripes longtable docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     batch=1
    </p>
   </th>
   <th class="head">
    <p>
     1D
    </p>
   </th>
   <th class="head">
    <p>
     2D
    </p>
   </th>
   <th class="head">
    <p>
     3D
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      C2C
     </span>
     /
     <span class="pre">
      Z2Z
     </span>
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       2,4,8,16 GPUs
      </p>
     </li>
     <li>
      <p>
       power of 2 sizes only
      </p>
     </li>
     <li>
      <p>
       Minimum size for 2-4 GPUs is 64
      </p>
     </li>
     <li>
      <p>
       Minimum size for 8 GPUs is 128
      </p>
     </li>
     <li>
      <p>
       Minimum size for 16 GPUs is 1024
      </p>
     </li>
    </ul>
   </td>
   <td colspan="2">
    <ul class="simple">
     <li>
      <p>
       2-16 GPUs
      </p>
     </li>
     <li>
      <p>
       One of the following conditions is met for each dimension:
      </p>
      <ul>
       <li>
        <p>
         Dimension must factor into primes less than or equal to 127
        </p>
       </li>
       <li>
        <p>
         Maximum dimension size is 4096 for single precision
        </p>
       </li>
       <li>
        <p>
         Maximum dimension size is 2048 for double precision
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       Minimum size is 32
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      R2C
     </span>
     /
     <span class="pre">
      D2Z
     </span>
    </p>
   </td>
   <td>
    <p>
     not supported
    </p>
   </td>
   <td colspan="2">
    <ul class="simple">
     <li>
      <p>
       2-16 GPUs
      </p>
     </li>
     <li>
      <p>
       One of the following conditions is met for each dimension:
      </p>
      <ul>
       <li>
        <p>
         Dimension must factor into primes less than or equal to 127
        </p>
       </li>
       <li>
        <p>
         Maximum dimension size is 4096 for single precision
        </p>
       </li>
       <li>
        <p>
         Maximum dimension size is 2048 for double precision
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       Minimum size is 32
      </p>
     </li>
     <li>
      <p>
       Fastest changing dimension size needs to be even
      </p>
     </li>
     <li>
      <p>
       Supports only
       <span class="pre">
        CUFFT_XT_FORMAT_INPLACE
       </span>
       input descriptor format
      </p>
     </li>
     <li>
      <p>
       No callback support
      </p>
     </li>
    </ul>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      C2R
     </span>
     /
     <span class="pre">
      Z2D
     </span>
    </p>
   </td>
   <td>
    <p>
     not supported
    </p>
   </td>
   <td colspan="2">
    <ul class="simple">
     <li>
      <p>
       2-16 GPUs
      </p>
     </li>
     <li>
      <p>
       One of the following conditions is met for each dimension:
      </p>
      <ul>
       <li>
        <p>
         Dimension must factor into primes less than or equal to 127
        </p>
       </li>
       <li>
        <p>
         Maximum dimension size is 4096 for single precision
        </p>
       </li>
       <li>
        <p>
         Maximum dimension size is 2048 for double precision
        </p>
       </li>
      </ul>
     </li>
     <li>
      <p>
       Minimum size is 32
      </p>
     </li>
     <li>
      <p>
       Fastest changing dimension size needs to be even
      </p>
     </li>
     <li>
      <p>
       Supports only
       <span class="pre">
        CUFFT_XT_FORMAT_INPLACE_SHUFFLED
       </span>
       input descriptor format
      </p>
     </li>
     <li>
      <p>
       No callback support
      </p>
     </li>
    </ul>
   </td>
  </tr>
 </table>
 <p>
  General guidelines are:
 </p>
 <ul class="simple">
  <li>
   <p>
    Parameter
    <span class="pre">
     whichGPUs
    </span>
    of
    <span class="pre">
     cufftXtSetGPUs()
    </span>
    function determines ordering of the GPUs with respect to data decomposition (first data chunk is placed on GPU denoted by first element of
    <span class="pre">
     whichGPUs
    </span>
    )
   </p>
  </li>
  <li>
   <p>
    The data for the entire transform must fit within the memory of the GPUs assigned to it.
   </p>
  </li>
  <li>
   <p>
    For batch size
    <span class="pre">
     m
    </span>
    on
    <span class="pre">
     n
    </span>
    GPUs :
   </p>
   <ul>
    <li>
     <p>
      The first
      <span class="pre">
       m
      </span>
      <span class="pre">
       %
      </span>
      <span class="pre">
       n
      </span>
      GPUs execute
      <span class="math notranslate nohighlight">
       \(\left\lfloor \frac{m}{n} \right\rfloor+\ 1\)
      </span>
      transforms.
     </p>
    </li>
    <li>
     <p>
      The remaining GPUs execute
      <span class="math notranslate nohighlight">
       \(\left\lfloor \frac{m}{n} \right\rfloor\)
      </span>
      transforms.
     </p>
    </li>
   </ul>
  </li>
 </ul>
 <p>
  Batch size output differences:
 </p>
 <p>
  Single GPU cuFFT results are always returned in natural order. When multiple GPUs are used to perform more than one transform, the results are also returned in natural order. When multiple GPUs are used to perform a single transform the results are returned in a permutation of the normal results to reduce communication time. This behavior is summarized in the following table:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Number of GPUs
    </p>
   </th>
   <th class="head">
    <p>
     Number of transforms
    </p>
   </th>
   <th class="head">
    <p>
     Output Order on GPUs
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     One
    </p>
   </td>
   <td>
    <p>
     One or multiple transforms
    </p>
   </td>
   <td>
    <p>
     Natural order
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Multiple
    </p>
   </td>
   <td>
    <p>
     One
    </p>
   </td>
   <td>
    <p>
     Permuted results
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Multiple
    </p>
   </td>
   <td>
    <p>
     Multiple
    </p>
   </td>
   <td>
    <p>
     Natural order
    </p>
   </td>
  </tr>
 </table>
 <p>
  To produce natural order results in GPU memory for multi-GPU runs in the 1D single transform case, requires calling
  <span class="pre">
   cufftXtMemcpy()
  </span>
  with
  <span class="pre">
   CUFFT_COPY_DEVICE_TO_DEVICE
  </span>
  .
 </p>
 <p>
  2D and 3D multi-GPU transforms support execution of a transform given permuted order results as input. After execution in this case, the output will be in natural order. It is also possible to use
  <span class="pre">
   cufftXtMemcpy()
  </span>
  with
  <span class="pre">
   CUFFT_COPY_DEVICE_TO_DEVICE
  </span>
  to return 2D or 3D data to natural order.
 </p>
 <p>
  See the cuFFT Code Examples section for single GPU and multiple GPU examples.
 </p>
 <h2>
  <span class="section-number">
   2.9.
  </span>
  cuFFT Callback Routines
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-callback-routines" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Callback routines are user-supplied kernel routines that cuFFT will call when loading or storing data. They allow the user to do data pre- or post- processing without additional kernel calls.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Starting from CUDA 11.4, support for callback functionality using separately compiled device code is deprecated on all GPU architectures. Callback functionality will continue to be supported for all GPU architectures.
 </p>
 <h3>
  <span class="section-number">
   2.9.1.
  </span>
  Overview of the cuFFT Callback Routine Feature
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#overview-of-the-cufft-callback-routine-feature" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  cuFFT provides a set of APIs that allow the cuFFT user to provide CUDA functions that re-direct or manipulate the data as it is loaded prior to processing the FFT, or stored once the FFT has been done. For the load callback, cuFFT passes the callback routine the address of the input data and the offset to the value to be loaded from device memory, and the callback routine returns the value it wishes cuFFT to use instead. For the store callback, cuFFT passes the callback routine the value it has computed, along with the address of the output data and the offset to the value to be written to device memory, and the callback routine modifies the value and stores the modified result.
 </p>
 <p>
  In order to provide a callback to cuFFT, a plan is created and configured normally using the extensible plan APIs. After the call to
  <span class="pre">
   cufftCreate
  </span>
  and
  <span class="pre">
   cufftMakePlan
  </span>
  , the user may associate a load callback routine, or a store callback routine, or both, with the plan, by calling
  <span class="pre">
   cufftXtSetCallback
  </span>
  . The caller also has the option to specify a device pointer to an opaque structure they wish to associate with the plan. This pointer will be passed to the callback routine by the cuFFT library. The caller may use this structure to remember plan dimensions and strides, or have a pointer to auxiliary data, etc.
 </p>
 <p>
  With some restrictions, the callback routine is allowed to request shared memory for its own use. If the requested amount of shared memory is available, cufft will pass a pointer to it when it calls the callback routine.
 </p>
 <p>
  CUFFT allows for 8 types of callback routine, one for each possible combination of: load or store, real or complex, single precision or double.
  It is the callerâs responsibility to provide a routine that matches the function prototype for the type of routine specified.
  If there is already a callback of the specified type associated with the plan, the set callback function will replace it with the new one.
 </p>
 <p>
  The callback routine extensions to cuFFT are built on the extensible cuFFT API. The general steps in defining and executing a transform with callbacks are:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cufftCreate()
    </span>
    - create an empty plan, as in the single GPU case
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftMakePlan{1d,2d,3d,Many}()
    </span>
    - create the plan. These are the same functions used in the single GPU case.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtSetCallback()
    </span>
    - called for load and/or store callback for this plan
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftExecC2C()
    </span>
    <span class="pre">
     etc.
    </span>
    - execute the plan
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftDestroy()
    </span>
    - free cuFFT plan resources
   </p>
  </li>
 </ul>
 <p>
  Callback functions are not supported on transforms with a dimension size that does not factor into primes smaller than 127. Callback functions on plans whose dimensionsâ prime factors are limited to 2, 3, 5, and 7 can safely call
  <span class="pre">
   __syncthreads()
  </span>
  . On other plans, results are not defined.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  The callback API is available in the statically linked cuFFT library only, and only on 64 bit LINUX operating systems.
 </p>
 <h3>
  <span class="section-number">
   2.9.2.
  </span>
  Specifying Load and Store Callback Routines
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#specifying-load-and-store-callback-routines" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  In order to associate a callback routine with a plan, it is necessary to obtain a device pointer to the callback routine.
 </p>
 <p>
  As an example, if the user wants to specify a load callback for an R2C transform, they would write the device code for the callback function, and define a global device variable that contains a pointer to the function:
 </p>
 <pre><span class="n">__device__</span><span class="n">cufftReal</span><span class="n">myOwnCallback</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPtr</span><span class="p">)</span><span class="p">{</span>
<span class="n">cufftReal</span><span class="n">ret</span><span class="p">;</span>
<span class="c1">// use offset, dataIn, and optionally callerInfo to</span>
<span class="c1">// compute the return value</span>
<span class="k">return</span><span class="n">ret</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">__device__</span><span class="n">cufftCallbackLoadR</span><span class="n">myOwnCallbackPtr</span><span class="o">=</span><span class="n">myOwnCallback</span><span class="p">;</span>
</pre>
 <p>
  From the host side, the user then has to get the address of the callback routine, which is stored in
  <span class="pre">
   myOwnCallbackPtr
  </span>
  . This is done with
  <span class="pre">
   cudaMemcpyFromSymbol
  </span>
  , as follows:
 </p>
 <pre><span class="n">cufftCallbackLoadR</span><span class="n">hostCopyOfCallbackPtr</span><span class="p">;</span>

<span class="n">cudaMemcpyFromSymbol</span><span class="p">(</span><span class="o">&amp;</span><span class="n">hostCopyOfCallbackPtr</span><span class="p">,</span>
<span class="n">myOwnCallbackPtr</span><span class="p">,</span>
<span class="k">sizeof</span><span class="p">(</span><span class="n">hostCopyOfCallbackPtr</span><span class="p">));</span>
</pre>
 <p>
  <span class="pre">
   hostCopyOfCallbackPtr
  </span>
  then contains the device address of the callback routine, that should be passed to
  <span class="pre">
   cufftXtSetCallback
  </span>
  . Note that, for multi-GPU transforms,
  <span class="pre">
   hostCopyOfCallbackPtr
  </span>
  will need to be an array of pointers, and the
  <span class="pre">
   cudaMemcpyFromSymbol
  </span>
  will have to be invoked for each GPU. Please note that
  <span class="pre">
   __managed__
  </span>
  variables are not suitable to pass to
  <span class="pre">
   cufftSetCallback
  </span>
  due to restrictions on variable usage (See the
  NVIDIA CUDA Programming Guide
  for more information about
  <span class="pre">
   __managed__
  </span>
  variables).
 </p>
 <h3>
  <span class="section-number">
   2.9.3.
  </span>
  Callback Routine Function Details
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#callback-routine-function-details" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Below are the function prototypes, and typedefs for pointers to the user supplied callback routines that cuFFT calls to load data prior to the transform.
 </p>
 <pre><span class="k">typedef</span><span class="n">cufftComplex</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadC</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="n">cufftDoubleComplex</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadZ</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="n">cufftReal</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadR</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="n">cufftDoubleReal</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadD</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>
</pre>
 <p>
  Parameters for all of the load callbacks are defined as below:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     offset
    </span>
    : offset of the input element from the start of output data. This is not a byte offset, rather it is the number of elements from start of data.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     dataIn
    </span>
    : device pointer to the start of the input array that was passed in the
    <span class="pre">
     cufftExecute
    </span>
    call.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     callerInfo
    </span>
    : device pointer to the optional caller specified data passed in the
    <span class="pre">
     cufftXtSetCallback
    </span>
    call.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     sharedPointer
    </span>
    : pointer to shared memory, valid only if the user has called
    <span class="pre">
     cufftXtSetCallbackSharedSize()
    </span>
    .
   </p>
  </li>
 </ul>
 <p>
  Below are the function prototypes, and typedefs for pointers to the user supplied callback routines that cuFFT calls to store data after completion of the transform. Note that the store callback functions do not return a value. This is because a store callback function is responsible not only for transforming the data as desired, but also for writing the data to the desired location. This allows the store callback to rearrange the data, for example to shift the zero frequency result to the center of the ouput.
 </p>
 <pre><span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreC</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="n">cufftComplex</span><span class="n">element</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreZ</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="n">cufftDoubleComplex</span><span class="n">element</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreR</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="n">cufftReal</span><span class="n">element</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreD</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span>
<span class="n">cufftDoubleReal</span><span class="n">element</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span>
<span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>
</pre>
 <p>
  Parameters for all of the store callbacks are defined as below:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     offset
    </span>
    : offset of the output element from the start of output data. This is not a byte offset, rather it is the number of elements from start of data.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     dataOut
    </span>
    : device pointer to the start of the output array that was passed in the
    <span class="pre">
     cufftExecute
    </span>
    call.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     element
    </span>
    : the real or complex result computed by CUFFT for the element specified by the offset argument.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     callerInfo
    </span>
    : device pointer to the optional caller specified data passed in the
    <span class="pre">
     cufftXtSetCallback
    </span>
    call.
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     sharedPointer
    </span>
    : pointer to shared memory, valid only if the user has called
    <span class="pre">
     cufftXtSetCallbackSharedSize()
    </span>
    .
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   2.9.4.
  </span>
  Coding Considerations for the cuFFT Callback Routine Feature
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#coding-considerations-for-the-cufft-callback-routine-feature" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  cuFFT supports callbacks on all types of transforms, dimension, batch, stride between elements or number of GPUs. Callbacks are supported for transforms of single and double precision.
 </p>
 <p>
  cuFFT supports a wide range of parameters, and based on those for a given plan, it attempts to optimize performance. The number of kernels launched, and for each of those, the number of blocks launched and the number of threads per block, will vary depending on how cuFFT decomposes the transform. For some configurations, cuFFT will load or store (and process) multiple inputs or outputs per thread. For some configurations, threads may load or store inputs or outputs in any order, and cuFFT does not guarantee that the inputs or outputs handled by a given thread will be contiguous. These characteristics may vary with transform size, transform type (e.g. C2C vs C2R), number of dimensions, and GPU architecture. These variations may also change from one library version to the next.
 </p>
 <p>
  cuFFT will call the load callback routine, for each point in the input, once and only once. Similarly it will call the store callback routine, for each point in the output, once and only once. If the transform is being done in-place (i.e. the input and output data are in the same memory location) the store callback for a given element cannot overwrite other elements. It can either overwrite the given element, or write in a completely distinct output buffer.
 </p>
 <p>
  When more than one kernel are used to implement a transform, the thread and block structure of the first kernel (the one that does the load) is often different from the thread and block structure of the last kernel (the one that does the store).
 </p>
 <p>
  One common use of callbacks is to reduce the amount of data read or written to memory, either by selective filtering or via type conversions. When more than one kernel are used to implement a transform, cuFFT alternates using the workspace and the output buffer to write intermediate results. This means that the output buffer must always be large enough to accommodate the entire transform.
 </p>
 <p>
  For multi-GPU transforms, the index passed to the callback routine is the element index from the start of data
  on that GPU
  , not from the start of the entire input or output data array.
 </p>
 <p>
  For transforms whose dimensions can be factored into powers of 2, 3, 5, or 7, cuFFT guarantees that it will call the load and store callback routines from points in the kernel that is safe to call
  <span class="pre">
   __syncthreads
  </span>
  function from within callback routine. Caller is responsible for guaranteeing that the callback routine is at a point where the callback code has converged, to avoid deadlock. For plans whose dimensions are factored into higher primes, results of a callback routine calling
  <span class="pre">
   __syncthreads
  </span>
  are not defined.
 </p>
 <h4>
  <span class="section-number">
   2.9.4.1.
  </span>
  No Ordering Guarantees Within a Kernel
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#no-ordering-guarantees-within-a-kernel" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  Note that there are no guarantees on the relative order of execution of blocks within a grid. As such, callbacks should not rely on any particular ordering within a kernel. For instance, reordering data (such as an FFT-shift) could rely on the order of execution of the blocks. Results in this case would be undefined.
 </p>
 <h2>
  <span class="section-number">
   2.10.
  </span>
  Thread Safety
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#thread-safety" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  cuFFT APIs are thread safe as long as different host threads execute FFTs using different plans and the output data are disjoint.
 </p>
 <h2>
  <span class="section-number">
   2.11.
  </span>
  CUDA Graphs Support
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cuda-graphs-support" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Using
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-graphs">
   CUDA Graphs
  </a>
  with cuFFT is supported on single GPU plans. It is also supported on multiple GPU plans starting with cuFFT version 10.4.0. The stream associated with a cuFFT plan must meet the requirements stated in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#creating-a-graph-using-stream-capture">
   Creating a Graph Using Stream Capture
  </a>
  .
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  Starting from CUDA 11.8 (including CUDA 12.0 onward), CUDA Graphs are no longer supported for callback routines that load data in out-of-place mode transforms. An upcoming release will update the cuFFT callback implementation, removing this limitation. cuFFT deprecated callback functionality based on separate compiled device code in cuFFT 11.4.
 </p>
 <h2>
  <span class="section-number">
   2.12.
  </span>
  Static Library and Callback Support
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#static-library-and-callback-support" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Starting with release 6.5, the cuFFT libraries are also delivered in a static form as libcufft_static.a and libcufftw_static.a on Linux and Mac. Static libraries are not supported on Windows. The static cufft and cufftw libraries depend on thread abstraction layer library
  <span class="pre">
   libculibos.a
  </span>
  .
 </p>
 <p>
  For example, on linux, to compile a small application using cuFFT against the dynamic library, the following command can be used:
 </p>
 <pre>nvcc mCufftApp.c  -lcufft  -o myCufftApp
</pre>
 <p>
  For cufftw on Linux, to compile a small application against the dynamic library, the following command can be used:
 </p>
 <pre>nvcc mCufftwApp.c  -lcufftw  -lcufft  -o myCufftwApp
</pre>
 <p>
  Whereas to compile against the static cuFFT library, extra steps need to be taken. The library needs to be device linked. It may happen during building and linking of a simple program, or as a separate step. The entire process is described in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#using-separate-compilation-in-cuda">
   Using Separarate Compilation in CUDA
  </a>
  .
 </p>
 <p>
  For cuFFT and cufftw in version 9.0 or later any supported architecture can be used to do the device linking:
 </p>
 <p>
  Static cuFFT compilation command:
 </p>
 <pre>nvcc mCufftApp.c  -lcufft_static   -lculibos -o myCufftApp
</pre>
 <p>
  Static cufftw compilation command:
 </p>
 <pre>nvcc mCufftwApp.c   -lcufftw_static  -lcufft_static   -lculibos  -o myCufftwApp
</pre>
 <p>
  Prior to version 9.0 proper linking required specifying a subset of supported architectures, as shown in the following commands:
 </p>
 <p>
  Static cuFFT compilation command:
 </p>
 <pre>nvcc mCufftApp.c  -lcufft_static   -lculibos -o myCufftApp\
    -gencode arch=compute_20,\"code=sm_20\"\
    -gencode arch=compute_30,\"code=sm_30\"\
    -gencode arch=compute_35,\"code=sm_35\"\
    -gencode arch=compute_50,\"code=sm_50\"\
    -gencode arch=compute_60,\"code=sm_60\"\
    -gencode arch=compute_60,\"code=compute_60\"
</pre>
 <p>
  Static cufftw compilation command:
 </p>
 <pre>nvcc mCufftwApp.c    -lcufftw_static  -lcufft_static   -lculibos  -o myCufftwApp\
    -gencode arch=compute_20,\"code=sm_20\"\
    -gencode arch=compute_30,\"code=sm_30\"\
    -gencode arch=compute_35,\"code=sm_35\"\
    -gencode arch=compute_50,\"code=sm_50\"\
    -gencode arch=compute_60,\"code=sm_60\"\
    -gencode arch=compute_60,\"code=compute_60\"
</pre>
 <p>
  Please note that the cuFFT library might not contain code for certain architectures as long as there is code for a lower architecture that is binary compatibile (e.g. SM37, SM52, SM61). This is reflected in link commands above and significant when using versions prior r9.0. To determine if a specific SM is included in the cuFFT library, one may use
  <span class="pre">
   cuobjdump
  </span>
  utility. For example, if you wish to know if SM_50 is included, the command to run is
  <span class="pre">
   cuobjdump
  </span>
  <span class="pre">
   -arch
  </span>
  <span class="pre">
   sm_50
  </span>
  <span class="pre">
   libcufft_static.a
  </span>
  . Some kernels are built only on select architectures (e.g. kernels with half precision arithmetics are present only for SM53 and above). This can cause warnings at link time that architectures are missing from these kernels. These warnings can be safely ignored.
 </p>
 <p>
  It is also possible to use the native Host C++ compiler and perform device link as a separate step. Please consult NVCC documentation for more details. Depending on the Host Operating system, some additional libraries like
  <span class="pre">
   pthread
  </span>
  or
  <span class="pre">
   dl
  </span>
  might be needed on the linking line.
 </p>
 <p>
  Note that in this case, the library
  <span class="pre">
   cuda
  </span>
  is not needed. The CUDA Runtime will try to open explicitly the
  <span class="pre">
   cuda
  </span>
  library if needed. In the case of a system which does not have the CUDA driver installed, this allows the application to gracefully manage this issue and potentially run if a CPU-only path is available.
 </p>
 <p>
  The cuFFT static library supports user supplied callback routines. The callback routines are CUDA device code, and must be separately compiled with NVCC and linked with the cuFFT library. Please refer to the NVCC documentation regarding separate compilation for details. If you specify an SM when compiling your callback functions, you must specify one of the SMâs cuFFT includes.
 </p>
 <h3>
  <span class="section-number">
   2.12.1.
  </span>
  Static library without callback support
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#static-library-without-callback-support" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Starting with cuFFT version 9.2, a new variant of the cuFTT static library,
  <span class="pre">
   libcufft_static_nocallback.a
  </span>
  , was added. This new version does not contain callback functionality and can be linked using the host compiler only.
 </p>
 <h2>
  <span class="section-number">
   2.13.
  </span>
  Accuracy and Performance
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#accuracy-and-performance" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  A DFT can be implemented as a matrix vector multiplication that requires
  <span class="math notranslate nohighlight">
   \(O(N^{2})\)
  </span>
  operations. However, the cuFFT Library employs the
  <a class="reference external" href="http://en.wikipedia.org/wiki/Cooley-Tukey_FFT_algorithm">
   Cooley-Tukey algorithm
  </a>
  to reduce the number of required operations to optimize the performance of particular transform sizes. This algorithm expresses the DFT matrix as a product of sparse building block matrices. The cuFFT Library implements the following building blocks: radix-2, radix-3, radix-5, and radix-7. Hence the performance of any transform size that can be factored as
  <span class="math notranslate nohighlight">
   \(2^{a} \times 3^{b} \times 5^{c} \times 7^{d}\)
  </span>
  (where
  a
  ,
  b
  ,
  c
  , and
  d
  are non-negative integers) is optimized in the cuFFT library. There are also radix-m building blocks for other primes, m, whose value is &lt; 128. When the length cannot be decomposed as multiples of powers of primes from 2 to 127,
  <a class="reference external" href="http://en.wikipedia.org/wiki/Bluestein's_FFT_algorithm">
   Bluesteinâs algorithm
  </a>
  is used. Since the Bluestein implementation requires more computations per output point than the Cooley-Tukey implementation, the accuracy of the Cooley-Tukey algorithm is better. The pure Cooley-Tukey implementation has excellent accuracy, with the relative error growing proportionally to
  <span class="math notranslate nohighlight">
   \(\log_{2}(N)\)
  </span>
  , where
  <span class="math notranslate nohighlight">
   \(N\)
  </span>
  is the transform size in points.
 </p>
 <p>
  For sizes handled by the Cooley-Tukey code path, the most efficient implementation is obtained by applying the following constraints (listed in order from the most generic to the most specialized constraint, with each subsequent constraint providing the potential of an additional performance improvement).
 </p>
 <p>
  Half precision transforms might not be suitable for all kinds of problems due to limited range represented by half precision floating point arithmetics. Please note that the first element of FFT result is the sum of all input elements and it is likely to overflow for certain inputs.
 </p>
 <p>
  Results produced by the cuFFT library are deterministic (ie, bitwise reproducible) as long as the following are kept constant between runs: plan input parameters, cuFFT version, and GPU model.
 </p>
 <p>
  cuFFT batched plans require that input data includes valid signal for all batches. Performance optimizations in batched mode can combine signal from different batches for processing. Optimizations used in cuFFT can vary from version to version.
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Applies to
    </p>
   </th>
   <th class="head">
    <p>
     Recommendation
    </p>
   </th>
   <th class="head">
    <p>
     Comment
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     All
    </p>
   </td>
   <td>
    <p>
     Use single precision transforms.
    </p>
   </td>
   <td>
    <p>
     Single precision transforms require less bandwidth per computation than double precision transforms.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     All
    </p>
   </td>
   <td>
    <p>
     Restrict the size along all dimensions to be representable as
     <span class="math notranslate nohighlight">
      \(2^{a} \times 3^{b} \times 5^{c} \times 7^{d}\)
     </span>
     .
    </p>
   </td>
   <td>
    <p>
     The cuFFT library has highly optimized kernels for transforms whose dimensions have these prime factors. In general the best performance occurs when using powers of 2, followed by powers of 3, then 5, 7.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     All
    </p>
   </td>
   <td>
    <p>
     Restrict the size along each dimension to use fewer distinct prime factors.
    </p>
   </td>
   <td>
    <p>
     A transform of size
     <span class="math notranslate nohighlight">
      \(2^{n}\)
     </span>
     or
     <span class="math notranslate nohighlight">
      \(3^{n}\)
     </span>
     will usually be faster than one of size
     <span class="math notranslate nohighlight">
      \(2^{i} \times 3^{j}\)
     </span>
     even if the latter is slightly smaller, due to the composition of specialized paths.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     All
    </p>
   </td>
   <td>
    <p>
     Restrict the data to be contiguous in memory when performing a single transform. When performing multiple transforms make the individual datasets contiguous
    </p>
   </td>
   <td>
    <p>
     The cuFFT library has been optimized for this data layout.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     All
    </p>
   </td>
   <td>
    <p>
     Perform multiple (i.e., batched) transforms.
    </p>
   </td>
   <td>
    <p>
     Additional optimizations are performed in batched mode.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     real-to-complex transforms or complex-to-real transforms
    </p>
   </td>
   <td>
    <p>
     Ensure problem size of x dimension is a multiple of 4.
    </p>
   </td>
   <td>
    <p>
     This scheme uses more efficient kernels to implement conjugate symmetry property.
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     real-to-complex transforms or complex-to-real transforms
    </p>
   </td>
   <td>
    <p>
     Use
     <span class="pre">
      out-of-place
     </span>
     mode.
    </p>
   </td>
   <td>
    <p>
     This scheme uses more efficient kernels than
     <span class="pre">
      in-place
     </span>
     mode.
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Multiple GPU transforms
    </p>
   </td>
   <td>
    <p>
     Use PCI Express 3.0 between GPUs and ensure the GPUs are on the same switch.
    </p>
   </td>
   <td>
    <p>
     The faster the interconnect between the GPUs, the faster the performance.
    </p>
   </td>
  </tr>
 </table>
 <h2>
  <span class="section-number">
   2.14.
  </span>
  Caller Allocated Work Area Support
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#caller-allocated-work-area-support" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  cuFFT plans may use additional memory to store intermediate results. The cuFFT library offers several functions to manage this temporary memory utilization behavior:
 </p>
 <ul class="simple">
  <li>
   <p>
    <span class="pre">
     cufftSetAutoAllocation
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftEstimate1d
    </span>
    ,
    <span class="pre">
     cufftEstimate2d
    </span>
    ,
    <span class="pre">
     cufftEstimate3d
    </span>
    and
    <span class="pre">
     cufftEstimateMany
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftGetSize
    </span>
   </p>
  </li>
  <li>
   <p>
    <span class="pre">
     cufftXtSetWorkAreaPolicy
    </span>
   </p>
  </li>
 </ul>
 <p>
  The first two functions manage allocation and ownership of temporary memory. By default cuFFT always allocates its own work area in GPU memory. Each cuFFT handle allocates data separately. If multiple cuFFT plans are to be launched sequentially it is possible to assign the same memory chunk as work area to all those plans and reduce memory overhead.
 </p>
 <p>
  The memory assigned as work area needs to be GPU visible. In addition to the regular memory acquired with
  <span class="pre">
   cudaMalloc
  </span>
  , usage of CUDA Unified Virtual Addressing enables cuFFT to use the following types of memory as work area memory: pinned host memory, managed memory, memory on GPU other than the one performing the calculations. While this provides flexibility, it comes with a performance penalty whose magnitude depends on the available memory bandwidth.
 </p>
 <p>
  The
  <span class="pre">
   cufftEstimateNd
  </span>
  ,
  <span class="pre">
   cufftEstimateMany
  </span>
  , and
  <span class="pre">
   cufftGetSize
  </span>
  functions provide information about the required memory size for cases where the user is allocating the work space buffer.
 </p>
 In version 9.2 cuFFT also introduced the
 <span class="pre">
  cufftXtSetWorkAreaPolicy
 </span>
 function. This function allows fine tuning of work area memory usage.
 cuFFT 9.2 version supports only the
 <span class="pre">
  CUFFT_WORKAREA_MINIMAL
 </span>
 policy, which instructs cuFFT to re-plan the existing plan without the need to use work area memory.
 <p>
  Also as of cuFFT 9.2, supported FFT transforms that allow for
  <span class="pre">
   CUFFT_WORKAREA_MINIMAL
  </span>
  policy are as follows:
 </p>
 <ul class="simple">
  <li>
   <p>
    Transforms of type
    <span class="pre">
     C2C
    </span>
    are supported with sizes up to 4096 in any dimension.
   </p>
  </li>
  <li>
   <p>
    Transforms of type
    <span class="pre">
     Z2Z
    </span>
    are supported with sizes up to 2048 in any dimension.
   </p>
  </li>
  <li>
   <p>
    Only single GPU transforms are supported.
   </p>
  </li>
 </ul>
 <p>
  Depending on the FFT transform size, a different FFT algorithm may be used when the
  <span class="pre">
   CUFFT_WORKAREA_MINIMAL
  </span>
  policy is set.
 </p>
 <h2>
  <span class="section-number">
   2.15.
  </span>
  cuFFT Link-Time Optimized Kernels
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-link-time-optimized-kernels" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Starting from CUDA 12.4, cuFFT ships Link-Time Optimized (LTO) kernels. These kernels are linked and finalized at runtime as part of the cuFFT planning routines. This enables the cuFFT library to generate kernels optimized for the underlying architecture and the specific problem to solve.
 </p>
 <p>
  The current LTO kernel coverage includes:
 </p>
 <ul class="simple">
  <li>
   <p>
    Kernels for 64-bit addressing (with FFTs spanning addresses greater than 2^(32)-1 elements).
   </p>
  </li>
  <li>
   <p>
    Some single- and double-precision R2C and C2R sizes.
   </p>
  </li>
 </ul>
 <p>
  The number and coverage of LTO kernels will grow with future releases of cuFFT. We encourage our users to test whether LTO kernels improve the performance for their use case.
 </p>
 <p>
  Users can opt-in into LTO kernels by setting the
  <span class="pre">
   NVFFT_PLAN_PROPERTY_INT64_PATIENT_JIT
  </span>
  plan property using the
  <span class="pre">
   cufftSetPlanProperty
  </span>
  routine.
 </p>
 <p>
  In order to finalize LTO kernels, cuFFT relies on the nvJitLink library that ships as part of the CUDA Toolkit. Finalizing the kernels at runtime can cause an
  increase in planning time
  (which could be in the order of hundreds of milliseconds, depending on the cuFFT plan and hardware characteristics of the host system), in exchange for faster execution time of the optimized kernels. Note that nvJitLink caches kernels linked at runtime to speed-up subsequent kernel finalizations in repeated planning routines.
 </p>
 <p>
  If for any reason the runtime linking of the kernel fails, cuFFT will fall back to offline-compiled kernels to compute the FFT.
 </p>
 <p class="admonition-title">
  Note
 </p>
 <p>
  cuFFT LTO kernels for a given toolkit version require using the nvJitLink library from the same toolkit or greater, but within the same toolkit major. For example, cuFFT in 12.4 requires nvJitLink to be from a CUDA Toolkit 12.X, with
  <span class="pre">
   X
  </span>
  <span class="pre">
   &gt;=
  </span>
  <span class="pre">
   4
  </span>
  .
 </p>
 <p>
  The nvJitLink library is loaded dynamically, and should be present in the systemâs dynamic linking path (e.g.
  <span class="pre">
   LD_LIBRARY_PATH
  </span>
  on Unix systems, or
  <span class="pre">
   PATH
  </span>
  on Windows systems).
 </p>
 <h3>
  <span class="section-number">
   2.15.1.
  </span>
  Overview of the cuFFT Callback Routine Feature
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#id1" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  cuFFT provides a set of APIs that allow the cuFFT user to provide CUDA functions that re-direct or manipulate the data as it is loaded prior to processing the FFT, or stored once the FFT has been done. For the load callback, cuFFT passes the callback routine the address of the input data and the offset to the value to be loaded from device memory, and the callback routine returns the value it wishes cuFFT to use instead. For the store callback, cuFFT passes the callback routine the value it has computed, along with the address of the output data and the offset to the value to be written to device memory, and the callback routine modifies the value and stores the modified result.
 </p>
 <h1>
  <span class="section-number">
   3.
  </span>
  cuFFT API Reference
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-api-reference" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  This chapter specifies the behavior of the cuFFT library functions by describing their input/output parameters, data types, and error codes. The cuFFT library is initialized upon the first invocation of an API function, and cuFFT shuts down automatically when all user-created FFT plans are destroyed.
 </p>
 <h2>
  <span class="section-number">
   3.1.
  </span>
  Return value cufftResult
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#return-value-cufftresult" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  All cuFFT Library return values except for
  <span class="pre">
   CUFFT_SUCCESS
  </span>
  indicate that the current API call failed and the user should reconfigure to correct the problem. The possible return values are defined as follows:
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">cufftResult_t</span><span class="p">{</span>
<span class="n">CUFFT_SUCCESS</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="c1">//  The cuFFT operation was successful</span>
<span class="n">CUFFT_INVALID_PLAN</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="c1">//  cuFFT was passed an invalid plan handle</span>
<span class="n">CUFFT_ALLOC_FAILED</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="c1">//  cuFFT failed to allocate GPU or CPU memory</span>
<span class="n">CUFFT_INVALID_TYPE</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="c1">//  No longer used</span>
<span class="n">CUFFT_INVALID_VALUE</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="c1">//  User specified an invalid pointer or parameter</span>
<span class="n">CUFFT_INTERNAL_ERROR</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="c1">//  Driver or internal cuFFT library error</span>
<span class="n">CUFFT_EXEC_FAILED</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="c1">//  Failed to execute an FFT on the GPU</span>
<span class="n">CUFFT_SETUP_FAILED</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="c1">//  The cuFFT library failed to initialize</span>
<span class="n">CUFFT_INVALID_SIZE</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="c1">//  User specified an invalid transform size</span>
<span class="n">CUFFT_UNALIGNED_DATA</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span><span class="c1">//  No longer used</span>
<span class="n">CUFFT_INCOMPLETE_PARAMETER_LIST</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="c1">//  Missing parameters in call</span>
<span class="n">CUFFT_INVALID_DEVICE</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span><span class="c1">//  Execution of a plan was on different GPU than plan creation</span>
<span class="n">CUFFT_PARSE_ERROR</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span><span class="c1">//  Internal plan database error</span>
<span class="n">CUFFT_NO_WORKSPACE</span><span class="o">=</span><span class="mi">13</span><span class="c1">//  No workspace has been provided prior to plan execution</span>
<span class="n">CUFFT_NOT_IMPLEMENTED</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="c1">// Function does not implement functionality for parameters given.</span>
<span class="n">CUFFT_LICENSE_ERROR</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span><span class="c1">// Used in previous versions.</span>
<span class="n">CUFFT_NOT_SUPPORTED</span><span class="o">=</span><span class="mi">16</span><span class="c1">// Operation is not supported for parameters given.</span>
<span class="p">}</span><span class="n">cufftResult</span><span class="p">;</span>
</pre>
 <p>
  Users are encouraged to check return values from cuFFT functions for errors as shown in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-code-examples">
   cuFFT Code Examples
  </a>
  .
 </p>
 <h2>
  <span class="section-number">
   3.2.
  </span>
  cuFFT Basic Plans
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-basic-plans" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.2.1.
  </span>
  cufftPlan1d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplan1d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftPlan1d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftPlan1d" title="Permalink to this definition">
  ï
 </a>
 <p>
  Creates a 1D FFT plan configuration for a specified signal size and data type. The
  <span class="pre">
   batch
  </span>
  input parameter tells cuFFT how many 1D transforms to configure.
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â Pointer to a
    <span class="pre">
     cufftHandle
    </span>
    object.
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size (e.g. 256 for a 256-point FFT).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2C
    </span>
    for single precision complex to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Number of transforms of size
    <span class="pre">
     nx
    </span>
    . Please consider using
    <span class="pre">
     cufftPlanMany
    </span>
    for multiple transforms.
   </p>
  </li>
  <li>
   <p>
    plan[Out]
    â Contains a cuFFT 1D plan handle value.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â The
    <span class="pre">
     nx
    </span>
    or
    <span class="pre">
     batch
    </span>
    parameter is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.2.2.
  </span>
  cufftPlan2d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplan2d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftPlan2d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftPlan2d" title="Permalink to this definition">
  ï
 </a>
 <p>
  Creates a 2D FFT plan configuration according to specified signal sizes and data type.
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â Pointer to a
    <span class="pre">
     cufftHandle
    </span>
    object.
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension This is slowest changing dimension of a transform (strided in memory).
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension. This is fastest changing dimension of a transform (contiguous in memory).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2R
    </span>
    for single precision complex to real).
   </p>
  </li>
  <li>
   <p>
    plan[Out]
    â Contains a cuFFT 2D plan handle value.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â Either or both of the
    <span class="pre">
     nx
    </span>
    or
    <span class="pre">
     ny
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.2.3.
  </span>
  cufftPlan3d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplan3d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftPlan3d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nz
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftPlan3d" title="Permalink to this definition">
  ï
 </a>
 <p>
  Creates a 3D FFT plan configuration according to specified signal sizes and data type. This function is the same as
  <span class="pre">
   cufftPlan2d()
  </span>
  except that it takes a third size parameter
  <span class="pre">
   nz
  </span>
  .
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â Pointer to a
    <span class="pre">
     cufftHandle
    </span>
    object.
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension. This is slowest changing dimension of a transform (strided in memory).
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension.
   </p>
  </li>
  <li>
   <p>
    nz[In]
    â The transform size in the
    z
    dimension. This is fastest changing dimension of a transform (contiguous in memory).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    plan[Out]
    â Contains a cuFFT 3D plan handle value.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the
    <span class="pre">
     nx
    </span>
    ,
    <span class="pre">
     ny
    </span>
    , or
    <span class="pre">
     nz
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.2.4.
  </span>
  cufftPlanMany()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftplanmany" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftPlanMany
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftPlanMany" title="Permalink to this definition">
  ï
 </a>
 <p>
  Creates a FFT plan configuration of dimension
  <span class="pre">
   rank
  </span>
  , with sizes specified in the array
  <span class="pre">
   n
  </span>
  . The
  <span class="pre">
   batch
  </span>
  input parameter tells cuFFT how many transforms to configure. With this function, batched plans of 1, 2, or 3 dimensions may be created.
 </p>
 <p>
  The
  <span class="pre">
   cufftPlanMany()
  </span>
  API supports more complicated input and output data layouts via the advanced data layout parameters:
  <span class="pre">
   inembed
  </span>
  ,
  <span class="pre">
   istride
  </span>
  ,
  <span class="pre">
   idist
  </span>
  ,
  <span class="pre">
   onembed
  </span>
  ,
  <span class="pre">
   ostride
  </span>
  , and
  <span class="pre">
   odist
  </span>
  .
 </p>
 <p>
  If
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  are set to
  <span class="pre">
   NULL
  </span>
  , all other stride information is ignored, and default strides are used. The default assumes contiguous data arrays.
 </p>
 <p>
  All arrays are assumed to be in CPU memory.
 </p>
 <p>
  Please note that behavior of
  <span class="pre">
   cufftPlanMany
  </span>
  function when
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  is
  <span class="pre">
   NULL
  </span>
  is different than corresponding function in FFTW library
  <span class="pre">
   fftw_plan_many_dft
  </span>
  .
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â Pointer to a
    <span class="pre">
     cufftHandle
    </span>
    object.
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension,
    <span class="pre">
     n[0]
    </span>
    being the size of the outermost and
    <span class="pre">
     n[rank-1]
    </span>
    innermost (contiguous) dimension of a transform.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    plan[Out]
    â Contains a cuFFT plan handle.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.3.
  </span>
  cuFFT Extensible Plans
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-extensible-plans" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This API separates handle creation from plan generation. This makes it possible to change plan settings, which may alter the outcome of the plan generation phase, before the plan is actually generated.
 </p>
 <h3>
  <span class="section-number">
   3.3.1.
  </span>
  cufftCreate()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftcreate" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftCreate
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftCreate" title="Permalink to this definition">
  ï
 </a>
 <p>
  Creates only an opaque handle, and allocates small data structures on the host. The
  <span class="pre">
   cufftMakePlan*()
  </span>
  calls actually do the plan generation.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â Pointer to a
    <span class="pre">
     cufftHandle
    </span>
    object.
   </p>
  </li>
  <li>
   <p>
    plan[Out]
    â Contains a cuFFT plan handle value.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.2.
  </span>
  cufftDestroy()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftdestroy" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftDestroy
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftDestroy" title="Permalink to this definition">
  ï
 </a>
 <p>
  Frees all GPU resources associated with a cuFFT plan and destroys the internal plan data structure. This function should be called once a plan is no longer needed, to avoid wasting GPU memory.
In the case of multi-GPU plans, the plan created first should be destroyed last.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â The
    <span class="pre">
     cufftHandle
    </span>
    object of the plan to be destroyed.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully destroyed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.3.
  </span>
  cufftMakePlan1d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplan1d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftMakePlan1d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftMakePlan1d" title="Permalink to this definition">
  ï
 </a>
 <p>
  Following a call to
  <span class="pre">
   cufftCreate()
  </span>
  makes a 1D FFT plan configuration for a specified signal size and data type. The
  <span class="pre">
   batch
  </span>
  input parameter tells cuFFT how many 1D transforms to configure.
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 <p>
  If
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  was called prior to this call with multiple GPUs, then
  <span class="pre">
   workSize
  </span>
  will contain multiple sizes. See sections on multiple GPUs for more details.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size (e.g. 256 for a 256-point FFT). For multiple GPUs, this must be a power of 2.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2C
    </span>
    for single precision complex to complex). For multiple GPUs this must be a complex to complex transform.
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Number of transforms of size
    <span class="pre">
     nx
    </span>
    . Please consider using
    <span class="pre">
     cufftMakePlanMany
    </span>
    for multiple transforms.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size(s) of the work areas.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked or multi-GPU restrictions are not met.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED`
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â The
    <span class="pre">
     nx
    </span>
    or
    <span class="pre">
     batch
    </span>
    parameter is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.4.
  </span>
  cufftMakePlan2d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplan2d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftMakePlan2d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftMakePlan2d" title="Permalink to this definition">
  ï
 </a>
 <p>
  Following a call to
  <span class="pre">
   cufftCreate()
  </span>
  makes a 2D FFT plan configuration according to specified signal sizes and data type.
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 <p>
  If
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  was called prior to this call with multiple GPUs, then
  <span class="pre">
   workSize
  </span>
  will contain multiple sizes. See sections on multiple GPUs for more details.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension. This is slowest changing dimension of a transform (strided in memory). For multiple GPUs, this must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension. This is fastest changing dimension of a transform (contiguous in memory). For 2 GPUs, this must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2R
    </span>
    for single precision complex to real).
   </p>
  </li>
  <li>
   <p>
    workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size(s) of the work areas.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â Either or both of the
    <span class="pre">
     nx
    </span>
    or
    <span class="pre">
     ny
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.5.
  </span>
  cufftMakePlan3d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplan3d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftMakePlan3d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nz
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftMakePlan3d" title="Permalink to this definition">
  ï
 </a>
 <p>
  Following a call to
  <span class="pre">
   cufftCreate()
  </span>
  makes a 3D FFT plan configuration according to specified signal sizes and data type. This function is the same as
  <span class="pre">
   cufftPlan2d()
  </span>
  except that it takes a third size parameter
  <span class="pre">
   nz
  </span>
  .
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 <p>
  If
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  was called prior to this call with multiple GPUs, then
  <span class="pre">
   workSize
  </span>
  will contain multiple sizes. See sections on multiple GPUs for more details.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension. This is slowest changing dimension of a transform (strided in memory). For multiple GPUs, this must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension. For multiple GPUs, this must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    nz[In]
    â The transform size in the
    z
    dimension. This is fastest changing dimension of a transform (contiguous in memory). For multiple GPUs, this must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size(s) of the work area(s).
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the
    <span class="pre">
     nx
    </span>
    ,
    <span class="pre">
     ny
    </span>
    , or
    <span class="pre">
     nz
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.6.
  </span>
  cufftMakePlanMany()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplanmany" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftMakePlanMany
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftMakePlanMany" title="Permalink to this definition">
  ï
 </a>
 <p>
  Following a call to
  <span class="pre">
   cufftCreate()
  </span>
  makes a FFT plan configuration of dimension
  <span class="pre">
   rank
  </span>
  , with sizes specified in the array
  <span class="pre">
   n
  </span>
  . The
  <span class="pre">
   batch
  </span>
  input parameter tells cuFFT how many transforms to configure. With this function, batched plans of 1, 2, or 3 dimensions may be created.
 </p>
 <p>
  The
  <span class="pre">
   cufftPlanMany()
  </span>
  API supports more complicated input and output data layouts via the advanced data layout parameters:
  <span class="pre">
   inembed
  </span>
  ,
  <span class="pre">
   istride
  </span>
  ,
  <span class="pre">
   idist
  </span>
  ,
  <span class="pre">
   onembed
  </span>
  ,
  <span class="pre">
   ostride
  </span>
  , and
  <span class="pre">
   odist
  </span>
  .
 </p>
 <p>
  If
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  are set to
  <span class="pre">
   NULL
  </span>
  , all other stride information is ignored, and default strides are used. The default assumes contiguous data arrays.
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 <p>
  If
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  was called prior to this call with multiple GPUs, then
  <span class="pre">
   workSize
  </span>
  will contain multiple sizes. See sections on multiple GPUs for more details.
 </p>
 <p>
  All arrays are assumed to be in CPU memory.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3)
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension,
    <span class="pre">
     n[0]
    </span>
    being the size of the outermost and
    <span class="pre">
     n[rank-1]
    </span>
    innermost (contiguous) dimension of a transform. For multiple GPUs and rank equal to 1, the sizes must be a power of 2. For multiple GPUs and rank equal to 2 or 3, the sizes must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory,
    <span class="pre">
     inembed[0]
    </span>
    being the storage dimension of the outermost dimension. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory,
    <span class="pre">
     onembed[0]
    </span>
    being the storage dimension of the outermost dimension. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex). For 2 GPUs this must be a complex to complex transform.
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size(s) of the work areas.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked or multi-GPU restrictions are not met.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.7.
  </span>
  cufftMakePlanMany64()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftmakeplanmany64" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftMakePlanMany64
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftMakePlanMany64" title="Permalink to this definition">
  ï
 </a>
 <p>
  Following a call to
  <span class="pre">
   cufftCreate()
  </span>
  makes a FFT plan configuration of dimension
  <span class="pre">
   rank
  </span>
  , with sizes specified in the array
  <span class="pre">
   n
  </span>
  . The
  <span class="pre">
   batch
  </span>
  input parameter tells cuFFT how many transforms to configure. With this function, batched plans of 1, 2, or 3 dimensions may be created.
 </p>
 <p>
  This API is identical to
  <span class="pre">
   cufftMakePlanMany
  </span>
  except that the arguments specifying sizes and strides are 64 bit integers. This API makes very large transforms possible. cuFFT includes kernels that use 32 bit indexes, and kernels that use 64 bit indexes. cuFFT planning selects 32 bit kernels whenever possible to avoid any overhead due to 64 bit arithmetic.
 </p>
 <p>
  All sizes and types of transform are supported by this interface, with two exceptions. For transforms whose size exceeds 4G elements, the dimensions specified in the array
  <span class="pre">
   n
  </span>
  must be factorable into primes that are less than or equal to 127. For real to complex and complex to real transforms whose size exceeds 4G elements, the fastest changing dimension must be even.
 </p>
 <p>
  The
  <span class="pre">
   cufftPlanMany64()
  </span>
  API supports more complicated input and output data layouts via the advanced data layout parameters:
  <span class="pre">
   inembed
  </span>
  ,
  <span class="pre">
   istride
  </span>
  ,
  <span class="pre">
   idist
  </span>
  ,
  <span class="pre">
   onembed
  </span>
  ,
  <span class="pre">
   ostride
  </span>
  , and
  <span class="pre">
   odist
  </span>
  .
 </p>
 <p>
  If
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  are set to
  <span class="pre">
   NULL
  </span>
  , all other stride information is ignored, and default strides are used. The default assumes contiguous data arrays.
 </p>
 <p>
  This call can only be used once for a given handle. It will fail and return
  <span class="pre">
   CUFFT_INVALID_PLAN
  </span>
  if the plan is locked, i.e. the handle was previously used with a different
  <span class="pre">
   cufftPlan
  </span>
  or
  <span class="pre">
   cufftMakePlan
  </span>
  call.
 </p>
 <p>
  If
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  was called prior to this call with multiple GPUs, then
  <span class="pre">
   workSize
  </span>
  will contain multiple sizes. See sections on multiple GPUs for more details.
 </p>
 <p>
  All arrays are assumed to be in CPU memory.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension. For multiple GPUs and rank equal to 1, the sizes must be a power of 2. For multiple GPUs and rank equal to 2 or 3, the sizes must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex). For 2 GPUs this must be a complex to complex transform.
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size(s) of the work areas.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when the plan is locked or multi-GPU restrictions are not met.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.3.8.
  </span>
  cufftXtMakePlanMany()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtmakeplanmany" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtMakePlanMany
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaDataType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inputtype
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaDataType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   outputtype
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaDataType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   executiontype
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtMakePlanMany" title="Permalink to this definition">
  ï
 </a>
 <p>
  Following a call to
  <span class="pre">
   cufftCreate()
  </span>
  makes an FFT plan configuration of dimension
  <span class="pre">
   rank
  </span>
  , with sizes specified in the array
  <span class="pre">
   n
  </span>
  . The
  <span class="pre">
   batch
  </span>
  input parameter tells cuFFT how many transforms to configure. With this function, batched plans of 1, 2, or 3 dimensions may be created.
 </p>
 <p>
  Type specifiers
  <span class="pre">
   inputtype
  </span>
  ,
  <span class="pre">
   outputtype
  </span>
  and
  <span class="pre">
   executiontype
  </span>
  dictate type and precision of transform to be performed. Not all combinations of parameters are supported. Currently all three parameters need to match precision. Parameters
  <span class="pre">
   inputtype
  </span>
  and
  <span class="pre">
   outputtype
  </span>
  need to match transform type complex-to-complex, real-to-complex or complex-to-real. Parameter
  <span class="pre">
   executiontype
  </span>
  needs to match precision and be of a complex type. Example: for a half-precision real-to-complex transform, parameters
  <span class="pre">
   inputtype
  </span>
  ,
  <span class="pre">
   outputtype
  </span>
  and
  <span class="pre">
   executiontype
  </span>
  would have values of
  <span class="pre">
   CUDA_R_16F
  </span>
  ,
  <span class="pre">
   CUDA_C_16F
  </span>
  and
  <span class="pre">
   CUDA_C_16F
  </span>
  respectively. Similarly, a bfloat16 complex-to-real transform would use
  <span class="pre">
   CUDA_C_16BF
  </span>
  for
  <span class="pre">
   inputtype
  </span>
  and
  <span class="pre">
   executiontype
  </span>
  , and
  <span class="pre">
   CUDA_R_16BF
  </span>
  for
  <span class="pre">
   outputtype
  </span>
  .
 </p>
 <p>
  The
  <span class="pre">
   cufftXtMakePlanMany()
  </span>
  API supports more complicated input and output data layouts via the advanced data layout parameters:
  <span class="pre">
   inembed
  </span>
  ,
  <span class="pre">
   istride
  </span>
  ,
  <span class="pre">
   idist
  </span>
  ,
  <span class="pre">
   onembed
  </span>
  ,
  <span class="pre">
   ostride
  </span>
  , and
  <span class="pre">
   odist
  </span>
  .
 </p>
 <p>
  If
  <span class="pre">
   inembed
  </span>
  and
  <span class="pre">
   onembed
  </span>
  are set to
  <span class="pre">
   NULL
  </span>
  , all other stride information is ignored, and default strides are used. The default assumes contiguous data arrays.
 </p>
 <p>
  If
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  was called prior to this call with multiple GPUs, then
  <span class="pre">
   workSize
  </span>
  will contain multiple sizes. See sections on multiple GPUs for more details.
 </p>
 <p>
  All arrays are assumed to be in CPU memory.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension,
    <span class="pre">
     n[0]
    </span>
    being the size of the outermost and
    <span class="pre">
     n[rank-1]
    </span>
    innermost (contiguous) dimension of a transform. For multiple GPUs and rank equal to 1, the sizes must be a power of 2. For multiple GPUs and rank equal to 2 or 3, the sizes must be factorable into primes less than or equal to 127.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory,
    <span class="pre">
     inembed[0]
    </span>
    being the storage dimension of the outermost dimension. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    inputtype[In]
    â Type of input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory,
    <span class="pre">
     onembed[0]
    </span>
    being the storage dimension of the outermost dimension. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    outputtype[In]
    â Type of output data.
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    executiontype[In]
    â Type of data to be used for computations.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size(s) of the work areas.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully created the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle. Handle is not valid when multi-GPU restrictions are not met.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.4.
  </span>
  cuFFT Plan Properties
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-plan-properties" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Users can further customize cuFFT plans using plan properties. These properties can be set, queried and reset on a per-plan basis as needed, using the routines listed in this section.
 </p>
 <p>
  The current supported properties are listed below:
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Property
    </p>
   </th>
   <th class="head">
    <p>
     Underlying Type
    </p>
   </th>
   <th class="head">
    <p>
     Description
    </p>
   </th>
   <th class="head">
    <p>
     Behavior
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      NVFFT_PLAN_PROPERTY_INT64_PATIENT_JIT
     </span>
    </p>
   </td>
   <td>
    <p>
     long long int
    </p>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Runtime LTO kernels are enabled when set to not-zero value. See
       <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-link-time-optimized-kernels">
        Link-Time Optimized Kernels
       </a>
      </p>
     </li>
     <li>
      <p>
       Runtime LTO kernles are disabled when set to zero (default)
      </p>
     </li>
    </ul>
   </td>
   <td>
    <ul class="simple">
     <li>
      <p>
       Can be set / reset before planning
      </p>
     </li>
     <li>
      <p>
       Cannot be set / reset after planning
      </p>
     </li>
    </ul>
   </td>
  </tr>
 </table>
 <h3>
  <span class="section-number">
   3.4.1.
  </span>
  cufftSetPlanPropertyInt64()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetplanpropertyint64" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftSetPlanPropertyInt64
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftProperty
  </span>
 </span>
 <span class="n">
  <span class="pre">
   property
  </span>
 </span>
 ,
 <span class="k">
  <span class="pre">
   const
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   propertyValueInt64
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftSetPlanPropertyInt64" title="Permalink to this definition">
  ï
 </a>
 <p>
  Associates a cuFFT plan with a property identified by the key
  <span class="pre">
   property
  </span>
  . The value for the property is given by value
  <span class="pre">
   propertyValueInt64
  </span>
  , which is a signed long long integer.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    property[In]
    â The property identifier, of type
    <span class="pre">
     cufftPlanProperty
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    propertyValueInt64[In]
    â Value to set for the property, a long long signed integer.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully set the property.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_NOT_SUPPORTED
    â The property is not supported, or it cannot be set at the time (e.g. some properties cannot be set after calling a planning routine for the plan, see
    <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-plan-properties">
     cuFFT Plan Properties
    </a>
    ).
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â Invalid property or value with which to set the property
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.4.2.
  </span>
  cufftGetPlanPropertyInt64()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetplanpropertyint64" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetPlanPropertyInt64
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftProperty
  </span>
 </span>
 <span class="n">
  <span class="pre">
   property
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   propertyValueInt64
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetPlanPropertyInt64" title="Permalink to this definition">
  ï
 </a>
 <p>
  Retrieves the property value identified by the key
  <span class="pre">
   property
  </span>
  associated with the cuFFT plan
  <span class="pre">
   plan
  </span>
  . The value for the property, which is a signed long long integer, is set in the address space pointed by
  <span class="pre">
   propertyValueInt64
  </span>
  .
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    property[In]
    â The property identifier, of type
    <span class="pre">
     cufftPlanProperty
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    propertyValueInt64[In]
    â Pointer to the value to be set with the value of the property.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully retrieved the property value.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_NOT_SUPPORTED
    â The property is not supported.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â Invalid property, or pointer
    <span class="pre">
     propertyValueInt64
    </span>
    is null
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.4.3.
  </span>
  cufftResetPlanProperty()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftresetplanproperty" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftResetPlanProperty
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftProperty
  </span>
 </span>
 <span class="n">
  <span class="pre">
   property
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftResetPlanProperty" title="Permalink to this definition">
  ï
 </a>
 <p>
  Resets the value of the property identified by the key
  <span class="pre">
   property
  </span>
  , associated with the cuFFT plan
  <span class="pre">
   plan
  </span>
  , to its default value.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    property[In]
    â The property identifier, of type
    <span class="pre">
     cufftPlanProperty
    </span>
    .
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully reset the property value.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_NOT_SUPPORTED
    â The property is not supported for
    <span class="pre">
     plan
    </span>
    , or cannot be reset at present time (see Behavior column on
    <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-plan-properties">
     cuFFT Plan Properties
    </a>
    ).
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â Invalid property
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.5.
  </span>
  cuFFT Estimated Size of Work Area
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-estimated-size-of-work-area" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  During plan execution, cuFFT requires a work area for temporary storage of intermediate results. The
  <span class="pre">
   cufftEstimate*()
  </span>
  calls return an estimate for the size of the work area required, given the specified parameters, and assuming default plan settings. Some problem sizes require much more storage than others. In particular powers of 2 are very efficient in terms of temporary storage. Large prime numbers, however, use different algorithms and may need up to the eight times that of a similarly sized power of 2. These routines return estimated
  <span class="pre">
   workSize
  </span>
  values which may still be smaller than the actual values needed especially for values of
  <span class="pre">
   n
  </span>
  that are not multiples of powers of 2, 3, 5 and 7. More refined values are given by the
  <span class="pre">
   cufftGetSize*()
  </span>
  routines, but these values may still be conservative.
 </p>
 <h3>
  <span class="section-number">
   3.5.1.
  </span>
  cufftEstimate1d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimate1d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftEstimate1d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftEstimate1d" title="Permalink to this definition">
  ï
 </a>
 <p>
  During plan execution, cuFFT requires a work area for temporary storage of intermediate results. This call returns an estimate for the size of the work area required, given the specified parameters, and assuming default plan settings.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    nx[In]
    â The transform size (e.g. 256 for a 256-point FFT).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2C
    </span>
    for single precision complex to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Number of transforms of size
    <span class="pre">
     nx
    </span>
    . Please consider using
    <span class="pre">
     cufftEstimateMany
    </span>
    for multiple transforms.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size, in bytes, of the work space.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â The
    <span class="pre">
     nx
    </span>
    parameter is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.5.2.
  </span>
  cufftEstimate2d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimate2d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftEstimate2d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftEstimate2d" title="Permalink to this definition">
  ï
 </a>
 <p>
  During plan execution, cuFFT requires a work area for temporary storage of intermediate results. This call returns an estimate for the size of the work area required, given the specified parameters, and assuming default plan settings.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension (number of rows).
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension (number of columns).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2R
    </span>
    for single precision complex to real).
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size, in bytes, of the work space.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â Either or both of the
    <span class="pre">
     nx
    </span>
    or
    <span class="pre">
     ny
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.5.3.
  </span>
  cufftEstimate3d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimate3d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftEstimate3d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nz
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftEstimate3d" title="Permalink to this definition">
  ï
 </a>
 <p>
  During plan execution, cuFFT requires a work area for temporary storage of intermediate results. This call returns an estimate for the size of the work area required, given the specified parameters, and assuming default plan settings.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension.
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension.
   </p>
  </li>
  <li>
   <p>
    nz[In]
    â The transform size in the
    z
    dimension.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size, in bytes, of the work space.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the
    <span class="pre">
     nx
    </span>
    ,
    <span class="pre">
     ny
    </span>
    , or
    <span class="pre">
     nz
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.5.4.
  </span>
  cufftEstimateMany()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftestimatemany" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftEstimateMany
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftEstimateMany" title="Permalink to this definition">
  ï
 </a>
 <p>
  During plan execution, cuFFT requires a work area for temporary storage of intermediate results. This call returns an estimate for the size of the work area required, given the specified parameters, and assuming default plan settings.
 </p>
 <p>
  The
  <span class="pre">
   cufftEstimateMany()
  </span>
  API supports more complicated input and output data layouts via the advanced data layout parameters:
  <span class="pre">
   inembed
  </span>
  ,
  <span class="pre">
   istride
  </span>
  ,
  <span class="pre">
   idist
  </span>
  ,
  <span class="pre">
   onembed
  </span>
  ,
  <span class="pre">
   ostride
  </span>
  , and
  <span class="pre">
   odist
  </span>
  .
 </p>
 <p>
  All arrays are assumed to be in CPU memory.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size, in bytes, of the work space.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.6.
  </span>
  cuFFT Refined Estimated Size of Work Area
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-refined-estimated-size-of-work-area" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  The
  <span class="pre">
   cufftGetSize*()
  </span>
  routines give a more accurate estimate of the work area size required for a plan than the
  <span class="pre">
   cufftEstimate*()
  </span>
  routines as they take into account any plan settings that may have been made. As discussed in the section
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#work-estimate">
   cuFFT Estimated Size of Work Area
  </a>
  , the
  <span class="pre">
   workSize
  </span>
  value(s) returned may be conservative especially for values of
  <span class="pre">
   n
  </span>
  that are not multiples of powers of 2, 3, 5 and 7.
 </p>
 <h3>
  <span class="section-number">
   3.6.1.
  </span>
  cufftGetSize1d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize1d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetSize1d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetSize1d" title="Permalink to this definition">
  ï
 </a>
 <p>
  This call gives a more accurate estimate of the work area size required for a plan than
  <span class="pre">
   cufftEstimate1d()
  </span>
  , given the specified parameters, and taking into account any plan settings that may have been made.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size (e.g. 256 for a 256-point FFT).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2C
    </span>
    for single precision complex to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Number of transforms of size
    <span class="pre">
     nx
    </span>
    . Please consider using
    <span class="pre">
     cufftGetSizeMany
    </span>
    for multiple transforms.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â The
    <span class="pre">
     nx
    </span>
    parameter is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.6.2.
  </span>
  cufftGetSize2d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize2d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetSize2d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetSize2d" title="Permalink to this definition">
  ï
 </a>
 <p>
  This call gives a more accurate estimate of the work area size required for a plan than
  <span class="pre">
   cufftEstimate2d()
  </span>
  , given the specified parameters, and taking into account any plan settings that may have been made.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension (number of rows).
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension (number of columns).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_C2R
    </span>
    for single precision complex to real).
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â Either or both of the
    <span class="pre">
     nx
    </span>
    or
    <span class="pre">
     ny
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.6.3.
  </span>
  cufftGetSize3d()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize3d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetSize3d
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nx
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ny
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nz
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetSize3d" title="Permalink to this definition">
  ï
 </a>
 <p>
  This call gives a more accurate estimate of the work area size required for a plan than
  <span class="pre">
   cufftEstimate3d()
  </span>
  , given the specified parameters, and taking into account any plan settings that may have been made.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nx[In]
    â The transform size in the
    x
    dimension.
   </p>
  </li>
  <li>
   <p>
    ny[In]
    â The transform size in the
    y
    dimension.
   </p>
  </li>
  <li>
   <p>
    nz[In]
    â The transform size in the
    z
    dimension.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work space.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the
    <span class="pre">
     nx
    </span>
    ,
    <span class="pre">
     ny
    </span>
    , or
    <span class="pre">
     nz
    </span>
    parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.6.4.
  </span>
  cufftGetSizeMany()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsizemany" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetSizeMany
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetSizeMany" title="Permalink to this definition">
  ï
 </a>
 <p>
  This call gives a more accurate estimate of the work area size required for a plan than
  <span class="pre">
   cufftEstimateSizeMany()
  </span>
  , given the specified parameters, and taking into account any plan settings that may have been made.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work area.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.6.5.
  </span>
  cufftGetSizeMany64()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsizemany64" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetSizeMany64
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetSizeMany64" title="Permalink to this definition">
  ï
 </a>
 <p>
  This call gives a more accurate estimate of the work area size required for a plan than
  <span class="pre">
   cufftEstimateSizeMany()
  </span>
  , given the specified parameters, and taking into account any plan settings that may have been made.
 </p>
 <p>
  This API is identical to
  <span class="pre">
   cufftMakePlanMany
  </span>
  except that the arguments specifying sizes and strides are 64 bit integers. This API makes very large transforms possible. cuFFT includes kernels that use 32 bit indexes, and kernels that use 64 bit indexes. cuFFT planning selects 32 bit kernels whenever possible to avoid any overhead due to 64 bit arithmetic.
 </p>
 <p>
  All sizes and types of transform are supported by this interface, with two exceptions. For transforms whose total size exceeds 4G elements, the dimensions specified in the array
  <span class="pre">
   n
  </span>
  must be factorable into primes that are less than or equal to 127. For real to complex and complex to real transforms whose total size exceeds 4G elements, the fastest changing dimension must be even.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â The transform data type (e.g.,
    <span class="pre">
     CUFFT_R2C
    </span>
    for single precision real to complex).
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work area.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.6.6.
  </span>
  cufftXtGetSizeMany()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtgetsizemany" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtGetSizeMany
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   rank
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   n
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   istride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaDataType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   inputtype
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   onembed
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   ostride
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odist
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaDataType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   outputtype
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   long
  </span>
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   batch
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaDataType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   executiontype
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtGetSizeMany" title="Permalink to this definition">
  ï
 </a>
 <p>
  This call gives a more accurate estimate of the work area size required for a plan than
  <span class="pre">
   cufftEstimateSizeMany()
  </span>
  , given the specified parameters that match signature of
  <span class="pre">
   cufftXtMakePlanMany
  </span>
  function, and taking into account any plan settings that may have been made.
 </p>
 <p>
  For more information about valid combinations of
  <span class="pre">
   inputtype
  </span>
  ,
  <span class="pre">
   outputtype
  </span>
  and
  <span class="pre">
   executiontype
  </span>
  parameters please refer to documentation of
  <span class="pre">
   cufftXtMakePlanMany
  </span>
  function.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    rank[In]
    â Dimensionality of the transform (1, 2, or 3).
   </p>
  </li>
  <li>
   <p>
    n[In]
    â Array of size
    <span class="pre">
     rank
    </span>
    , describing the size of each dimension.
   </p>
  </li>
  <li>
   <p>
    inembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the input data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    istride[In]
    â Indicates the distance between two successive input elements in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    idist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the input data.
   </p>
  </li>
  <li>
   <p>
    inputtype[In]
    (
    <span>
     <span class="c-expr sig sig-inline c">
      <span class="n">
       cudaDataType
      </span>
     </span>
    </span>
    ) â Type of input data.
   </p>
  </li>
  <li>
   <p>
    onembed[In]
    â Pointer of size
    <span class="pre">
     rank
    </span>
    that indicates the storage dimensions of the output data in memory. If set to NULL all other advanced data layout parameters are ignored.
   </p>
  </li>
  <li>
   <p>
    ostride[In]
    â Indicates the distance between two successive output elements in the output array in the least significant (i.e., innermost) dimension.
   </p>
  </li>
  <li>
   <p>
    odist[In]
    â Indicates the distance between the first element of two consecutive signals in a batch of the output data.
   </p>
  </li>
  <li>
   <p>
    outputtype[In]
    (
    <span>
     <span class="c-expr sig sig-inline c">
      <span class="n">
       cudaDataType
      </span>
     </span>
    </span>
    ) â Type of output data.
   </p>
  </li>
  <li>
   <p>
    batch[In]
    â Batch size for this transform.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    executiontype[In]
    (
    <span>
     <span class="c-expr sig sig-inline c">
      <span class="n">
       cudaDataType
      </span>
     </span>
    </span>
    ) â Type of data to be used for computations.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work area.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â One or more of the parameters is not a supported size.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.7.
  </span>
  cufftGetSize()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetsize" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetSize
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetSize" title="Permalink to this definition">
  ï
 </a>
 <p>
  Once plan generation has been done, either with the original API or the extensible API, this call returns the actual size of the work area required to support the plan. Callers who choose to manage work area allocation within their application must use this call after plan generation, and after any
  <span class="pre">
   cufftSet*()
  </span>
  calls subsequent to plan generation, if those calls might alter the required work space size.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Pointer to the size(s), in bytes, of the work areas. For example for two GPUs worksize must be declared to have two elements.
   </p>
  </li>
  <li>
   <p>
    *workSize[Out]
    â Pointer to the size of the work area.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.8.
  </span>
  cuFFT Caller Allocated Work Area Support
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-caller-allocated-work-area-support" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.8.1.
  </span>
  cufftSetAutoAllocation()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetautoallocation" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftSetAutoAllocation
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   autoAllocate
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftSetAutoAllocation" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftSetAutoAllocation()
  </span>
  indicates that the caller intends to allocate and manage work areas for plans that have been generated. cuFFT default behavior is to allocate the work area at plan generation time. If
  <span class="pre">
   cufftSetAutoAllocation()
  </span>
  has been called with autoAllocate set to 0 (âfalseâ) prior to one of the
  <span class="pre">
   cufftMakePlan*()
  </span>
  calls, cuFFT does not allocate the work area. This is the preferred sequence for callers wishing to manage work area allocation.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    autoAllocate[In]
    â Indicates whether to allocate work area.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.8.2.
  </span>
  cufftSetWorkArea()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetworkarea" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftSetWorkArea
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workArea
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftSetWorkArea" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftSetWorkArea()
  </span>
  overrides the work area pointer associated with a plan. If the work area was auto-allocated, cuFFT frees the auto-allocated space. The
  <span class="pre">
   cufftExecute*()
  </span>
  calls assume that the work area pointer is valid and that it points to a contiguous region in device memory that does not overlap with any other work area. If this is not the case, results are indeterminate.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    *workArea[In]
    â Pointer to
    <span class="pre">
     workArea
    </span>
    . For multiple GPUs, multiple work area pointers must be given.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.8.3.
  </span>
  cufftXtSetWorkAreaPolicy()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetworkareapolicy" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtSetWorkAreaPolicy
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftXtWorkAreaPolicy
  </span>
 </span>
 <span class="n">
  <span class="pre">
   policy
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtSetWorkAreaPolicy" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtSetWorkAreaPolicy()
  </span>
  indicates that the caller intends to change work area size for a given plan handle. cuFFTâs default behavior is to allocate the work area at plan generation time with a default size that depends on the plan type and other parameters. If
  <span class="pre">
   cufftXtSetWorkAreaPolicy()
  </span>
  has been called with the
  <span class="pre">
   policy
  </span>
  parameter set to
  <span class="pre">
   CUFFT_WORKAREA_MINIMAL
  </span>
  , cuFFT will attempt to re-plan the handle to use zero bytes of work area memory. If the
  <span class="pre">
   cufftXtSetWorkAreaPolicy()
  </span>
  call is successful the auto-allocated work area memory is released.
 </p>
 <p>
  Currently the policies
  <span class="pre">
   CUFFT_WORKAREA_PERFORMANCE
  </span>
  ,
  <span class="pre">
   CUFFT_WORKAREA_USER
  </span>
  and the
  <span class="pre">
   workSize
  </span>
  parameter are not supported and reserved for use in future cuFFT releases.
 </p>
 <p>
  This function can be called once per lifetime of a plan handle.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    policy[In]
    â Type of work area policy to apply.
   </p>
  </li>
  <li>
   <p>
    *workSize[In]
    â Reserved for future use.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â FFT size does not allow use of the selected policy.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.9.
  </span>
  cuFFT Execution
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-execution" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.9.1.
  </span>
  cufftExecC2C() and cufftExecZ2Z()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftexecc2c-and-cufftexecz2z" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftExecC2C
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idata
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odata
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   direction
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftExecC2C" title="Permalink to this definition">
  ï
 </a>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftExecZ2Z
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftDoubleComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idata
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftDoubleComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odata
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   direction
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftExecZ2Z" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftExecC2C()
  </span>
  (
  <span class="pre">
   cufftExecZ2Z()
  </span>
  ) executes a single-precision (double-precision) complex-to-complex transform plan in the transform direction as specified by
  <span class="pre">
   direction
  </span>
  parameter. cuFFT uses the GPU memory pointed to by the
  <span class="pre">
   idata
  </span>
  parameter as input data. This function stores the Fourier coefficients in the
  <span class="pre">
   odata
  </span>
  array. If
  <span class="pre">
   idata
  </span>
  and
  <span class="pre">
   odata
  </span>
  are the same, this method does an in-place transform.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    idata[In]
    â Pointer to the complex input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    odata[In]
    â Pointer to the complex output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    direction[In]
    â The transform direction:
    <span class="pre">
     CUFFT_FORWARD
    </span>
    or
    <span class="pre">
     CUFFT_INVERSE
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    odata[Out]
    â ontains the complex Fourier coefficients.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     idata
    </span>
    ,
    <span class="pre">
     odata
    </span>
    , and
    <span class="pre">
     direction
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.9.2.
  </span>
  cufftExecR2C() and cufftExecD2Z()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftexecr2c-and-cufftexecd2z" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftExecR2C
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftReal
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idata
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odata
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftExecR2C" title="Permalink to this definition">
  ï
 </a>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftExecD2Z
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftDoubleReal
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idata
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftDoubleComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odata
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftExecD2Z" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftExecR2C()
  </span>
  (
  <span class="pre">
   cufftExecD2Z()
  </span>
  ) executes a single-precision (double-precision) real-to-complex, implicitly forward, cuFFT transform plan. cuFFT uses as input data the GPU memory pointed to by the
  <span class="pre">
   idata
  </span>
  parameter. This function stores the nonredundant Fourier coefficients in the
  <span class="pre">
   odata
  </span>
  array. Pointers to
  <span class="pre">
   idata
  </span>
  and
  <span class="pre">
   odata
  </span>
  are both required to be aligned to
  <span class="pre">
   cufftComplex
  </span>
  data type in single-precision transforms and
  <span class="pre">
   cufftDoubleComplex
  </span>
  data type in double-precision transforms. If
  <span class="pre">
   idata
  </span>
  and
  <span class="pre">
   odata
  </span>
  are the same, this method does an in-place transform. Note the data layout differences between in-place and out-of-place transforms as described in
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-transform-types">
   Parameter cufftType
  </a>
  .
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    idata[In]
    â Pointer to the real input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    odata[In]
    â Pointer to the complex output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    odata[Out]
    â Contains the complex Fourier coefficients.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully returned the size of the work space.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     idata
    </span>
    and
    <span class="pre">
     odata
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.9.3.
  </span>
  cufftExecC2R() and cufftExecZ2D()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftexecc2r-and-cufftexecz2d" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftExecC2R
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idata
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftReal
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odata
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftExecC2R" title="Permalink to this definition">
  ï
 </a>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftExecZ2D
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftDoubleComplex
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   idata
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftDoubleReal
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   odata
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftExecZ2D" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftExecC2R()
  </span>
  (
  <span class="pre">
   cufftExecZ2D()
  </span>
  ) executes a single-precision (double-precision) complex-to-real, implicitly inverse, cuFFT transform plan. cuFFT uses as input data the GPU memory pointed to by the
  <span class="pre">
   idata
  </span>
  parameter. The input array holds only the nonredundant complex Fourier coefficients. This function stores the real output values in the
  <span class="pre">
   odata
  </span>
  array. and pointers are both required to be aligned to
  <span class="pre">
   cufftComplex
  </span>
  data type in single-precision transforms and
  <span class="pre">
   cufftDoubleComplex
  </span>
  type in double-precision transforms. If
  <span class="pre">
   idata
  </span>
  and
  <span class="pre">
   odata
  </span>
  are the same, this method does an in-place transform.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    idata[In]
    â Pointer to the complex input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    odata[In]
    â Pointer to the real output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    odata[Out]
    â Contains the real output data.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully executed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     idata
    </span>
    and
    <span class="pre">
     odata
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.9.4.
  </span>
  cufftXtExec()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexec" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExec
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   direction
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExec" title="Permalink to this definition">
  ï
 </a>
 <p>
  Function
  <span class="pre">
   cufftXtExec
  </span>
  executes any cuFFT transform regardless of precision and type. In case of complex-to-real and real-to-complex transforms
  <span class="pre">
   direction
  </span>
  parameter is ignored. cuFFT uses the GPU memory pointed to by the
  <span class="pre">
   input
  </span>
  parameter as input data. This function stores the Fourier coefficients in the
  <span class="pre">
   output
  </span>
  array. If
  <span class="pre">
   input
  </span>
  and
  <span class="pre">
   output
  </span>
  are the same, this method does an in-place transform.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    input[In]
    â Pointer to the input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    output[In]
    â Pointer to the output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    direction[In]
    â The transform direction:
    <span class="pre">
     CUFFT_FORWARD
    </span>
    or
    <span class="pre">
     CUFFT_INVERSE
    </span>
    . Ignored for complex-to-real and real-to-complex transforms.
   </p>
  </li>
  <li>
   <p>
    output[Out]
    â Contains the complex Fourier coefficients.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully executed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     idata
    </span>
    ,
    <span class="pre">
     odata
    </span>
    , and
    <span class="pre">
     direction
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.9.5.
  </span>
  cufftXtExecDescriptor()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptor" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptor
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   direction
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptor" title="Permalink to this definition">
  ï
 </a>
 <p>
  Function
  <span class="pre">
   cufftXtExecDescriptor()
  </span>
  executes any cuFFT transform regardless of precision and type. In case of complex-to-real and real-to-complex transforms
  <span class="pre">
   direction
  </span>
  parameter is ignored. cuFFT uses the GPU memory pointed to by
  <span class="pre">
   cudaLibXtDesc
  </span>
  Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â
  <span class="pre">
   *input
  </span>
  descriptor as input data and
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *output
  </span>
  as output data.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    input[In]
    â Pointer to the complex input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    output[In]
    â Pointer to the complex output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    direction[In]
    â The transform direction:
    <span class="pre">
     CUFFT_FORWARD
    </span>
    or
    <span class="pre">
     CUFFT_INVERSE
    </span>
    . Ignored for complex-to-real and real-to-complex transforms.
   </p>
  </li>
  <li>
   <p>
    idata[Out]
    â Contains the complex Fourier coefficients.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully executed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     idata
    </span>
    and
    <span class="pre">
     direction
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified in a descriptor.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.10.
  </span>
  cuFFT and Multiple GPUs
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-and-multiple-gpus" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.10.1.
  </span>
  cufftXtSetGPUs()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetgpus" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtSetGPUs
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   nGPUs
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   whichGPUs
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtSetGPUs" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  identifies which GPUs are to be used with the plan. As in the single GPU case
  <span class="pre">
   cufftCreate()
  </span>
  creates a plan and
  <span class="pre">
   cufftMakePlan*()
  </span>
  does the plan generation. In cuFFT prior to 10.4.0, this call will return an error if a non-default stream has been associated with the plan.
 </p>
 <p>
  Note that the call to
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  must occur after the call to
  <span class="pre">
   cufftCreate()
  </span>
  and prior to the call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  . Parameter
  <span class="pre">
   whichGPUs
  </span>
  of
  <span class="pre">
   cufftXtSetGPUs()
  </span>
  function determines ordering of the GPUs with respect to data decomposition (first data chunk is placed on GPU denoted by first element of
  <span class="pre">
   whichGPUs
  </span>
  ).
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    nGPUs[In]
    â Number of GPUs to use.
   </p>
  </li>
  <li>
   <p>
    whichGPUs[In]
    â The GPUs to use.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully set the GPUs to use.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle, or a
    <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#streamed-cufft-transforms">
     non-default stream has been associated with the plan in cuFFT prior to 10.4.0
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â The requested number of GPUs was less than 2 or more than 8.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_SIZE
    â Transform size that
    <span class="pre">
     plan
    </span>
    was created for does not meet minimum size criteria.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.10.2.
  </span>
  cufftXtSetWorkArea()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetworkarea" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtSetWorkArea
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   workArea
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtSetWorkArea" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtSetWorkArea()
  </span>
  overrides the work areas associated with a plan. If the work area was auto-allocated, cuFFT frees the auto-allocated space. The
  <span class="pre">
   cufftXtExec*()
  </span>
  calls assume that the work area is valid and that it points to a contiguous region in each device memory that does not overlap with any other work area. If this is not the case, results are indeterminate.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    workArea[In]
    â Pointer to the pointers to workArea.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully set the GPUs to use.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â A GPU associated with the plan could not be selected.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.10.3.
  </span>
  cuFFT Multiple GPU Execution
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-multiple-gpu-execution" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <h4>
  <span class="section-number">
   3.10.3.1.
  </span>
  cufftXtExecDescriptorC2C() and cufftXtExecDescriptorZ2Z()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptorc2c-and-cufftxtexecdescriptorz2z" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptorC2C
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   direction
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptorC2C" title="Permalink to this definition">
  ï
 </a>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptorZ2Z
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="n">
  <span class="pre">
   direction
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptorZ2Z" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtExecDescriptorC2C()
  </span>
  (
  <span class="pre">
   cufftXtExecDescriptorZ2Z()
  </span>
  ) executes a single-precision (double-precision) complex-to-complex transform plan in the transform direction as specified by
  <span class="pre">
   direction
  </span>
  parameter. cuFFT uses the GPU memory pointed to by
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *input
  </span>
  as input data. Since only in-place multiple GPU functionality is supported, this function also stores the result in the
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *input
  </span>
  arrays.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    *input[In]
    â Pointer to the complex input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    *output[In]
    â Pointer to the complex output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    direction[In]
    â The transform direction:
    <span class="pre">
     CUFFT_FORWARD
    </span>
    or
    <span class="pre">
     CUFFT_INVERSE
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    input[Out]
    â Contains the complex Fourier coefficients.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully executed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     input
    </span>
    and
    <span class="pre">
     direction
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified in a descriptor.
   </p>
  </li>
 </ul>
 <h4>
  <span class="section-number">
   3.10.3.2.
  </span>
  cufftXtExecDescriptorR2C() and cufftXtExecDescriptorD2Z()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptorr2c-and-cufftxtexecdescriptord2z" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptorR2C
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptorR2C" title="Permalink to this definition">
  ï
 </a>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptorD2Z
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptorD2Z" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtExecDescriptorR2C()
  </span>
  (
  <span class="pre">
   cufftXtExecDescriptorD2Z()
  </span>
  ) executes a single-precision (double-precision) real-to-complex transform plan. cuFFT uses the GPU memory pointed to by
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *input
  </span>
  as input data. Since only in-place multiple GPU functionality is supported, this function also stores the result in the
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *input
  </span>
  arrays.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    *input[In]
    â Pointer to the complex input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    *output[In]
    â Pointer to the complex output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    input[Out]
    â Contains the complex Fourier coefficients
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully executed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     input
    </span>
    and
    <span class="pre">
     direction
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified in a descriptor.
   </p>
  </li>
 </ul>
 <h4>
  <span class="section-number">
   3.10.3.3.
  </span>
  cufftXtExecDescriptorC2R() and cufftXtExecDescriptorZ2D()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtexecdescriptorc2r-and-cufftxtexecdescriptorz2d" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptorC2R
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptorC2R" title="Permalink to this definition">
  ï
 </a>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtExecDescriptorZ2D
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   input
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   output
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtExecDescriptorZ2D" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtExecDescriptorC2R()
  </span>
  (
  <span class="pre">
   cufftXtExecDescriptorZ2D()
  </span>
  ) executes a single-precision (double-precision) complex-to-real transform plan in the transform direction as specified by
  <span class="pre">
   direction
  </span>
  parameter. cuFFT uses the GPU memory pointed to by
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *input
  </span>
  as input data. Since only in-place multiple GPU functionality is supported, this function also stores the result in the
  <span class="pre">
   cudaLibXtDesc
  </span>
  <span class="pre">
   *input
  </span>
  arrays.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    *input[In]
    â Pointer to the complex input data (in GPU memory) to transform.
   </p>
  </li>
  <li>
   <p>
    *output[In]
    â Pointer to the complex output data (in GPU memory).
   </p>
  </li>
  <li>
   <p>
    input[Out]
    â Contains the complex Fourier coefficients.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully executed the FFT plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â At least one of the parameters
    <span class="pre">
     input
    </span>
    and
    <span class="pre">
     direction
    </span>
    is not valid.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_EXEC_FAILED
    â cuFFT failed to execute the transform on the GPU.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified in a descriptor.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.10.4.
  </span>
  Memory Allocation and Data Movement Functions
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#memory-allocation-and-data-movement-functions" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  Multiple GPU cuFFT execution functions assume a certain data layout in terms of what input data has been copied to which GPUs prior to execution, and what output data resides in which GPUs post execution. The following functions assist in allocation, setup and retrieval of the data. They must be called after the call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  .
 </p>
 <h4>
  <span class="section-number">
   3.10.4.1.
  </span>
  cufftXtMalloc()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtmalloc" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtMalloc
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   descriptor
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftXtSubFormat
  </span>
 </span>
 <span class="n">
  <span class="pre">
   format
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtMalloc" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtMalloc()
  </span>
  allocates a descriptor, and all memory for data in GPUs associated with the plan, and returns a pointer to the descriptor. Note the descriptor contains an array of device pointers so that the application may preprocess or postprocess the data on the GPUs. The enumerated parameter
  <span class="pre">
   cufftXtSubFormat_t
  </span>
  indicates if the buffer will be used for input or output.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    **descriptor[In]
    â Pointer to a pointer to a
    <span class="pre">
     cudaLibXtDesc
    </span>
    object.
   </p>
  </li>
  <li>
   <p>
    format[In]
    â cufftXtSubFormat`` value.
   </p>
  </li>
  <li>
   <p>
    **descriptor[Out]
    â Pointer to a pointer to a
    <span class="pre">
     cudaLibXtDesc
    </span>
    object.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully allows user to allocate descriptor and GPU memory.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle or it is not a multiple GPU
    <span class="pre">
     plan
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â The allocation of GPU resources for the plan failed.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified in the descriptor.
   </p>
  </li>
 </ul>
 <h5>
  <span class="section-number">
   3.10.4.1.1.
  </span>
  Parameter cufftXtSubFormat
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#parameter-cufftxtsubformat" title="Permalink to this headline">
   ï
  </a>
 </h5>
 <p>
  <span class="pre">
   cufftXtSubFormat_t
  </span>
  is an enumerated type that indicates if the buffer will be used for input or output and the ordering of the data.
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">cufftXtSubFormat_t</span><span class="p">{</span>
<span class="n">CUFFT_XT_FORMAT_INPUT</span><span class="p">,</span><span class="c1">//by default input is in linear order across GPUs</span>
<span class="n">CUFFT_XT_FORMAT_OUTPUT</span><span class="p">,</span><span class="c1">//by default output is in scrambled order depending on transform</span>
<span class="n">CUFFT_XT_FORMAT_INPLACE</span><span class="p">,</span><span class="c1">//by default inplace is input order, which is linear across GPUs</span>
<span class="n">CUFFT_XT_FORMAT_INPLACE_SHUFFLED</span><span class="p">,</span><span class="c1">//shuffled output order after execution of the transform</span>
<span class="n">CUFFT_FORMAT_UNDEFINED</span>
<span class="p">}</span><span class="n">cufftXtSubFormat</span><span class="p">;</span>
</pre>
 <h4>
  <span class="section-number">
   3.10.4.2.
  </span>
  cufftXtFree()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtfree" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtFree
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="n">
  <span class="pre">
   cudaLibXtDesc
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   descriptor
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtFree" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtFree()
  </span>
  frees the descriptor and all memory associated with it. The descriptor and memory must have been returned by a previous call to
  <span class="pre">
   cufftXtMalloc()
  </span>
  .
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    *descriptor[In]
    â Pointer to a
    <span class="pre">
     cudaLibXtDesc
    </span>
    object.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully allows user to free descriptor and associated GPU memory.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
 </ul>
 <h4>
  <span class="section-number">
   3.10.4.3.
  </span>
  cufftXtMemcpy()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtmemcpy" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtMemcpy
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   dstPointer
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   srcPointer
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftXtCopyType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtMemcpy" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtMemcpy()
  </span>
  copies data between buffers on the host and GPUs or between GPUs. The enumerated parameter
  <span class="pre">
   cufftXtCopyType_t
  </span>
  indicates the type and direction of transfer. Calling
  <span class="pre">
   cufftXtMemcpy
  </span>
  function for multi-GPU batched FFT plans with
  <span class="pre">
   CUFFT_COPY_DEVICE_TO_DEVICE
  </span>
  transfer type is not supported.
 </p>
 <p>
  Note that starting from CUDA 11.2 (cuFFT 10.4.0),
  <span class="pre">
   cufftSetStream()
  </span>
  is supported on multi-GPU plans. When associating a stream with a plan,
  <span class="pre">
   cufftXtMemcpy()
  </span>
  remains synchronous across the multiple GPUs.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    dstPointer[In]
    â Pointer to the destination address(es).
   </p>
  </li>
  <li>
   <p>
    srcPointer[In]
    â Pointer to the source address(es).
   </p>
  </li>
  <li>
   <p>
    type[In]
    â
    <span class="pre">
     cufftXtCopyType
    </span>
    value.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully allows user to copy memory between host and GPUs or between GPUs.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â One or more invalid parameters were passed to the API.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_DEVICE
    â An invalid GPU index was specified in a descriptor.
   </p>
  </li>
 </ul>
 <h5>
  <span class="section-number">
   3.10.4.3.1.
  </span>
  Parameter cufftXtCopyType
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#parameter-cufftxtcopytype" title="Permalink to this headline">
   ï
  </a>
 </h5>
 <p>
  <span class="pre">
   cufftXtCopyType_t
  </span>
  is an enumerated type for multiple GPU functions that specifies the type of copy for
  <span class="pre">
   cufftXtMemcpy()
  </span>
  .
 </p>
 <p>
  <span class="pre">
   CUFFT_COPY_HOST_TO_DEVICE
  </span>
  copies data from a contiguous host buffer to multiple device buffers, in the layout cuFFT requires for input data.
  <span class="pre">
   dstPointer
  </span>
  must point to a
  <span class="pre">
   cudaLibXtDesc
  </span>
  structure, and
  <span class="pre">
   srcPointer
  </span>
  must point to a host memory buffer.
 </p>
 <p>
  <span class="pre">
   CUFFT_COPY_DEVICE_TO_HOST
  </span>
  copies data from multiple device buffers, in the layout cuFFT produces for output data, to a contiguous host buffer.
  <span class="pre">
   dstPointer
  </span>
  must point to a host memory buffer, and
  <span class="pre">
   srcPointer
  </span>
  must point to a
  <span class="pre">
   cudaLibXtDesc
  </span>
  structure.
 </p>
 <p>
  <span class="pre">
   CUFFT_COPY_DEVICE_TO_DEVICE
  </span>
  copies data from multiple device buffers, in the layout cuFFT produces for output data, to multiple device buffers, in the layout cuFFT requires for input data.
  <span class="pre">
   dstPointer
  </span>
  and
  <span class="pre">
   srcPointer
  </span>
  must point to different
  <span class="pre">
   cudaLibXtDesc
  </span>
  structures (and therefore memory locations). That is, the copy cannot be in-place. Note that device_to_device
  <span class="pre">
   cufftXtMemcpy()
  </span>
  for 2D and 3D data is not currently supported.
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">cufftXtCopyType_t</span><span class="p">{</span>
<span class="n">CUFFT_COPY_HOST_TO_DEVICE</span><span class="p">,</span>
<span class="n">CUFFT_COPY_DEVICE_TO_HOST</span><span class="p">,</span>
<span class="n">CUFFT_COPY_DEVICE_TO_DEVICE</span>
<span class="p">}</span><span class="n">cufftXtCopyType</span><span class="p">;</span>
</pre>
 <h3>
  <span class="section-number">
   3.10.5.
  </span>
  General Multiple GPU Descriptor Types
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#general-multiple-gpu-descriptor-types" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <h4>
  <span class="section-number">
   3.10.5.1.
  </span>
  cudaXtDesc
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cudaxtdesc" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  A descriptor type used in multiple GPU routines that contains information about the GPUs and their memory locations.
 </p>
 <pre><span class="k">struct</span><span class="nc">cudaXtDesc_t</span><span class="p">{</span>
<span class="kt">int</span><span class="n">version</span><span class="p">;</span><span class="c1">//descriptor version</span>
<span class="kt">int</span><span class="n">nGPUs</span><span class="p">;</span><span class="c1">//number of GPUs</span>
<span class="kt">int</span><span class="n">GPUs</span><span class="p">[</span><span class="n">MAX_CUDA_DESCRIPTOR_GPUS</span><span class="p">];</span><span class="c1">//array of device IDs</span>
<span class="kt">void</span><span class="o">*</span><span class="n">data</span><span class="p">[</span><span class="n">MAX_CUDA_DESCRIPTOR_GPUS</span><span class="p">];</span><span class="c1">//array of pointers to data, one per GPU</span>
<span class="kt">size_t</span><span class="n">size</span><span class="p">[</span><span class="n">MAX_CUDA_DESCRIPTOR_GPUS</span><span class="p">];</span><span class="c1">//array of data sizes, one per GPU</span>
<span class="kt">void</span><span class="o">*</span><span class="n">cudaXtState</span><span class="p">;</span><span class="c1">//opaque CUDA utility structure</span>
<span class="p">};</span>
<span class="k">typedef</span><span class="k">struct</span><span class="nc">cudaXtDesc_t</span><span class="n">cudaXtDesc</span><span class="p">;</span>
</pre>
 <h4>
  <span class="section-number">
   3.10.5.2.
  </span>
  cudaLibXtDesc
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cudalibxtdesc" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  A descriptor type used in multiple GPU routines that contains information about the library used.
 </p>
 <pre><span class="k">struct</span><span class="nc">cudaLibXtDesc_t</span><span class="p">{</span>
<span class="kt">int</span><span class="n">version</span><span class="p">;</span><span class="c1">//descriptor version</span>
<span class="n">cudaXtDesc</span><span class="o">*</span><span class="n">descriptor</span><span class="p">;</span><span class="c1">//multi-GPU memory descriptor</span>
<span class="n">libFormat</span><span class="n">library</span><span class="p">;</span><span class="c1">//which library recognizes the format</span>
<span class="kt">int</span><span class="n">subFormat</span><span class="p">;</span><span class="c1">//library specific enumerator of sub formats</span>
<span class="kt">void</span><span class="o">*</span><span class="n">libDescriptor</span><span class="p">;</span><span class="c1">//library specific descriptor e.g. FFT transform plan object</span>
<span class="p">};</span>
<span class="k">typedef</span><span class="k">struct</span><span class="nc">cudaLibXtDesc_t</span><span class="n">cudaLibXtDesc</span><span class="p">;</span>
</pre>
 <h2>
  <span class="section-number">
   3.11.
  </span>
  cuFFT Callbacks
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-callbacks" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.11.1.
  </span>
  cufftXtSetCallback()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetcallback" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtSetCallback
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   callbackRoutine
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftXtCallbackType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   void
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   callerInfo
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtSetCallback" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtSetCallback()
  </span>
  specifies a load or store callback to be used with the plan. This call is valid only after a call to
  <span class="pre">
   cufftMakePlan*()
  </span>
  , which does the plan generation. If there was already a callback of this type associated with the plan, this new callback routine replaces it. If the new callback requires shared memory, you must call
  <span class="pre">
   cufftXtSetCallbackSharedSize
  </span>
  with the amount of shared memory it needs. cuFFT will not retain the amount of shared memory associated with the previous callback.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    callbackRoutine[In]
    â Array of callback routine pointers, one per GPU.
   </p>
  </li>
  <li>
   <p>
    type[In]
    â Type of callback routine.
   </p>
  </li>
  <li>
   <p>
    callerInfo[In]
    â Optional array of device pointers to caller specific information, one per GPU.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully associated the callback function with the plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle, or a
    <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#streamed-cufft-transforms">
     non-default stream has been associated with the plan in cuFFT prior to 10.4.0
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_SETUP_FAILED
    â The cuFFT library failed to initialize.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.11.2.
  </span>
  cufftXtClearCallback()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtclearcallback" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtClearCallback
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftXtCallbackType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtClearCallback" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtClearCallback()
  </span>
  instructs cuFFT to stop invoking the specified callback type when executing the plan. Only the specified callback is cleared. If no callback of this type had been specified, the return code is
  <span class="pre">
   CUFFT_SUCCESS
  </span>
  .
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    type[In]
    â Type of callback routine.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT successfully disassociated the callback function with the plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle, or a
    <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#streamed-cufft-transforms">
     non-default stream has been associated with the plan in cuFFT prior to 10.4.0
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
 </ul>
 <h3>
  <span class="section-number">
   3.11.3.
  </span>
  cufftXtSetCallbackSharedSize()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftxtsetcallbacksharedsize" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftXtSetCallbackSharedSize
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cufftXtCallbackType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   size_t
  </span>
 </span>
 <span class="n">
  <span class="pre">
   sharedSize
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftXtSetCallbackSharedSize" title="Permalink to this definition">
  ï
 </a>
 <p>
  <span class="pre">
   cufftXtSetCallbackSharedSize()
  </span>
  instructs cuFFT to dynamically allocate shared memory at launch time, for use by the callback. The maximum allowable amount of shared memory is 16K bytes. cuFFT passes a pointer to this shared memory to the callback routine at execution time. This shared memory is only valid for the life of the load or store callback operation. During execution, cuFFT may overwrite shared memory for its own purposes.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â
    <span class="pre">
     cufftHandle
    </span>
    returned by
    <span class="pre">
     cufftCreate
    </span>
    .
   </p>
  </li>
  <li>
   <p>
    type[In]
    â Type of callback routine.
   </p>
  </li>
  <li>
   <p>
    sharedSize[In]
    â Amount of shared memory requested.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â cuFFT will invoke the callback routine with a pointer to the requested amount of shared memory.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle, or a
    <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#streamed-cufft-transforms">
     non-default stream has been associated with the plan in cuFFT prior to 10.4.0
    </a>
    .
   </p>
  </li>
  <li>
   <p>
    CUFFT_INTERNAL_ERROR
    â An internal driver error was detected.
   </p>
  </li>
  <li>
   <p>
    CUFFT_ALLOC_FAILED
    â cuFFT will not be able to allocate the requested amount of shared memory.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.12.
  </span>
  cufftSetStream()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftsetstream" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftSetStream
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <a class="reference internal" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="cufftHandle">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </a>
 <span class="n">
  <span class="pre">
   plan
  </span>
 </span>
 ,
 <span class="n">
  <span class="pre">
   cudaStream_t
  </span>
 </span>
 <span class="n">
  <span class="pre">
   stream
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftSetStream" title="Permalink to this definition">
  ï
 </a>
 <p>
  Associates a CUDA stream with a cuFFT plan. All kernel launches made during plan execution are now done through the associated stream, enabling overlap with activity in other streams (e.g. data copying). The association remains until the plan is destroyed or the stream is changed with another call to
  <span class="pre">
   cufftSetStream()
  </span>
  .
 </p>
 <p>
  Note that starting from CUDA 11.2 (cuFFT 10.4.0),
  <span class="pre">
   cufftSetStream()
  </span>
  is supported on multi-GPU plans. When associating a stream with a plan,
  <span class="pre">
   cufftXtMemcpy()
  </span>
  remains synchronous across the multiple GPUs. For previous versions of cuFFT,
  <span class="pre">
   cufftSetStream()
  </span>
  will return an error in multiple GPU plans.
 </p>
 <p>
  Note that starting from CUDA 12.2 (cuFFT 11.0.8), on multi-GPU plans,
  <span class="pre">
   stream
  </span>
  can be associated with any context on any GPU. However, repeated calls to
  <span class="pre">
   cufftSetStream()
  </span>
  with streams from different contexts incur a small time penalty. Optimal performance is obtained when repeated calls to
  <span class="pre">
   cufftSetStream
  </span>
  use streams from the same CUDA context.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    plan[In]
    â The
    <span class="pre">
     cufftHandle
    </span>
    object to associate with the stream.
   </p>
  </li>
  <li>
   <p>
    stream[In]
    â A valid CUDA stream created with
    <span class="pre">
     cudaStreamCreate()
    </span>
    ;
    <span class="pre">
     0
    </span>
    for the default stream.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â The stream was associated with the plan.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_PLAN
    â The
    <span class="pre">
     plan
    </span>
    parameter is not a valid handle, or plan is multi-gpu in cuFFT version prior to 10.4.0.
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.13.
  </span>
  cufftGetVersion()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetversion" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetVersion
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   version
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetVersion" title="Permalink to this definition">
  ï
 </a>
 <p>
  Returns the version number of cuFFT.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    *version[In]
    â Pointer to the version number.
   </p>
  </li>
  <li>
   <p>
    *version[Out]
    â Contains the version number.
   </p>
  </li>
 </ul>
 Return values
 <p>
  CUFFT_SUCCESS
  â cuFFT successfully returned the version number.
 </p>
 <h2>
  <span class="section-number">
   3.14.
  </span>
  cufftGetProperty()
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftgetproperty" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <span class="n">
  <span class="pre">
   cufftResult
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftGetProperty
   </span>
  </span>
 </span>
 <span class="sig-paren">
  (
 </span>
 <span class="n">
  <span class="pre">
   libraryPropertyType
  </span>
 </span>
 <span class="n">
  <span class="pre">
   type
  </span>
 </span>
 ,
 <span class="kt">
  <span class="pre">
   int
  </span>
 </span>
 <span class="p">
  <span class="pre">
   *
  </span>
 </span>
 <span class="n">
  <span class="pre">
   value
  </span>
 </span>
 <span class="sig-paren">
  )
 </span>
 <span class="p">
  <span class="pre">
   ;
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftGetProperty" title="Permalink to this definition">
  ï
 </a>
 <p>
  Return in
  <span class="pre">
   *value
  </span>
  the number for the property described by
  <span class="pre">
   type
  </span>
  of the dynamically linked CUFFT library.
 </p>
 Parameters
 <ul class="simple">
  <li>
   <p>
    type[In]
    â CUDA library property.
   </p>
  </li>
  <li>
   <p>
    value[Out]
    â Contains the integer value for the requested property.
   </p>
  </li>
 </ul>
 Return values
 <ul class="simple">
  <li>
   <p>
    CUFFT_SUCCESS
    â The property value was successfully returned.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_TYPE
    â The property type is not recognized.
   </p>
  </li>
  <li>
   <p>
    CUFFT_INVALID_VALUE
    â
    <span class="pre">
     value
    </span>
    is
    <span class="pre">
     NULL
    </span>
    .
   </p>
  </li>
 </ul>
 <h2>
  <span class="section-number">
   3.15.
  </span>
  cuFFT Types
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-types" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.15.1.
  </span>
  Parameter cufftType
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#parameter-cuffttype" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The cuFFT library supports complex- and real-data transforms. The
  <span class="pre">
   cufftType
  </span>
  data type is an enumeration of the types of transform data supported by cuFFT.
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">cufftType_t</span><span class="p">{</span>
<span class="n">CUFFT_R2C</span><span class="o">=</span><span class="mh">0x2a</span><span class="p">,</span><span class="c1">// Real to complex (interleaved)</span>
<span class="n">CUFFT_C2R</span><span class="o">=</span><span class="mh">0x2c</span><span class="p">,</span><span class="c1">// Complex (interleaved) to real</span>
<span class="n">CUFFT_C2C</span><span class="o">=</span><span class="mh">0x29</span><span class="p">,</span><span class="c1">// Complex to complex (interleaved)</span>
<span class="n">CUFFT_D2Z</span><span class="o">=</span><span class="mh">0x6a</span><span class="p">,</span><span class="c1">// Double to double-complex (interleaved)</span>
<span class="n">CUFFT_Z2D</span><span class="o">=</span><span class="mh">0x6c</span><span class="p">,</span><span class="c1">// Double-complex (interleaved) to double</span>
<span class="n">CUFFT_Z2Z</span><span class="o">=</span><span class="mh">0x69</span><span class="c1">// Double-complex to double-complex (interleaved)</span>
<span class="p">}</span><span class="n">cufftType</span><span class="p">;</span>
</pre>
 <h3>
  <span class="section-number">
   3.15.2.
  </span>
  Parameters for Transform Direction
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#parameters-for-transform-direction" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The cuFFT library defines forward and inverse Fast Fourier Transforms according to the sign of the complex exponential term.
 </p>
 <pre><span class="cp">#define cuFFTFORWARD -1</span>
<span class="cp">#define cuFFTINVERSE 1</span>
</pre>
 <p>
  cuFFT performs un-normalized FFTs; that is, performing a forward FFT on an input data set followed by an inverse FFT on the resulting set yields data that is equal to the input, scaled by the number of elements. Scaling either transform by the reciprocal of the size of the data set is left for the user to perform as seen fit.
 </p>
 <h3>
  <span class="section-number">
   3.15.3.
  </span>
  Type definitions for callbacks
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#type-definitions-for-callbacks" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The cuFFT library supports callback funtions for all combinations of single or double precision, real or complex data, load or store. These are enumerated in the parameter
  <span class="pre">
   cufftXtCallbackType
  </span>
  .
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">cufftXtCallbackType_t</span><span class="p">{</span>
<span class="n">CUFFT_CB_LD_COMPLEX</span><span class="o">=</span><span class="mh">0x0</span><span class="p">,</span>
<span class="n">CUFFT_CB_LD_COMPLEX_DOUBLE</span><span class="o">=</span><span class="mh">0x1</span><span class="p">,</span>
<span class="n">CUFFT_CB_LD_REAL</span><span class="o">=</span><span class="mh">0x2</span><span class="p">,</span>
<span class="n">CUFFT_CB_LD_REAL_DOUBLE</span><span class="o">=</span><span class="mh">0x3</span><span class="p">,</span>
<span class="n">CUFFT_CB_ST_COMPLEX</span><span class="o">=</span><span class="mh">0x4</span><span class="p">,</span>
<span class="n">CUFFT_CB_ST_COMPLEX_DOUBLE</span><span class="o">=</span><span class="mh">0x5</span><span class="p">,</span>
<span class="n">CUFFT_CB_ST_REAL</span><span class="o">=</span><span class="mh">0x6</span><span class="p">,</span>
<span class="n">CUFFT_CB_ST_REAL_DOUBLE</span><span class="o">=</span><span class="mh">0x7</span><span class="p">,</span>
<span class="n">CUFFT_CB_UNDEFINED</span><span class="o">=</span><span class="mh">0x8</span>
<span class="p">}</span><span class="n">cufftXtCallbackType</span><span class="p">;</span>
</pre>
 <p>
  The corresponding function prototypes and pointer type definitions are as follows:
 </p>
 <pre><span class="k">typedef</span><span class="n">cufftComplex</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadC</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="n">cufftDoubleComplex</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadZ</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="n">cufftReal</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadR</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="n">cufftDoubleReal</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackLoadD</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataIn</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>


<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreC</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="n">cufftComplex</span><span class="n">element</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreZ</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="n">cufftDoubleComplex</span><span class="n">element</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreR</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="n">cufftReal</span><span class="n">element</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>

<span class="k">typedef</span><span class="kt">void</span><span class="p">(</span><span class="o">*</span><span class="n">cufftCallbackStoreD</span><span class="p">)(</span><span class="kt">void</span><span class="o">*</span><span class="n">dataOut</span><span class="p">,</span><span class="kt">size_t</span><span class="n">offset</span><span class="p">,</span><span class="n">cufftDoubleReal</span><span class="n">element</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">callerInfo</span><span class="p">,</span><span class="kt">void</span><span class="o">*</span><span class="n">sharedPointer</span><span class="p">);</span>
</pre>
 <h3>
  <span class="section-number">
   3.15.4.
  </span>
  Other cuFFT Types
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#other-cufft-types" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <h4>
  <span class="section-number">
   3.15.4.1.
  </span>
  cufftHandle
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cuffthandle" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <span class="k">
  <span class="pre">
   type
  </span>
 </span>
 <span class="sig-name descname">
  <span class="n">
   <span class="pre">
    cufftHandle
   </span>
  </span>
 </span>
 <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#c.cufftHandle" title="Permalink to this definition">
  ï
 </a>
 <p>
  A handle type used to store and access cuFFT plans. The user receives a handle after creating a cuFFT plan and uses this handle to execute the plan.
 </p>
 <pre><span class="k">typedef</span><span class="kt">unsigned</span><span class="kt">int</span><span class="n">cufftHandle</span><span class="p">;</span>
</pre>
 <h4>
  <span class="section-number">
   3.15.4.2.
  </span>
  cufftReal
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftreal" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  A single-precision, floating-point real data type.
 </p>
 <pre><span class="k">typedef</span><span class="kt">float</span><span class="n">cufftReal</span><span class="p">;</span>
</pre>
 <h4>
  <span class="section-number">
   3.15.4.3.
  </span>
  cufftDoubleReal
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftdoublereal" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  A double-precision, floating-point real data type.
 </p>
 <pre><span class="k">typedef</span><span class="kt">double</span><span class="n">cufftDoubleReal</span><span class="p">;</span>
</pre>
 <h4>
  <span class="section-number">
   3.15.4.4.
  </span>
  cufftComplex
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftcomplex" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  A single-precision, floating-point complex data type that consists of interleaved real and imaginary components.
 </p>
 <pre><span class="k">typedef</span><span class="n">cuComplex</span><span class="n">cufftComplex</span><span class="p">;</span>
</pre>
 <h4>
  <span class="section-number">
   3.15.4.5.
  </span>
  cufftDoubleComplex
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufftdoublecomplex" title="Permalink to this headline">
   ï
  </a>
 </h4>
 <p>
  A double-precision, floating-point complex data type that consists of interleaved real and imaginary components.
 </p>
 <pre><span class="k">typedef</span><span class="n">cuDoubleComplex</span><span class="n">cufftDoubleComplex</span><span class="p">;</span>
</pre>
 <h2>
  <span class="section-number">
   3.16.
  </span>
  Common types
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#common-types" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <h3>
  <span class="section-number">
   3.16.1.
  </span>
  cudaDataType
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cudadatatype" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  <span class="pre">
   cudaDataType
  </span>
  data type is an enumeration of the types supported by CUDA libraries.
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">cudaDataType_t</span>
<span class="p">{</span>
<span class="n">CUDA_R_16F</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="c1">// 16 bit real</span>
<span class="n">CUDA_C_16F</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="c1">// 16 bit complex</span>
<span class="n">CUDA_R_32F</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="c1">// 32 bit real</span>
<span class="n">CUDA_C_32F</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="c1">// 32 bit complex</span>
<span class="n">CUDA_R_64F</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="c1">// 64 bit real</span>
<span class="n">CUDA_C_64F</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="c1">// 64 bit complex</span>
<span class="n">CUDA_R_8I</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="c1">// 8 bit real as a signed integer</span>
<span class="n">CUDA_C_8I</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span><span class="c1">// 8 bit complex as a pair of signed integers</span>
<span class="n">CUDA_R_8U</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="c1">// 8 bit real as an unsigned integer</span>
<span class="n">CUDA_C_8U</span><span class="o">=</span><span class="mi">9</span><span class="c1">// 8 bit complex as a pair of unsigned integers</span>
<span class="p">}</span><span class="n">cudaDataType</span><span class="p">;</span>
</pre>
 <h3>
  <span class="section-number">
   3.16.2.
  </span>
  libraryPropertyType
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#librarypropertytype" title="Permalink to this headline">
   ï
  </a>
 </h3>
 <p>
  The
  <span class="pre">
   libraryPropertyType
  </span>
  data type is an enumeration of library property types. (ie. CUDA version X.Y.Z would yield
  <span class="pre">
   MAJOR_VERSION=X
  </span>
  ,
  <span class="pre">
   MINOR_VERSION=Y
  </span>
  ,
  <span class="pre">
   PATCH_LEVEL=Z
  </span>
  )
 </p>
 <pre><span class="k">typedef</span><span class="k">enum</span><span class="nc">libraryPropertyType_t</span>
<span class="p">{</span>
<span class="n">MAJOR_VERSION</span><span class="p">,</span>
<span class="n">MINOR_VERSION</span><span class="p">,</span>
<span class="n">PATCH_LEVEL</span>
<span class="p">}</span><span class="n">libraryPropertyType</span><span class="p">;</span>
</pre>
 <h1>
  <span class="section-number">
   4.
  </span>
  cuFFT Code Examples
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#cufft-code-examples" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  For simple examples of complex and real 1D, 2D, and 3D transforms that use cuFFT to perform forward and inverse FFTs, refer to the cuFFT Library samples on
  <a class="reference external" href="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuFFT">
   GitHub
  </a>
  .
 </p>
 <h1>
  <span class="section-number">
   5.
  </span>
  Multiple GPU Data Organization
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  This chapter explains how data are distributed between the GPUs, before and after a multiple GPU transform. For simplicity, it is assumed in this chapter that the caller has specified GPU 0 and GPU 1 to perform the transform.
 </p>
 <h2>
  <span class="section-number">
   5.1.
  </span>
  Multiple GPU Data Organization for Batched Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization-for-batched-transforms" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  For batches of transforms, each individual transform is executed on a single GPU. If possible the batches are evenly distributed among the GPUs. For a batch of size
  <span class="pre">
   m
  </span>
  performed on
  <span class="pre">
   n
  </span>
  GPUs, where
  <span class="pre">
   m
  </span>
  is not divisible by
  <span class="pre">
   n
  </span>
  , the first
  <span class="pre">
   m
  </span>
  <span class="pre">
   %
  </span>
  <span class="pre">
   n
  </span>
  GPUs will perform
  <span class="math notranslate nohighlight">
   \(\left\lfloor \frac{m}{n} \right\rfloor+\ 1\)
  </span>
  transforms. The remaining GPUs will perform
  <span class="math notranslate nohighlight">
   \(\left\lfloor \frac{m}{n} \right\rfloor\)
  </span>
  transforms. For example, in a batch of 15 transforms performed on 4 GPUs, the first three GPUs would perform 4 transforms, and the last GPU would perform 3 transforms. This approach removes the need for data exchange between the GPUs, and results in nearly perfect scaling for cases where the batch size is divisible by the number of GPUs.
 </p>
 <h2>
  <span class="section-number">
   5.2.
  </span>
  Multiple GPU Data Organization for Single 2D and 3D Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization-for-single-2d-and-3d-transforms" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  Single transforms performed on multiple GPUs require the data to be divided between the GPUs. Then execution takes place in phases. For example with 2 GPUs, for 2D and 3D transforms with even sized dimensions, each GPU does half of the transform in (rank - 1) dimensions. Then data are exchanged between the GPUs so that the final dimension can be processed.
 </p>
 <p>
  Since 2D and 3D transforms support sizes other than powers of 2, it is possible that the data can not be evenly distributed among the GPUs. In general for the case of
  <span class="pre">
   n
  </span>
  GPUs, a dimension of size
  <span class="pre">
   m
  </span>
  that is not a multiple of
  <span class="pre">
   n
  </span>
  would be distributed such that the first
  <span class="pre">
   m
  </span>
  <span class="pre">
   %
  </span>
  <span class="pre">
   n
  </span>
  GPUs would get one extra row for 2D transforms, one extra plane for 3D transforms.
 </p>
 <p>
  Take for example, a 2D transform on 4 GPUs, using an array declared in C as
  <span class="pre">
   data[x][y]
  </span>
  , where
  <span class="pre">
   x
  </span>
  is 65 and
  <span class="pre">
   y
  </span>
  is 99. The surface is distributed prior to the transform such that GPU 0 receives a surface with dimensions
  <span class="pre">
   [17][99]
  </span>
  , and GPUs 1â¦3 receive surfaces with dimensions
  <span class="pre">
   [16][99]
  </span>
  . After the transform, each GPU again has a portion of the surface, but divided in the y dimension. GPUs 0â¦2 have surfaces with dimensions
  <span class="pre">
   [65][25]
  </span>
  . GPU 3 has a surface with dimensions
  <span class="pre">
   [65][24]
  </span>
 </p>
 <p>
  For a 3D transform on 4 GPUs consider an array declared in C as
  <span class="pre">
   data[x][y][z]
  </span>
  , where
  <span class="pre">
   x
  </span>
  is 103,
  <span class="pre">
   y
  </span>
  is 122, and
  <span class="pre">
   z
  </span>
  is 64. The volume is distributed prior to the transform such that each GPUs 0â¦2 receive volumes with dimensions
  <span class="pre">
   [26][122][64]
  </span>
  , and GPU 3 receives a volume with dimensions
  <span class="pre">
   [25][122][64]
  </span>
  . After the transform, each GPU again has a portion of the surface, but divided in the y dimension. GPUs 0 and 1 have a volumes with dimensions
  <span class="pre">
   [103][31][64]
  </span>
  , and GPUs 2 and 3 have volumes with dimensions
  <span class="pre">
   [103][30][64]
  </span>
  .
 </p>
 <h2>
  <span class="section-number">
   5.3.
  </span>
  Multiple-GPU Data Organization for Single 1D Transforms
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#multiple-gpu-data-organization-for-single-1d-transforms" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  By default for 1D transforms, the initial distribution of data to the GPUs is similar to the 2D and 3D cases. For a transform of dimension x on two GPUs, GPU 0 receives data ranging from 0â¦(x/2-1). GPU 1 receives data ranging from (x/2)â¦(x-1). Similarly, with 4 GPUs, the data are evenly distributed among all 4 GPUs.
 </p>
 <p>
  Before computation can begin, data are redistributed among the GPUs. It is possible to perform this redistribution in the copy from host memory, in cases where the application does not need to pre-process the data prior to the transform. To do this, the application can create the data descriptor with
  <span class="pre">
   cufftXtMalloc
  </span>
  using the sub-format
  <span class="pre">
   CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
  </span>
  . This can significantly reduce the time it takes to execute the transform.
 </p>
 <p>
  cuFFT performs multiple GPU 1D transforms by decomposing the transform size into factors
  <span class="pre">
   Factor1
  </span>
  and
  <span class="pre">
   Factor2
  </span>
  , and treating the data as a grid of size
  <span class="pre">
   Factor1
  </span>
  x
  <span class="pre">
   Factor2
  </span>
  . The four steps done to calculate the 1D FFT are:
  <span class="pre">
   Factor1
  </span>
  transforms of size
  <span class="pre">
   Factor2
  </span>
  , data exchange between the GPUs, a pointwise twiddle multiplication, and
  <span class="pre">
   Factor2
  </span>
  transforms of size
  <span class="pre">
   Factor1
  </span>
  .
 </p>
 <p>
  To gain efficiency by overlapping computation with data exchange, cuFFT breaks the whole transform into independent segments or strings, which can be processed while others are in flight. A side effect of this algorithm is that the output of the transform is not in linear order. The output in GPU memory is in strings, each of which is composed of
  <span class="pre">
   Factor2
  </span>
  substrings of equal size. Each substring contains contiguous results starting
  <span class="pre">
   Factor1
  </span>
  elements subsequent to start of the previous substring. Each string starts substring size elements after the start of the previous string. The strings appear in order, the first half on GPU 0, and the second half on GPU 1. See the example below:
 </p>
 <pre><span class="n">transform</span><span class="n">size</span><span class="o">=</span><span class="mi">1024</span>
<span class="n">number</span><span class="n">of</span><span class="n">strings</span><span class="o">=</span><span class="mi">8</span>
<span class="n">Factor1</span><span class="o">=</span><span class="mi">64</span>
<span class="n">Factor2</span><span class="o">=</span><span class="mi">16</span>
<span class="n">substrings</span><span class="n">per</span><span class="n">string</span><span class="k">for</span><span class="n">output</span><span class="n">layout</span><span class="n">is</span><span class="n">Factor2</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
<span class="n">string</span><span class="n">size</span><span class="o">=</span><span class="mi">1024</span><span class="o">/</span><span class="mi">8</span><span class="o">=</span><span class="mi">128</span>
<span class="n">substring</span><span class="n">size</span><span class="o">=</span><span class="mi">128</span><span class="o">/</span><span class="mi">16</span><span class="o">=</span><span class="mi">8</span>
<span class="n">stride</span><span class="n">between</span><span class="n">substrings</span><span class="o">=</span><span class="mi">1024</span><span class="o">/</span><span class="mi">16</span><span class="o">=</span><span class="n">Factor1</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>

<span class="n">On</span><span class="n">GPU</span><span class="mi">0</span><span class="o">:</span>
<span class="n">string</span><span class="mi">0</span><span class="n">has</span><span class="n">substrings</span><span class="n">with</span><span class="n">indices</span><span class="mf">0.</span><span class="p">.</span><span class="mf">.7</span><span class="mf">64.</span><span class="p">.</span><span class="mf">.71</span><span class="mf">128.</span><span class="p">.</span><span class="mf">.135</span><span class="p">...</span><span class="mf">960.</span><span class="p">.</span><span class="mf">.967</span>
<span class="n">string</span><span class="mi">1</span><span class="n">has</span><span class="n">substrings</span><span class="n">with</span><span class="n">indices</span><span class="mf">8.</span><span class="p">.</span><span class="mf">.15</span><span class="mf">72.</span><span class="p">.</span><span class="mf">.79</span><span class="mf">136.</span><span class="p">.</span><span class="mf">.143</span><span class="p">...</span><span class="mf">968.</span><span class="p">.</span><span class="mf">.975</span>
<span class="p">...</span>
<span class="n">On</span><span class="n">GPU</span><span class="mi">1</span><span class="o">:</span>
<span class="n">string</span><span class="mi">4</span><span class="n">has</span><span class="n">substrings</span><span class="n">with</span><span class="n">indices</span><span class="mf">32.</span><span class="p">.</span><span class="mf">.39</span><span class="mf">96.</span><span class="p">.</span><span class="mf">.103</span><span class="mf">160.</span><span class="p">.</span><span class="mf">.167</span><span class="p">...</span><span class="mf">992.</span><span class="p">.</span><span class="mf">.999</span>
<span class="p">...</span>
<span class="n">string</span><span class="mi">7</span><span class="n">has</span><span class="n">substrings</span><span class="n">with</span><span class="n">indices</span><span class="mf">56.</span><span class="p">.</span><span class="mf">.63</span><span class="mf">120.</span><span class="p">.</span><span class="mf">.127</span><span class="mf">184.</span><span class="p">.</span><span class="mf">.191</span><span class="p">...</span><span class="mf">1016.</span><span class="p">.</span><span class="mf">.1023</span>
</pre>
 <p>
  The cufftXtQueryPlan API allows the caller to retrieve a structure containing the number of strings, the decomposition factors, and (in the case of power of 2 size) some useful mask and shift elements. The example below shows how cufftXtQueryPlan is invoked. It also shows how to translate from an index in the host input array to the corresponding index on the device, and vice versa.
 </p>
 <pre><span class="cm">/*</span>
<span class="cm"> * These routines demonstrate the use of cufftXtQueryPlan to get the 1D</span>
<span class="cm"> * factorization and convert between permuted and linear indexes.</span>
<span class="cm"> */</span>
<span class="cm">/*</span>
<span class="cm"> * Set up a 1D plan that will execute on GPU 0 and GPU1, and query</span>
<span class="cm"> * the decomposition factors</span>
<span class="cm"> */</span>
<span class="kt">int</span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="n">argc</span><span class="p">,</span><span class="kt">char</span><span class="o">**</span><span class="n">argv</span><span class="p">){</span>
<span class="n">cufftHandle</span><span class="n">plan</span><span class="p">;</span>
<span class="n">cufftResult</span><span class="n">stat</span><span class="p">;</span>
<span class="kt">int</span><span class="n">whichGPUs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">};</span>
<span class="n">cufftXt1dFactors</span><span class="n">factors</span><span class="p">;</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cufftCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">plan</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUFFT_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"Create error %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">stat</span><span class="p">);</span>
<span class="k">return</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cufftXtSetGPUs</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">whichGPUs</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUFFT_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"SetGPU error %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">stat</span><span class="p">);</span>
<span class="k">return</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cufftMakePlan1d</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span><span class="n">size</span><span class="p">,</span><span class="n">CUFFT_C2C</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">workSizes</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUFFT_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"MakePlan error %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">stat</span><span class="p">);</span>
<span class="k">return</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">stat</span><span class="o">=</span><span class="n">cufftXtQueryPlan</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">factors</span><span class="p">,</span><span class="n">CUFFT_QUERY_1D_FACTORS</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="n">stat</span><span class="o">!=</span><span class="n">CUFFT_SUCCESS</span><span class="p">)</span><span class="p">{</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"QueryPlan error %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">stat</span><span class="p">);</span>
<span class="k">return</span><span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">printf</span><span class="p">(</span><span class="s">"Factor 1 %zd, Factor2 %zd</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">factors</span><span class="p">.</span><span class="n">factor1</span><span class="p">,</span><span class="n">factors</span><span class="p">.</span><span class="n">factor2</span><span class="p">);</span>
<span class="n">cufftDestroy</span><span class="p">(</span><span class="n">plan</span><span class="p">);</span>
<span class="k">return</span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre>
 <pre><span class="cm">/*</span>
<span class="cm"> * Given an index into a permuted array, and the GPU index return the</span>
<span class="cm"> * corresponding linear index from the beginning of the input buffer.</span>
<span class="cm"> *</span>
<span class="cm"> * Parameters:</span>
<span class="cm"> *      factors     input:  pointer to cufftXt1dFactors as returned by</span>
<span class="cm"> *                          cufftXtQueryPlan</span>
<span class="cm"> *      permutedIx  input:  index of the desired element in the device output</span>
<span class="cm"> *                          array</span>
<span class="cm"> *      linearIx    output: index of the corresponding input element in the</span>
<span class="cm"> *                          host array</span>
<span class="cm"> *      GPUix       input:  index of the GPU containing the desired element</span>
<span class="cm"> */</span>
<span class="n">cufftResult</span><span class="nf">permuted2Linear</span><span class="p">(</span><span class="n">cufftXt1dFactors</span><span class="o">*</span><span class="n">factors</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">permutedIx</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">linearIx</span><span class="p">,</span>
<span class="kt">int</span><span class="n">GPUIx</span><span class="p">)</span><span class="p">{</span>
<span class="kt">size_t</span><span class="n">indexInSubstring</span><span class="p">;</span>
<span class="kt">size_t</span><span class="n">whichString</span><span class="p">;</span>
<span class="kt">size_t</span><span class="n">whichSubstring</span><span class="p">;</span>
<span class="c1">// the low order bits of the permuted index match those of the linear index</span>
<span class="n">indexInSubstring</span><span class="o">=</span><span class="n">permutedIx</span><span class="o">&amp;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringMask</span><span class="p">;</span>
<span class="c1">// the next higher bits are the substring index</span>
<span class="n">whichSubstring</span><span class="o">=</span><span class="p">(</span><span class="n">permutedIx</span><span class="o">&gt;&gt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringShift</span><span class="p">)</span><span class="o">&amp;</span>
<span class="n">factors</span><span class="o">-&gt;</span><span class="n">factor2Mask</span><span class="p">;</span>
<span class="c1">// the next higher bits are the string index on this GPU</span>
<span class="n">whichString</span><span class="o">=</span><span class="p">(</span><span class="n">permutedIx</span><span class="o">&gt;&gt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringShift</span><span class="p">)</span><span class="o">&amp;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringMask</span><span class="p">;</span>
<span class="c1">// now adjust the index for the second GPU</span>
<span class="k">if</span><span class="p">(</span><span class="n">GPUIx</span><span class="p">)</span><span class="p">{</span>
<span class="n">whichString</span><span class="o">+=</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringCount</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// linear index low order bits are the same</span>
<span class="c1">// next higher linear index bits are the string index</span>
<span class="o">*</span><span class="n">linearIx</span><span class="o">=</span><span class="n">indexInSubstring</span><span class="o">+</span><span class="p">(</span><span class="n">whichString</span><span class="o">&lt;&lt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringShift</span><span class="p">);</span>
<span class="c1">// next higher bits of linear address are the substring index</span>
<span class="o">*</span><span class="n">linearIx</span><span class="o">+=</span><span class="n">whichSubstring</span><span class="o">&lt;&lt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">factor1Shift</span><span class="p">;</span>
<span class="k">return</span><span class="n">CUFFT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre>
 <pre><span class="cm">/*</span>
<span class="cm"> * Given a linear index into a 1D array, return the GPU containing the permuted</span>
<span class="cm"> * result, and index from the start of the data buffer for that element.</span>
<span class="cm"> *</span>
<span class="cm"> * Parameters:</span>
<span class="cm"> *      factors     input:  pointer to cufftXt1dFactors as returned by</span>
<span class="cm"> *                          cufftXtQueryPlan</span>
<span class="cm"> *      linearIx    input:  index of the desired element in the host input</span>
<span class="cm"> *                          array</span>
<span class="cm"> *      permutedIx  output: index of the corresponding result in the device</span>
<span class="cm"> *                          output array</span>
<span class="cm"> *      GPUix       output: index of the GPU containing the result</span>
<span class="cm"> */</span>
<span class="n">cufftResult</span><span class="nf">linear2Permuted</span><span class="p">(</span><span class="n">cufftXt1dFactors</span><span class="o">*</span><span class="n">factors</span><span class="p">,</span>
<span class="kt">size_t</span><span class="n">linearIx</span><span class="p">,</span>
<span class="kt">size_t</span><span class="o">*</span><span class="n">permutedIx</span><span class="p">,</span>
<span class="kt">int</span><span class="o">*</span><span class="n">GPUIx</span><span class="p">)</span><span class="p">{</span>
<span class="kt">size_t</span><span class="n">indexInSubstring</span><span class="p">;</span>
<span class="kt">size_t</span><span class="n">whichString</span><span class="p">;</span>
<span class="kt">size_t</span><span class="n">whichSubstring</span><span class="p">;</span>
<span class="kt">size_t</span><span class="n">whichStringMask</span><span class="p">;</span>
<span class="kt">int</span><span class="n">whichStringShift</span><span class="p">;</span>
<span class="k">if</span><span class="p">(</span><span class="n">linearIx</span><span class="o">&gt;=</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">size</span><span class="p">)</span><span class="p">{</span>
<span class="k">return</span><span class="n">CUFFT_INVALID_VALUE</span><span class="p">;</span>
<span class="p">}</span>
<span class="c1">// get a useful additional mask and shift count</span>
<span class="n">whichStringMask</span><span class="o">=</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringCount</span><span class="mi">-1</span><span class="p">;</span>
<span class="n">whichStringShift</span><span class="o">=</span><span class="p">(</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">factor1Shift</span><span class="o">+</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">factor2Shift</span><span class="p">)</span><span class="o">-</span>
<span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringShift</span><span class="p">;</span>
<span class="c1">// the low order bits identify the index within the substring</span>
<span class="n">indexInSubstring</span><span class="o">=</span><span class="n">linearIx</span><span class="o">&amp;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringMask</span><span class="p">;</span>
<span class="c1">// first determine which string has our linear index.</span>
<span class="c1">// the low order bits indentify the index within the substring.</span>
<span class="c1">// the next higher order bits identify which string.</span>
<span class="n">whichString</span><span class="o">=</span><span class="p">(</span><span class="n">linearIx</span><span class="o">&gt;&gt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringShift</span><span class="p">)</span><span class="o">&amp;</span><span class="n">whichStringMask</span><span class="p">;</span>
<span class="c1">// the first stringCount/2 strings are in the first GPU,</span>
<span class="c1">// the rest are in the second.</span>
<span class="o">*</span><span class="n">GPUIx</span><span class="o">=</span><span class="n">whichString</span><span class="o">/</span><span class="p">(</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringCount</span><span class="o">/</span><span class="mi">2</span><span class="p">);</span>
<span class="c1">// next determine which substring within the string has our index</span>
<span class="c1">// the substring index is in the next higher order bits of the index</span>
<span class="n">whichSubstring</span><span class="o">=</span><span class="p">(</span><span class="n">linearIx</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringShift</span><span class="o">+</span><span class="n">whichStringShift</span><span class="p">))</span><span class="o">&amp;</span>
<span class="n">factors</span><span class="o">-&gt;</span><span class="n">factor2Mask</span><span class="p">;</span>
<span class="c1">// now we can re-assemble the index</span>
<span class="o">*</span><span class="n">permutedIx</span><span class="o">=</span><span class="n">indexInSubstring</span><span class="p">;</span>
<span class="o">*</span><span class="n">permutedIx</span><span class="o">+=</span><span class="n">whichSubstring</span><span class="o">&lt;&lt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">substringShift</span><span class="p">;</span>
<span class="k">if</span><span class="p">(</span><span class="o">!*</span><span class="n">GPUIx</span><span class="p">)</span><span class="p">{</span>
<span class="o">*</span><span class="n">permutedIx</span><span class="o">+=</span><span class="n">whichString</span><span class="o">&lt;&lt;</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringShift</span><span class="p">;</span>
<span class="p">}</span><span class="k">else</span><span class="p">{</span>
<span class="o">*</span><span class="n">permutedIx</span><span class="o">+=</span><span class="p">(</span><span class="n">whichString</span><span class="o">-</span><span class="p">(</span><span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringCount</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="p">)</span><span class="o">&lt;&lt;</span>
<span class="n">factors</span><span class="o">-&gt;</span><span class="n">stringShift</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">return</span><span class="n">CUFFT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre>
 <h1>
  <span class="section-number">
   6.
  </span>
  FFTW Conversion Guide
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#fftw-conversion-guide" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  cuFFT differs from FFTW in that FFTW has many plans and a single execute function while cuFFT has fewer plans, but multiple execute functions. The cuFFT execute functions determine the precision (single or double) and whether the input is complex or real valued. The following table shows the relationship between the two interfaces.
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     FFTW function
    </p>
   </th>
   <th class="head">
    <p>
     cuFFT function
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      fftw_plan_dft_1d(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c_1d(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r_1d()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftPlan1d()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      fftw_plan_dft_2d(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c_2d(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r_2d()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftPlan2d()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      fftw_plan_dft_3d(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c_3d(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r_3d()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftPlan3d()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      fftw_plan_dft(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftPlanMany()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      fftw_plan_many_dft(),
     </span>
     <span class="pre">
      fftw_plan_many_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_many_dft_c2r()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftPlanMany()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     <span class="pre">
      fftw_execute()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftExecC2C(),
     </span>
     <span class="pre">
      cufftExecZ2Z(),
     </span>
     <span class="pre">
      cufftExecR2C(),
     </span>
     <span class="pre">
      cufftExecD2Z(),
     </span>
     <span class="pre">
      cufftExecC2R(),
     </span>
     <span class="pre">
      cufftExecZ2D()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     <span class="pre">
      fftw_destroy_plan()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      cufftDestroy()
     </span>
    </p>
   </td>
  </tr>
 </table>
 <h1>
  <span class="section-number">
   7.
  </span>
  FFTW Interface to cuFFT
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#fftw-interface-to-cufft" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  NVIDIA provides FFTW3 interfaces to the cuFFT library. This allows applications using FFTW to use NVIDIA GPUs with minimal modifications to program source code. To use the interface first do the following two steps
 </p>
 <ul class="simple">
  <li>
   <p>
    It is recommended that you replace the include file
    <span class="pre">
     fftw3.h
    </span>
    with
    <span class="pre">
     cufftw.h
    </span>
   </p>
  </li>
  <li>
   <p>
    Instead of linking with the double/single precision libraries such as
    <span class="pre">
     fftw3/fftw3f
    </span>
    libraries, link with both the cuFFT and cuFFTW libraries
   </p>
  </li>
  <li>
   <p>
    Ensure the search path includes the directory containing
    <span class="pre">
     cuda_runtime_api.h
    </span>
   </p>
  </li>
 </ul>
 <p>
  After an application is working using the FFTW3 interface, users may want to modify their code to move data to and from the GPU and use the routines documented in the
  <a class="reference external" href="https://docs.nvidia.com/cuda/cufft/index.html#fftw-conversion-guide">
   FFTW Conversion Guide
  </a>
  for the best performance.
 </p>
 <p>
  The following tables show which components and functions of FFTW3 are supported in cuFFT.
 </p>
 <table class="table-no-stripes docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Section in FFTW manual
    </p>
   </th>
   <th class="head">
    <p>
     Supported
    </p>
   </th>
   <th class="head">
    <p>
     Unsupported
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Complex numbers
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_complex,
     </span>
     <span class="pre">
      fftwf_complex
     </span>
     types
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Precision
    </p>
   </td>
   <td>
    <p>
     double
     <span class="pre">
      fftw3
     </span>
     , single
     <span class="pre">
      fftwf3
     </span>
    </p>
   </td>
   <td>
    <p>
     long double
     <span class="pre">
      fftw3l
     </span>
     , quad precision
     <span class="pre">
      fftw3q
     </span>
     are not supported since CUDA functions operate on double and single precision floating-point quantities
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Memory Allocation
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_malloc(),
     </span>
     <span class="pre">
      fftw_free(),
     </span>
     <span class="pre">
      fftw_alloc_real(),
     </span>
     <span class="pre">
      fftw_alloc_complex(),
     </span>
     <span class="pre">
      fftwf_alloc_real(),
     </span>
     <span class="pre">
      fftwf_alloc_complex()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Multi-threaded FFTW
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw3_threads,
     </span>
     <span class="pre">
      fftw3_omp
     </span>
     are not supported
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Distributed-memory FFTW with MPI
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw3_mpi,fftw3f_mpi
     </span>
     are not supported
    </p>
   </td>
  </tr>
 </table>
 <p>
  Note that for each of the double precision functions below there is a corresponding single precision version with the letters
  <span class="pre">
   fftw
  </span>
  replaced by
  <span class="pre">
   fftwf
  </span>
  .
 </p>
 <table class="table-no-stripes longtable docutils align-default">
  <tr class="row-odd">
   <th class="head">
    <p>
     Section in FFTW manual
    </p>
   </th>
   <th class="head">
    <p>
     Supported
    </p>
   </th>
   <th class="head">
    <p>
     Unsupported
    </p>
   </th>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Using Plans
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_execute(),
     </span>
     <span class="pre">
      fftw_destroy_plan(),
     </span>
     <span class="pre">
      fftw_cleanup()
     </span>
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_print_plan(),
     </span>
     <span class="pre">
      fftw_cost(),
     </span>
     <span class="pre">
      fftw_flops()
     </span>
     exist but are not functional
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Basic Interface
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Complex DFTs
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_dft_1d(),
     </span>
     <span class="pre">
      fftw_plan_dft_2d(),
     </span>
     <span class="pre">
      fftw_plan_dft_3d(),
     </span>
     <span class="pre">
      fftw_plan_dft()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Planner Flags
    </p>
   </td>
   <td>
    <p>
     Planner flags are ignored and the same plan is returned regardless
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Real-data DFTs
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_dft_r2c_1d(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c_2d(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c_3d(),
     </span>
     <span class="pre">
      fftw_plan_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r_1d(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r_2d(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r_3d(),
     </span>
     <span class="pre">
      fftw_plan_dft_c2r()
     </span>
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Read-data DFT Array Format
    </p>
   </td>
   <td>
    <p>
     Not supported
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Read-to-Real Transform
    </p>
   </td>
   <td>
    <p>
     Not supported
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Read-to-Real Transform Kinds
    </p>
   </td>
   <td>
    <p>
     Not supported
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Advanced Interface
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Advanced Complex DFTs
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_many_dft()
     </span>
     with multiple 1D, 2D, 3D transforms
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_many_dft()
     </span>
     with 4D or higher transforms or a 2D or higher batch of embedded transforms
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Advanced Real-data DFTs
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_many_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_many_dft_c2r()
     </span>
     with multiple 1D, 2D, 3D transforms
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_many_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_many_dft_c2r()
     </span>
     with 4D or higher transforms or a 2D or higher batch of embedded transforms
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Advanced Real-to-Real Transforms
    </p>
   </td>
   <td>
    <p>
     Not supported
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Guru Interface
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Interleaved and split arrays
    </p>
   </td>
   <td>
    <p>
     Interleaved format
    </p>
   </td>
   <td>
    <p>
     Split format
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Guru vector and transform sizes
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_iodim
     </span>
     struct
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Guru Complex DFTs
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_guru_dft(),
     </span>
     <span class="pre">
      fftw_plan_guru_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_guru_dft_c2r()
     </span>
     with multiple 1D, 2D, 3D transforms
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_guru_dft(),
     </span>
     <span class="pre">
      fftw_plan_guru_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_guru_dft_c2r()
     </span>
     with 4D or higher transforms or a 2D or higher batch of transforms
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Guru Real-data DFTs
    </p>
   </td>
   <td>
    <p>
     Not supported
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     Guru Real-to-real Transforms
    </p>
   </td>
   <td>
    <p>
     Not supported
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     64-bit Guru Interface
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_guru64_dft(),
     </span>
     <span class="pre">
      fftw_plan_guru64_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_guru64_dft_c2r()
     </span>
     with multiple 1D, 2D, 3D transforms
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_plan_guru64_dft(),
     </span>
     <span class="pre">
      fftw_plan_guru64_dft_r2c(),
     </span>
     <span class="pre">
      fftw_plan_guru64_dft_c2r()
     </span>
     with 4D or higher transforms or a 2D or higher batch of transforms
    </p>
   </td>
  </tr>
  <tr class="row-odd">
   <td>
    <p>
     New-array Execute Functions
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_execute_dft(),
     </span>
     <span class="pre">
      fftw_execute_dft_r2c(),
     </span>
     <span class="pre">
      fftw_execute_dft_c2r()
     </span>
     with interleaved format
    </p>
   </td>
   <td>
    <p>
     Split format and real-to-real functions
    </p>
   </td>
  </tr>
  <tr class="row-even">
   <td>
    <p>
     Wisdom
    </p>
   </td>
   <td>
    <p>
     <span class="pre">
      fftw_export_wisdom_to_file(),
     </span>
     <span class="pre">
      fftw_import_wisdom_from_file()
     </span>
     exist but are not functional. Other wisdom functions do not have entry points in the library.
    </p>
   </td>
  </tr>
 </table>
 <h1>
  <span class="section-number">
   8.
  </span>
  Deprecated Functionality
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#deprecated-functionality" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <p>
  Starting from CUDA 12.0:
 </p>
 <ul class="simple">
  <li>
   <p>
    GPU architectures SM35 and SM37 are no longer supported. The minimum required architecture is SM50.
   </p>
  </li>
 </ul>
 <p>
  Starting from CUDA 11.8:
 </p>
 <ul class="simple">
  <li>
   <p>
    CUDA Graphs capture is no longer supported for callback routines that load data in out-of-place mode transforms. An upcoming release will update the cuFFT callback implementation, removing this limitation.
   </p>
  </li>
 </ul>
 <p>
  Starting from CUDA 11.4:
 </p>
 <ul class="simple">
  <li>
   <p>
    Support for callback functionality using separately compiled device code is deprecated on all GPU architectures. Callback functionality will continue to be supported for all GPU architectures.
   </p>
  </li>
 </ul>
 <p>
  Starting from CUDA 11.0:
 </p>
 <ul class="simple">
  <li>
   <p>
    GPU architecture SM30 is no longer supported. The minimum required architecture is SM35.
   </p>
  </li>
  <li>
   <p>
    Support for GPU architectures SM35, SM37 (Kepler), and SM50, SM52 (Maxwell) is deprecated.
   </p>
  </li>
 </ul>
 <p>
  Function
  <span class="pre">
   cufftSetCompatibilityMode
  </span>
  was removed in version 9.1.
 </p>
 <h1>
  <span class="section-number">
   9.
  </span>
  Notices
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#notices" title="Permalink to this headline">
   ï
  </a>
 </h1>
 <h2>
  <span class="section-number">
   9.1.
  </span>
  Notice
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#notice" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product. NVIDIA Corporation (âNVIDIAâ) makes no representations or warranties, expressed or implied, as to the accuracy or completeness of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use. This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality.
 </p>
 <p>
  NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any time without notice.
 </p>
 <p>
  Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete.
 </p>
 <p>
  NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (âTerms of Saleâ). NVIDIA hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in this document. No contractual obligations are formed either directly or indirectly by this document.
 </p>
 <p>
  NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications and therefore such inclusion and/or use is at customerâs own risk.
 </p>
 <p>
  NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is customerâs sole responsibility to evaluate and determine the applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer, and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customerâs product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product designs.
 </p>
 <p>
  No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights of NVIDIA.
 </p>
 <p>
  Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices.
 </p>
 <p>
  THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, âMATERIALSâ) ARE BEING PROVIDED âAS IS.â NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any reason whatsoever, NVIDIAâs aggregate and cumulative liability towards customer for the products described herein shall be limited in accordance with the Terms of Sale for the product.
 </p>
 <h2>
  <span class="section-number">
   9.2.
  </span>
  OpenCL
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#opencl" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc.
 </p>
 <h2>
  <span class="section-number">
   9.3.
  </span>
  Trademarks
  <a class="headerlink" href="https://docs.nvidia.com/cuda/cufft/index.html#trademarks" title="Permalink to this headline">
   ï
  </a>
 </h2>
 <p>
  NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.
 </p>
 <p class="notices">
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
   Privacy Policy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">
   Manage My Privacy
  </a>
  |
  <a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">
   Do Not Sell or Share My Data
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
   Terms of Service
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
   Accessibility
  </a>
  |
  <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
   Corporate Policies
  </a>
  |
  <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
   Product Security
  </a>
  |
  <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
   Contact
  </a>
 </p>
 <p>
  Copyright Â© 2007-2024, NVIDIA Corporation &amp; affiliates. All rights reserved.
 </p>
 <p>
  <span class="lastupdated">
   Last updated on Jul 1, 2024.
  </span>
 </p>
</body>
</body></html>