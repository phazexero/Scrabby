<html><head><title>CUDA Driver API :: CUDA Toolkit Documentation</title></head><body><body>
 <span id="company">
  NVIDIA
 </span>
 <span id="site-title">
  CUDA Toolkit Documentation
 </span>
 Search In:
 Entire Site
 Just This Document
 clear search
 search
 <a href="https://docs.nvidia.com/cuda/index.html" title="The root of the site.">
  CUDA Toolkit 
                  
                  
                  v12.5.1
 </a>
 <a href="https://docs.nvidia.com/cuda/cuda-driver-api/index.html" title="CUDA Driver API">
  CUDA Driver API
 </a>
 <ul>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/driver-vs-runtime-api.html#driver-vs-runtime-api">
    1.Â Difference between the driver and runtime APIs
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/api-sync-behavior.html#api-sync-behavior">
    2.Â API synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/stream-sync-behavior.html#stream-sync-behavior">
    3.Â Stream synchronization behavior
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/graphs-thread-safety.html#graphs-thread-safety">
    4.Â Graph object thread safety
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/version-mixing-rules.html#version-mixing-rules">
    5.Â Rules for version mixing
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/modules.html#modules">
    6.Â Modules
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES">
      6.1.Â Data types used by CUDA driver
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__ERROR.html#group__CUDA__ERROR">
      6.2.Â Error Handling
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__INITIALIZE.html#group__CUDA__INITIALIZE">
      6.3.Â Initialization
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VERSION.html#group__CUDA__VERSION">
      6.4.Â Version Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE">
      6.5.Â Device Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE__DEPRECATED.html#group__CUDA__DEVICE__DEPRECATED">
      6.6.Â Device Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PRIMARY__CTX.html#group__CUDA__PRIMARY__CTX">
      6.7.Â Primary Context Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX">
      6.8.Â Context Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX__DEPRECATED.html#group__CUDA__CTX__DEPRECATED">
      6.9.Â Context Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE">
      6.10.Â Module Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE__DEPRECATED.html#group__CUDA__MODULE__DEPRECATED">
      6.11.Â Module Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__LIBRARY.html#group__CUDA__LIBRARY">
      6.12.Â Library Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM">
      6.13.Â Memory Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VA.html#group__CUDA__VA">
      6.14.Â Virtual Memory Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC">
      6.15.Â Stream Ordered Memory Allocator
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MULTICAST.html#group__CUDA__MULTICAST">
      6.16.Â Multicast Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED">
      6.17.Â Unified Addressing
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM">
      6.18.Â Stream Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EVENT.html#group__CUDA__EVENT">
      6.19.Â Event Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXTRES__INTEROP.html#group__CUDA__EXTRES__INTEROP">
      6.20.Â External Resource Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEMOP.html#group__CUDA__MEMOP">
      6.21.Â Stream Memory Operations
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC">
      6.22.Â Execution Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC__DEPRECATED.html#group__CUDA__EXEC__DEPRECATED">
      6.23.Â Execution Control [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__GRAPH.html#group__CUDA__GRAPH">
      6.24.Â Graph Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY">
      6.25.Â Occupancy
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TEXREF__DEPRECATED.html#group__CUDA__TEXREF__DEPRECATED">
      6.26.Â Texture Reference Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__SURFREF__DEPRECATED.html#group__CUDA__SURFREF__DEPRECATED">
      6.27.Â Surface Reference Management [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TEXOBJECT.html#group__CUDA__TEXOBJECT">
      6.28.Â Texture Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__SURFOBJECT.html#group__CUDA__SURFOBJECT">
      6.29.Â Surface Object Management
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TENSOR__MEMORY.html#group__CUDA__TENSOR__MEMORY">
      6.30.Â Tensor Map Object Managment
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PEER__ACCESS.html#group__CUDA__PEER__ACCESS">
      6.31.Â Peer Context Memory Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__GRAPHICS.html#group__CUDA__GRAPHICS">
      6.32.Â Graphics Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DRIVER__ENTRY__POINT.html#group__CUDA__DRIVER__ENTRY__POINT">
      6.33.Â Driver Entry Point Access
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP">
      6.34.Â Coredump Attributes Control API
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__GREEN__CONTEXTS.html#group__CUDA__GREEN__CONTEXTS">
      6.35.Â Green Contexts
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PROFILER__DEPRECATED.html#group__CUDA__PROFILER__DEPRECATED">
      6.36.Â Profiler Control [DEPRECATED]
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PROFILER.html#group__CUDA__PROFILER">
      6.37.Â Profiler Control
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__GL.html#group__CUDA__GL">
      6.38.Â OpenGL Interoperability
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__GL__DEPRECATED.html#group__CUDA__GL__DEPRECATED">
        6.38.1.Â OpenGL Interoperability [DEPRECATED]
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__D3D9.html#group__CUDA__D3D9">
      6.39.Â Direct3D 9 Interoperability
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__D3D9__DEPRECATED.html#group__CUDA__D3D9__DEPRECATED">
        6.39.1.Â Direct3D 9 Interoperability [DEPRECATED]
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__D3D10.html#group__CUDA__D3D10">
      6.40.Â Direct3D 10 Interoperability
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__D3D10__DEPRECATED.html#group__CUDA__D3D10__DEPRECATED">
        6.40.1.Â Direct3D 10 Interoperability [DEPRECATED]
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__D3D11.html#group__CUDA__D3D11">
      6.41.Â Direct3D 11 Interoperability
     </a>
     <ul>
      <li>
       <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__D3D11__DEPRECATED.html#group__CUDA__D3D11__DEPRECATED">
        6.41.1.Â Direct3D 11 Interoperability [DEPRECATED]
       </a>
      </li>
     </ul>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__VDPAU.html#group__CUDA__VDPAU">
      6.42.Â VDPAU Interoperability
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EGL.html#group__CUDA__EGL">
      6.43.Â EGL Interoperability
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/annotated.html#annotated">
    7.Â Data Structures
   </a>
   <ul>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUaccessPolicyWindow__v1.html#structCUaccessPolicyWindow__v1">
      7.1.Â CUaccessPolicyWindow_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUarrayMapInfo__v1.html#structCUarrayMapInfo__v1">
      7.2.Â CUarrayMapInfo_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUasyncNotificationInfo.html#structCUasyncNotificationInfo">
      7.3.Â CUasyncNotificationInfo
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUctxCigParam.html#structCUctxCigParam">
      7.4.Â CUctxCigParam
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUctxCreateParams.html#structCUctxCreateParams">
      7.5.Â CUctxCreateParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__ARRAY3D__DESCRIPTOR__v2.html#structCUDA__ARRAY3D__DESCRIPTOR__v2">
      7.6.Â CUDA_ARRAY3D_DESCRIPTOR_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__ARRAY__DESCRIPTOR__v2.html#structCUDA__ARRAY__DESCRIPTOR__v2">
      7.7.Â CUDA_ARRAY_DESCRIPTOR_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__ARRAY__MEMORY__REQUIREMENTS__v1.html#structCUDA__ARRAY__MEMORY__REQUIREMENTS__v1">
      7.8.Â CUDA_ARRAY_MEMORY_REQUIREMENTS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__ARRAY__SPARSE__PROPERTIES__v1.html#structCUDA__ARRAY__SPARSE__PROPERTIES__v1">
      7.9.Â CUDA_ARRAY_SPARSE_PROPERTIES_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__BATCH__MEM__OP__NODE__PARAMS__v2.html">
      7.10.Â
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__CHILD__GRAPH__NODE__PARAMS.html#structCUDA__CHILD__GRAPH__NODE__PARAMS">
      7.11.Â CUDA_CHILD_GRAPH_NODE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__CONDITIONAL__NODE__PARAMS.html#structCUDA__CONDITIONAL__NODE__PARAMS">
      7.12.Â CUDA_CONDITIONAL_NODE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EVENT__RECORD__NODE__PARAMS.html#structCUDA__EVENT__RECORD__NODE__PARAMS">
      7.13.Â CUDA_EVENT_RECORD_NODE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EVENT__WAIT__NODE__PARAMS.html#structCUDA__EVENT__WAIT__NODE__PARAMS">
      7.14.Â CUDA_EVENT_WAIT_NODE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXT__SEM__SIGNAL__NODE__PARAMS__v1.html#structCUDA__EXT__SEM__SIGNAL__NODE__PARAMS__v1">
      7.15.Â CUDA_EXT_SEM_SIGNAL_NODE_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXT__SEM__SIGNAL__NODE__PARAMS__v2.html#structCUDA__EXT__SEM__SIGNAL__NODE__PARAMS__v2">
      7.16.Â CUDA_EXT_SEM_SIGNAL_NODE_PARAMS_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXT__SEM__WAIT__NODE__PARAMS__v1.html#structCUDA__EXT__SEM__WAIT__NODE__PARAMS__v1">
      7.17.Â CUDA_EXT_SEM_WAIT_NODE_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXT__SEM__WAIT__NODE__PARAMS__v2.html#structCUDA__EXT__SEM__WAIT__NODE__PARAMS__v2">
      7.18.Â CUDA_EXT_SEM_WAIT_NODE_PARAMS_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXTERNAL__MEMORY__BUFFER__DESC__v1.html#structCUDA__EXTERNAL__MEMORY__BUFFER__DESC__v1">
      7.19.Â CUDA_EXTERNAL_MEMORY_BUFFER_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXTERNAL__MEMORY__HANDLE__DESC__v1.html#structCUDA__EXTERNAL__MEMORY__HANDLE__DESC__v1">
      7.20.Â CUDA_EXTERNAL_MEMORY_HANDLE_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXTERNAL__MEMORY__MIPMAPPED__ARRAY__DESC__v1.html#structCUDA__EXTERNAL__MEMORY__MIPMAPPED__ARRAY__DESC__v1">
      7.21.Â CUDA_EXTERNAL_MEMORY_MIPMAPPED_ARRAY_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXTERNAL__SEMAPHORE__HANDLE__DESC__v1.html#structCUDA__EXTERNAL__SEMAPHORE__HANDLE__DESC__v1">
      7.22.Â CUDA_EXTERNAL_SEMAPHORE_HANDLE_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXTERNAL__SEMAPHORE__SIGNAL__PARAMS__v1.html#structCUDA__EXTERNAL__SEMAPHORE__SIGNAL__PARAMS__v1">
      7.23.Â CUDA_EXTERNAL_SEMAPHORE_SIGNAL_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__EXTERNAL__SEMAPHORE__WAIT__PARAMS__v1.html#structCUDA__EXTERNAL__SEMAPHORE__WAIT__PARAMS__v1">
      7.24.Â CUDA_EXTERNAL_SEMAPHORE_WAIT_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__GRAPH__INSTANTIATE__PARAMS.html#structCUDA__GRAPH__INSTANTIATE__PARAMS">
      7.25.Â CUDA_GRAPH_INSTANTIATE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__HOST__NODE__PARAMS__v1.html#structCUDA__HOST__NODE__PARAMS__v1">
      7.26.Â CUDA_HOST_NODE_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__HOST__NODE__PARAMS__v2.html#structCUDA__HOST__NODE__PARAMS__v2">
      7.27.Â CUDA_HOST_NODE_PARAMS_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__KERNEL__NODE__PARAMS__v1.html#structCUDA__KERNEL__NODE__PARAMS__v1">
      7.28.Â CUDA_KERNEL_NODE_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__KERNEL__NODE__PARAMS__v2.html#structCUDA__KERNEL__NODE__PARAMS__v2">
      7.29.Â CUDA_KERNEL_NODE_PARAMS_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__KERNEL__NODE__PARAMS__v3.html#structCUDA__KERNEL__NODE__PARAMS__v3">
      7.30.Â CUDA_KERNEL_NODE_PARAMS_v3
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__LAUNCH__PARAMS__v1.html#structCUDA__LAUNCH__PARAMS__v1">
      7.31.Â CUDA_LAUNCH_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEM__ALLOC__NODE__PARAMS__v1.html#structCUDA__MEM__ALLOC__NODE__PARAMS__v1">
      7.32.Â CUDA_MEM_ALLOC_NODE_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEM__ALLOC__NODE__PARAMS__v2.html#structCUDA__MEM__ALLOC__NODE__PARAMS__v2">
      7.33.Â CUDA_MEM_ALLOC_NODE_PARAMS_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEM__FREE__NODE__PARAMS.html#structCUDA__MEM__FREE__NODE__PARAMS">
      7.34.Â CUDA_MEM_FREE_NODE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEMCPY2D__v2.html#structCUDA__MEMCPY2D__v2">
      7.35.Â CUDA_MEMCPY2D_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEMCPY3D__PEER__v1.html#structCUDA__MEMCPY3D__PEER__v1">
      7.36.Â CUDA_MEMCPY3D_PEER_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEMCPY3D__v2.html#structCUDA__MEMCPY3D__v2">
      7.37.Â CUDA_MEMCPY3D_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEMCPY__NODE__PARAMS.html#structCUDA__MEMCPY__NODE__PARAMS">
      7.38.Â CUDA_MEMCPY_NODE_PARAMS
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEMSET__NODE__PARAMS__v1.html#structCUDA__MEMSET__NODE__PARAMS__v1">
      7.39.Â CUDA_MEMSET_NODE_PARAMS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__MEMSET__NODE__PARAMS__v2.html#structCUDA__MEMSET__NODE__PARAMS__v2">
      7.40.Â CUDA_MEMSET_NODE_PARAMS_v2
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__POINTER__ATTRIBUTE__P2P__TOKENS__v1.html#structCUDA__POINTER__ATTRIBUTE__P2P__TOKENS__v1">
      7.41.Â CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__RESOURCE__DESC__v1.html#structCUDA__RESOURCE__DESC__v1">
      7.42.Â CUDA_RESOURCE_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__RESOURCE__VIEW__DESC__v1.html#structCUDA__RESOURCE__VIEW__DESC__v1">
      7.43.Â CUDA_RESOURCE_VIEW_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUDA__TEXTURE__DESC__v1.html#structCUDA__TEXTURE__DESC__v1">
      7.44.Â CUDA_TEXTURE_DESC_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUdevprop__v1.html#structCUdevprop__v1">
      7.45.Â CUdevprop_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUdevResource.html#structCUdevResource">
      7.46.Â CUdevResource
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUdevSmResource.html#structCUdevSmResource">
      7.47.Â CUdevSmResource
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUeglFrame__v1.html#structCUeglFrame__v1">
      7.48.Â CUeglFrame_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUexecAffinityParam__v1.html#structCUexecAffinityParam__v1">
      7.49.Â CUexecAffinityParam_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUexecAffinitySmCount__v1.html#structCUexecAffinitySmCount__v1">
      7.50.Â CUexecAffinitySmCount_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUgraphEdgeData.html#structCUgraphEdgeData">
      7.51.Â CUgraphEdgeData
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUgraphExecUpdateResultInfo__v1.html#structCUgraphExecUpdateResultInfo__v1">
      7.52.Â CUgraphExecUpdateResultInfo_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUgraphNodeParams.html#structCUgraphNodeParams">
      7.53.Â CUgraphNodeParams
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUipcEventHandle__v1.html#structCUipcEventHandle__v1">
      7.54.Â CUipcEventHandle_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUipcMemHandle__v1.html#structCUipcMemHandle__v1">
      7.55.Â CUipcMemHandle_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUlaunchAttribute.html#structCUlaunchAttribute">
      7.56.Â CUlaunchAttribute
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/unionCUlaunchAttributeValue.html#unionCUlaunchAttributeValue">
      7.57.Â CUlaunchAttributeValue
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUlaunchConfig.html#structCUlaunchConfig">
      7.58.Â CUlaunchConfig
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUlaunchMemSyncDomainMap.html#structCUlaunchMemSyncDomainMap">
      7.59.Â CUlaunchMemSyncDomainMap
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmemAccessDesc__v1.html#structCUmemAccessDesc__v1">
      7.60.Â CUmemAccessDesc_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmemAllocationProp__v1.html#structCUmemAllocationProp__v1">
      7.61.Â CUmemAllocationProp_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmemFabricHandle__v1.html#structCUmemFabricHandle__v1">
      7.62.Â CUmemFabricHandle_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmemLocation__v1.html#structCUmemLocation__v1">
      7.63.Â CUmemLocation_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmemPoolProps__v1.html#structCUmemPoolProps__v1">
      7.64.Â CUmemPoolProps_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmemPoolPtrExportData__v1.html#structCUmemPoolPtrExportData__v1">
      7.65.Â CUmemPoolPtrExportData_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUmulticastObjectProp__v1.html#structCUmulticastObjectProp__v1">
      7.66.Â CUmulticastObjectProp_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/unionCUstreamBatchMemOpParams__v1.html#unionCUstreamBatchMemOpParams__v1">
      7.67.Â CUstreamBatchMemOpParams_v1
     </a>
    </li>
    <li>
     <a href="https://docs.nvidia.com/cuda/cuda-driver-api/structCUtensorMap.html#structCUtensorMap">
      7.68.Â CUtensorMap
     </a>
    </li>
   </ul>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/functions.html#functions">
    8.Â Data Fields
   </a>
  </li>
  <li>
   <a href="https://docs.nvidia.com/cuda/cuda-driver-api/deprecated.html#deprecated">
    9.Â Deprecated List
   </a>
  </li>
 </ul>
 <h2>
  Search Results
 </h2>
 <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DRIVER__ENTRY__POINT.html" shape="rect">
  &lt; Previous
 </a>
 |
 <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__GREEN__CONTEXTS.html" shape="rect">
  Next &gt;
 </a>
 CUDA Driver API
                  (
 <a href="https://docs.nvidia.com/cuda/pdf/CUDA_Driver_API.pdf">
  PDF
 </a>
 )
                  -
                   
                  
                  
                  v12.5.1
                  (
 <a href="https://developer.nvidia.com/cuda-toolkit-archive">
  older
 </a>
 )
                  -
                  Last updated July 1, 2024
                  -
 <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA%20Toolkit%20Documentation%20Feedback:%20CUDA%20Driver%20API">
  Send Feedback
 </a>
 <a name="group__CUDA__COREDUMP" shape="rect">
  <!-- -->
 </a>
 <h2 class="topictitle2 cppModule">
  6.34.Â Coredump Attributes Control API
 </h2>
 <p>
  This section describes the coredump attribute control functions of the low-level CUDA driver application programming interface.
 </p>
 <h3 class="fake_sectiontitle member_header">
  Enumerations
 </h3>
 <span class="member_type">
  enumÂ
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g516d6bb94a388c0efa9f50efa6d215c9" shape="rect">
   CUCoredumpGenerationFlags
  </a>
 </span>
 <span class="member_type">
  enumÂ
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect">
   CUcoredumpSettings
  </a>
 </span>
 <h3 class="fake_sectiontitle member_header">
  Functions
 </h3>
 <span class="member_type">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g56d7eb4975c7eb8e2b4eb0713fd8cedd" shape="rect">
   cuCoredumpGetAttribute
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 <span class="desc">
  Allows caller to fetch a coredump attribute value for the current context.
 </span>
 <span class="member_type">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g5cb5b7ddf41a2c3631eed8d00c4ae819" shape="rect">
   cuCoredumpGetAttributeGlobal
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 <span class="desc">
  Allows caller to fetch a coredump attribute value for the entire application.
 </span>
 <span class="member_type">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g45b806050f3211e840eb3c8d91e93fcb" shape="rect">
   cuCoredumpSetAttribute
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 <span class="desc">
  Allows caller to set a coredump attribute value for the current context.
 </span>
 <span class="member_type">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  Â
 </span>
 <span class="member_name">
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" shape="rect">
   cuCoredumpSetAttributeGlobal
  </a>
  (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 <span class="desc">
  Allows caller to set a coredump attribute value globally.
 </span>
 <h3 class="sectiontitle">
  Enumerations
 </h3>
 <a id="group__CUDA__COREDUMP_1g516d6bb94a388c0efa9f50efa6d215c9" name="group__CUDA__COREDUMP_1g516d6bb94a388c0efa9f50efa6d215c9" shape="rect">
  <!-- -->
 </a>
 <span>
  enum CUCoredumpGenerationFlags
 </span>
 <p>
  Flags for controlling coredump contents
 </p>
 <h6 class="enumerator_header">
  Values
 </h6>
 <span class="enum-member-name-def">
  CU_COREDUMP_DEFAULT_FLAGS =
  <span class="ph ph apiData">
   0
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES =
  <span class="ph ph apiData">
   (1&lt;&lt;0)
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_SKIP_GLOBAL_MEMORY =
  <span class="ph ph apiData">
   (1&lt;&lt;1)
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_SKIP_SHARED_MEMORY =
  <span class="ph ph apiData">
   (1&lt;&lt;2)
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_SKIP_LOCAL_MEMORY =
  <span class="ph ph apiData">
   (1&lt;&lt;3)
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_SKIP_ABORT =
  <span class="ph ph apiData">
   (1&lt;&lt;4)
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_LIGHTWEIGHT_FLAGS =
  <span class="ph ph apiData">
   CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES
                                          |CU_COREDUMP_SKIP_GLOBAL_MEMORY
                                          |CU_COREDUMP_SKIP_SHARED_MEMORY
                                          |CU_COREDUMP_SKIP_LOCAL_MEMORY
  </span>
 </span>
 <a id="group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" name="group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect">
  <!-- -->
 </a>
 <span>
  enum CUcoredumpSettings
 </span>
 <p>
  Flags for choosing a coredump attribute to get/set
 </p>
 <h6 class="enumerator_header">
  Values
 </h6>
 <span class="enum-member-name-def">
  CU_COREDUMP_ENABLE_ON_EXCEPTION =
  <span class="ph ph apiData">
   1
  </span>
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_TRIGGER_HOST
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_LIGHTWEIGHT
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_ENABLE_USER_TRIGGER
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_FILE
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_PIPE
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_GENERATION_FLAGS
 </span>
 <span class="enum-member-name-def">
  CU_COREDUMP_MAX
 </span>
 <h3 class="sectiontitle">
  Functions
 </h3>
 <a id="group__CUDA__COREDUMP_1g56d7eb4975c7eb8e2b4eb0713fd8cedd" name="group__CUDA__COREDUMP_1g56d7eb4975c7eb8e2b4eb0713fd8cedd" shape="rect">
  <!-- -->
 </a>
 <span>
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  cuCoredumpGetAttribute (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 Allows caller to fetch a coredump attribute value for the current context.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  attrib
 </span>
 - The enum defining which value to fetch.
 <span class="keyword keyword apiItemName">
  value
 </span>
 - void* containing the requested data.
 <span class="keyword keyword apiItemName">
  size
 </span>
 - The size of the memory region
 value
 points to.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a0eed720f8a87cd1c5fd1c453bc7a03d" shape="rect">
   CUDA_SUCCESS
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e990696c86fcee1f536a1ec7d25867feeb" shape="rect">
   CUDA_ERROR_INVALID_VALUE
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9e23d0197c490ec332a43e55b167968a3" shape="rect">
   CUDA_ERROR_NOT_PERMITTED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9acf52f132faf29b473cdda6061f0f44a" shape="rect">
   CUDA_ERROR_DEINITIALIZED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e98feb999f0af99b4a25ab26b3866f4df8" shape="rect">
   CUDA_ERROR_NOT_INITIALIZED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a484e9af32c1e9893ff21f0e0191a12d" shape="rect">
   CUDA_ERROR_INVALID_CONTEXT
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9b27ac43f7ce8446f5c9636dd73fb2139" shape="rect">
   CUDA_ERROR_CONTEXT_IS_DESTROYED
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *value
  the requested value specified by
  attrib
  . It is up to the caller to ensure that the data type and size of
  *value
  matches the request.
 </p>
 <p class="p">
  If the caller calls this function with
  *value
  equal to NULL, the size of the memory region (in bytes) expected for
  attrib
  will be placed in
  size
  .
 </p>
 <p class="p">
  The supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_ON_EXCEPTION: Bool where true means that GPU exceptions from this context will create a coredump at the
                                          location specified by CU_COREDUMP_FILE. The default value is false unless set to true globally or locally, or the CU_CTX_USER_COREDUMP_ENABLE
                                          flag was set during context creation.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_TRIGGER_HOST: Bool where true means that the host CPU will also create a coredump. The default value is true unless
                                          set to false globally or or locally. This value is deprecated as of CUDA 12.5 - raise the CU_COREDUMP_SKIP_ABORT flag to disable
                                          host device abort() if needed.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_LIGHTWEIGHT: Bool where true means that any resulting coredumps will not have a dump of GPU memory or non-reloc
                                          ELF images. The default value is false unless set to true globally or locally. This attribute is deprecated as of CUDA 12.5,
                                          please use CU_COREDUMP_GENERATION_FLAGS instead.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_USER_TRIGGER: Bool where true means that a coredump can be created by writing to the system pipe specified
                                          by CU_COREDUMP_PIPE. The default value is false unless set to true globally or locally.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_FILE: String of up to 1023 characters that defines the location where any coredumps generated by this context
                                          will be written. The default value is core.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the CUDA
                                          applications and PID is the process ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_PIPE: String of up to 1023 characters that defines the name of the pipe that will be monitored if user-triggered
                                          coredumps are enabled. The default value is corepipe.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running
                                          the CUDA application and PID is the process ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_GENERATION_FLAGS: An integer with values to allow granular control the data contained in a coredump specified
                                          as a bitwise OR combination of the following values: + CU_COREDUMP_DEFAULT_FLAGS - if set by itself, coredump generation returns
                                          to its default settings of including all memory regions that it is able to access + CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES
                                          - Coredump will not include the data from CUDA source modules that are not relocated at runtime. + CU_COREDUMP_SKIP_GLOBAL_MEMORY
                                          - Coredump will not include device-side global data that does not belong to any context. + CU_COREDUMP_SKIP_SHARED_MEMORY
                                          - Coredump will not include grid-scale shared memory for the warp that the dumped kernel belonged to. + CU_COREDUMP_SKIP_LOCAL_MEMORY
                                          - Coredump will not include local memory from the kernel. + CU_COREDUMP_LIGHTWEIGHT_FLAGS - Enables all of the above options.
                                          Equiavlent to setting the CU_COREDUMP_LIGHTWEIGHT attribute to true. + CU_COREDUMP_SKIP_ABORT - If set, GPU exceptions will
                                          not raise an abort() in the host CPU process. Same functional goal as CU_COREDUMP_TRIGGER_HOST but better reflects the default
                                          behavior.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g5cb5b7ddf41a2c3631eed8d00c4ae819" shape="rect" title="Allows caller to fetch a coredump attribute value for the entire application.">
   cuCoredumpGetAttributeGlobal
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g45b806050f3211e840eb3c8d91e93fcb" shape="rect" title="Allows caller to set a coredump attribute value for the current context.">
   cuCoredumpSetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" shape="rect" title="Allows caller to set a coredump attribute value globally.">
   cuCoredumpSetAttributeGlobal
  </a>
 </p>
 <a id="group__CUDA__COREDUMP_1g5cb5b7ddf41a2c3631eed8d00c4ae819" name="group__CUDA__COREDUMP_1g5cb5b7ddf41a2c3631eed8d00c4ae819" shape="rect">
  <!-- -->
 </a>
 <span>
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  cuCoredumpGetAttributeGlobal (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 Allows caller to fetch a coredump attribute value for the entire application.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  attrib
 </span>
 - The enum defining which value to fetch.
 <span class="keyword keyword apiItemName">
  value
 </span>
 - void* containing the requested data.
 <span class="keyword keyword apiItemName">
  size
 </span>
 - The size of the memory region
 value
 points to.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a0eed720f8a87cd1c5fd1c453bc7a03d" shape="rect">
   CUDA_SUCCESS
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e990696c86fcee1f536a1ec7d25867feeb" shape="rect">
   CUDA_ERROR_INVALID_VALUE
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  Returns in
  *value
  the requested value specified by
  attrib
  . It is up to the caller to ensure that the data type and size of
  *value
  matches the request.
 </p>
 <p class="p">
  If the caller calls this function with
  *value
  equal to NULL, the size of the memory region (in bytes) expected for
  attrib
  will be placed in
  size
  .
 </p>
 <p class="p">
  The supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_ON_EXCEPTION: Bool where true means that GPU exceptions from this context will create a coredump at the
                                          location specified by CU_COREDUMP_FILE. The default value is false.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_TRIGGER_HOST: Bool where true means that the host CPU will also create a coredump. The default value is true unless
                                          set to false globally or or locally. This value is deprecated as of CUDA 12.5 - raise the CU_COREDUMP_SKIP_ABORT flag to disable
                                          host device abort() if needed.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_LIGHTWEIGHT: Bool where true means that any resulting coredumps will not have a dump of GPU memory or non-reloc
                                          ELF images. The default value is false. This attribute is deprecated as of CUDA 12.5, please use CU_COREDUMP_GENERATION_FLAGS
                                          instead.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_USER_TRIGGER: Bool where true means that a coredump can be created by writing to the system pipe specified
                                          by CU_COREDUMP_PIPE. The default value is false.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_FILE: String of up to 1023 characters that defines the location where any coredumps generated by this context
                                          will be written. The default value is core.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the CUDA
                                          applications and PID is the process ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_PIPE: String of up to 1023 characters that defines the name of the pipe that will be monitored if user-triggered
                                          coredumps are enabled. The default value is corepipe.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running
                                          the CUDA application and PID is the process ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_GENERATION_FLAGS: An integer with values to allow granular control the data contained in a coredump specified
                                          as a bitwise OR combination of the following values: + CU_COREDUMP_DEFAULT_FLAGS - if set by itself, coredump generation returns
                                          to its default settings of including all memory regions that it is able to access + CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES
                                          - Coredump will not include the data from CUDA source modules that are not relocated at runtime. + CU_COREDUMP_SKIP_GLOBAL_MEMORY
                                          - Coredump will not include device-side global data that does not belong to any context. + CU_COREDUMP_SKIP_SHARED_MEMORY
                                          - Coredump will not include grid-scale shared memory for the warp that the dumped kernel belonged to. + CU_COREDUMP_SKIP_LOCAL_MEMORY
                                          - Coredump will not include local memory from the kernel. + CU_COREDUMP_LIGHTWEIGHT_FLAGS - Enables all of the above options.
                                          Equiavlent to setting the CU_COREDUMP_LIGHTWEIGHT attribute to true. + CU_COREDUMP_SKIP_ABORT - If set, GPU exceptions will
                                          not raise an abort() in the host CPU process. Same functional goal as CU_COREDUMP_TRIGGER_HOST but better reflects the default
                                          behavior.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g56d7eb4975c7eb8e2b4eb0713fd8cedd" shape="rect" title="Allows caller to fetch a coredump attribute value for the current context.">
   cuCoredumpGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g45b806050f3211e840eb3c8d91e93fcb" shape="rect" title="Allows caller to set a coredump attribute value for the current context.">
   cuCoredumpSetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" shape="rect" title="Allows caller to set a coredump attribute value globally.">
   cuCoredumpSetAttributeGlobal
  </a>
 </p>
 <a id="group__CUDA__COREDUMP_1g45b806050f3211e840eb3c8d91e93fcb" name="group__CUDA__COREDUMP_1g45b806050f3211e840eb3c8d91e93fcb" shape="rect">
  <!-- -->
 </a>
 <span>
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  cuCoredumpSetAttribute (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 Allows caller to set a coredump attribute value for the current context.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  attrib
 </span>
 - The enum defining which value to set.
 <span class="keyword keyword apiItemName">
  value
 </span>
 - void* containing the requested data.
 <span class="keyword keyword apiItemName">
  size
 </span>
 - The size of the memory region
 value
 points to.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a0eed720f8a87cd1c5fd1c453bc7a03d" shape="rect">
   CUDA_SUCCESS
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e990696c86fcee1f536a1ec7d25867feeb" shape="rect">
   CUDA_ERROR_INVALID_VALUE
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9e23d0197c490ec332a43e55b167968a3" shape="rect">
   CUDA_ERROR_NOT_PERMITTED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9acf52f132faf29b473cdda6061f0f44a" shape="rect">
   CUDA_ERROR_DEINITIALIZED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e98feb999f0af99b4a25ab26b3866f4df8" shape="rect">
   CUDA_ERROR_NOT_INITIALIZED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a484e9af32c1e9893ff21f0e0191a12d" shape="rect">
   CUDA_ERROR_INVALID_CONTEXT
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9b27ac43f7ce8446f5c9636dd73fb2139" shape="rect">
   CUDA_ERROR_CONTEXT_IS_DESTROYED
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e954756ae7ade0dfd09faeccb513dd831b" shape="rect">
   CUDA_ERROR_NOT_SUPPORTED
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  This function should be considered an alternate interface to the CUDA-GDB environment variables defined in this document:
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-gdb/index.html#gpu-coredump" shape="rect" target="_blank">
   https://docs.nvidia.com/cuda/cuda-gdb/index.html#gpu-coredump
  </a>
 </p>
 <p class="p">
  An important design decision to note is that any coredump environment variable values set before CUDA initializes will take
                                 permanent precedence over any values set with this function. This decision was made to ensure no change in behavior for any
                                 users that may be currently using these variables to get coredumps.
 </p>
 <p class="p">
  *value
  shall contain the requested value specified by
  set
  . It is up to the caller to ensure that the data type and size of
  *value
  matches the request.
 </p>
 <p class="p">
  If the caller calls this function with
  *value
  equal to NULL, the size of the memory region (in bytes) expected for
  set
  will be placed in
  size
  .
 </p>
 <p class="p">
  /note This function will return
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e954756ae7ade0dfd09faeccb513dd831b" shape="rect">
   CUDA_ERROR_NOT_SUPPORTED
  </a>
  if the caller attempts to set CU_COREDUMP_ENABLE_ON_EXCEPTION on a GPU of with Compute Capability &lt; 6.0.
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" shape="rect" title="Allows caller to set a coredump attribute value globally.">
   cuCoredumpSetAttributeGlobal
  </a>
  works on those platforms as an alternative.
 </p>
 <p class="p">
  /note CU_COREDUMP_ENABLE_USER_TRIGGER and CU_COREDUMP_PIPE cannot be set on a per-context basis.
 </p>
 <p class="p">
  The supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_ON_EXCEPTION: Bool where true means that GPU exceptions from this context will create a coredump at the
                                          location specified by CU_COREDUMP_FILE. The default value is false.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_TRIGGER_HOST: Bool where true means that the host CPU will also create a coredump. The default value is true unless
                                          set to false globally or or locally. This value is deprecated as of CUDA 12.5 - raise the CU_COREDUMP_SKIP_ABORT flag to disable
                                          host device abort() if needed.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_LIGHTWEIGHT: Bool where true means that any resulting coredumps will not have a dump of GPU memory or non-reloc
                                          ELF images. The default value is false. This attribute is deprecated as of CUDA 12.5, please use CU_COREDUMP_GENERATION_FLAGS
                                          instead.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_FILE: String of up to 1023 characters that defines the location where any coredumps generated by this context
                                          will be written. The default value is core.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the CUDA
                                          applications and PID is the process ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_GENERATION_FLAGS: An integer with values to allow granular control the data contained in a coredump specified
                                          as a bitwise OR combination of the following values: + CU_COREDUMP_DEFAULT_FLAGS - if set by itself, coredump generation returns
                                          to its default settings of including all memory regions that it is able to access + CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES
                                          - Coredump will not include the data from CUDA source modules that are not relocated at runtime. + CU_COREDUMP_SKIP_GLOBAL_MEMORY
                                          - Coredump will not include device-side global data that does not belong to any context. + CU_COREDUMP_SKIP_SHARED_MEMORY
                                          - Coredump will not include grid-scale shared memory for the warp that the dumped kernel belonged to. + CU_COREDUMP_SKIP_LOCAL_MEMORY
                                          - Coredump will not include local memory from the kernel. + CU_COREDUMP_LIGHTWEIGHT_FLAGS - Enables all of the above options.
                                          Equiavlent to setting the CU_COREDUMP_LIGHTWEIGHT attribute to true. + CU_COREDUMP_SKIP_ABORT - If set, GPU exceptions will
                                          not raise an abort() in the host CPU process. Same functional goal as CU_COREDUMP_TRIGGER_HOST but better reflects the default
                                          behavior.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g5cb5b7ddf41a2c3631eed8d00c4ae819" shape="rect" title="Allows caller to fetch a coredump attribute value for the entire application.">
   cuCoredumpGetAttributeGlobal
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g56d7eb4975c7eb8e2b4eb0713fd8cedd" shape="rect" title="Allows caller to fetch a coredump attribute value for the current context.">
   cuCoredumpGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" shape="rect" title="Allows caller to set a coredump attribute value globally.">
   cuCoredumpSetAttributeGlobal
  </a>
 </p>
 <a id="group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" name="group__CUDA__COREDUMP_1ga7645a8f68dd5379a03852b462727990" shape="rect">
  <!-- -->
 </a>
 <span>
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9" shape="rect" title="">
   CUresult
  </a>
  cuCoredumpSetAttributeGlobal (
  <a href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g9b1cc417bdebfe4230e6dba3ea3d5b62" shape="rect" title="">
   CUcoredumpSettings
  </a>
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   attrib
  </span>
  , void*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   value
  </span>
  , size_t*
  <span>
   Â
  </span>
  <span class="keyword keyword apiItemName">
   size
  </span>
  )
 </span>
 Allows caller to set a coredump attribute value globally.
 <h6 class="parameter_header">
  Parameters
 </h6>
 <span class="keyword keyword apiItemName">
  attrib
 </span>
 - The enum defining which value to set.
 <span class="keyword keyword apiItemName">
  value
 </span>
 - void* containing the requested data.
 <span class="keyword keyword apiItemName">
  size
 </span>
 - The size of the memory region
 value
 points to.
 <h6 class="return_header">
  Returns
 </h6>
 <p class="return">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9a0eed720f8a87cd1c5fd1c453bc7a03d" shape="rect">
   CUDA_SUCCESS
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e990696c86fcee1f536a1ec7d25867feeb" shape="rect">
   CUDA_ERROR_INVALID_VALUE
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1ggc6c391505e117393cc2558fff6bfc2e9e23d0197c490ec332a43e55b167968a3" shape="rect">
   CUDA_ERROR_NOT_PERMITTED
  </a>
 </p>
 <h6 class="description_header">
  Description
 </h6>
 <p>
  This function should be considered an alternate interface to the CUDA-GDB environment variables defined in this document:
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-gdb/index.html#gpu-coredump" shape="rect" target="_blank">
   https://docs.nvidia.com/cuda/cuda-gdb/index.html#gpu-coredump
  </a>
 </p>
 <p class="p">
  An important design decision to note is that any coredump environment variable values set before CUDA initializes will take
                                 permanent precedence over any values set with this function. This decision was made to ensure no change in behavior for any
                                 users that may be currently using these variables to get coredumps.
 </p>
 <p class="p">
  *value
  shall contain the requested value specified by
  set
  . It is up to the caller to ensure that the data type and size of
  *value
  matches the request.
 </p>
 <p class="p">
  If the caller calls this function with
  *value
  equal to NULL, the size of the memory region (in bytes) expected for
  set
  will be placed in
  size
  .
 </p>
 <p class="p">
  The supported attributes are:
 </p>
 <ul class="ul">
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_ON_EXCEPTION: Bool where true means that GPU exceptions from this context will create a coredump at the
                                          location specified by CU_COREDUMP_FILE. The default value is false.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_TRIGGER_HOST: Bool where true means that the host CPU will also create a coredump. The default value is true unless
                                          set to false globally or or locally. This value is deprecated as of CUDA 12.5 - raise the CU_COREDUMP_SKIP_ABORT flag to disable
                                          host device abort() if needed.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_LIGHTWEIGHT: Bool where true means that any resulting coredumps will not have a dump of GPU memory or non-reloc
                                          ELF images. The default value is false. This attribute is deprecated as of CUDA 12.5, please use CU_COREDUMP_GENERATION_FLAGS
                                          instead.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_ENABLE_USER_TRIGGER: Bool where true means that a coredump can be created by writing to the system pipe specified
                                          by CU_COREDUMP_PIPE. The default value is false.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_FILE: String of up to 1023 characters that defines the location where any coredumps generated by this context
                                          will be written. The default value is core.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the CUDA
                                          applications and PID is the process ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_PIPE: String of up to 1023 characters that defines the name of the pipe that will be monitored if user-triggered
                                          coredumps are enabled. This value may not be changed after CU_COREDUMP_ENABLE_USER_TRIGGER is set to true. The default value
                                          is corepipe.cuda.HOSTNAME.PID where HOSTNAME is the host name of the machine running the CUDA application and PID is the process
                                          ID of the CUDA application.
   </p>
  </li>
  <li class="li">
   <p class="p">
    CU_COREDUMP_GENERATION_FLAGS: An integer with values to allow granular control the data contained in a coredump specified
                                          as a bitwise OR combination of the following values: + CU_COREDUMP_DEFAULT_FLAGS - if set by itself, coredump generation returns
                                          to its default settings of including all memory regions that it is able to access + CU_COREDUMP_SKIP_NONRELOCATED_ELF_IMAGES
                                          - Coredump will not include the data from CUDA source modules that are not relocated at runtime. + CU_COREDUMP_SKIP_GLOBAL_MEMORY
                                          - Coredump will not include device-side global data that does not belong to any context. + CU_COREDUMP_SKIP_SHARED_MEMORY
                                          - Coredump will not include grid-scale shared memory for the warp that the dumped kernel belonged to. + CU_COREDUMP_SKIP_LOCAL_MEMORY
                                          - Coredump will not include local memory from the kernel. + CU_COREDUMP_LIGHTWEIGHT_FLAGS - Enables all of the above options.
                                          Equiavlent to setting the CU_COREDUMP_LIGHTWEIGHT attribute to true. + CU_COREDUMP_SKIP_ABORT - If set, GPU exceptions will
                                          not raise an abort() in the host CPU process. Same functional goal as CU_COREDUMP_TRIGGER_HOST but better reflects the default
                                          behavior.
   </p>
  </li>
 </ul>
 <p class="p apiDesc_subtitle">
  See also:
 </p>
 <p class="p see_subsection">
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g56d7eb4975c7eb8e2b4eb0713fd8cedd" shape="rect" title="Allows caller to fetch a coredump attribute value for the current context.">
   cuCoredumpGetAttribute
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g5cb5b7ddf41a2c3631eed8d00c4ae819" shape="rect" title="Allows caller to fetch a coredump attribute value for the entire application.">
   cuCoredumpGetAttributeGlobal
  </a>
  ,
  <a class="xref" href="https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__COREDUMP.html#group__CUDA__COREDUMP_1g45b806050f3211e840eb3c8d91e93fcb" shape="rect" title="Allows caller to set a coredump attribute value for the current context.">
   cuCoredumpSetAttribute
  </a>
 </p>
 <a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">
  Privacy Policy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/privacy-center/" target="_blank">
  Manage My Privacy
 </a>
 |
 <a href="https://www.nvidia.com/en-us/preferences/email-preferences/" target="_blank">
  Do Not Sell or Share My Data
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">
  Terms of Service
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">
  Accessibility
 </a>
 |
 <a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">
  Corporate Policies
 </a>
 |
 <a href="https://www.nvidia.com/en-us/product-security/" target="_blank">
  Product Security
 </a>
 |
 <a href="https://www.nvidia.com/en-us/contact/" target="_blank">
  Contact
 </a>
 Copyright Â© 2007-2024 NVIDIA Corporation
</body>
</body></html>